%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[a4paper,11pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



% begin user_preamble:
\usepackage{mathrsfs}
\usepackage{amsmath}
\usepackage{amssymb}
% end user_preamble


\title{User Documentation}
\date{Dec 28, 2020}
\release{5.4.1}
\author{Yves Renard, Julien Pommier, Konstantinos Poulios}
\newcommand{\sphinxlogo}{\sphinxincludegraphics{logogetfem.png}\par}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{userdoc/index::doc}}



\chapter{Introduction}
\label{\detokenize{userdoc/intro:introduction}}\label{\detokenize{userdoc/intro:ud-intro}}\label{\detokenize{userdoc/intro::doc}}
The \sphinxstyleemphasis{GetFEM} project focuses on the development of a generic and
efficient \sphinxstyleemphasis{C++} library for finite element methods elementary
computations. The goal is to provide a library allowing the
computation of any elementary matrix (even for mixed finite element
methods) on the largest class of methods and elements, and for
arbitrary dimension (i.e. not only 2D and 3D problems).

It offers a complete separation between integration methods (exact or
approximated), geometric transformations (linear or not) and finite
element methods of arbitrary degrees. It can really relieve a more
integrated finite element code of technical difficulties of
elementary computations.

Examples of available finite element method are : Pk on simplices in
arbitrary degrees and dimensions, Qk on parallelepipeds, P1, P2 with
bubble functions, Hermite elements, elements with hierarchic basis
(for multigrid methods for instance), discontinuous Pk or Qk, XFem,
Argyris, HCT, Raviart\sphinxhyphen{}Thomas, etc.

The addition of a new finite element method is straightforward. Its
description on the reference element must be provided (in most of the
cases, this is the description of the basis functions, and nothing
more). Extensions are provided for Hermite elements, piecewise
polynomial, non\sphinxhyphen{}polynomial and vectorial elements, XFem.

The library also includes the usual tools for finite elements such as
assembly procedures for classical PDEs, interpolation methods,
computation of norms, mesh operations, boundary conditions,
post\sphinxhyphen{}processing tools such as extraction of slices from a mesh, etc.

\sphinxstyleemphasis{GetFEM} can be used to build very general finite elements codes, where
the finite elements, integration methods, dimension of the meshes,
are just some parameters that can be changed very easily, thus
allowing a large spectrum of experimentations. Numerous examples are
available in the \sphinxcode{\sphinxupquote{tests}} directory of the distribution.

\sphinxstyleemphasis{GetFEM} has only a (very) experimental meshing procedure (and produces regular meshes), hence it is generally
necessary to import meshes. Imports formats currently known by \sphinxstyleemphasis{GetFEM}
are \sphinxstyleemphasis{GiD}, \sphinxstyleemphasis{Gmsh} and \sphinxstyleemphasis{emc2} mesh files. However, given a mesh, it
is possible to refine it automatically.

Copyright © 2004\sphinxhyphen{}2020 \sphinxstyleemphasis{GetFEM} project.

The text of the \sphinxstyleemphasis{GetFEM} website and the documentations are available for modification and reuse under the terms of the \sphinxhref{http://www.gnu.org/licenses/fdl.html}{GNU Free Documentation License}

GetFEM  is  free software;  you  can  redistribute  it  and/or modify it
under  the  terms  of the  GNU  Lesser General Public License as published
by  the  Free Software Foundation;  either version 3 of the License,  or
(at your option) any later version along with the GCC Runtime Library
Exception either version 3.1 or (at your option) any later version.
This program  is  distributed  in  the  hope  that it will be useful,  but
WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
or  FITNESS  FOR  A PARTICULAR PURPOSE.  See the GNU Lesser General Public
License and GCC Runtime Library Exception for more details.
You  should  have received a copy of the GNU Lesser General Public License
along  with  this program;  if not, write to the Free Software Foundation,
Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110\sphinxhyphen{}1301, USA.


\chapter{How to install}
\label{\detokenize{userdoc/install:how-to-install}}\label{\detokenize{userdoc/install:ud-install}}\label{\detokenize{userdoc/install::doc}}
Since we use standard \sphinxstyleemphasis{GNU} tools, the installation of the \sphinxstyleemphasis{GetFEM} library is
somewhat standard. See the \sphinxhref{../download.html}{download and install} page for more details for the installations on the different plateforms.


\chapter{Linear algebra procedures}
\label{\detokenize{userdoc/linalg:linear-algebra-procedures}}\label{\detokenize{userdoc/linalg:ud-linalg}}\label{\detokenize{userdoc/linalg::doc}}
The linear algebra library used by \sphinxstyleemphasis{GetFEM} is \sphinxstyleemphasis{Gmm++} which is now a separate library.
Please see the \sphinxhref{http://getfem.org/gmm.html}{GMM++ user documentation}.

Note that \sphinxstyleemphasis{GetFEM} includes (since release 1.7) its own version of \sphinxstyleemphasis{SuperLU} 3.0 (see
\sphinxhref{http://crd.lbl.gov/~xiaoye/SuperLU}{SuperLU web site}) hence a direct sparse
solver is available out of the box. Note that an option of the \sphinxcode{\sphinxupquote{./configure}}
file allows to disable the included version of \sphinxstyleemphasis{SuperLU} in order to use a
pre\sphinxhyphen{}installed version.

A small interface to \sphinxstyleemphasis{MUMPS} is also provided (see \sphinxhref{http://graal.ens-lyon.fr/MUMPS}{MUMPS web1} or \sphinxhref{http://www.enseeiht.fr/apo/MUMPS}{MUMPS web2}). See the file
\sphinxcode{\sphinxupquote{gmm/gmm\_MUMPS\_interface.h}}. In order to use \sphinxstyleemphasis{MUMPS}, you have to indicates
some options to the configure shell:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{with}\PYG{o}{\PYGZhy{}}\PYG{n}{mumps}\PYG{o}{\PYGZhy{}}\PYG{n}{include}\PYG{o}{\PYGZhy{}}\PYG{n}{dir}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ \PYGZhy{}I /path/to/MUMPS/include }\PYG{l+s}{\PYGZdq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{with}\PYG{o}{\PYGZhy{}}\PYG{n}{mumps}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ F90 libraries and libs of MUMPS to be linked }\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

alternatively, the option \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}mumps}} will search for an installed MUMPS library. Note that if both the sequential and the parallel version is installed on your system (especially on Debian and Ubuntu), the default version will be the parallel one. To select the sequential one it is necessary to add the option \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}with\sphinxhyphen{}mumps="\sphinxhyphen{}lsmumps\_seq \sphinxhyphen{}ldmumps\_seq \sphinxhyphen{}lcmumps\_seq \sphinxhyphen{}lzmumps\_seq"}}.

For instance if you want to use the sequential version of \sphinxstyleemphasis{MUMPS} with double and
complex double:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{with}\PYG{o}{\PYGZhy{}}\PYG{n}{mumps}\PYG{o}{\PYGZhy{}}\PYG{n}{include}\PYG{o}{\PYGZhy{}}\PYG{n}{dir}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ \PYGZhy{}I /path/to/MUMPS/include }\PYG{l+s}{\PYGZdq{}}
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}\PYG{n}{with}\PYG{o}{\PYGZhy{}}\PYG{n}{mumps}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ ...F90libs...  \PYGZhy{}L /path/to/MUMPS/lib \PYGZhy{}ldmumps \PYGZhy{}lzmumps \PYGZhy{}lpord}
            \PYG{o}{\PYGZhy{}}\PYG{n}{L} \PYG{o}{/}\PYG{n}{path}\PYG{o}{/}\PYG{n}{to}\PYG{o}{/}\PYG{n}{MUMPS}\PYG{o}{/}\PYG{n}{libseq} \PYG{o}{\PYGZhy{}}\PYG{n}{lmpiseq} \PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{...F90libs...}} are the libraries of the fortran compiler used to compile
\sphinxstyleemphasis{MUMPS} (these are highly dependant on the fortran 90 compiler used, the
\sphinxcode{\sphinxupquote{./configure}} script should detect the options relative to the default fortran
90 compiler on your machine and display it \textendash{} for example, with the intel
\sphinxcode{\sphinxupquote{ifort}} compiler, it is \sphinxcode{\sphinxupquote{\sphinxhyphen{}L/opt/icc8.0/lib \sphinxhyphen{}lifport \sphinxhyphen{}lifcoremt \sphinxhyphen{}limf \sphinxhyphen{}lm
\sphinxhyphen{}lcxa \sphinxhyphen{}lunwind \sphinxhyphen{}lpthread}})


\chapter{MPI Parallelization of \sphinxstyleemphasis{GetFEM}}
\label{\detokenize{userdoc/parallel:mpi-parallelization-of-gf}}\label{\detokenize{userdoc/parallel:ud-parallel}}\label{\detokenize{userdoc/parallel::doc}}
Of course, each different problem should require a different
parallelization adapted to its specificities in order to
obtain a good load balancing. You may build your own parallelization
using the mesh regions to parallelize assembly procedures.

Nevertheless, the brick system offers a generic parallelization based on \sphinxhref{https://www.open-mpi.org}{Open MPI}
(communication between processes),
\sphinxhref{http://glaros.dtc.umn.edu/gkhome/metis/metis/overview}{METIS}
(partition of the mesh)
and \sphinxhref{http://graal.ens-lyon.fr/MUMPS}{MUMPS} (parallel sparse direct solver).
It is available with the compiler option \sphinxcode{\sphinxupquote{\sphinxhyphen{}D GETFEM\_PARA\_LEVEL=2}}
and the library itself has to be compiled with the
option \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}paralevel=2}} of the configure script.
Initial MPI parallelization of \sphinxstyleemphasis{GetFEM} has been designed with the help of Nicolas Renon from CALMIP, Toulouse.

When the configure script is run with the option \sphinxcode{\sphinxupquote{\sphinxhyphen{}\sphinxhyphen{}enable\sphinxhyphen{}paralevel=2}},
it searches for MPI, METIS and parallel MUMPS libraries.
If the python interface is built, it searches also for MPI4PY library.
In that case, the python interface can
be used to drive the parallel version of getfem (the other interfaces has
not been parallelized for the moment). See demo\_parallel\_laplacian.py in
the interface/test/python directory.

With the option \sphinxcode{\sphinxupquote{\sphinxhyphen{}D GETFEM\_PARA\_LEVEL=2}}, each mesh used is implicitly
partitionned (using METIS) into a
number of regions corresponding to the number of processors and the assembly
procedures are parallelized. This means that the tangent matrix and the
constraint matrix assembled in the model\_state variable are distributed.
The choice made (for the moment) is not to distribute the vectors.
So that the right hand side vectors in the model\_state variable
are communicated to each processor (the sum of each contribution is made
at the end of the assembly and each processor has the complete vector).
Note that you have to think to the fact that the matrices stored by the
bricks are all distributed.

A model of C++ parallelized program is \sphinxcode{\sphinxupquote{tests/elastostatic.cc}}.
To run it in parallel you have to launch for instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mpirun} \PYG{o}{\PYGZhy{}}\PYG{n}{n} \PYG{l+m+mi}{4} \PYG{n}{elastostatic} \PYG{n}{elastostatic}\PYG{p}{.}\PYG{n}{param}
\end{sphinxVerbatim}

For a python interfaced program, the call reads:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mpirun} \PYG{o}{\PYGZhy{}}\PYG{n}{n} \PYG{l+m+mi}{4} \PYG{n}{python} \PYG{n}{demo\PYGZus{}parallel\PYGZus{}laplacian}\PYG{p}{.}\PYG{n}{py}
\end{sphinxVerbatim}

If you do not perform a \sphinxtitleref{make install}, do not forget to first set the shell variable PYTHONPATH to the python\sphinxhyphen{}getfem library with for instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{export} \PYG{n}{PYTHONPATH}\PYG{o}{=}\PYG{n}{my\PYGZus{}getfem\PYGZus{}directory}\PYG{o}{/}\PYG{n}{interface}\PYG{o}{/}\PYG{n}{src}\PYG{o}{/}\PYG{n}{python}
\end{sphinxVerbatim}


\section{State of progress of \sphinxstyleemphasis{GetFEM} MPI parallelization}
\label{\detokenize{userdoc/parallel:state-of-progress-of-gf-mpi-parallelization}}
Parallelization of getfem is still considered a “work in progress”. A certain number of procedure are still remaining sequential. Of course, a good test to see if the parallelization of your program is correct is to verify that the result of the computation is indeed independent of the number of process.
\begin{itemize}
\item {} 
Assembly procedures

Most of assembly procedures (in \sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}}) have a parameter corresponding to the region in which the assembly is to be computed. They are not parallelized themselves but aimed to be called with a different region in each process to distribute the job. Note that the file \sphinxcode{\sphinxupquote{getfem/getfem\_config.h}} contains a procedures called MPI\_SUM\_SPARSE\_MATRIX allowing to gather the contributions of a distributed sparse matrix.

The following assembly procedures are implicitly parallelized using the option \sphinxcode{\sphinxupquote{\sphinxhyphen{}D GETFEM\_PARA\_LEVEL=2}}:
\begin{itemize}
\item {} 
computation of norms (\sphinxcode{\sphinxupquote{asm\_L2\_norm}}, \sphinxcode{\sphinxupquote{asm\_H1\_norm}}, \sphinxcode{\sphinxupquote{asm\_H2\_norm}} …, in \sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}}),

\item {} 
\sphinxcode{\sphinxupquote{asm\_mean\_value}} (in \sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}}),

\item {} 
\sphinxcode{\sphinxupquote{error\_estimate}} (in \sphinxcode{\sphinxupquote{getfem/getfem\_error\_estimate.h}}).

\end{itemize}

This means in particular that these functions have to be called on each
processor.

\item {} 
Mesh\_fem object

The dof numbering of the getfem::mesh\_fem object remains sequential and is executed on each process.  The parallelization is to be done. This could affect the efficiency of the parallelization for very large and/or evoluting meshes.

\item {} 
Model object and bricks

The model system is globally parallelized, which mainly means that the
assembly procedures of standard bricks use a METIS partition of the
meshes to distribute the assembly. The tangent/stiffness matrices
remain distibuted and the standard solve call the parallel version
of MUMPS (which accept distributed matrices).

For the moment, the procedure \sphinxcode{\sphinxupquote{actualize\_sizes()}} of the model
object remains sequential and is executed on each process.
The parallelization is to be done.

Some specificities:
\begin{itemize}
\item {} 
The explicit matrix brick: the given matrix is considered to be
distributed. If it is not, only add it on the master process (otherwise,
the contribution will be multiplied by the number of processes).

\item {} 
The explicit rhs brick: the given vector is not considered to be
distributed. Only the given vector on the master process is taken into
account.

\item {} 
Constraint brick: The given matrix and rhs are not considered to be
distributed. Only the given matrix and vector on the master process are
taken into account.

\item {} 
Concerning contact bricks, only integral contact bricks are fully
parallelized for the moment. Nodal contact bricks work in parallel
but all the computation is done on the master process.

\end{itemize}

\end{itemize}


\chapter{Catch errors}
\label{\detokenize{userdoc/catch:catch-errors}}\label{\detokenize{userdoc/catch:ud-catch}}\label{\detokenize{userdoc/catch::doc}}
Errors used in \sphinxstyleemphasis{GetFEM} are defined in the file \sphinxcode{\sphinxupquote{gmm/gmm\_except.h}}. In order to
make easier the error catching all errors derive from the type
\sphinxcode{\sphinxupquote{std::logic\_error}} defined in the file \sphinxcode{\sphinxupquote{stdexcept}} of the S.T.L.

A standard procedure, \sphinxcode{\sphinxupquote{GMM\_STANDARD\_CATCH\_ERROR}}, is defined in
\sphinxcode{\sphinxupquote{gmm/gmm\_except.h}}. This procedure catches all errors and prints the error
message when an error occurs. It can be used in the main procedure of the program
as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{int} \PYG{n+nf}{main}\PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{k}{try} \PYG{p}{\PYGZob{}}
    \PYG{p}{.}\PYG{p}{.}\PYG{p}{.} \PYG{n}{main} \PYG{n}{program} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
  \PYG{p}{\PYGZcb{}} \PYG{n}{GMM\PYGZus{}STANDARD\PYGZus{}CATCH\PYGZus{}ERROR}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\chapter{Build a mesh}
\label{\detokenize{userdoc/bmesh:build-a-mesh}}\label{\detokenize{userdoc/bmesh:ud-bmesh}}\label{\detokenize{userdoc/bmesh::doc}}
As a preliminary, you may want to read this short introduction to the \sphinxstyleemphasis{GetFEM}
\sphinxhref{http://getfem.org/getfem\_reference/index.html}{vocabulary}.

\sphinxstyleemphasis{GetFEM} has its own structure to store meshes defined in the files
\sphinxcode{\sphinxupquote{getfem/bgeot\_mesh\_structure.h}} and \sphinxcode{\sphinxupquote{getfem/getfem\_mesh.h}}. The main
structure is defined in \sphinxcode{\sphinxupquote{getfem/getfem\_mesh.h}} by the object \sphinxcode{\sphinxupquote{getfem::mesh}}.

This object is able to store any element in any dimension even if you mix
elements with different dimensions.

There is only a (very) experimental meshing procedure in \sphinxstyleemphasis{GetFEM} to mesh complex geometries. But you can easily load a mesh from any format (some
procedures are in \sphinxcode{\sphinxupquote{getfem/getfem\_import.h}} to load meshes from some public
domain mesh generators).

The structure \sphinxcode{\sphinxupquote{getfem::mesh}} may also contain a description about a region of the mesh,
such as a boundary or a set of elements. This is handled via a container of
convexes and convex faces, \sphinxcode{\sphinxupquote{getfem::mesh\_region}}. We refer to \sphinxcite{biblio:remacle2003} for a discussion on mesh representation.


\section{Add an element to a mesh}
\label{\detokenize{userdoc/bmesh:add-an-element-to-a-mesh}}
Suppose the variable \sphinxcode{\sphinxupquote{mymesh}} has been declared by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh} \PYG{n}{mymesh}\PYG{p}{;}
\end{sphinxVerbatim}

then you have two ways to insert a new element to this mesh: from a list of
points or from a list of indexes of already existing points.

To enter a new point on a mesh use the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{i} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}point}\PYG{p}{(}\PYG{n}{pt}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{pt}} is of type \sphinxcode{\sphinxupquote{bgeot::base\_node}}. The index \sphinxcode{\sphinxupquote{i}} is the index of this point on
the mesh. If the point already exists in the mesh, a new point is not inserted
and the index of the already existing point is returned. A mesh has a principal
dimension, which is the dimension of its points. It is not possible to have
points of different dimensions in a same mesh.

The most basic function to add a new element to a mesh is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{j} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}convex}\PYG{p}{(}\PYG{n}{pgt}\PYG{p}{,} \PYG{n}{it}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This is a template function, with \sphinxcode{\sphinxupquote{pgt}} of type \sphinxcode{\sphinxupquote{bgeot::pgeometric\_trans}} (basically a pointer
to an instance of type \sphinxcode{\sphinxupquote{bgeot::geometric\_trans}}) and \sphinxcode{\sphinxupquote{it}} is an iterator on a list of indexes of
already existing points. For instance, if one needs to add a new triangle in a 3D
mesh, one needs to define first an array with the indexes of the three points:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{size\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{ind}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ind}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}point}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ind}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}point}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ind}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}point}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

then adding the element is done by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}convex}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{simplex\PYGZus{}geotrans}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{ind}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{bgeot::simplex\_geotrans(N,1);}} denotes the usual linear geometric
transformation for simplices of dimension N.

For simplices, a more specialized function exists, which is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}simplex}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{ind}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is also possible to give directly the list of points with the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}convex\PYGZus{}by\PYGZus{}points}\PYG{p}{(}\PYG{n}{pgt}\PYG{p}{,} \PYG{n}{itp}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where now \sphinxcode{\sphinxupquote{itp}} is an iterator on an array of points. For example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{o}{\PYGZgt{}} \PYG{n}{pts}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{pts}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{pts}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{pts}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{1.0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}convex\PYGZus{}by\PYGZus{}points}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{simplex\PYGZus{}geotrans}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,} \PYG{n}{pts}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is possible to use also:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}simplex\PYGZus{}by\PYGZus{}points}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{pts}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For other elements than simplices, it is still possible to use
\sphinxcode{\sphinxupquote{mymesh.add\_convex\_by\_points}} or \sphinxcode{\sphinxupquote{mymesh.add\_convex}} with the appropriate
geometric transformation.
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{bgeot::parallelepiped\_geotrans(N, 1)}} describes the usual transformation for
parallelepipeds of dimension \sphinxcode{\sphinxupquote{N}} (quadrilateron for \sphinxcode{\sphinxupquote{N=2}}, hexahedron for
\sphinxcode{\sphinxupquote{N=3}}, …)

\item {} 
\sphinxcode{\sphinxupquote{bgeot::prism\_geotrans(N, 1)}} describes the usual transformation for prisms of
dimension \sphinxcode{\sphinxupquote{N}} (usual prism is for \sphinxcode{\sphinxupquote{N=3}}. A generalized prism is the product
of a simplex of dimension \sphinxcode{\sphinxupquote{N\sphinxhyphen{}1}} with a segment)

\end{itemize}

Specialized functions exist also:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}parallelepiped}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{it}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}parallelepiped\PYGZus{}by\PYGZus{}points}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{itp}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}prism}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{it}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{add\PYGZus{}prism\PYGZus{}by\PYGZus{}points}\PYG{p}{(}\PYG{n}{N}\PYG{p}{,} \PYG{n}{itp}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The order of the points in the array of points is not important for simplices
(except if you care about the orientation of your simplices). For other elements, it is important to respect the vertex order shown in {\hyperref[\detokenize{userdoc/bmesh:ud-fig-elem}]{\sphinxcrossref{\DUrole{std,std-ref}{Vertex numeration for usual first order elements}}}} (first order elements).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=15cm]{{getfemuserelem}.png}
\caption{Vertex numeration for usual first order elements}\label{\detokenize{userdoc/bmesh:id2}}\label{\detokenize{userdoc/bmesh:ud-fig-elem}}\end{figure}

Note that a general rule, including for higher order transformations, is that the vertex numeration follows the one of the corresponding Lagrange finite element method (see  {\hyperref[\detokenize{userdoc/appendixA:ud-appendixa}]{\sphinxcrossref{\DUrole{std,std-ref}{Appendix A. Finite element method list}}}}).


\section{Remove an element from a mesh}
\label{\detokenize{userdoc/bmesh:remove-an-element-from-a-mesh}}
To remove an element from a mesh, simply use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{sup\PYGZus{}convex}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{i}} is the index of the element.


\section{Simple structured meshes}
\label{\detokenize{userdoc/bmesh:simple-structured-meshes}}
For parallelepiped domains, it is possible to obtain structured meshes with
simplices, parallelepipeds or prisms elements from three functions defined in
\sphinxcode{\sphinxupquote{getfem/getfem\_regular\_meshes.h}}.

The simplest function to use is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{regular\PYGZus{}unit\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mesh}\PYG{o}{\PYGZam{}} \PYG{n}{m}\PYG{p}{,} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{size\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{nsubdiv}\PYG{p}{,}
                       \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pgeometric\PYGZus{}trans} \PYG{n}{pgt}\PYG{p}{,} \PYG{k+kt}{bool} \PYG{n}{noised} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which fills the mesh \sphinxcode{\sphinxupquote{m}} with a regular mesh of simplices/parallelepipeds/prisms
(depending on the value of \sphinxcode{\sphinxupquote{pgt}}). The number of cells in each direction is given
by \sphinxcode{\sphinxupquote{nsubdiv}}. The following example builds a mesh of quadratic triangles on the
unit square (the mesh can be scaled and translated afterwards):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{size\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{nsubdiv}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{nsubdiv}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{;} \PYG{n}{nsubdiv}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{20}\PYG{p}{;}
\PYG{n}{regular\PYGZus{}unit\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{m}\PYG{p}{,} \PYG{n}{nsubdiv}\PYG{p}{,} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{simplex\PYGZus{}geotrans}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

More specialized regular mesh functions are also available:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{parallelepiped\PYGZus{}regular\PYGZus{}simplex\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{,} \PYG{n}{N}\PYG{p}{,} \PYG{n}{org}\PYG{p}{,} \PYG{n}{ivect}\PYG{p}{,} \PYG{n}{iref}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{parallelepiped\PYGZus{}regular\PYGZus{}prism\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{,} \PYG{n}{N}\PYG{p}{,} \PYG{n}{org}\PYG{p}{,} \PYG{n}{ivect}\PYG{p}{,} \PYG{n}{iref}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{parallelepiped\PYGZus{}regular\PYGZus{}pyramid\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{,} \PYG{n}{N}\PYG{p}{,} \PYG{n}{org}\PYG{p}{,} \PYG{n}{ivect}\PYG{p}{,} \PYG{n}{iref}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{parallelepiped\PYGZus{}regular\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{,} \PYG{n}{N}\PYG{p}{,} \PYG{n}{org}\PYG{p}{,} \PYG{n}{ivect}\PYG{p}{,} \PYG{n}{iref}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mymesh}} is a mesh variable in which the structured mesh will be built,
\sphinxcode{\sphinxupquote{N}} is the dimension (limited to 4 for simplices, 5 for prisms, unlimited for
parallelepipeds), \sphinxcode{\sphinxupquote{org}} is of type \sphinxcode{\sphinxupquote{bgeot::base\_node}} and represents the
origin of the mesh, \sphinxcode{\sphinxupquote{ivect}} is an iterator on an array of \sphinxcode{\sphinxupquote{N}} vectors to
build the parallelepiped domain, \sphinxcode{\sphinxupquote{iref}} is an iterator on an array of \sphinxcode{\sphinxupquote{N}}
integers representing the number of division on each direction.

For instance, to build a mesh with tetrahedrons for a unit cube with
\(10\times~10\times~10\) cells one can write:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh} \PYG{n}{mymesh}\PYG{p}{;}
\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}node} \PYG{n}{org}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}small\PYGZus{}vector}\PYG{o}{\PYGZgt{}} \PYG{n}{vect}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{vect}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}small\PYGZus{}vector}\PYG{p}{(}\PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{vect}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}small\PYGZus{}vector}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{vect}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]} \PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}small\PYGZus{}vector}\PYG{p}{(}\PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{,} \PYG{l+m+mf}{0.1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{k+kt}{int}\PYG{o}{\PYGZgt{}} \PYG{n}{ref}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{ref}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]} \PYG{o}{=} \PYG{n}{ref}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]} \PYG{o}{=} \PYG{n}{ref}\PYG{p}{[}\PYG{l+m+mi}{2}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{10}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{parallelepiped\PYGZus{}regular\PYGZus{}simplex\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{,} \PYG{n}{org}\PYG{p}{,} \PYG{n}{vect}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{ref}\PYG{p}{.}\PYG{n}{begin}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\begin{sphinxadmonition}{note}{Note:}
\sphinxcode{\sphinxupquote{base\_node}} and \sphinxcode{\sphinxupquote{base\_small\_vector}} are almost identical, they are both
‘’small’’ vector classes (they cannot store more than 16 elements), used to
describe geometrical points, and geometrical vectors. Their memory footprint
is lower than a \sphinxcode{\sphinxupquote{std::vector}}.
\end{sphinxadmonition}


\section{Mesh regions}
\label{\detokenize{userdoc/bmesh:mesh-regions}}\label{\detokenize{userdoc/bmesh:ud-mesh-regions}}
A mesh object can contain many \sphinxcode{\sphinxupquote{getfem::mesh\_region}} objects (declaration in
\sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_region.h}}). These objects are containers for a set of
convexes and convex faces. They are used to define boundaries, or a partition of
the mesh for parallel solvers, etc.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{region}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)}\PYG{p}{.}\PYG{n}{add}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}   \PYG{c+c1}{// adds convex 2 into region 30}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{region}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)}\PYG{p}{.}\PYG{n}{add}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}   \PYG{c+c1}{// adds convex 3 into region 30}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{region}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)}\PYG{p}{.}\PYG{n}{add}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// adds face 3 of convex 4 into region 30}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{region}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)}\PYG{p}{.}\PYG{n}{sup}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{)}\PYG{p}{;}   \PYG{c+c1}{// Removes convex 3 from region 30}
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{sup\PYGZus{}convex}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{;}       \PYG{c+c1}{// Removes convex 4 from both the mesh and all the regions}
\PYG{k}{for} \PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mr\PYGZus{}visitor} \PYG{n}{i}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{region}\PYG{p}{(}\PYG{l+m+mi}{30}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;} \PYG{o}{!}\PYG{n}{i}\PYG{p}{.}\PYG{n}{finished}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{i}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{convex: }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{i}\PYG{p}{.}\PYG{n}{cv}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ face:}\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{i}\PYG{p}{.}\PYG{n}{f}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{endl}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\section{Methods of the \sphinxstyleliteralintitle{\sphinxupquote{getfem::mesh}} object}
\label{\detokenize{userdoc/bmesh:methods-of-the-gf-m-object}}
The list is not exhaustive.
\index{getfem::mesh::dim (C++ function)@\spxentry{getfem::mesh::dim}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh3dimEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{dim}}}{}{}%
\pysigstopmultiline
main dimension of the mesh.

\end{fulllineitems}

\index{getfem::mesh::points\_index (C++ function)@\spxentry{getfem::mesh::points\_index}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh12points_indexEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{points\_index}}}{}{}%
\pysigstopmultiline
gives a \sphinxcode{\sphinxupquote{dal::bit\_vector}} object which represents all the indexes
of valid points of a mesh (see below).

\end{fulllineitems}

\index{getfem::mesh::points (C++ function)@\spxentry{getfem::mesh::points}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh6pointsEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{points}}}{}{}%
\pysigstopmultiline
gives the point of each index (a \sphinxcode{\sphinxupquote{bgeot::base\_node}}).

\end{fulllineitems}

\index{getfem::mesh::convex\_index (C++ function)@\spxentry{getfem::mesh::convex\_index}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh12convex_indexEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{convex\_index}}}{}{}%
\pysigstopmultiline
gives a \sphinxcode{\sphinxupquote{dal::bit\_vector}} object which represents all the indexes
of valid elements of a mesh (see below).

\end{fulllineitems}

\index{bgeot::mesh\_structure::structure\_of\_convex (C++ function)@\spxentry{bgeot::mesh\_structure::structure\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot14mesh_structure19structure_of_convexE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::mesh\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{structure\_of\_convex}}}{i}{}%
\pysigstopmultiline
gives the description of the structure of element of index \sphinxcode{\sphinxupquote{i}}. The function
return a \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{bgeot::convex\_structure::nb\_faces (C++ function)@\spxentry{bgeot::convex\_structure::nb\_faces}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot16convex_structure8nb_facesEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::convex\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{nb\_faces}}}{}{}%
\pysigstopmultiline
number of faces of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{bgeot::convex\_structure::nb\_points (C++ function)@\spxentry{bgeot::convex\_structure::nb\_points}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot16convex_structure9nb_pointsEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::convex\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{nb\_points}}}{}{}%
\pysigstopmultiline
number of vertices of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{bgeot::convex\_structure::dim (C++ function)@\spxentry{bgeot::convex\_structure::dim}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot16convex_structure3dimEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::convex\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{dim}}}{}{}%
\pysigstopmultiline
intrinsic dimension of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{bgeot::convex\_structure::nb\_points\_of\_face (C++ function)@\spxentry{bgeot::convex\_structure::nb\_points\_of\_face}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot16convex_structure17nb_points_of_faceE1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::convex\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{nb\_points\_of\_face}}}{f}{}%
\pysigstopmultiline
number of vertices of the face of local index \sphinxcode{\sphinxupquote{f}} of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{bgeot::convex\_structure::ind\_points\_of\_face (C++ function)@\spxentry{bgeot::convex\_structure::ind\_points\_of\_face}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot16convex_structure18ind_points_of_faceE1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::convex\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{ind\_points\_of\_face}}}{f}{}%
\pysigstopmultiline
return a container with the local indexes of all vertices of the
face of local index \sphinxcode{\sphinxupquote{f}} of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}. For instance
\sphinxcode{\sphinxupquote{mesh.structure\_of\_convex(i)\sphinxhyphen{}\textgreater{}ind\_points\_of\_face(f){[}0{]}}} is the
local index of the first vertex.

\end{fulllineitems}

\index{bgeot::convex\_structure::face\_structure (C++ function)@\spxentry{bgeot::convex\_structure::face\_structure}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N5bgeot16convex_structure14face_structureE1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{bgeot::convex\_structure\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{face\_structure}}}{f}{}%
\pysigstopmultiline
gives the structure (a \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}) of local index \sphinxcode{\sphinxupquote{f}}
of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{getfem::mesh::ind\_points\_of\_convex (C++ function)@\spxentry{getfem::mesh::ind\_points\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh20ind_points_of_convexE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{ind\_points\_of\_convex}}}{i}{}%
\pysigstopmultiline
gives a container with the global indexes of vertices of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}.

\end{fulllineitems}

\index{getfem::mesh::points\_of\_convex (C++ function)@\spxentry{getfem::mesh::points\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh16points_of_convexE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{points\_of\_convex}}}{i}{}%
\pysigstopmultiline
gives a container with the vertices of \sphinxcode{\sphinxupquote{bgeot::pconvex\_structure}}. This
is an array of \sphinxcode{\sphinxupquote{bgeot::base\_node}}.

\end{fulllineitems}

\index{getfem::mesh::convex\_to\_point (C++ function)@\spxentry{getfem::mesh::convex\_to\_point}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh15convex_to_pointE3ipt}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{convex\_to\_point}}}{ipt}{}%
\pysigstopmultiline
gives a container with the indexes of all elements attached to the
point of global index \sphinxcode{\sphinxupquote{ipt}}.

\end{fulllineitems}

\index{getfem::mesh::neighbors\_of\_convex (C++ function)@\spxentry{getfem::mesh::neighbors\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh19neighbors_of_convexE2ic1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{neighbors\_of\_convex}}}{ic, f}{}%
\pysigstopmultiline
gives a container with the indexes of all elements in \sphinxcode{\sphinxupquote{mesh}} having
the common face of local index \sphinxcode{\sphinxupquote{f}} of element \sphinxcode{\sphinxupquote{ic}} except element
\sphinxcode{\sphinxupquote{ic}}.

\end{fulllineitems}

\index{getfem::mesh::neighbor\_of\_convex (C++ function)@\spxentry{getfem::mesh::neighbor\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh18neighbor_of_convexE2ic1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{neighbor\_of\_convex}}}{ic, f}{}%
\pysigstopmultiline
gives the index of the first elements in \sphinxcode{\sphinxupquote{mesh}} having the common
face of local index \sphinxcode{\sphinxupquote{f}} of element \sphinxcode{\sphinxupquote{ic}} except element \sphinxcode{\sphinxupquote{ic}}.
return size\_type(\sphinxhyphen{}1) if none is found.

\end{fulllineitems}

\index{getfem::mesh::is\_convex\_having\_neighbor (C++ function)@\spxentry{getfem::mesh::is\_convex\_having\_neighbor}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh25is_convex_having_neighborE2ic1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_convex\_having\_neighbor}}}{ic, f}{}%
\pysigstopmultiline
return whether or not the element \sphinxcode{\sphinxupquote{ic}} has a neighbor with respect
to its face of local index \sphinxcode{\sphinxupquote{f}}.

\end{fulllineitems}

\index{getfem::mesh::clear (C++ function)@\spxentry{getfem::mesh::clear}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh5clearEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{clear}}}{}{}%
\pysigstopmultiline
delete all elements and points from the mesh.

\end{fulllineitems}

\index{getfem::mesh::optimize\_structure (C++ function)@\spxentry{getfem::mesh::optimize\_structure}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh18optimize_structureEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{optimize\_structure}}}{}{}%
\pysigstopmultiline
compact the structure (renumbers points and convexes such that there
is no hole in their numbering).

\end{fulllineitems}

\index{getfem::mesh::trans\_of\_convex (C++ function)@\spxentry{getfem::mesh::trans\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh15trans_of_convexE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{trans\_of\_convex}}}{i}{}%
\pysigstopmultiline
return the geometric transformation of the element of index \sphinxcode{\sphinxupquote{i}} (in
a \sphinxcode{\sphinxupquote{bgeot::pgeometric\_trans}}). See \DUrole{xref,std,std-ref}{dp} for more details about geometric transformations.

\end{fulllineitems}

\index{getfem::mesh::normal\_of\_face\_of\_convex (C++ function)@\spxentry{getfem::mesh::normal\_of\_face\_of\_convex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh24normal_of_face_of_convexE2ic1f2pt}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{normal\_of\_face\_of\_convex}}}{ic, f, pt}{}%
\pysigstopmultiline
gives a \sphinxcode{\sphinxupquote{bgeot::base\_small\_vector}} representing an outward normal
to the element at the face of local index \sphinxcode{\sphinxupquote{f}} at the point of local
coordinates (coordinates in the element of reference) \sphinxcode{\sphinxupquote{pt}}. The
point \sphinxcode{\sphinxupquote{pt}} has no influence if the geometric transformation is
linear. This is not a unit normal, the norm of the resulting vector
is the ratio between the surface of the face of the reference
element and the surface of the face of the real element.

\end{fulllineitems}

\index{getfem::mesh::convex\_area\_estimate (C++ function)@\spxentry{getfem::mesh::convex\_area\_estimate}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh20convex_area_estimateE2ic}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{convex\_area\_estimate}}}{ic}{}%
\pysigstopmultiline
gives an estimate of the area of convex \sphinxcode{\sphinxupquote{ic}}.

\end{fulllineitems}

\index{getfem::mesh::convex\_quality\_estimate (C++ function)@\spxentry{getfem::mesh::convex\_quality\_estimate}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh23convex_quality_estimateE2ic}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{convex\_quality\_estimate}}}{ic}{}%
\pysigstopmultiline
gives a rough estimate of the quality of element \sphinxcode{\sphinxupquote{ic}}.

\end{fulllineitems}

\index{getfem::mesh::convex\_radius\_estimate (C++ function)@\spxentry{getfem::mesh::convex\_radius\_estimate}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh22convex_radius_estimateE2ic}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{convex\_radius\_estimate}}}{ic}{}%
\pysigstopmultiline
gives an estimate of the radius of element \sphinxcode{\sphinxupquote{ic}}.

\end{fulllineitems}

\index{getfem::mesh::region (C++ function)@\spxentry{getfem::mesh::region}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh6regionE3irg}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{region}}}{irg}{}%
\pysigstopmultiline
return a \sphinxcode{\sphinxupquote{getfem::mesh\_region}}. The region is stored in the mesh, and can
contain a set of convex numbers and or convex faces.

\end{fulllineitems}

\index{getfem::mesh::has\_region (C++ function)@\spxentry{getfem::mesh::has\_region}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh10has_regionE3irg}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{has\_region}}}{irg}{}%
\pysigstopmultiline
returns true if the region of index \sphinxcode{\sphinxupquote{irg}} has been created.

\end{fulllineitems}


The methods of the convexes/convex faces container \sphinxcode{\sphinxupquote{getfem::mesh\_region}} are:
\index{getfem::mesh\_region::add (C++ function)@\spxentry{getfem::mesh\_region::add}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region3addE2ic}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add}}}{ic}{}%
\pysigstopmultiline
add the convex of index \sphinxcode{\sphinxupquote{ic}} to the region.

\end{fulllineitems}

\index{getfem::mesh\_region::add (C++ function)@\spxentry{getfem::mesh\_region::add}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region3addE2ic1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add}}}{ic, f}{}%
\pysigstopmultiline
add the face number \sphinxcode{\sphinxupquote{f}} of the convex \sphinxcode{\sphinxupquote{ic}}.

\end{fulllineitems}

\index{getfem::mesh\_region::sup (C++ function)@\spxentry{getfem::mesh\_region::sup}\spxextra{C++ function}}\index{getfem::mesh\_region::sup (C++ function)@\spxentry{getfem::mesh\_region::sup}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region3supE2ic}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{sup}}}{ic}{}%
\pysigstopmultiline\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region3supE2ic1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{sup}}}{ic, f}{}%
\pysigstopmultiline
remove the convex or the convex face from the region.

\end{fulllineitems}

\index{getfem::mesh\_region::is\_in (C++ function)@\spxentry{getfem::mesh\_region::is\_in}\spxextra{C++ function}}\index{getfem::mesh\_region::is\_in (C++ function)@\spxentry{getfem::mesh\_region::is\_in}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region5is_inE2ic}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_in}}}{ic}{}%
\pysigstopmultiline\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region5is_inE2ic1f}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_in}}}{ic, f}{}%
\pysigstopmultiline
return true if the convex (or convex face) is in the region.

\end{fulllineitems}

\index{getfem::mesh\_region::is\_only\_faces (C++ function)@\spxentry{getfem::mesh\_region::is\_only\_faces}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region13is_only_facesEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_only\_faces}}}{}{}%
\pysigstopmultiline
return true if the region does not contain any convex.

\end{fulllineitems}

\index{getfem::mesh\_region::is\_only\_convexes (C++ function)@\spxentry{getfem::mesh\_region::is\_only\_convexes}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region16is_only_convexesEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_only\_convexes}}}{}{}%
\pysigstopmultiline
return true if the region does not contain any convex face.

\end{fulllineitems}

\index{getfem::mesh\_region::index (C++ function)@\spxentry{getfem::mesh\_region::index}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem11mesh_region5indexEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_region\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{index}}}{}{}%
\pysigstopmultiline
return a \sphinxcode{\sphinxupquote{dal::bit\_vector}} containing the list of convexes
which are stored (or whose faces are stored) in the region.

\end{fulllineitems}


Iteration over a \sphinxcode{\sphinxupquote{getfem::mesh\_region}} should be done with \sphinxcode{\sphinxupquote{getfem::mr\_visitor}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}region} \PYG{o}{\PYGZam{}}\PYG{n}{rg} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{region}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{for} \PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mr\PYGZus{}visitor} \PYG{n}{i}\PYG{p}{(}\PYG{n}{rg}\PYG{p}{)}\PYG{p}{;} \PYG{o}{!}\PYG{n}{i}\PYG{p}{.}\PYG{n}{finished}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{i}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{contains convex }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}} \PYG{o}{\PYGZlt{}} \PYG{n}{i}\PYG{p}{.}\PYG{n}{cv}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{i}\PYG{p}{.}\PYG{n}{is\PYGZus{}face}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)} \PYG{n}{cout}  \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{face }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{i}\PYG{p}{.}\PYG{n}{f}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{endl}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\section{Using \sphinxstyleliteralintitle{\sphinxupquote{dal::bit\_vector}}}
\label{\detokenize{userdoc/bmesh:using-dal-bv}}
The object \sphinxcode{\sphinxupquote{dal::bit\_vector}} (declared in \sphinxcode{\sphinxupquote{getfem/dal\_bit\_vector.h}}) is a structure
heavily used in \sphinxstyleemphasis{GetFEM}. It is very close to \sphinxcode{\sphinxupquote{std::bitset}} and
\sphinxcode{\sphinxupquote{std::vector\textless{}bool\textgreater{}}} but with additional functionalities to represent a set of
non negative integers and iterate over them.

If \sphinxcode{\sphinxupquote{nn}} is declared to be a \sphinxcode{\sphinxupquote{dal::bit\_vector}}, the two
instructions \sphinxcode{\sphinxupquote{nn.add(6)}} or \sphinxcode{\sphinxupquote{nn{[}6{]} = true}} are equivalent and
means that integer 6 is added to the set.

In a same way \sphinxcode{\sphinxupquote{nn.sup(6)}} or \sphinxcode{\sphinxupquote{nn{[}6{]} = false}} remove the integer 6
from the set. The instruction \sphinxcode{\sphinxupquote{nn.add(6, 4)}} adds 6,7,8,9 to the
set.

To iterate on a \sphinxcode{\sphinxupquote{dal::bit\_vector}}, it is possible to use iterators
as usual, but, most of the time, as this object represents a set of
integers, one just wants to iterate on the integers included into the
set. The simplest way to do that is to use the pseudo\sphinxhyphen{}iterator
\sphinxcode{\sphinxupquote{dal::bv\_visitor}}.

For instance, here is the code to iterate on the points of a mesh and
print it to the standard output:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{for} \PYG{p}{(}\PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bv\PYGZus{}visitor} \PYG{n}{i}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{points\PYGZus{}index}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;} \PYG{o}{!}\PYG{n}{i}\PYG{p}{.}\PYG{n}{finished}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{i}\PYG{p}{)}
  \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Point of index }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{i} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ of the mesh: }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{points}\PYG{p}{(}\PYG{p}{)}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{endl}\PYG{p}{;}
\end{sphinxVerbatim}


\section{Face numbering}
\label{\detokenize{userdoc/bmesh:face-numbering}}
The numeration of faces on usual elements is given in figure {\hyperref[\detokenize{userdoc/bmesh:ud-fig-elemf}]{\sphinxcrossref{\DUrole{std,std-ref}{faces numeration for usual elements}}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=12cm]{{getfemuserelemf}.png}
\caption{faces numeration for usual elements}\label{\detokenize{userdoc/bmesh:id3}}\label{\detokenize{userdoc/bmesh:ud-fig-elemf}}\end{figure}

Note that, while the convexes and the points are globally numbered in a \sphinxcode{\sphinxupquote{getfem::mesh}}
object, there is no global numbering of the faces, so the only way to refer to
a given face, is to give the convex number, and the local face number in the
convex.


\section{Save and load meshes}
\label{\detokenize{userdoc/bmesh:save-and-load-meshes}}\label{\detokenize{userdoc/bmesh:ud-load-save-mesh}}

\subsection{From \sphinxstyleemphasis{GetFEM} file format}
\label{\detokenize{userdoc/bmesh:from-gf-file-format}}
In \sphinxcode{\sphinxupquote{getfem/getfem\_mesh.h}}, two methods are defined to load meshes from file
and write meshes to a file.
\index{getfem::mesh::write\_to\_file (C++ function)@\spxentry{getfem::mesh::write\_to\_file}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh13write_to_fileERKNSt6stringE}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{write\_to\_file}}}{\sphinxbfcode{\sphinxupquote{const}} std::string \&\sphinxstyleemphasis{name}}{}%
\pysigstopmultiline
save the mesh into a file.

\end{fulllineitems}

\index{getfem::mesh::read\_from\_file (C++ function)@\spxentry{getfem::mesh::read\_from\_file}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bmesh:_CPPv4N6getfem4mesh14read_from_fileERKNSt6stringE}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{read\_from\_file}}}{\sphinxbfcode{\sphinxupquote{const}} std::string \&\sphinxstyleemphasis{name}}{}%
\pysigstopmultiline
load the mesh from a file.

\end{fulllineitems}


The following is an example of how to load a mesh and extract information on it:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+cp}{\PYGZsh{}}\PYG{c+cp}{include} \PYG{c+cpf}{\PYGZlt{}getfem/getfem\PYGZus{}mesh.h\PYGZgt{}}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh} \PYG{n}{mymesh}\PYG{p}{;}

\PYG{k+kt}{int} \PYG{n+nf}{main}\PYG{p}{(}\PYG{k+kt}{int} \PYG{n}{argc}\PYG{p}{,} \PYG{k+kt}{char} \PYG{o}{*}\PYG{n}{argv}\PYG{p}{[}\PYG{p}{]}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{k}{try} \PYG{p}{\PYGZob{}}
    \PYG{c+c1}{// read the mesh from the file name given by the first argument}
    \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{read\PYGZus{}from\PYGZus{}file}\PYG{p}{(}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{n}{argv}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

    \PYG{c+c1}{// List all the convexes}
    \PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector} \PYG{n}{nn} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{convex\PYGZus{}index}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{size\PYGZus{}type} \PYG{n}{i}\PYG{p}{;}
    \PYG{k}{for} \PYG{p}{(}\PYG{n}{i} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{nn}\PYG{p}{;} \PYG{n}{i} \PYG{o}{!}\PYG{o}{=} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{;} \PYG{n}{i} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{nn}\PYG{p}{)} \PYG{p}{\PYGZob{}}
      \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Convex of index }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{i} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{endl}\PYG{p}{;}
      \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pconvex\PYGZus{}structure} \PYG{n}{cvs} \PYG{o}{=} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{structure\PYGZus{}of\PYGZus{}convex}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{p}{;}
      \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Number of vertices: }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{nb\PYGZus{}points}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{endl}\PYG{p}{;}
      \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Number of faces: }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{nb\PYGZus{}faces}\PYG{p}{(}\PYG{p}{)} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{endl}\PYG{p}{;}
      \PYG{k}{for} \PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{short\PYGZus{}type} \PYG{n}{f} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;} \PYG{n}{f} \PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{nb\PYGZus{}faces}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{f}\PYG{p}{)} \PYG{p}{\PYGZob{}}
        \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{face }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{f} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ has }\PYG{l+s}{\PYGZdq{}} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{nb\PYGZus{}points\PYGZus{}of\PYGZus{}face}\PYG{p}{(}\PYG{n}{f}\PYG{p}{)}\PYG{p}{;}
        \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ vertices with local indexes: }\PYG{l+s}{\PYGZdq{}}\PYG{p}{;}
        \PYG{k}{for} \PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{size\PYGZus{}type} \PYG{n}{k} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;} \PYG{n}{k} \PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{nb\PYGZus{}points\PYGZus{}of\PYGZus{}face}\PYG{p}{(}\PYG{n}{f}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{k}\PYG{p}{)}
          \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{ind\PYGZus{}points\PYGZus{}of\PYGZus{}face}\PYG{p}{(}\PYG{n}{f}\PYG{p}{)}\PYG{p}{[}\PYG{n}{k}\PYG{p}{]} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ }\PYG{l+s}{\PYGZdq{}}\PYG{p}{;}
        \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ and global indexes: }\PYG{l+s}{\PYGZdq{}}\PYG{p}{;}
        \PYG{k}{for} \PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{size\PYGZus{}type} \PYG{n}{k} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;} \PYG{n}{k} \PYG{o}{\PYGZlt{}} \PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{nb\PYGZus{}points\PYGZus{}of\PYGZus{}face}\PYG{p}{(}\PYG{n}{f}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{k}\PYG{p}{)}
          \PYG{n}{cout} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{ind\PYGZus{}points\PYGZus{}of\PYGZus{}convex}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{p}{[}\PYG{n}{cvs}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{ind\PYGZus{}points\PYGZus{}of\PYGZus{}face}\PYG{p}{(}\PYG{n}{f}\PYG{p}{)}\PYG{p}{[}\PYG{n}{k}\PYG{p}{]}\PYG{p}{]} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ }\PYG{l+s}{\PYGZdq{}}\PYG{p}{;}
      \PYG{p}{\PYGZcb{}}
    \PYG{p}{\PYGZcb{}}
  \PYG{p}{\PYGZcb{}} \PYG{n}{GMM\PYGZus{}STANDARD\PYGZus{}CATCH\PYGZus{}ERROR}\PYG{p}{;} \PYG{c+c1}{// catches standard errors}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Import a mesh}
\label{\detokenize{userdoc/bmesh:import-a-mesh}}
The file \sphinxcode{\sphinxupquote{getfem/getfem\_import.h}} provides the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{import\PYGZus{}mesh}\PYG{p}{(}\PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZam{}} \PYG{n}{fmtfilename}\PYG{p}{,} \PYG{n}{mesh}\PYG{o}{\PYGZam{}} \PYG{n}{m}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Here the string \sphinxcode{\sphinxupquote{fmtfilename}} must contain a descriptor of the
file format (“gid”, “gmsh”, “cdb”, “noboite”, “am\_fmt”, “emc2\_mesh”,
or “structured”), followed by a colon and the file name (if there is
not format descriptor, it is assumed that the file is a native getfem
mesh and the \sphinxcode{\sphinxupquote{mesh::read\_from\_file()}} method is used). Example:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh} \PYG{n}{m}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{import\PYGZus{}mesh}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{gid:../tests/meshes/tripod.GiD.msh}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{m}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Alternatively the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{import\PYGZus{}mesh}\PYG{p}{(}\PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZam{}} \PYG{n}{filename}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZam{}} \PYG{n}{fmt}\PYG{p}{,}
                 \PYG{n}{mesh}\PYG{o}{\PYGZam{}} \PYG{n}{m}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

can be used in an equivalent manner with the string \sphinxcode{\sphinxupquote{fmt}} being one of
the aforementioned format specifiers.

The “gid” format specifier is for meshes generated by \sphinxhref{http://gid.cimne.upc.es}{GiD} and “gmsh”
is for meshes generated by the open\sphinxhyphen{}source mesh generator \sphinxhref{http://www.geuz.org/gmsh}{Gmsh}.
The “cdb” format specifier is for reading meshes from \sphinxhref{http://www.ansys.com}{ANSYS} models
exported in blocked format with the CDWRITE command. Currently the
\sphinxhref{http://www.ansys.com}{ANSYS} element types 42,45,73,82,87,89,90,92,95,162,182,183,185,186,187
and 191 can be imported, this however does not include any finite element
techology linked to these elements but only their geometry.
The “noboite” format is for TetMesh\sphinxhyphen{}GHS3D, and the
“am\_fmt” and “emc2\_mesh” are for files built with \sphinxhref{http://www-rocq1.inria.fr/gamma/cdrom/www/emc2/eng.htm}{EMC2} (but 2D only).

The “structured” format is just a short specification for regular meshes:
the rest of \sphinxcode{\sphinxupquote{fmtfilename}} in that case is not a filename, but a string
whose format is following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{import\PYGZus{}mesh}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{structured:GT=\PYGZsq{}GT\PYGZus{}PK(2,1)\PYGZsq{};}\PYG{l+s}{\PYGZdq{}}
                    \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{NSUBDIV=[5,5];}\PYG{l+s}{\PYGZdq{}}
                    \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ORG=[0,0];}\PYG{l+s}{\PYGZdq{}}
                    \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{SIZES=[1,1];}\PYG{l+s}{\PYGZdq{}}
                    \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{NOISED=0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{m}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{GT}} is the name of the geometric transformation, \sphinxcode{\sphinxupquote{NSUBDIV}} a
vector of the number of subdivisions in each coordinate (default value 2),
\sphinxcode{\sphinxupquote{ORG}} is the origin of the mesh (default value \sphinxcode{\sphinxupquote{{[}0,0,...{]}}}), \sphinxcode{\sphinxupquote{SIZES}}
is a vector of the sizes in each direction (default value \sphinxcode{\sphinxupquote{{[}1, 1, ...{]}}}
and if \sphinxcode{\sphinxupquote{NOISED=1}} the nodes of the interior of the mesh are randomly
“shaken” (default value \sphinxcode{\sphinxupquote{NOISED=0}}). In that string, all the parameters
are optional except \sphinxcode{\sphinxupquote{GT}}.

\index{fem@\spxentry{fem}}\index{mesh@\spxentry{mesh}}\index{mesh\_fem@\spxentry{mesh\_fem}}\ignorespaces 

\chapter{Build a finite element method on a mesh}
\label{\detokenize{userdoc/bfem:build-a-finite-element-method-on-a-mesh}}\label{\detokenize{userdoc/bfem:ud-bfem}}\label{\detokenize{userdoc/bfem:index-0}}\label{\detokenize{userdoc/bfem::doc}}
The object \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} defined in \sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_fem.h}} is designed to
describe a finite element method on a whole mesh, i.e. to describe the finite
element space on which some variables will be described. This is a rather complex
object which is central in \sphinxstyleemphasis{GetFEM}. Basically, this structure describes the finite
element method on each element of the mesh and some additional optional
transformations. It is possible to have an arbitrary number of finite element
descriptions for a single mesh. This is particularly necessary for mixed methods,
but also to describe different data on the same mesh. One can instantiate a
\sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{n}{mf}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mymesh}} is an already existing mesh. The structure will be linked to this
mesh and will react when modifications will be done on it.

It is possible to specify element by element the finite element method, so that
element of mixed types can be treated, even if the dimensions are different. For
usual elements, the connection between two elements is done when the two elements
are compatibles (same degrees of freedom on the common face). A numeration of the
degrees of freedom is automatically done with a Cuthill Mc Kee like algorithm. You
have to keep in mind that there is absolutely no connection between the numeration
of vertices of the mesh and the numeration of the degrees of freedom. Every
\sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object has its own numeration.

There are three levels in the \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object:
\begin{itemize}
\item {} 
The element level: one finite element method per element. It is possible to mix
the dimensions of the elements and the property to be vectorial or scalar.

\item {} 
The optional vectorization/tensorization (the qdim in getfem jargon,
see \sphinxhref{http://getfem.org/getfem\_reference/index.html}{vocabulary}). For instance to represent a displacement or a
tensor field in continuum mechanics. Scalar
elements are used componentwise. Note that you can mix some
intrinsic vectorial elements (Raviart\sphinxhyphen{}Thomas element for instance)
which will not be vectorized and
scalar elements which will be.

\item {} 
(\sphinxstyleemphasis{GetFEM} version 4.0) The optional additional linear transformation (reduction) of
the degrees of freedom. It will consist in giving two matrices, the reduction
matrix and the extension matrix. The reduction matrix should transform the basic
dofs into the reduced dofs (the number of reduced dofs should be less or equal
than the number of basic dofs). The extension matrix should describe the inverse
transformation. The product of the reduction matrix with the extension matrix
should be the identity matrix (ensuring in particular that the two matrices are
of maximal rank). This optional transformation can be used to reduce the finite
element space to a certain region (tipically a boundary) or to prescribe some
matching conditions between non naturally compatible fems (for instance fems
with different degrees).

\end{itemize}

One has to keep in mind this construction manipulating the degrees of freedom of a
\sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object.


\section{First level: manipulating fems on each elements}
\label{\detokenize{userdoc/bfem:first-level-manipulating-fems-on-each-elements}}
To select a particular finite element method on a given element, use the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{set\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{pf}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{i}} is the index of the element and \sphinxcode{\sphinxupquote{pf}} is the descriptor (of type
\sphinxcode{\sphinxupquote{getfem::pfem}}, basically a pointer to an object which inherits from \sphinxcode{\sphinxupquote{getfem::virtual\_fem}}) of the
finite element method. Alternative forms of this member function are:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{k}{const} \PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{cvs}\PYG{p}{,}
                                  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pfem} \PYG{n}{pf}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pfem} \PYG{n}{pf}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which set the finite elements for either the convexes listed in the \sphinxcode{\sphinxupquote{bit\_vector
cvs}}, or all the convexes of the mesh. Note that the last method makes a call to
the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}auto\PYGZus{}add}\PYG{p}{(}\PYG{n}{pfem} \PYG{n}{pf}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which defines the default finite element method which will be automatically added
on new elements of the mesh (this is very useful, for instance, when a refinement
of the mesh is performed).

Descriptors for finite element methods and integration methods are available
thanks to the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pfem} \PYG{n}{pf} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{fem\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{name of method}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{"name of method"}} is to be chosen among the existing methods. A name of a
method can be retrieved thanks to the following functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{femname} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{name\PYGZus{}of\PYGZus{}fem}\PYG{p}{(}\PYG{n}{pf}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

A non exhaustive list (see {\hyperref[\detokenize{userdoc/appendixA:ud-appendixa}]{\sphinxcrossref{\DUrole{std,std-ref}{Appendix A. Finite element method list}}}} or \sphinxcode{\sphinxupquote{getfem/getfem\_fem.h}} for
exhaustive lists) of finite element methods is given by:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{"FEM\_PK(n,k)"}}: Classical \(P_K\) methods on simplexes of dimension \sphinxcode{\sphinxupquote{n}}
with degree \sphinxcode{\sphinxupquote{k}} polynomials.

\item {} 
\sphinxcode{\sphinxupquote{"FEM\_QK(n,k)"}}: Classical \(Q_K\) methods on parallelepiped of dimension
\sphinxcode{\sphinxupquote{n}}. Tensorial product of degree \sphinxcode{\sphinxupquote{k}} \(P_K\) method on the segment.

\item {} 
\sphinxcode{\sphinxupquote{"FEM\_PK\_PRISM(n,k)"}}: Classical methods on prism of dimension \sphinxcode{\sphinxupquote{n}}.
Tensorial product of two degree \sphinxcode{\sphinxupquote{k}} \(P_K\) method.

\item {} 
\sphinxcode{\sphinxupquote{"FEM\_PRODUCT(a,b)"}}: Tensorial product of the two polynomial finite element
method \sphinxcode{\sphinxupquote{a}} and \sphinxcode{\sphinxupquote{b}}.

\item {} 
\sphinxcode{\sphinxupquote{"FEM\_PK\_DISCONTINUOUS(n,k)"}}: discontinuous \(P_K\) methods on simplexes
of dimension \sphinxcode{\sphinxupquote{n}} with degree \sphinxcode{\sphinxupquote{k}} polynomials.

\end{itemize}

An alternative way to obtain a Lagrange polynomial fem suitable for a given
geometric transformation is to use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pfem} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{classical\PYGZus{}fem}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pgeometric\PYGZus{}trans} \PYG{n}{pg}\PYG{p}{,}
                                   \PYG{n}{short\PYGZus{}type} \PYG{n}{degree}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pfem} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{classical\PYGZus{}discontinuous\PYGZus{}fem}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pgeometric\PYGZus{}trans} \PYG{n}{pg}\PYG{p}{,}
                                                 \PYG{n}{short\PYGZus{}type} \PYG{n}{degree}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The \sphinxtitleref{mesh\_fem} can call directly these functions via:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}classical\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{k}{const} \PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{cvs}\PYG{p}{,}
                                            \PYG{n}{dim\PYGZus{}type} \PYG{n}{fem\PYGZus{}degree}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}classical\PYGZus{}discontinuous\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{k}{const} \PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{cvs}\PYG{p}{,}
                                                          \PYG{n}{dim\PYGZus{}type} \PYG{n}{fem\PYGZus{}degree}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}classical\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{dim\PYGZus{}type} \PYG{n}{fem\PYGZus{}degree}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}fem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}classical\PYGZus{}discontinuous\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{dim\PYGZus{}type} \PYG{n}{fem\PYGZus{}degree}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Some other methods:
\index{getfem::mesh\_fem::convex\_index (C++ function)@\spxentry{getfem::mesh\_fem::convex\_index}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem12convex_indexEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{convex\_index}}}{}{}%
\pysigstopmultiline
Set of indexes (a \sphinxcode{\sphinxupquote{dal::bit\_vector}}) on which a finite element method is defined.

\end{fulllineitems}

\index{getfem::mesh\_fem::linked\_mesh (C++ function)@\spxentry{getfem::mesh\_fem::linked\_mesh}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem11linked_meshEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{linked\_mesh}}}{}{}%
\pysigstopmultiline
gives a reference to the linked mesh.

\end{fulllineitems}

\index{getfem::mesh\_fem::fem\_of\_element (C++ function)@\spxentry{getfem::mesh\_fem::fem\_of\_element}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem14fem_of_elementE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{fem\_of\_element}}}{i}{}%
\pysigstopmultiline
gives a descriptor on the finite element method defined on element of index
\sphinxcode{\sphinxupquote{i}} (does not take into account the qdim nor the optional reduction).

\end{fulllineitems}

\index{getfem::mesh\_fem::clear (C++ function)@\spxentry{getfem::mesh\_fem::clear}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem5clearEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{clear}}}{}{}%
\pysigstopmultiline
Clears the structure, no finite element method is still defined.

\end{fulllineitems}



\section{Examples}
\label{\detokenize{userdoc/bfem:examples}}
For instance if one needs to have a description of a \(P_1\) finite element
method on a triangle, the way to set it is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{set\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{fem\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{FEM\PYGZus{}PK(2, 1)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{i}} is still the index of the triangle. It is also possible to select a
particular method directly on a set of element, passing to
\sphinxcode{\sphinxupquote{mf.set\_finite\_element}} a \sphinxcode{\sphinxupquote{dal::bit\_vector}} instead of a single index. For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{set\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{convex\PYGZus{}index}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
                      \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{fem\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{FEM\PYGZus{}PK(2, 1)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

selects the method on all the elements of the mesh.


\section{Second level: the optional “vectorization/tensorization”}
\label{\detokenize{userdoc/bfem:second-level-the-optional-vectorization-tensorization}}
If the finite element represents an unknown which is a vector field, the method \sphinxcode{\sphinxupquote{mf.set\_qdim(Q)}} allows set the target dimension for the definition of the
target dimension \(Q\).

If the target dimension \(Q\) is set to a value different of \(1\), the
scalar FEMs (such as \(P_k\) fems etc.) are automatically “vectorized” from
the \sphinxtitleref{mesh\_fem} object point of view, i.e. each scalar degree of freedom appears \(Q\)
times in order to represent the \(Q\) components of the vector field. If an
intrinsically vectorial element is used, the target dimension of the \sphinxcode{\sphinxupquote{fem}} and
the one of the \sphinxtitleref{mesh\_fem} object have to match. To sum it up,
\begin{itemize}
\item {} 
if the fem of the \(ith\) element is intrinsically a vector FEM, then:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{get\PYGZus{}qdim}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{n}{mf}\PYG{p}{.}\PYG{n}{fem\PYGZus{}of\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZgt{}}\PYG{n}{target\PYGZus{}dim}\PYG{p}{(}\PYG{p}{)}
\PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}}
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof\PYGZus{}of\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{n}{mf}\PYG{p}{.}\PYG{n}{fem\PYGZus{}of\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\item {} 
if the fem has a \sphinxcode{\sphinxupquote{target\_dim}} equal to \(1\), then:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof\PYGZus{}of\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{n}{mf}\PYG{p}{.}\PYG{n}{get\PYGZus{}qdim}\PYG{p}{(}\PYG{p}{)}\PYG{o}{*}\PYG{n}{mf}\PYG{p}{.}\PYG{n}{fem\PYGZus{}of\PYGZus{}element}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\end{itemize}

Additionally, if the field to be represented is a tensor field instead of a vector field (for instance the stress or strain tensor field in elasticity), it is possible to specify the tensor dimensions with the methods:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{set\PYGZus{}qdim}\PYG{p}{(}\PYG{n}{dim\PYGZus{}type} \PYG{n}{M}\PYG{p}{,} \PYG{n}{dim\PYGZus{}type} \PYG{n}{N}\PYG{p}{)}
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{set\PYGZus{}qdim}\PYG{p}{(}\PYG{n}{dim\PYGZus{}type} \PYG{n}{M}\PYG{p}{,} \PYG{n}{dim\PYGZus{}type} \PYG{n}{N}\PYG{p}{,} \PYG{n}{dim\PYGZus{}type} \PYG{n}{O}\PYG{p}{,} \PYG{n}{dim\PYGZus{}type} \PYG{n}{P}\PYG{p}{)}
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{set\PYGZus{}qdim}\PYG{p}{(}\PYG{k}{const} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{multi\PYGZus{}index} \PYG{o}{\PYGZam{}}\PYG{n}{mii}\PYG{p}{)}
\end{sphinxVerbatim}

respectively for a tensor field of order two, four and arbitrary (but limited to 6). For most of the operations, this is equivalent to declare a vector field of the size the product of the dimensions. However, the declared tensor dimensions are taken into account into the high level generic assembly. Remember that the components inside a tensor are stored in Fortran order.

At this level are defined the basic degrees of freedom. Some methods of the
\sphinxcode{\sphinxupquote{getfem::mesh\_fem}} allows to obtain information on the basic dofs:
\index{getfem::mesh\_fem::nb\_basic\_dof\_of\_element (C++ function)@\spxentry{getfem::mesh\_fem::nb\_basic\_dof\_of\_element}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem23nb_basic_dof_of_elementE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{nb\_basic\_dof\_of\_element}}}{i}{}%
\pysigstopmultiline
gives the number of basic degrees of freedom on the element of index \sphinxcode{\sphinxupquote{i}}.

\end{fulllineitems}

\index{getfem::mesh\_fem::ind\_basic\_dof\_of\_element (C++ function)@\spxentry{getfem::mesh\_fem::ind\_basic\_dof\_of\_element}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem24ind_basic_dof_of_elementE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{ind\_basic\_dof\_of\_element}}}{i}{}%
\pysigstopmultiline
gives a container (an array) with all the global indexes of the basic degrees
of freedom of element of index \sphinxcode{\sphinxupquote{i}}.

\end{fulllineitems}

\index{getfem::mesh\_fem::point\_of\_basic\_dof (C++ function)@\spxentry{getfem::mesh\_fem::point\_of\_basic\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem18point_of_basic_dofE1i1j}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{point\_of\_basic\_dof}}}{i, j}{}%
\pysigstopmultiline
gives a \sphinxcode{\sphinxupquote{bgeot::base\_node}} which represents the point associated with the
basic dof of local index \sphinxcode{\sphinxupquote{j}} on element of index \sphinxcode{\sphinxupquote{i}}.

\end{fulllineitems}

\index{getfem::mesh\_fem::point\_of\_basic\_dof (C++ function)@\spxentry{getfem::mesh\_fem::point\_of\_basic\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem18point_of_basic_dofE1j}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{point\_of\_basic\_dof}}}{j}{}%
\pysigstopmultiline
gives a \sphinxcode{\sphinxupquote{bgeot::base\_node}} which represents the point associated with the
basic dof of global index \sphinxcode{\sphinxupquote{j}}.

\end{fulllineitems}

\index{getfem::mesh\_fem::reference\_point\_of\_basic\_dof (C++ function)@\spxentry{getfem::mesh\_fem::reference\_point\_of\_basic\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem28reference_point_of_basic_dofE1i1j}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{reference\_point\_of\_basic\_dof}}}{i, j}{}%
\pysigstopmultiline
gives a \sphinxcode{\sphinxupquote{bgeot::base\_node}} which represents the point associated with the
basic dof of local index \sphinxcode{\sphinxupquote{j}} on element of index \sphinxcode{\sphinxupquote{i}} in the coordinates of
the reference element.

\end{fulllineitems}

\index{getfem::mesh\_fem::first\_convex\_of\_basic\_dof (C++ function)@\spxentry{getfem::mesh\_fem::first\_convex\_of\_basic\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem25first_convex_of_basic_dofE1j}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{first\_convex\_of\_basic\_dof}}}{j}{}%
\pysigstopmultiline
gives the index of the first element on which the basic degree of freedom of
global index \sphinxcode{\sphinxupquote{j}} is defined.

\end{fulllineitems}

\index{getfem::mesh\_fem::nb\_basic\_dof (C++ function)@\spxentry{getfem::mesh\_fem::nb\_basic\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem12nb_basic_dofEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{nb\_basic\_dof}}}{}{}%
\pysigstopmultiline
gives the total number of different basic degrees of freedom.

\end{fulllineitems}

\index{getfem::mesh\_fem::get\_qdim (C++ function)@\spxentry{getfem::mesh\_fem::get\_qdim}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem8get_qdimEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{get\_qdim}}}{}{}%
\pysigstopmultiline
gives the target dimension \sphinxcode{\sphinxupquote{Q}}.

\end{fulllineitems}

\index{getfem::mesh\_fem::basic\_dof\_on\_region (C++ function)@\spxentry{getfem::mesh\_fem::basic\_dof\_on\_region}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem19basic_dof_on_regionE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{basic\_dof\_on\_region}}}{i}{}%
\pysigstopmultiline
Return a \sphinxcode{\sphinxupquote{dal::bit\_vector}} which represents the indices of basic dof which are in the
set of convexes or the set of faces of index \sphinxcode{\sphinxupquote{i}} (see the \sphinxcode{\sphinxupquote{getfem::mesh}} object).

\end{fulllineitems}

\index{getfem::mesh\_fem::dof\_on\_region (C++ function)@\spxentry{getfem::mesh\_fem::dof\_on\_region}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem13dof_on_regionE1i}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{dof\_on\_region}}}{i}{}%
\pysigstopmultiline
Return a \sphinxcode{\sphinxupquote{dal::bit\_vector}} which represents the indices of dof which are in the set of
convexes or the set of faces of index \sphinxcode{\sphinxupquote{i}} (see the \sphinxcode{\sphinxupquote{getfem::mesh}} object). For a
reduced mesh\_fem, a dof is lying on a region if its potential corresponding
shape function is nonzero on this region. The extension matrix is used to make
the correspondence between basic and reduced dofs.

\end{fulllineitems}



\section{Third level: the optional linear transformation (or reduction)}
\label{\detokenize{userdoc/bfem:third-level-the-optional-linear-transformation-or-reduction}}
As described above, it is possible to provide two matrices, a reduction matrix
\(R\) and an extension matrix \(E\) which will describe a linear
transformation of the degrees of freedom. If \(V\) is the vector of basic
degrees of freedom, then \(U=RV\) will be the vector of reduced degrees of
freedom. Contrarily, given a vector \(U\) of reduced dof, \(V=EU\) will
correspond to a vector of basic dof. In simple cases, \(E\) will be simply the
transpose of \(R\). NOTE that every line of the extension matrix should be
sparse. Otherwise, each assembled matrix will be plain !

A natural condition is that \(RE = I\) where \(I\) is the identity matrix.
\index{getfem::mesh\_fem::nb\_dof (C++ function)@\spxentry{getfem::mesh\_fem::nb\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem6nb_dofEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{nb\_dof}}}{}{}%
\pysigstopmultiline
gives the total number of different degrees of freedom. If the optional
reduction is used, this will be the number of columns of the reduction matrix.
Otherwise it will return the number of basic degrees of freedom.

\end{fulllineitems}

\index{getfem::mesh\_fem::is\_reduced (C++ function)@\spxentry{getfem::mesh\_fem::is\_reduced}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem10is_reducedEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_reduced}}}{}{}%
\pysigstopmultiline
return a boolean. True if the reduction is used.

\end{fulllineitems}

\index{getfem::mesh\_fem::reduction\_matrix (C++ function)@\spxentry{getfem::mesh\_fem::reduction\_matrix}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem16reduction_matrixEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{reduction\_matrix}}}{}{}%
\pysigstopmultiline
return a const reference to the reduction matrix \(R\).

\end{fulllineitems}

\index{getfem::mesh\_fem::extension\_matrix (C++ function)@\spxentry{getfem::mesh\_fem::extension\_matrix}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem16extension_matrixEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{extension\_matrix}}}{}{}%
\pysigstopmultiline
return a const reference to the extension matrix \(E\).

\end{fulllineitems}

\index{getfem::mesh\_fem::set\_reduction\_matrices (C++ function)@\spxentry{getfem::mesh\_fem::set\_reduction\_matrices}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem22set_reduction_matricesE1R1E}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{set\_reduction\_matrices}}}{R, E}{}%
\pysigstopmultiline
Set the reduction and extension matrices to \sphinxcode{\sphinxupquote{R}} and \sphinxcode{\sphinxupquote{E}} and validate their
use.

\end{fulllineitems}

\index{getfem::mesh\_fem::set\_reduction (C++ function)@\spxentry{getfem::mesh\_fem::set\_reduction}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem13set_reductionE1b}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{set\_reduction}}}{b}{}%
\pysigstopmultiline
Where \(b\) is a boolean. Cancel the reduction if \(b\) is false and
validate it if \sphinxcode{\sphinxupquote{b}} is true. If \sphinxcode{\sphinxupquote{b}} is true, the extension and reduction
matrices have to be set previously.

\end{fulllineitems}

\index{getfem::mesh\_fem::reduce\_to\_basic\_dof (C++ function)@\spxentry{getfem::mesh\_fem::reduce\_to\_basic\_dof}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/bfem:_CPPv4N6getfem8mesh_fem19reduce_to_basic_dofE4idof}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::mesh\_fem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{reduce\_to\_basic\_dof}}}{idof}{}%
\pysigstopmultiline
Set the reduction and extension matrices corresponding to keep only the basic
dofs present in \sphinxcode{\sphinxupquote{idof}}. The parameter \sphinxcode{\sphinxupquote{idof}} is either a \sphinxcode{\sphinxupquote{dal::bit\_vector}} or a
\sphinxcode{\sphinxupquote{std::set\textless{}size\_type\textgreater{}}}. This is equivalent to the use of a
\sphinxcode{\sphinxupquote{getfem::partial\_mesh\_fem}} object.

\end{fulllineitems}



\section{Obtaining generic \sphinxtitleref{mesh\_fem}’s}
\label{\detokenize{userdoc/bfem:obtaining-generic-mf-s}}
It is possible to use the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{const} \PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{classical\PYGZus{}mesh\PYGZus{}fem}\PYG{p}{(}\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh} \PYG{o}{\PYGZam{}}\PYG{n}{mymesh}\PYG{p}{,} \PYG{n}{dim\PYGZus{}type} \PYG{n}{K}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

to get a classical polynomial \sphinxtitleref{mesh\_fem} of order \(K\) on the given \sphinxcode{\sphinxupquote{mymesh}}.
The returned \sphinxtitleref{mesh\_fem} will be destroyed automatically when its linked mesh is
destroyed. All the \sphinxtitleref{mesh\_fem} built by this function are stored in a cache, which means
that calling this function twice with the same arguments will return the same \sphinxtitleref{mesh\_fem}
object. A consequence is that you should NEVER modify this \sphinxtitleref{mesh\_fem}!


\section{The partial\_mesh\_fem object}
\label{\detokenize{userdoc/bfem:the-partial-mesh-fem-object}}
The \sphinxcode{\sphinxupquote{getfem::partial\_mesh\_fem}} object defined in the file
\sphinxcode{\sphinxupquote{getfem\_partial\_mesh\_fem.h}} allows to reduce a \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object to a set of dofs.
The interest is this is not a complete description of a finite element method, it
refers to the original \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} and just add reduction and extension matrices. For
instance, you can reduce a \sphinxtitleref{mesh\_fem} obtained by the function
\sphinxcode{\sphinxupquote{getfem::classical\_mesh\_fem(mesh, K)}} to obtain a finite element method on a
mesh region (which can be a boundary). The \sphinxcode{\sphinxupquote{getfem::partial\_mesh\_fem}} is in
particular used to obtain multiplier description to prescribed boundary
conditions.

The declaration of a \sphinxcode{\sphinxupquote{getfem::partial\_mesh\_fem}} object is the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{partial\PYGZus{}mesh\PYGZus{}fem} \PYG{n}{partial\PYGZus{}mf}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Then, one has to call the adapt method as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{partial\PYGZus{}mf}\PYG{p}{.}\PYG{n}{adapt}\PYG{p}{(}\PYG{n}{kept\PYGZus{}dof}\PYG{p}{,} \PYG{n}{rejected\PYGZus{}elt} \PYG{o}{=} \PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{kept\_dof}} and \sphinxcode{\sphinxupquote{rejected\_elt}} are some \sphinxcode{\sphinxupquote{dal::bit\_vector}}. \sphinxcode{\sphinxupquote{kept\_dof}} is the
list of dof indices of the original \sphinxtitleref{mesh\_fem} \sphinxcode{\sphinxupquote{mf}} to be kept. \sphinxcode{\sphinxupquote{rejected\_elt}} is an
optional parameter that contains a list of element indices on which the
\sphinxcode{\sphinxupquote{getfem::partial\_mesh\_fem}} states that there is no finite element method. This
is to avoid unnecessary computations during assembly procedures.


\chapter{Selecting integration methods}
\label{\detokenize{userdoc/binteg:selecting-integration-methods}}\label{\detokenize{userdoc/binteg:ud-binteg}}\label{\detokenize{userdoc/binteg::doc}}
The description of an integration method on a whole mesh is done thanks to the
structure \sphinxcode{\sphinxupquote{getfem::mesh\_im}}, defined in the file \sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_im.h}}.
Basically, this structure describes the integration method on each element of the
mesh. One can instantiate a \sphinxcode{\sphinxupquote{getfem::mesh\_im}} object as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{n}{mim}\PYG{p}{(}\PYG{n}{mymesh}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mymesh}} is an already existing mesh. The structure will be linked to this
mesh and will react when modifications will be done on it (for example when the
mesh is refined, the integration method will be also refined).

It is possible to specify element by element the integration method, so that
element of mixed types can be treated, even if the dimensions are different.

To select a particular integration method on a given element, one can use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mim}\PYG{p}{.}\PYG{n}{set\PYGZus{}integration\PYGZus{}method}\PYG{p}{(}\PYG{n}{i}\PYG{p}{,} \PYG{n}{ppi}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{i}} is the index of the element and \sphinxcode{\sphinxupquote{ppi}} is the descriptor of the
integration method. Alternative forms of this member function are:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}im}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}integration\PYGZus{}method}\PYG{p}{(}\PYG{k}{const} \PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{cvs}\PYG{p}{,}
                                      \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pintegration\PYGZus{}method} \PYG{n}{ppi}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{void} \PYG{n}{mesh\PYGZus{}im}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}integration\PYGZus{}method}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pintegration\PYGZus{}method} \PYG{n}{ppi}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which set the integration method for either the convexes listed in the \sphinxtitleref{bit\_vector} cvs,
or all the convexes of the mesh.

The list of all available descriptors of integration methods is in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_integration.h}}. Descriptors for integration methods are
available thanks to the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pintegration\PYGZus{}method} \PYG{n}{ppi} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{int\PYGZus{}method\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{name of method}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{"name of method"}} is to be chosen among the existing methods. A name of a
method can be retrieved with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{im\PYGZus{}name} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{name\PYGZus{}of\PYGZus{}int\PYGZus{}method}\PYG{p}{(}\PYG{n}{ppi}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

A non exhaustive list (see {\hyperref[\detokenize{userdoc/appendixB:ud-appendixb}]{\sphinxcrossref{\DUrole{std,std-ref}{Appendix B. Cubature method list}}}} or
\sphinxcode{\sphinxupquote{getfem/getfem\_integration.h}} for exhaustive lists) of integration methods
is given below.

Examples of exact integration methods:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{"IM\_NONE()"}}:
Dummy integration method (new in getfem++\sphinxhyphen{}1.7).

\item {} 
\sphinxcode{\sphinxupquote{"IM\_EXACT\_SIMPLEX(n)"}}:
Description of the exact integration of polynomials on the simplex of reference
of dimension \sphinxcode{\sphinxupquote{n}}.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_PRODUCT(a, b)"}}:
Description of the exact integration on the convex which is the direct product
of the convex in \sphinxcode{\sphinxupquote{a}} and in \sphinxcode{\sphinxupquote{b}}.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_EXACT\_PARALLELEPIPED(n)"}}:
Description of the exact integration of polynomials on the parallelepiped of
reference of dimension \sphinxcode{\sphinxupquote{n}}

\item {} 
\sphinxcode{\sphinxupquote{"IM\_EXACT\_PRISM(n)"}}:
Description of the exact integration of polynomials on the prism of reference of
dimension \sphinxcode{\sphinxupquote{n}}

\end{itemize}

Examples of approximated integration methods:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{"IM\_GAUSS1D(k)"}}:
Description of the Gauss integration on a segment of order \sphinxcode{\sphinxupquote{k}}. Available for
all odd values of \sphinxcode{\sphinxupquote{k \textless{}= 99}}.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_NC(n,k)"}}:
Description of the integration on a simplex of reference of dimension \sphinxcode{\sphinxupquote{n}} for
polynomials of degree \sphinxcode{\sphinxupquote{k}} with the Newton Cotes method (based on Lagrange
interpolation).

\item {} 
\sphinxcode{\sphinxupquote{"IM\_PRODUCT(a,b)"}}:
Build a method doing the direct product of methods \sphinxcode{\sphinxupquote{a}} and \sphinxcode{\sphinxupquote{b}}.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(2)"}}:
Integration on a triangle of order 2 with 3 points.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(7)"}}:
Integration on a triangle of order 7 with 13 points.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(19)"}}:
Integration on a triangle of order 19 with 73 points.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_QUAD(2)"}}:
Integration on quadrilaterals of order 2 with 3 points.

\item {} 
\sphinxcode{\sphinxupquote{"IM\_GAUSS\_PARALLELEPIPED(2,3)"}}:
Integration on quadrilaterals of order 3 with 4 points (shortcut for
\sphinxcode{\sphinxupquote{"IM\_PRODUCT(IM\_GAUSS1D(3),IM\_GAUSS1D(3))"}}).

\item {} 
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(5)"}}:
Integration on a tetrahedron of order 5 with 15 points.

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
Note that \sphinxcode{\sphinxupquote{"IM\_QUAD(3)"}} is not able to integrate exactly the base functions
of the \sphinxcode{\sphinxupquote{"FEM\_QK(2,3)"}} finite element! Since its base function are tensorial
product of 1D polynomials of degree 3, one would need to use \sphinxcode{\sphinxupquote{"IM\_QUAD(7)"}}
(6 is not available). Hence \sphinxcode{\sphinxupquote{"IM\_GAUSS\_PARALLELEPIPED(2,k)"}} should always
be preferred over \sphinxcode{\sphinxupquote{"IM\_QUAD(2*k)"}} since it has less integration points.
\end{sphinxadmonition}

An alternative way to obtain integration methods:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pintegration\PYGZus{}method} \PYG{n}{ppi} \PYG{o}{=}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{classical\PYGZus{}exact\PYGZus{}im}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pgeometric\PYGZus{}trans} \PYG{n}{pgt}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pintegration\PYGZus{}method} \PYG{n}{ppi} \PYG{o}{=}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{classical\PYGZus{}approx\PYGZus{}im}\PYG{p}{(}\PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pgeometric\PYGZus{}trans} \PYG{n}{pgt}\PYG{p}{,} \PYG{n}{dim\PYGZus{}type} \PYG{n}{d}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

These functions return an exact (i.e. analytical) integration method, or select an
approximate integration method which is able to integrate exactly polynomials of
degree \textless{}= \sphinxcode{\sphinxupquote{d}} (at least) for convexes defined with the specified geometric
transformation.


\section{Methods of the \sphinxtitleref{mesh\_im} object}
\label{\detokenize{userdoc/binteg:methods-of-the-mim-object}}
Once an integration method is defined on a mesh, it is possible to obtain
information on it with the following methods (the list is not exhaustive).
\index{built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}!mim.convex\_index()@\spxentry{mim.convex\_index()}}\index{mim.convex\_index()@\spxentry{mim.convex\_index()}!built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/binteg:mim.convex_index}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{mim.}}\sphinxbfcode{\sphinxupquote{convex\_index}}}{}{}
Set of indexes (a \sphinxcode{\sphinxupquote{dal::bit\_vector}}) on which an integration method is defined.

\end{fulllineitems}

\index{built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}!mim.linked\_mesh()@\spxentry{mim.linked\_mesh()}}\index{mim.linked\_mesh()@\spxentry{mim.linked\_mesh()}!built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/binteg:mim.linked_mesh}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{mim.}}\sphinxbfcode{\sphinxupquote{linked\_mesh}}}{}{}
Gives a reference to the linked mesh.

\end{fulllineitems}

\index{built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}!mim.int\_method\_of\_element()@\spxentry{mim.int\_method\_of\_element()}}\index{mim.int\_method\_of\_element()@\spxentry{mim.int\_method\_of\_element()}!built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/binteg:mim.int_method_of_element}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{mim.}}\sphinxbfcode{\sphinxupquote{int\_method\_of\_element}}}{\emph{\DUrole{n}{i}}}{}
Gives a descriptor on the integration method defined on element of index \sphinxcode{\sphinxupquote{i}}.

\end{fulllineitems}

\index{built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}!mim.clear()@\spxentry{mim.clear()}}\index{mim.clear()@\spxentry{mim.clear()}!built\sphinxhyphen{}in function@\spxentry{built\sphinxhyphen{}in function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/binteg:mim.clear}}\pysiglinewithargsret{\sphinxcode{\sphinxupquote{mim.}}\sphinxbfcode{\sphinxupquote{clear}}}{}{}
Clear the structure. There are no further integration method defined on the
mesh.

\end{fulllineitems}



\chapter{Mesh refinement}
\label{\detokenize{userdoc/rmesh:mesh-refinement}}\label{\detokenize{userdoc/rmesh:ud-rmesh}}\label{\detokenize{userdoc/rmesh::doc}}
Mesh refinement with the Bank et all method (see \sphinxcite{biblio:bank1983}) is available in
dimension 1, 2 or 3 for simplex meshes (segments, triangles and tetrahedrons).
For a given object \sphinxcode{\sphinxupquote{mymesh}} of type \sphinxcode{\sphinxupquote{getfem::mesh}}, the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mymesh}\PYG{p}{.}\PYG{n}{Bank\PYGZus{}refine}\PYG{p}{(}\PYG{n}{bv}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

refines the elements whose indices are stored in \sphinxcode{\sphinxupquote{bv}} (a \sphinxcode{\sphinxupquote{dal::bit\_vector}} object). The
conformity of the mesh is kept thanks to additional refinement (the so called
green triangles). Information about green triangles (in Figure
{\hyperref[\detokenize{userdoc/rmesh:ud-fig-refine}]{\sphinxcrossref{\DUrole{std,std-ref}{Example of Bank refinement in 2D}}}}) is stored on the mesh object to gather them for further
refinements (see \sphinxcite{biblio:bank1983}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=7cm]{{getfemuserrefine}.png}
\caption{Example of Bank refinement in 2D}\label{\detokenize{userdoc/rmesh:id3}}\label{\detokenize{userdoc/rmesh:ud-fig-refine}}\end{figure}

Mesh refinement is most of the time coupled with an \sphinxstyleemphasis{a posteriori} error
estimate. A very basic error estimate is available in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_error\_estimate.h}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{error\PYGZus{}estimate}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{n}{err}\PYG{p}{,} \PYG{n}{rg}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mim}} is the integration method (a \sphinxcode{\sphinxupquote{getfem::mesh\_im}} object), \sphinxcode{\sphinxupquote{mf}} is the finite
element method on which the unknown has been computed (a \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object), \sphinxcode{\sphinxupquote{U}} is
the vector of degrees of freedom of the unknown, \sphinxcode{\sphinxupquote{err}} is a sufficiently large
vector in which the error estimate is computed for each element of the mesh, and
\sphinxcode{\sphinxupquote{rg}} is a mesh region bulild from elements on which the error estimate should be computed (a \sphinxcode{\sphinxupquote{getfem::mesh\_region}} object).

This basic error estimate is only valid for order two problems and just compute
the sum of the jump in normal derivative across the elements on each edge (for
two\sphinxhyphen{}dimensional problems) or each face (for three\sphinxhyphen{}dimensional problems). This
means that for each face \(e\) of the mesh the following quantity is
computed:
\begin{equation*}
\begin{split}\int_e |\hspace{0.01em}[\hspace{-0.12em}[
\partial_n u ]\hspace{-0.12em}]\hspace{0.01em}|^2 d \Gamma,\end{split}
\end{equation*}
where \([\hspace{-0.12em}[\partial_n u]\hspace{-0.12em}]\) is the jump of the normal derivative. Then, the error estimate for a given element is the sum of the computed quantities on each internal face multiplied by the element diameter. This basic error estimate can be taken as a model for more elaborated ones. It uses the high\sphinxhyphen{}level generic assembly and the \sphinxcode{\sphinxupquote{neighbor\_element}} interpolate transformation (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-inter-elt-disc}]{\sphinxcrossref{\DUrole{std,std-ref}{Evaluating discontinuities across inter\sphinxhyphen{}element edges/faces}}}}).

\index{asm@\spxentry{asm}}\index{generic assembly@\spxentry{generic assembly}}\ignorespaces 

\chapter{Compute arbitrary terms \sphinxhyphen{} high\sphinxhyphen{}level generic assembly procedures \sphinxhyphen{} Generic Weak\sphinxhyphen{}Form Language (GWFL)}
\label{\detokenize{userdoc/gasm_high:compute-arbitrary-terms-high-level-generic-assembly-procedures-generic-weak-form-language-gwfl}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high}}\label{\detokenize{userdoc/gasm_high:index-0}}\label{\detokenize{userdoc/gasm_high::doc}}
This section presents what is now the main generic assembly of \sphinxstyleemphasis{GetFEM}. It is a high\sphinxhyphen{}level generic assembly in the sense that it is based on Generic Weak Form Language (GWFL, \sphinxcite{biblio:getfem2020}) to describe the weak formulation of boundary value problems of partial differential equations. A symbolic differentiation algorithm is used. It simplifies a lot the approximation of nonlinear coupled problems since only the weak form is necessary to be described, the tangent system being automatically computed. Moreover, GWFL is compiled into optimized instructions before the evaluation on each integration point in order to obtain a an optimal computational cost.

The header file to be included to use the high\sphinxhyphen{}level generic assembly procedures in C++ is \sphinxcode{\sphinxupquote{getfem/generic\_assembly.h}}.


\section{Overview of GWFL}
\label{\detokenize{userdoc/gasm_high:overview-of-gwfl}}
Another description of the main principles can be found in \sphinxcite{biblio:getfem2020}.

A specific weak form language has been developed to describe the weak formulation of boundary value problems. It is intended to be close to the structure of a standard weak formulation and it incorporates the following components:
\begin{itemize}
\item {} 
Variable names: A list of variables should be given. The variables are described on a finite element method or can be a simple vector of unknowns. For instance \sphinxcode{\sphinxupquote{u}}, \sphinxcode{\sphinxupquote{v}}, \sphinxcode{\sphinxupquote{p}}, \sphinxcode{\sphinxupquote{pressure}}, \sphinxcode{\sphinxupquote{electric\_field}} are valid variable names.

\item {} 
Constant names: A list of constants could be given. The rules are the same as for the variables but no test functions can be associated to constants.

\item {} 
Test functions: Can be used with respect to any of the variables. They are identified by the prefix \sphinxcode{\sphinxupquote{Test\_}} followed by the corresponding variable name. For instance  \sphinxcode{\sphinxupquote{Test\_u}}, \sphinxcode{\sphinxupquote{Test\_v}}, \sphinxcode{\sphinxupquote{Test\_p}}, \sphinxcode{\sphinxupquote{Test\_pressure}}, \sphinxcode{\sphinxupquote{Test\_electric\_field}}. For the tangent system, second order test functions are denoted \sphinxcode{\sphinxupquote{Test2\_}} followed by the variable name.

\item {} 
Gradients: Spatial gradients of variables or test functions are identified by the prefix \sphinxcode{\sphinxupquote{Grad\_}} followed by the variable name or by \sphinxcode{\sphinxupquote{Test\_}} or \sphinxcode{\sphinxupquote{Test2\_}} followed itself by the variable name. This is available for FEM variables only. For instance \sphinxcode{\sphinxupquote{Grad\_u}}, \sphinxcode{\sphinxupquote{Grad\_pressure}}, \sphinxcode{\sphinxupquote{Grad\_electric\_field}} and \sphinxcode{\sphinxupquote{Grad\_Test\_u}}, \sphinxcode{\sphinxupquote{Grad\_Test2\_v}}. For vector fields, \sphinxcode{\sphinxupquote{Div\_u}} and \sphinxcode{\sphinxupquote{Div\_Test\_u}} are some shortcuts for \sphinxcode{\sphinxupquote{Trace(Grad\_u)}} and \sphinxcode{\sphinxupquote{Trace(Grad\_Test\_u)}}, respectively.

\item {} 
Hessians: The Hessian of a variable or test function is identified by the prefix \sphinxcode{\sphinxupquote{Hess\_}} followed by the variable name or by \sphinxcode{\sphinxupquote{Test\_}} or \sphinxcode{\sphinxupquote{Test2\_}} followed itself by the variable name. This is available for FEM variables only. For instance \sphinxcode{\sphinxupquote{Hess\_u}}, \sphinxcode{\sphinxupquote{Hess\_v}}, \sphinxcode{\sphinxupquote{Hess\_p}}, \sphinxcode{\sphinxupquote{Hess\_Test2\_v}}, \sphinxcode{\sphinxupquote{Hess\_Test\_p}}, \sphinxcode{\sphinxupquote{Hess\_Test\_pressure}}.

\item {} 
A certain number of predefined scalar functions (\sphinxcode{\sphinxupquote{sin(t)}}, \sphinxcode{\sphinxupquote{cos(t)}}, \sphinxcode{\sphinxupquote{pow(t,u)}}, \sphinxcode{\sphinxupquote{sqrt(t)}}, \sphinxcode{\sphinxupquote{sqr(t)}}, \sphinxcode{\sphinxupquote{Heaviside(t)}}, …). A scalar function can be applied to scalar or vector/matrix/tensor expressions. It applies componentwise. For functions having two arguments (\sphinxcode{\sphinxupquote{pow(t,u)}}, \sphinxcode{\sphinxupquote{min(t,u)}} …) if two non\sphinxhyphen{}scalar arguments are passed, the dimension have to be the same. For instance “max({[}1;2{]},{[}0;3{]})” will return “{[}1;3{]}”.

\item {} 
A certain number of operations: \sphinxcode{\sphinxupquote{+}}, \sphinxcode{\sphinxupquote{\sphinxhyphen{}}}, \sphinxcode{\sphinxupquote{*}}, \sphinxcode{\sphinxupquote{/}}, \sphinxcode{\sphinxupquote{:}}, \sphinxcode{\sphinxupquote{.}}, \sphinxcode{\sphinxupquote{.*}}, \sphinxcode{\sphinxupquote{./}}, \sphinxcode{\sphinxupquote{@}}, \sphinxcode{\sphinxupquote{\textquotesingle{}}}, \sphinxcode{\sphinxupquote{Cross\_product(v1,v2)}}.

\item {} 
A certain number of linear operator: \sphinxcode{\sphinxupquote{Trace(M)}}, \sphinxcode{\sphinxupquote{Sym(M)}}, \sphinxcode{\sphinxupquote{Skew(M)}}, …

\item {} 
A certain number of nonlinear operator: \sphinxcode{\sphinxupquote{Norm(V)}}, \sphinxcode{\sphinxupquote{Det(M)}}, \sphinxcode{\sphinxupquote{Sym(M)}}, \sphinxcode{\sphinxupquote{Skew(M)}}, …

\item {} 
Some constants: \sphinxcode{\sphinxupquote{pi}}, \sphinxcode{\sphinxupquote{meshdim}} (the dimension of the current mesh), \sphinxcode{\sphinxupquote{qdim(u)}} and \sphinxcode{\sphinxupquote{qdims(u)}} the dimensions of the variable \sphinxcode{\sphinxupquote{u}} (the size for fixed size variables and the dimension of the vector field for FEM variables), \sphinxcode{\sphinxupquote{Id(n)}} the identity \(n\times n\) matrix.

\item {} 
Parentheses can be used to change the operations order in a standard way. For instance \sphinxcode{\sphinxupquote{(1+2)*4}} or \sphinxcode{\sphinxupquote{(u+v)*Test\_u}} are valid expressions.

\item {} 
The access to a component of a vector/matrix/tensor can be done by following a term by a left parenthesis, the list of components and a right parenthesis. For instance \sphinxcode{\sphinxupquote{{[}1,1,2{]}(3)}} is correct and will return \sphinxcode{\sphinxupquote{2}}. Note that indices are assumed to begin by 1 (even in C++ and with the python interface). A colon can replace the value of an index in a Matlab like syntax.

\item {} 
Explicit vectors: For instance \sphinxcode{\sphinxupquote{{[}1;2;3;4{]}}} is an explicit vector of size four. Each component can be an expression.

\item {} 
Explicit matrices: For instance \sphinxcode{\sphinxupquote{{[}1,3;2,4{]}}} and \sphinxcode{\sphinxupquote{{[}{[}1,2{]},{[}3,4{]}{]}}} denote the same 2x2 matrix. Each component can be an expression.

\item {} 
Explicit fourth order tensors: example of explicit 3x2x2x2 fourth order tensor in the nested format: \sphinxcode{\sphinxupquote{{[}{[}{[}{[}1,2,3{]},{[}1,2,3{]}{]},{[}{[}1,2,3{]},{[}1,2,3{]}{]}{]},{[}{[}{[}1,2,3{]},{[}1,2,3{]}{]},{[}{[}1,2,3{]},{[}1,2,3{]}{]}{]}{]}}}.

\item {} 
\sphinxcode{\sphinxupquote{X}} is the current coordinate on the real element, \sphinxcode{\sphinxupquote{X(i)}} is its i\sphinxhyphen{}th component.

\item {} 
\sphinxcode{\sphinxupquote{Normal}} is the outward unit normal vector to a boundary, when integrating on a domain boundary, or the unit normal vector to a level\sphinxhyphen{}set when integrating on a level\sphinxhyphen{}set with a \sphinxcode{\sphinxupquote{mesh\_im\_level\_set}} method. In the latter case, the normal vector is in the direction of the level\sphinxhyphen{}set function gradient.

\item {} 
\sphinxcode{\sphinxupquote{Reshape(t, i, j, ...)}}: Reshape a vector/matrix/tensor. Note that all tensors in \sphinxstyleemphasis{GetFEM} are stored in the Fortran order.

\item {} 
A certain number of linear and nonlinear operators (\sphinxcode{\sphinxupquote{Trace}}, \sphinxcode{\sphinxupquote{Norm}}, \sphinxcode{\sphinxupquote{Det}}, \sphinxcode{\sphinxupquote{Deviator}}, \sphinxcode{\sphinxupquote{Contract}}, …). The nonlinear operators cannot be applied to test functions.

\item {} 
\sphinxcode{\sphinxupquote{Diff(expression, variable)}}: The possibility to explicit differentiate an expression with respect to a variable (symbolic differentiation).

\item {} 
\sphinxcode{\sphinxupquote{Diff(expression, variable, direction)}}: computes the derivative of \sphinxcode{\sphinxupquote{expression}} with respect to \sphinxcode{\sphinxupquote{variable}} in the direction \sphinxcode{\sphinxupquote{direction}}.

\item {} 
\sphinxcode{\sphinxupquote{Grad(expression)}}: When possible, symbolically derive the gradient of the given expression.

\item {} 
Possiblility of macro definition (in the model, the ga\_workspace object or directly in the assembly string). The macros should be some valid expressions that are expanded inline at the lexical analysis phase (if they are used several times, the computation is automatically factorized at the compilation stage).

\item {} 
\sphinxcode{\sphinxupquote{Interpolate(variable, transformation)}}: Powerful operation which allows to interpolate the variables, or test functions either on the same mesh on other elements or on another mesh. \sphinxcode{\sphinxupquote{transformation}} is an object stored by the workspace or model object which describes the map from the current point to the point where to perform the interpolation. This functionality can be used for instance to prescribe periodic conditions or to compute mortar matrices for two finite element spaces defined on different meshes or more generally for fictitious domain methods such as fluid\sphinxhyphen{}structure interaction.

\item {} 
\sphinxcode{\sphinxupquote{Elementary\_transformation(variable, transformation, dest)}}: Allow a linear transformation defined at the element level (i.e. not possible to define at the gauss point level). This feature has been added mostly for defining a reduction for plate elements (projection onto low\sphinxhyphen{}level vector element such as rotated RT0). \sphinxcode{\sphinxupquote{transformation}} is an object stored by the workspace or model object which describes the trasformation for a particular element. \sphinxcode{\sphinxupquote{dest}} is an optional argument refering to a model variable or data whose fem will be the target fem of the transformation. If omitted, the target fem of the transformation is the one of the first variable.

\item {} 
Possibility of integration on the direct product of two\sphinxhyphen{}domains for double integral computation or coupling of two variables with a Kernel / convolution / exchange integral. This allows terms like \(\displaystyle\int_{\Omega_1}\int_{\Omega_2}k(x,y)u(x)v(y)dydx\) with \(\Omega_1\) and \(\Omega_2\) two domains, different or not, having their own meshes, integration methods and with \(u\) a variable defined on \(\Omega_1\) and \(v\) a variable defined on \(\Omega_2\). The keyword \sphinxcode{\sphinxupquote{Secondary\_domain(variable)}} allows to access to the variables on the second domain of integration.

\end{itemize}


\section{Some basic examples}
\label{\detokenize{userdoc/gasm_high:some-basic-examples}}
The weak formulation for the Poisson problem on a domain \(\Omega\)
\begin{equation*}
\begin{split}-\mbox{div } \nabla u = f, \mbox{ in } \Omega,\end{split}
\end{equation*}
with Dirichlet boundary conditions \(u = 0\) on \(\partial\Omega\) is classically
\begin{equation*}
\begin{split}\int_{\Omega} \nabla u\cdot \nabla v dx = \int_{\Omega} f v dx,\end{split}
\end{equation*}
for all test functions \(v\) vanishing on  \(\partial\Omega\).
The corresponding expression on the assembly string is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Grad\PYGZus{}u.Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} my\PYGZus{}f*Test\PYGZus{}u
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{my\_f}} is the expression of the source term. If now the equation is
\begin{equation*}
\begin{split}-\mbox{div } a\nabla u = f, \mbox{ in } \Omega,\end{split}
\end{equation*}
for \sphinxcode{\sphinxupquote{a}} a scalar coefficient, the corresponding assembly string is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
a*Grad\PYGZus{}u.Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} my\PYGZus{}f*Test\PYGZus{}u
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{a}} has to be declared as a scalar constant or a scalar field. Not that is is also possible to describe it explicitly. For instance the problem
\begin{equation*}
\begin{split}-\mbox{div } \sin(x_1+x_2)\nabla u = f, \mbox{ in } \Omega,\end{split}
\end{equation*}
where \(x_1, x_2\) are the coordinates on the mesh, can be expressed:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
sin(X(1)+X(2))*Grad\PYGZus{}u.Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} my\PYGZus{}f*Test\PYGZus{}u
\end{sphinxVerbatim}

Another classical equation is linear elasticity:
\begin{equation*}
\begin{split}-\mbox{div } \sigma(u) = f, \mbox{ in } \Omega,\end{split}
\end{equation*}
for \(u\) a vector field and \(\sigma(u) = \lambda \mbox{div } u + \mu (\nabla u + (\nabla u)^T)\) when isotropic linear elasticity is considered. The corresponding assembly string to describe the weak formulation can be written:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}(lambda*Trace(Grad\PYGZus{}u)*Id(qdim(u)) + mu*(Grad\PYGZus{}u+Grad\PYGZus{}u\PYGZsq{})):Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} my\PYGZus{}f.Test\PYGZus{}u\PYGZdq{}
\end{sphinxVerbatim}

or:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}lambda*Div\PYGZus{}u*Div\PYGZus{}Test\PYGZus{}u + mu*(Grad\PYGZus{}u + Grad\PYGZus{}u\PYGZsq{}):Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} my\PYGZus{}f.Test\PYGZus{}u\PYGZdq{}
\end{sphinxVerbatim}

Here again, the coefficients \sphinxcode{\sphinxupquote{lambda}} and \sphinxcode{\sphinxupquote{mu}} can be given constants, or scalar field or explicit expression or even expression coming from some other variables in order to couples some problems. For instance, if the coefficients depends on a temperature field one can write:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}my\PYGZus{}f1(theta)*Div\PYGZus{}u*Div\PYGZus{}Test\PYGZus{}u + my\PYGZus{}f2(theta)*(Grad\PYGZus{}u + Grad\PYGZus{}u\PYGZsq{}):Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} my\PYGZus{}f.Grad\PYGZus{}Test\PYGZus{}u\PYGZdq{}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{theta}} is the temperature which can be the solution to a Poisson equation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}Grad\PYGZus{}theta.Grad\PYGZus{}Test\PYGZus{}theta \PYGZhy{} my\PYGZus{}f*Grad\PYGZus{}Test\PYGZus{}theta\PYGZdq{}
\end{sphinxVerbatim}

and \sphinxcode{\sphinxupquote{my\_f1}} and \sphinxcode{\sphinxupquote{my\_f2}} are some given functions. Note that in that case, the problem is nonlinear due to the coupling, even if the two functions  \sphinxcode{\sphinxupquote{my\_f1}} and \sphinxcode{\sphinxupquote{my\_f2}} are linear.


\section{Derivation order and symbolic differentiation}
\label{\detokenize{userdoc/gasm_high:derivation-order-and-symbolic-differentiation}}
The derivation order of the assembly string is automatically detected. This means that if no test functions are found, the order will be considered to be 0 (potential energy), if first order test functions are found, the order will be considered to be 1 (weak formulation) and if both first and second order test functions are found, the order will be considered to be 2 (tangent system).

In order to perform an assembly (see next section), one should specify the order (0, 1 or 2). If an order 1 string is furnished and an order 2 assembly is required, a symbolic differentiation of the expression is performed. The same if an order 0 string is furnished and if an order 1 or 2 assembly is required. Of course, the converse is not true. If an order 1 expression is given and an order 0 assembly is expected, no integration is performed. This should not be generally not possible since an arbitrary weak formulation do not necessary derive from a potential energy.

The standard way to use the generic assembly is to furnish order 1 expressions (i.e. a weak formulation). If a potential energy exists, one may furnish it. However, it will be derived twice to obtain the tangent system which could result in complicated expressions. For nonlinear problems, it is not allowed to furnish order 2 expressions directly. The reason is that the weak formulation is necessary to obtain the residual. So nothing could be done with a tangent term without having the corresponding order 1 term.

IMPORTANT REMARK: Note that for coupled problems, a global potential frequently do not exists. So that the part of problems directly defined with a potential may be difficult to couple. To illustrate this, if you defined a potential with some parameters (elasticity coefficients for instance), and the couplingconsists in a variation of these coefficients with respect to another variable, then the weak formulation do not consist of course in the derivative of the potential with respect to the coefficients which has generally no sense. This is the reason why the definition through a potential should be the exception.


\section{C++ Call of the assembly}
\label{\detokenize{userdoc/gasm_high:c-call-of-the-assembly}}
Note that the most natural way to use the generic assembly is by the use of the generic assembly bricks of the model object, see Section {\hyperref[\detokenize{userdoc/model_generic_assembly:ud-model-generic-assembly}]{\sphinxcrossref{\DUrole{std,std-ref}{Generic assembly bricks}}}}. It is however also possible to use the high level generic assembly on its own.

The generic assembly is driven by the object \sphinxcode{\sphinxupquote{getfem::ga\_workspace}} defined in \sphinxcode{\sphinxupquote{getfem/getfem\_generic\_assembly.h}}.

There is two ways to define a \sphinxcode{\sphinxupquote{getfem::ga\_workspace}} object. It can depend on a model (see {\hyperref[\detokenize{userdoc/model:ud-model}]{\sphinxcrossref{\DUrole{std,std-ref}{The model description and basic model bricks}}}}) and should be declared as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace(model);
\end{sphinxVerbatim}

with \sphinxcode{\sphinxupquote{model}} a previously define \sphinxcode{\sphinxupquote{getfem::model}} object. In that case the variable and constant considered are the one of the model. The second way it to define an independent \sphinxcode{\sphinxupquote{getfem::ga\_workspace}} object by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
\end{sphinxVerbatim}

In that case, the variable and constant have to be added to the workspace. This can be done thanks to the following methods:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.add\PYGZus{}fem\PYGZus{}variable(name, mf, I, V);

workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}variable(name, I, V);

workspace.add\PYGZus{}fem\PYGZus{}constant(name, mf, V);

workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}constant(name, V);

workspace.add\PYGZus{}im\PYGZus{}data(name, imd, V);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{name}} is the variable/constant name (see in the next sections the restriction on possible names), \sphinxcode{\sphinxupquote{mf}} is the \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object describing the finite element method, \sphinxcode{\sphinxupquote{I}} is an object of class \sphinxcode{\sphinxupquote{gmm::sub\_interval}} indicating the interval of the variable on the assembled vector/matrix and \sphinxcode{\sphinxupquote{V}} is a \sphinxcode{\sphinxupquote{getfem::base\_vector}} being the value of the variable/constant. The last method add a constant defined on an \sphinxcode{\sphinxupquote{im\_data}} object \sphinxcode{\sphinxupquote{imd}} which allows to store scalar/vector/tensor field informations on the integration points of an \sphinxcode{\sphinxupquote{mesh\_im}} object.

Once it is declared and once the variables and constant are declared, it is possible to add assembly string to the workspace with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.add\PYGZus{}expression(\PYGZdq{}my expression\PYGZdq{}, mim, rg = all\PYGZus{}convexes());
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{"my expression"}} is the assembly string, \sphinxcode{\sphinxupquote{mim}} is a \sphinxcode{\sphinxupquote{getfem::mesh\_im}} object and \sphinxcode{\sphinxupquote{rg}} if an optional valid region of the mesh corresponding to \sphinxcode{\sphinxupquote{mim}}.

As it is explained in the previous section, the order of the string will be automatically detected and a symbolic differentiation will be performed to obtain the corresponding tangent term.

Once assembly strings are added to the workspace, is is possible to call:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.assembly(order);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{order}} should be equal to 0 (potential energy), 1 (residual vector) or 2 (tangent term, or stiffness matrix for linear problems). The result of the assembly is available as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.assembled\PYGZus{}potential() // For order = 0

workspace.assembled\PYGZus{}vector()    // For order = 1

workspace.assembled\PYGZus{}matrix()    // For order = 2
\end{sphinxVerbatim}

By default, the assembled potential, vector and matrix is initialized to zero at the beginning of the assembly. It is however possible (and recommended) to set the assembly vector and matrix to external ones to perform an incremental assembly. The two methods:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.set\PYGZus{}assembled\PYGZus{}vector(getfem::base\PYGZus{}vector \PYGZam{}V);

workspace.set\PYGZus{}assembled\PYGZus{}matrix(getfem::model\PYGZus{}real\PYGZus{}sparse\PYGZus{}matrix \PYGZam{}K);
\end{sphinxVerbatim}

allows to do so. Be aware to give a vector and a matrix of the right dimension.

Note also that the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.clear\PYGZus{}expressions();
\end{sphinxVerbatim}

allows to cancel all furnished expressions and allows to re\sphinxhyphen{}use the same workspace for another assembly.

It is also possible to call the generic assembly from the Python/Scilab/Octave/Matlab interface. See \sphinxcode{\sphinxupquote{gf\_asm}} command of the interface for more details.


\section{C++ assembly examples}
\label{\detokenize{userdoc/gasm_high:c-assembly-examples}}
As a first example, if one needs to perform the assembly of a Poisson problem
\begin{equation*}
\begin{split}-\mbox{div } \nabla u = f, \mbox{ in } \Omega,\end{split}
\end{equation*}
the stiffness matrix is given
\begin{equation*}
\begin{split}K_{i,j} = \int_{\Omega} \nabla \varphi_i \cdot \nabla \varphi_j dx,\end{split}
\end{equation*}
and will be assembled by the following code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
getfem::size\PYGZus{}type nbdof = mf.nb\PYGZus{}dof();
getfem::base\PYGZus{}vector U(nbdof);
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}u\PYGZdq{}, mf, gmm::sub\PYGZus{}interval(0, nbdof), U);
workspace.add\PYGZus{}expression(\PYGZdq{}Grad\PYGZus{}u.Grad\PYGZus{}Test\PYGZus{}u\PYGZdq{}, mim);
getfem::model\PYGZus{}real\PYGZus{}sparse\PYGZus{}matrix K(nbdof, nbdof);
workspace.set\PYGZus{}assembled\PYGZus{}matrix(K);
workspace.assembly(2);
\end{sphinxVerbatim}

where of course, \sphinxcode{\sphinxupquote{mf}} is supposed to be an already declared \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object and \sphinxcode{\sphinxupquote{mim}} a already declared \sphinxcode{\sphinxupquote{getfem::mesh\_im}} object on the same mesh. Note that the value of the variable do not really intervene because of the linearity of the problem. This allows to pass \sphinxcode{\sphinxupquote{getfem::base\_vector(nbdof)}} as the value of the variable which will not be used. Note also that two other possible expressions for exactly the same result for the assembly string are \sphinxcode{\sphinxupquote{"Grad\_Test2\_u.Grad\_Test\_u"}} (i.e. an order 2 expression) or \sphinxcode{\sphinxupquote{"Norm\_sqr(Grad\_u)/2"}} (i.e. a potential). In fact other possible assembly string will give the same result such as \sphinxcode{\sphinxupquote{"Grad\_u.Grad\_u/2"}} or \sphinxcode{\sphinxupquote{"{[}Grad\_u(1), Grad\_u(2){]}.{[}Grad\_Test\_u(1), Grad\_Test\_u(2){]}"}} for two\sphinxhyphen{}dimensional problems. However, the recommendation is preferably to give an order 1 expression (weak formulation) if there is no particular reason to prefer an order 0 or an order 2 expression.

As a second example, let us consider a coupled problem, for instance the mixed problem of incompressible elasticity given by the equations
\begin{align*}\!\begin{aligned}
-\mbox{div}(\mu(\nabla u + (\nabla u)^T - p I_d)  = f, \mbox{ in } \Omega,\\
\mbox{div } u = 0.\\
\end{aligned}\end{align*}
where \sphinxcode{\sphinxupquote{u}} is the vector valued displacement and \sphinxcode{\sphinxupquote{p}} the pressure. The assembly of the matrix for the whole coupled system can be performed as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
getfem::size\PYGZus{}type nbdofu = mf\PYGZus{}u.nb\PYGZus{}dof();
getfem::size\PYGZus{}type nbdofp = mf\PYGZus{}p.nb\PYGZus{}dof();
getfem::base\PYGZus{}vector U(nbdofu);
getfem::base\PYGZus{}vector P(nbdofp);
getfem::base\PYGZus{}vector vmu(1); vmu[0] = mu;
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}u\PYGZdq{}, mf\PYGZus{}u, gmm::sub\PYGZus{}interval(0, nbdofu), U);
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}p\PYGZdq{}, mf\PYGZus{}p, gmm::sub\PYGZus{}interval(nbdofu, nbdofp), P);
workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}constant(\PYGZdq{}mu\PYGZdq{}, vmu);
workspace.add\PYGZus{}expression(\PYGZdq{}2*mu*Sym(Grad\PYGZus{}u):Grad\PYGZus{}Test\PYGZus{}u\PYGZdq{}
                      \PYGZdq{}\PYGZhy{} p*Trace(Grad\PYGZus{}Test\PYGZus{}u) \PYGZhy{} Test\PYGZus{}p*Trace(Grad\PYGZus{}u)\PYGZdq{}, mim);
getfem::model\PYGZus{}real\PYGZus{}sparse\PYGZus{}matrix K(nbdofu+nbdofp, nbdofu+nbdofp);
workspace.set\PYGZus{}assembled\PYGZus{}matrix(K);
workspace.assembly(2);
\end{sphinxVerbatim}

where, here, \sphinxcode{\sphinxupquote{mf\_u}} and \sphinxcode{\sphinxupquote{mf\_p}} are supposed to be some already declared \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} objects defined on the same mesh, \sphinxcode{\sphinxupquote{mim}} a already declared \sphinxcode{\sphinxupquote{getfem::mesh\_im}} object and \sphinxcode{\sphinxupquote{mu}} is the Lame coefficient. It is also possible to perform the assembly of the sub\sphinxhyphen{}matrix of this system separately.

Let us see now how to perform the assembly of a source term. The weak formulation of a volumic source term is
\begin{equation*}
\begin{split}\int_{\Omega} fv dx\end{split}
\end{equation*}
where \(f\) is the source term and \(v\) the test function. The corresponding assembly can be written:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
getfem::size\PYGZus{}type nbdofu = mf\PYGZus{}u.nb\PYGZus{}dof();
getfem::base\PYGZus{}vector U(nbdofu);
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}u\PYGZdq{}, mf\PYGZus{}u, gmm::sub\PYGZus{}interval(0, nbdofu), U);
workspace.add\PYGZus{}fem\PYGZus{}constant(\PYGZdq{}f\PYGZdq{}, mf\PYGZus{}data, F);
workspace.add\PYGZus{}expression(\PYGZdq{}f*Test\PYGZus{}u\PYGZdq{}, mim);
getfem::base\PYGZus{}vector L(nbdofu);
workspace.set\PYGZus{}assembled\PYGZus{}vector(L);
workspace.assembly(1);
\end{sphinxVerbatim}

if the source term is describe on a finite element \sphinxcode{\sphinxupquote{mf\_data}} and the corresponding vector of degrees of freedom \sphinxcode{\sphinxupquote{F}}. Explicit source terms are also possible. For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
getfem::size\PYGZus{}type nbdofu = mf\PYGZus{}u.nb\PYGZus{}dof();
getfem::base\PYGZus{}vector U(nbdofu);
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}u\PYGZdq{}, mf\PYGZus{}u, gmm::sub\PYGZus{}interval(0, nbdofu), U);
workspace.add\PYGZus{}expression(\PYGZdq{}sin(X(1)+X(2))*Test\PYGZus{}u\PYGZdq{}, mim);
getfem::base\PYGZus{}vector L(nbdofu);
workspace.set\PYGZus{}assembled\PYGZus{}vector(L);
workspace.assembly(1);
\end{sphinxVerbatim}

is also valid. If the source term is a boundary term (in case of a Neumann condition) the only difference is that the mesh region corresponding to the boundary have to be given as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.add\PYGZus{}expression(\PYGZdq{}sin(X(1)+X(2))*Test\PYGZus{}u\PYGZdq{}, mim, region);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{region}} is the mesh region number.

As another example, let us describe a simple nonlinear elasticity problem. Assume that we consider a Saint\sphinxhyphen{}Venant Kirchhoff constitutive law which means that we consider the following elastic energy on a body of reference configuration \(\Omega\):
\begin{equation*}
\begin{split}\int_{\Omega} \dfrac{\lambda}{2} (\mbox{tr}(E))^2 + \mu \mbox{tr}(E^2) dx\end{split}
\end{equation*}
where \(\lambda, \mu\) are the Lamé coefficients and  \(E\) is the strain tensor given by \(E = (\nabla u + (\nabla u)^T + (\nabla u)^T\nabla u)/2\).

This is possible to perform the assembly of the corresponding tangent problem as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
getfem::size\PYGZus{}type nbdofu = mf\PYGZus{}u.nb\PYGZus{}dof();
getfem::base\PYGZus{}vector vlambda(1); vlambda[0] = lambda;
getfem::base\PYGZus{}vector vmu(1); vmu[0] = mu;
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}u\PYGZdq{}, mf\PYGZus{}u, gmm::sub\PYGZus{}interval(0, nbdofu), U);
workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}constant(\PYGZdq{}lambda\PYGZdq{}, vlambda);
workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}constant(\PYGZdq{}mu\PYGZdq{}, vmu);
workspace.add\PYGZus{}expression(\PYGZdq{}lambda*sqr(Trace(Grad\PYGZus{}u+Grad\PYGZus{}u\PYGZsq{}+Grad\PYGZus{}u\PYGZsq{}*Grad\PYGZus{}u))\PYGZdq{}
                         \PYGZdq{}+ mu*Trace((Grad\PYGZus{}u+Grad\PYGZus{}u\PYGZsq{}+Grad\PYGZus{}u\PYGZsq{}*Grad\PYGZus{}u)\PYGZdq{}
                         \PYGZdq{}*(Grad\PYGZus{}u+Grad\PYGZus{}u\PYGZsq{}+Grad\PYGZus{}u\PYGZsq{}*Grad\PYGZus{}u))\PYGZdq{}, mim);
getfem::base\PYGZus{}vector L(nbdofu);
workspace.set\PYGZus{}assembled\PYGZus{}vector(V);
workspace.assembly(1);
getfem::model\PYGZus{}real\PYGZus{}sparse\PYGZus{}matrix K(nbdofu, nbdofu);
workspace.set\PYGZus{}assembled\PYGZus{}matrix(K);
workspace.assembly(2);
\end{sphinxVerbatim}

and to adapt a Newton\sphinxhyphen{}Raphson algorithm to solve that nonlinear problem. Of course the expression is rather repetitive and it would be preferable to define some intermediate nonlinear operators. However, note that repeated expressions are automatically detected and computed only once in the assembly.

The last example is the assembly of the stiffness matrix of an order four problem, the Kirchhoff\sphinxhyphen{}Love plate problem:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::ga\PYGZus{}workspace workspace;
getfem::size\PYGZus{}type nbdofu = mf\PYGZus{}u.nb\PYGZus{}dof();
getfem::base\PYGZus{}vector vD(1); vD[0] = D;
getfem::base\PYGZus{}vector vnu(1); vnu[0] = nu;
workspace.add\PYGZus{}fem\PYGZus{}variable(\PYGZdq{}u\PYGZdq{}, mf\PYGZus{}u, gmm::sub\PYGZus{}interval(0, nbdofu), U);
workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}constant(\PYGZdq{}D\PYGZdq{}, vD);
workspace.add\PYGZus{}fixed\PYGZus{}size\PYGZus{}constant(\PYGZdq{}nu\PYGZdq{}, vnu);
workspace.add\PYGZus{}expression(\PYGZdq{}D*(1\PYGZhy{}nu)*(Hess\PYGZus{}u:Hess\PYGZus{}Test\PYGZus{}u) \PYGZhy{}\PYGZdq{}
                         \PYGZdq{}D*nu*Trace(Hess\PYGZus{}u)*Trace(Hess\PYGZus{}Test\PYGZus{}u)\PYGZdq{}, mim);
getfem::model\PYGZus{}real\PYGZus{}sparse\PYGZus{}matrix K(nbdofu, nbdofu);
workspace.set\PYGZus{}assembled\PYGZus{}matrix(K);
workspace.assembly(2);
\end{sphinxVerbatim}

with \sphinxcode{\sphinxupquote{D}} the flexion modulus and \sphinxcode{\sphinxupquote{nu}} the Poisson ratio.


\section{Script languages call of the assembly}
\label{\detokenize{userdoc/gasm_high:script-languages-call-of-the-assembly}}
For the use with Python, Scilab, Octave or Matlab interfaces, see the respective documentation, in particular the \sphinxcode{\sphinxupquote{gf\_asm}} command and the \sphinxcode{\sphinxupquote{model}} object.


\section{The tensors}
\label{\detokenize{userdoc/gasm_high:the-tensors}}
Basically, what is manipulated in GWFL are tensors. This can be order 0 tensors in scalar expressions (for instance in \sphinxcode{\sphinxupquote{3+sin(pi/2)}}), order 1 tensors in vector expressions (such as \sphinxcode{\sphinxupquote{X.X}} or \sphinxcode{\sphinxupquote{Grad\_u}} if u is a scalar variable), order 2 tensors for matrix expressions and so on. For efficiency reasons, the language manipulates tensors up to order six. The language could be easily extended to support tensors of order greater than six but it may lead to inefficient computations. When an expression contains test functions (as in \sphinxcode{\sphinxupquote{Trace(Grad\_Test\_u)}} for a vector field \sphinxcode{\sphinxupquote{u}}), the computation is done for each test functions, which means that the tensor implicitly have a supplementary component. This means that, implicitly, the maximal order of manipulated tensors are in fact six (in \sphinxcode{\sphinxupquote{Grad\_Test\_u:Grad\_Test2\_u}} there are two components implicitly added for first and second order test functions).

Order four tensors are necessary for instance to express elasticity tensors or in general to obtain the tangent term for vector valued unknowns.


\section{The variables}
\label{\detokenize{userdoc/gasm_high:the-variables}}
A list of variables should be given to the \sphinxcode{\sphinxupquote{ga\_worspace}} object (directly or through a model object). The variables are described on a finite element method or can be a simple vector of unknowns. This means that it is possible also to couple algebraic equations to pde ones on a model. A variable name should begin by a letter (case sensitive) or an underscore followed by a letter, a number or an underscore. Some name are reserved, this is the case of operators names (\sphinxcode{\sphinxupquote{Det}}, \sphinxcode{\sphinxupquote{Norm}}, \sphinxcode{\sphinxupquote{Trace}}, \sphinxcode{\sphinxupquote{Deviator}}, …) and thus cannot be used as variable names. The name should not begin by \sphinxcode{\sphinxupquote{Test\_}}, \sphinxcode{\sphinxupquote{Test2\_}}, \sphinxcode{\sphinxupquote{Grad\_}}, \sphinxcode{\sphinxupquote{Div\_}} or \sphinxcode{\sphinxupquote{Hess\_}}. The variable name should not correspond to a predefined function (\sphinxcode{\sphinxupquote{sin}}, \sphinxcode{\sphinxupquote{cos}}, \sphinxcode{\sphinxupquote{acos}} …) and to constants (\sphinxcode{\sphinxupquote{pi}}, \sphinxcode{\sphinxupquote{Normal}}, \sphinxcode{\sphinxupquote{X}}, \sphinxcode{\sphinxupquote{Id}} …).


\section{The constants or data}
\label{\detokenize{userdoc/gasm_high:the-constants-or-data}}
A list of constants could also be given to the \sphinxcode{\sphinxupquote{ga\_worspace}} object. The rule are the same as for the variables but no test function can be associated to constants and there is no symbolic differentiation with respect to constants. Scalar constants are often defined to represent the coefficients which intervene in constitutive laws. Additionally, constants can be some scalar/vector/tensor fields defined on integration points via a \sphinxcode{\sphinxupquote{im\_data}} object (for instance for some implementation of the approximation of constitutive laws such as plasticity).


\section{Test functions}
\label{\detokenize{userdoc/gasm_high:test-functions}}
Each variable is associated with first order and second order test functions.
The first order test function are used in the weak formulation (which derive form the potential equation if it exists) and the second order test functions are used in the tangent system. For a variable \sphinxcode{\sphinxupquote{u}} the associated test functions are \sphinxcode{\sphinxupquote{Test\_u}} and \sphinxcode{\sphinxupquote{Test2\_u}}. The assembly string have to be linear with respect to test functions. As a result of the presence of the term \sphinxcode{\sphinxupquote{Test\_u}} on a assembly string, the expression will be evaluated for each shape function of the finite element corresponding to the variable \sphinxcode{\sphinxupquote{u}}. On a given element, if the finite element have \sphinxcode{\sphinxupquote{N}} shape functions ans if \sphinxcode{\sphinxupquote{u}} is a scalar field, the value of \sphinxcode{\sphinxupquote{Test\_u}} will be the value of each shape function on the current point. So \sphinxcode{\sphinxupquote{Test\_u}} return if face a vector of \sphinxcode{\sphinxupquote{N}} values. But of course, this is implicit in the language. So one do not have to care about this.


\section{Gradient}
\label{\detokenize{userdoc/gasm_high:gradient}}
The gradient of a variable or of test functions are identified by \sphinxcode{\sphinxupquote{Grad\_}} followed by the variable name or by \sphinxcode{\sphinxupquote{Test\_}} followed itself by the variable name. This is available for FEM variables (or constants) only. For instance \sphinxcode{\sphinxupquote{Grad\_u}}, \sphinxcode{\sphinxupquote{Grad\_v}}, \sphinxcode{\sphinxupquote{Grad\_p}}, \sphinxcode{\sphinxupquote{Grad\_pressure}}, \sphinxcode{\sphinxupquote{Grad\_electric\_field}} and \sphinxcode{\sphinxupquote{Grad\_Test\_u}}, \sphinxcode{\sphinxupquote{Grad\_Test\_v}}, \sphinxcode{\sphinxupquote{Grad\_Test\_p}}, \sphinxcode{\sphinxupquote{Grad\_Test\_pressure}}, \sphinxcode{\sphinxupquote{Grad\_Test\_electric\_field}}. The gradient is either a vector for scalar variables or a matrix for vector field variables. In the latter case, the first index corresponds to the vector field dimension and the second one to the index of the partial derivative.  \sphinxcode{\sphinxupquote{Div\_u}} and \sphinxcode{\sphinxupquote{Div\_Test\_u}} are some optimized shortcuts for \sphinxcode{\sphinxupquote{Trace(Grad\_u)}} and \sphinxcode{\sphinxupquote{Trace(Grad\_Test\_u)}}, respectively.


\section{Hessian}
\label{\detokenize{userdoc/gasm_high:hessian}}
Similarly, the Hessian of a variable or of test functions are identified by \sphinxcode{\sphinxupquote{Hess\_}} followed by the variable name or by \sphinxcode{\sphinxupquote{Test\_}} followed itself by the variable name. This is available for FEM variables only. For instance \sphinxcode{\sphinxupquote{Hess\_u}}, \sphinxcode{\sphinxupquote{Hess\_v}}, \sphinxcode{\sphinxupquote{Hess\_p}}, \sphinxcode{\sphinxupquote{Hess\_pressure}}, \sphinxcode{\sphinxupquote{Hess\_electric\_field}} and \sphinxcode{\sphinxupquote{Hess\_Test\_u}}, \sphinxcode{\sphinxupquote{Hess\_Test\_v}}, \sphinxcode{\sphinxupquote{Hess\_Test\_p}}, \sphinxcode{\sphinxupquote{Hess\_Test\_pressure}}, \sphinxcode{\sphinxupquote{Hess\_Test\_electric\_field}}. The Hessian is either a matrix for scalar variables or a third order tensor for vector field variables. In the latter case, the first index corresponds to the vector field dimension and the two remaining to the indices of partial derivatives.


\section{Predefined scalar functions}
\label{\detokenize{userdoc/gasm_high:predefined-scalar-functions}}
A certain number of predefined scalar functions can be used. The exhaustive list is the following and for most of them are equivalent to the corresponding C function:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{sqr(t)}} (the square of t, equivalent to t*t), \sphinxcode{\sphinxupquote{pow(t, u)}} (t to the power u),
\sphinxcode{\sphinxupquote{sqrt(t)}} (square root of t), \sphinxcode{\sphinxupquote{exp(t)}}, \sphinxcode{\sphinxupquote{log(t)}}, \sphinxcode{\sphinxupquote{log10(t)}}

\item {} 
\sphinxcode{\sphinxupquote{sin(t)}}, \sphinxcode{\sphinxupquote{cos(t)}}, \sphinxcode{\sphinxupquote{tan(t)}}, \sphinxcode{\sphinxupquote{asin(t)}}, \sphinxcode{\sphinxupquote{acos(t)}}, \sphinxcode{\sphinxupquote{atan(t)}}, \sphinxcode{\sphinxupquote{atan2(t, u)}}

\item {} 
\sphinxcode{\sphinxupquote{sinh(t)}}, \sphinxcode{\sphinxupquote{cosh(t)}}, \sphinxcode{\sphinxupquote{tanh(t)}}, \sphinxcode{\sphinxupquote{asinh(t)}}, \sphinxcode{\sphinxupquote{acosh(t)}}, \sphinxcode{\sphinxupquote{atanh(t)}}

\item {} 
\sphinxcode{\sphinxupquote{erf(t)}}, \sphinxcode{\sphinxupquote{erfc(t)}}

\item {} 
\sphinxcode{\sphinxupquote{sinc(t)}} (the cardinal sine function sin(t)/t)

\item {} 
\sphinxcode{\sphinxupquote{Heaviside(t)}} (\(0 \mbox{ for } t < 0, 1 \mbox{ for } t \ge 0\))

\item {} 
\sphinxcode{\sphinxupquote{sign(t)}}

\item {} 
\sphinxcode{\sphinxupquote{abs(t)}}

\item {} 
\sphinxcode{\sphinxupquote{pos\_part(t)}} (\(tH(t)\))

\item {} 
\sphinxcode{\sphinxupquote{reg\_pos\_part(t, eps)}} (\((t-eps/2-t^2/(2eps))H(t-eps) + t^2H(t)/(2eps)\))

\item {} 
\sphinxcode{\sphinxupquote{neg\_part(t)}} (\(-tH(-t)\)), \sphinxcode{\sphinxupquote{max(t, u)}}, \sphinxcode{\sphinxupquote{min(t, u)}}

\end{itemize}

A scalar function can be applied to a scalar expression, but also to a tensor one. If is is applied to a tensor expression, is is applied componentwise and the result is a tensor with the same dimensions. For functions having two arguments (pow(t,u), min(t,u) …) if two non\sphinxhyphen{}scalar arguments are passed, the dimension have to be the same. For instance “max({[}1;2{]},{[}0;3{]})” will return “{[}0;3{]}”.


\section{User defined scalar functions}
\label{\detokenize{userdoc/gasm_high:user-defined-scalar-functions}}
It is possible to add a scalar function to the already predefined ones. Note that the generic assembly consider only scalar function with one or two parameters. In order to add a scalar function to the generic assembly, one has to call:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ga\PYGZus{}define\PYGZus{}function(name, nb\PYGZus{}args, expr, der1=\PYGZdq{}\PYGZdq{}, der2=\PYGZdq{}\PYGZdq{});

ga\PYGZus{}define\PYGZus{}function(name, getfem::pscalar\PYGZus{}func\PYGZus{}onearg f1, der1=\PYGZdq{}\PYGZdq{});

ga\PYGZus{}define\PYGZus{}function(name, getfem::pscalar\PYGZus{}func\PYGZus{}twoargs f2, der1=\PYGZdq{}\PYGZdq{}, der2=\PYGZdq{}\PYGZdq{});
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{name}} is the name of the function to be defined, \sphinxcode{\sphinxupquote{nb\_args}} is equal to 1 or 2. In the first call, \sphinxcode{\sphinxupquote{expr}} is a string describing the function in GWFL and using \sphinxcode{\sphinxupquote{t}} as the first variable and \sphinxcode{\sphinxupquote{u}} as the second one (if \sphinxcode{\sphinxupquote{nb\_args}} is equal to 2). For instance, \sphinxcode{\sphinxupquote{sin(2*t)+sqr(t)}} is a valid expression. Note that it is not possible to refer to constant or data defined in a \sphinxcode{\sphinxupquote{ga\_workspace}} object. \sphinxcode{\sphinxupquote{der1}} and \sphinxcode{\sphinxupquote{der2}} are the expression of the derivatives with respect to \sphinxcode{\sphinxupquote{t}} and \sphinxcode{\sphinxupquote{u}}. They are optional. If they are not furnished, a symbolic differentiation is used if the derivative is needed. If \sphinxcode{\sphinxupquote{der1}} and \sphinxcode{\sphinxupquote{der2}} are defined to be only a function name, it will be understand that the derivative is the corresponding function. In the second call, \sphinxcode{\sphinxupquote{f1}} should be a C pointer on a scalar C function having one scalar parameter and in the third call, \sphinxcode{\sphinxupquote{f2}}  should be a C pointer on a scalar C function having two scalar parameters.

Additionally,:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
bool ga\PYGZus{}function\PYGZus{}exists(name)
\end{sphinxVerbatim}

return true is a function \sphinxcode{\sphinxupquote{name}} is already defined and:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ga\PYGZus{}undefine\PYGZus{}function(name)
\end{sphinxVerbatim}

cancel the definition of an already define function (it has no action if the function does not exist) which allow to redefine a function.


\section{Derivatives of defined scalar functions}
\label{\detokenize{userdoc/gasm_high:derivatives-of-defined-scalar-functions}}
It is possible to refer directly to the derivative of defined functions by adding the prefix \sphinxcode{\sphinxupquote{Derivative\_}} to the function name. For instance, \sphinxcode{\sphinxupquote{Derivative\_sin(t)}} will be equivalent to \sphinxcode{\sphinxupquote{cos(t)}}. For two arguments functions like \sphinxcode{\sphinxupquote{pow(t,u)}} one can refer to the derivative with respect to the second argument with the prefix  \sphinxcode{\sphinxupquote{Derivative\_2\_}} before the function name.


\section{Binary operations}
\label{\detokenize{userdoc/gasm_high:binary-operations}}
A certain number of binary operations between tensors are available:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{+}} and \sphinxcode{\sphinxupquote{\sphinxhyphen{}}} are the standard addition and subtraction of scalar, vector, matrix or tensors.

\item {} 
\sphinxcode{\sphinxupquote{*}} stands for the scalar, matrix\sphinxhyphen{}vector, matrix\sphinxhyphen{}matrix or (fourth order tensor)\sphinxhyphen{}matrix multiplication.

\item {} 
\sphinxcode{\sphinxupquote{/}} stands for the division by a scalar.

\item {} 
\sphinxcode{\sphinxupquote{.}} stands for the scalar product of vectors, or more generally to the contraction of a tensor with respect to its last index with a vector or with the first index of another tensor. Note that \sphinxcode{\sphinxupquote{*}} and \sphinxcode{\sphinxupquote{.}} are equivalent for matrix\sphinxhyphen{}vector or matrix\sphinxhyphen{}matrix multiplication.

\item {} 
\sphinxcode{\sphinxupquote{:}} stands for the Frobenius product of matrices or more generally to the contraction of a tensor with respect to the two last indices with a matrix or the two first indices of a higher order tensor. Note that \sphinxcode{\sphinxupquote{*}} and \sphinxcode{\sphinxupquote{:}} are equivalent for (fourth order tensor)\sphinxhyphen{}matrix multiplication.

\item {} 
\sphinxcode{\sphinxupquote{.*}} stands for the multiplication of two vectors/matrix/tensor componentwise.

\item {} 
\sphinxcode{\sphinxupquote{./}} stands for the division of two vectors/matrix/tensor componentwise.

\item {} 
\sphinxcode{\sphinxupquote{@}} stands for the tensor product.

\item {} 
\sphinxcode{\sphinxupquote{Cross\_product(V, W)}} stands for the cross product (vector product) of \sphinxcode{\sphinxupquote{V}} and \sphinxcode{\sphinxupquote{W}}. Defined only for three\sphinxhyphen{}dimensional vectors.

\item {} 
\sphinxcode{\sphinxupquote{Contract(A, i, B, j)}} stands for the contraction of tensors A and B with respect to the ith index of A and jth index of B. The first index is numbered 1. For instance \sphinxcode{\sphinxupquote{Contract(V,1,W,1)}} is equivalent to \sphinxcode{\sphinxupquote{V.W}} for two vectors \sphinxcode{\sphinxupquote{V}} and \sphinxcode{\sphinxupquote{W}}.

\item {} 
\sphinxcode{\sphinxupquote{Contract(A, i, j, B, k, l)}} stands for the double contraction of tensors A and B with respect to indices i,j of A and indices k,l of B. The first index is numbered 1. For instance \sphinxcode{\sphinxupquote{Contract(A,1,2,B,1,2)}} is equivalent to \sphinxcode{\sphinxupquote{A:B}} for two matrices \sphinxcode{\sphinxupquote{A}} and \sphinxcode{\sphinxupquote{B}}.

\end{itemize}


\section{Unary operators}
\label{\detokenize{userdoc/gasm_high:unary-operators}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{\sphinxhyphen{}}} the unary minus operator: change the sign of an expression.

\item {} 
\sphinxcode{\sphinxupquote{\textquotesingle{}}} stands for the transpose of a matrix or line view of a vector. It a tensor \sphinxcode{\sphinxupquote{A}} is of order greater than two,\textasciigrave{}\textasciigrave{}A’\textasciigrave{}\textasciigrave{} denotes the inversion of the two first indices.

\item {} 
\sphinxcode{\sphinxupquote{Contract(A, i, j)}} stands for the contraction of tensor A with respect to its ith and jth indices. The first index is numbered 1. For instance, \sphinxcode{\sphinxupquote{Contract(A, 1, 2)}} is equivalent to \sphinxcode{\sphinxupquote{Trace(A)}} for a matrix \sphinxcode{\sphinxupquote{A}}.

\item {} 
\sphinxcode{\sphinxupquote{Swap\_indices(A, i, j)}} exchange indices number i and j. The first index is numbered 1. For instance \sphinxcode{\sphinxupquote{Swap\_indices(A, 1, 2)}} is equivalent to \sphinxcode{\sphinxupquote{A\textquotesingle{}}} for a matrix \sphinxcode{\sphinxupquote{A}}.

\item {} 
\sphinxcode{\sphinxupquote{Index\_move\_last(A, i)}} move the index number i in order to be the last one. For instance, if \sphinxcode{\sphinxupquote{A}} is a fourth order tensor \(A_{i_1i_2i_3i_4}\), then the result of \sphinxcode{\sphinxupquote{Index\_move\_last(A, 2)}} will be the tensor \(B_{i_1i_3i_4i_2} = A_{i_1i_2i_3i_4}\). For a matrix, \sphinxcode{\sphinxupquote{Index\_move\_last(A, 1)}} is equivalent to \sphinxcode{\sphinxupquote{A\textquotesingle{}}}.

\end{itemize}


\section{Parentheses}
\label{\detokenize{userdoc/gasm_high:parentheses}}
Parentheses can be used in a standard way to change the operation order. If no parentheses are indicated, the usually priority order are used. The operations \sphinxcode{\sphinxupquote{+}}  and \sphinxcode{\sphinxupquote{\sphinxhyphen{}}} have the lower priority (with no distinction), then \sphinxcode{\sphinxupquote{*}}, \sphinxcode{\sphinxupquote{/}}, \sphinxcode{\sphinxupquote{:}}, \sphinxcode{\sphinxupquote{.}}, \sphinxcode{\sphinxupquote{.*}}, \sphinxcode{\sphinxupquote{./}}, \sphinxcode{\sphinxupquote{@}} with no distinction and the higher priority is reserved for the unary operators \sphinxcode{\sphinxupquote{\sphinxhyphen{}}} and \sphinxcode{\sphinxupquote{\textquotesingle{}}}.


\section{Explicit vectors}
\label{\detokenize{userdoc/gasm_high:explicit-vectors}}
GWFL allows to define explicit vectors (i.e. order 1 tensors) with the notation \sphinxcode{\sphinxupquote{{[}a,b,c,d,e{]}}}, i.e. an arbitrary number of components separated by a comma (note the separation with a semicolon \sphinxcode{\sphinxupquote{{[}a;b;c;d;e{]}}} is also permitted), the whole vector beginning with a right bracket and ended by a left bracket. The components can be some numeric constants, some valid expressions and may also contain test functions. In the latter case, the vector has to be homogeneous with respect to the test functions. This means that a construction of the type \sphinxcode{\sphinxupquote{{[}Test\_u; Test\_v{]}}} is not allowed. A valid example, with \sphinxcode{\sphinxupquote{u}} as a scalar field variable is \sphinxcode{\sphinxupquote{{[}5*Grad\_Test\_u(2), 2*Grad\_Test\_u(1){]}}}. Note also that using the quite opertor (transpose), an expression \sphinxcode{\sphinxupquote{{[}a,b,c,d,e{]}\textquotesingle{}}} stands for ‘row vector\textasciigrave{}, i.e. a 1x5 matrix.


\section{Explicit matrices}
\label{\detokenize{userdoc/gasm_high:explicit-matrices}}
Similarly to explicit vectors, it is possible to define explicit matrices (i.e. order 2 tensors) with the notation \sphinxcode{\sphinxupquote{{[}{[}a,b{]},{[}c,d{]}{]}}}, i.e. an arbitrary number of columns vectors separated by a comma (the syntax \sphinxcode{\sphinxupquote{{[}a,c;b,d{]}}} of lines separated by a semicolon is also permitted). For instance \sphinxcode{\sphinxupquote{{[}{[}11,21{]},{[}12,22{]},{[}13,23{]}{]}}} and \sphinxcode{\sphinxupquote{{[}11,12,13;21,22,23{]}}} both represent the same 2x3 matrix. The components can be some numeric constants, some valid expressions and may also contain test functions.


\section{Explicit tensors}
\label{\detokenize{userdoc/gasm_high:explicit-tensors}}
Explicit tensors of any order are permitted with the nested format. A tensor of order \sphinxcode{\sphinxupquote{n}} is written as a succession of tensor of order \sphinxcode{\sphinxupquote{n\sphinxhyphen{}1}} of equal dimensions and separated by a comma. For instance \sphinxcode{\sphinxupquote{{[}{[}{[}{[}1,2,3{]},{[}1,2,3{]}{]},{[}{[}1,2,3{]},{[}1,2,3{]}{]}{]},{[}{[}{[}1,2,3{]},{[}1,2,3{]}{]},{[}{[}1,2,3{]},{[}1,2,3{]}{]}{]}{]}}} is a fourth order tensor. Another possibility is to use the syntax \sphinxcode{\sphinxupquote{Reshape({[}1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3,1,2,3{]}, 3, 2, 2, 2)}} where the components have to be given in Fortran order.


\section{Access to tensor components}
\label{\detokenize{userdoc/gasm_high:access-to-tensor-components}}
The access to a component of a vector/matrix/tensor can be done by following a term by a left parenthesis, the list of components and a right parenthesis. For instance \sphinxcode{\sphinxupquote{{[}1,1,2{]}(3)}} is correct and is returning \sphinxcode{\sphinxupquote{2}} as expected. Note that indices are assumed to begin by 1 (even in C++ and with the python interface). The expressions \sphinxcode{\sphinxupquote{{[}1,1;2,3{]}(2,2)}} and \sphinxcode{\sphinxupquote{Grad\_u(2,2)}} are also correct provided that \sphinxcode{\sphinxupquote{u}} is a vector valued declared variable. Note that the components can be the result of a constant computation. For instance \sphinxcode{\sphinxupquote{{[}1,1;2,3{]}(1+1,a)}} is correct provided that \sphinxcode{\sphinxupquote{a}} is a declared constant but not if it is declared as a variable. A colon can replace the value of an index in a Matlab like syntax for instance to access to a line or a column of a matrix. \sphinxcode{\sphinxupquote{{[}1,1;2,3{]}(1,:)}} denotes the first line of the matrix \sphinxcode{\sphinxupquote{{[}1,1;2,3{]}}}. It can also be used for a fourth order tensor.


\section{Constant expressions}
\label{\detokenize{userdoc/gasm_high:constant-expressions}}\begin{itemize}
\item {} 
Floating points with standards notations (for instance \sphinxcode{\sphinxupquote{3}}, \sphinxcode{\sphinxupquote{1.456}}, \sphinxcode{\sphinxupquote{1E\sphinxhyphen{}6}})

\item {} 
\sphinxcode{\sphinxupquote{pi}}: the constant Pi.

\item {} 
\sphinxcode{\sphinxupquote{meshdim}}: the dimension of the current mesh (i.e. size of geometrical nodes)

\item {} 
\sphinxcode{\sphinxupquote{timestep}}: the main time step of the model on which this assembly string is evaluated (defined by \sphinxcode{\sphinxupquote{model.set\_time\_step(dt)}}). Do not work on pure workspaces.

\item {} 
\sphinxcode{\sphinxupquote{Id(n)}}: the identity matrix of size \(n\times n\). \sphinxtitleref{n} should be an integer expression. For instance \sphinxcode{\sphinxupquote{Id(meshdim)}} is allowed.

\item {} 
\sphinxcode{\sphinxupquote{qdim(u)}}: the total dimension of the variable \sphinxcode{\sphinxupquote{u}} (i.e. the  size for fixed size variables and the total dimension of the vector/tensor field for FEM variables)

\item {} 
\sphinxcode{\sphinxupquote{qdims(u)}}: the dimensions of the variable \sphinxcode{\sphinxupquote{u}} (i.e. the size for fixed size variables and the vector of dimensions of the vector/tensor field for FEM variables)

\end{itemize}


\section{Special expressions linked to the current position}
\label{\detokenize{userdoc/gasm_high:special-expressions-linked-to-the-current-position}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{X}} is the current coordinate on the real element (i.e. the position on the mesh of the current Gauss point on which the expression is evaluated), \sphinxcode{\sphinxupquote{X(i)}} is its i\sphinxhyphen{}th component. For instance \sphinxcode{\sphinxupquote{sin(X(1)+X(2))}} is a valid expression on a mesh of dimension greater or equal to two.

\item {} 
\sphinxcode{\sphinxupquote{Normal}} the outward unit normal vector to a boundary when integration on a boundary is performed.

\item {} 
\sphinxcode{\sphinxupquote{element\_size}} gives an estimate of the current element diameter (using getfem::convex\_radius\_estimate).

\item {} 
\sphinxcode{\sphinxupquote{element\_K}} gives the gradient of the geometric transformation (see \DUrole{xref,std,std-ref}{dp\sphinxhyphen{}transgeo}) from the reference (parent) element. Could be used only if the mesh do not contain elements of mixed dimensions.

\item {} 
\sphinxcode{\sphinxupquote{element\_B}} gives the transpose of the pseudo\sphinxhyphen{}inverse of the gradient of the geometric transformation (see \DUrole{xref,std,std-ref}{dp\sphinxhyphen{}transgeo}) from the reference (parent) element. Could be used only if the mesh do not contain elements of mixed dimensions.

\end{itemize}


\section{Print command}
\label{\detokenize{userdoc/gasm_high:print-command}}
For debugging purpose, the command \sphinxcode{\sphinxupquote{Print(a)}} is printing the tensor \sphinxcode{\sphinxupquote{a}} and pass it unchanged. For instance  \sphinxcode{\sphinxupquote{Grad\_u.Print(Grad\_Test\_u)}} will have the same effect as \sphinxcode{\sphinxupquote{Grad\_u.Grad\_Test\_u}} but printing the tensor \sphinxcode{\sphinxupquote{Grad\_Test\_u}} for each Gauss point of each element. Note that constant terms are printed only once at the beginning of the assembly. Note also that the expression could be derived so that the derivative of the term may be printed instead of the term itself.


\section{Reshape a tensor}
\label{\detokenize{userdoc/gasm_high:reshape-a-tensor}}
The command \sphinxcode{\sphinxupquote{Reshape(t, i, j, ...)}} reshapes the tensor \sphinxcode{\sphinxupquote{t}} (which could be an expression). The only constraint is that the number of components should be compatible. For instance  \sphinxcode{\sphinxupquote{Reshape(Grad\_u, 1, meshdim)}} is equivalent to \sphinxcode{\sphinxupquote{Grad\_u\textquotesingle{}}} for u a scalar variable. Note that the order of the components remain unchanged and are classically stored in Fortran order for compatibility with Blas/Lapack.


\section{Trace, Deviator, Sym and Skew operators}
\label{\detokenize{userdoc/gasm_high:trace-deviator-sym-and-skew-operators}}
Trace, Deviator, Sym and Skew operators are linear operators acting on square matrices:
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Trace(m)}} gives the trace (sum of diagonal components) of a square matrix \sphinxcode{\sphinxupquote{m}}.

\item {} 
\sphinxcode{\sphinxupquote{Deviator(m)}} gives the deviator of a square matrix \sphinxcode{\sphinxupquote{m}}. It is equivalent to \sphinxcode{\sphinxupquote{m \sphinxhyphen{} Trace(m)*Id(m\_dim)/m\_dim}}, where \sphinxcode{\sphinxupquote{m\_dim}} is the dimension of \sphinxcode{\sphinxupquote{m}}.

\item {} 
\sphinxcode{\sphinxupquote{Sym(m)}} gives the symmetric part of a square matrix \sphinxcode{\sphinxupquote{m}}, i.e. \sphinxcode{\sphinxupquote{(m + m\textquotesingle{})/2}}.

\item {} 
\sphinxcode{\sphinxupquote{Skew(m)}} gives the skew\sphinxhyphen{}symmetric part of a square matrix \sphinxcode{\sphinxupquote{m}}, i.e. \sphinxcode{\sphinxupquote{(m \sphinxhyphen{} m\textquotesingle{})/2}}.

\end{itemize}

The four operators can be applied on test functions. Which means that for instance both \sphinxcode{\sphinxupquote{Trace(Grad\_u)}} and  \sphinxcode{\sphinxupquote{Trace(Grad\_Test\_u)}} are valid when \sphinxcode{\sphinxupquote{Grad\_u}} is a square matrix (i.e. \sphinxcode{\sphinxupquote{u}} a vector field of the same dimension as the mesh).


\section{Nonlinear operators}
\label{\detokenize{userdoc/gasm_high:nonlinear-operators}}
GWFL provides some predefined nonlinear operator. Each nonlinear operator is available together with its first and second derivatives. Nonlinear operator can be applied to an expression as long as this expression do not contain some test functions.
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Norm(v)}} for \sphinxcode{\sphinxupquote{v}} a vector or a matrix gives the euclidean norm of a vector or a Frobenius norm of a matrix.

\item {} 
\sphinxcode{\sphinxupquote{Norm\_sqr(v)}} for \sphinxcode{\sphinxupquote{v}} a vector or a matrix gives the square of the euclidean norm of a vector or of the Frobenius norm of a matrix. For a vector this is equivalent to \sphinxcode{\sphinxupquote{v.v}} and for a matrix to \sphinxcode{\sphinxupquote{m:m}}.

\item {} 
\sphinxcode{\sphinxupquote{Normalized(v)}} for \sphinxcode{\sphinxupquote{v}} a vector or a matrix gives \sphinxcode{\sphinxupquote{v}} divided by its euclidean (for vectors) or Frobenius (for matrices) norm. In order to avoid problems when \sphinxcode{\sphinxupquote{v}} is close to 0, it is implemented as \sphinxcode{\sphinxupquote{Normalized\_reg(v, 1E\sphinxhyphen{}25)}}. Use with care. Think that the derivative at the origin of \sphinxcode{\sphinxupquote{Normalized(v)*Norm(v)}} is wrong (it vanishes) and very different from the derivative of \sphinxcode{\sphinxupquote{v}}.

\item {} 
\sphinxcode{\sphinxupquote{Normalized\_reg(v, eps)}} for \sphinxcode{\sphinxupquote{v}} a vector or a matrix gives a regularized version of \sphinxcode{\sphinxupquote{Normalized(v)}} : \sphinxcode{\sphinxupquote{v/sqrt(|v|*|v|+eps*eps)}}.

\item {} 
\sphinxcode{\sphinxupquote{Ball\_projection(v, r)}} for \sphinxcode{\sphinxupquote{v}} a vector or a matrix and \sphinxcode{\sphinxupquote{r}} a scalar, gives the projection of \sphinxcode{\sphinxupquote{v}} on the ball of radius \sphinxcode{\sphinxupquote{r}} and center the origin.

\item {} 
\sphinxcode{\sphinxupquote{Det(m)}} gives the determinant of a square matrix \sphinxcode{\sphinxupquote{m}}.

\item {} 
\sphinxcode{\sphinxupquote{Inv(m)}} gives the inverse of a square matrix \sphinxcode{\sphinxupquote{m}}. The second derivative is not available since it is an order 6 tensor. This means that \sphinxcode{\sphinxupquote{Inv(m)}} cannot be used in the description of a potential energy.

\item {} 
\sphinxcode{\sphinxupquote{Expm(m)}} gives the exponential of a square matrix \sphinxcode{\sphinxupquote{m}}.

\item {} 
\sphinxcode{\sphinxupquote{Logm(m)}} gives the logarithm of a square matrix \sphinxcode{\sphinxupquote{m}}.

\item {} 
\sphinxcode{\sphinxupquote{Matrix\_I2(m)}} gives the second invariants of a square matrix \sphinxcode{\sphinxupquote{m}} which is defined by \sphinxcode{\sphinxupquote{(sqr(Trace(m)) \sphinxhyphen{} Trace(m*m))/2}}.

\item {} 
\sphinxcode{\sphinxupquote{Matrix\_J1(m)}} gives the modified first invariant of a square matrix defined by \sphinxcode{\sphinxupquote{Trace(m)pow(Det(m),\sphinxhyphen{}1/3)}}.

\item {} 
\sphinxcode{\sphinxupquote{Matrix\_J2(m)}} gives the modified first invariant of a square matrix defined by \sphinxcode{\sphinxupquote{Matrix\_I2(m)*pow(Det(m),\sphinxhyphen{}2/3)}}.

\end{itemize}


\section{Macro definition}
\label{\detokenize{userdoc/gasm_high:macro-definition}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high-macros}}
GWFL allows the use of macros that are either predefined in the model or ga\_workspace object or directly defined at the begining of an assembly string. The definition into a ga\_workspace or model object is done as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.add\PYGZus{}macro(name, expr)
\end{sphinxVerbatim}

or:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.add\PYGZus{}macro(name, expr)
\end{sphinxVerbatim}

The definition of a macro into an assembly string is inserted before any regular expression, separated by a semicolon with the following syntax:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}Def name:=expr; regular\PYGZus{}expression\PYGZdq{}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{name}} is he macro name which then can be used in GWFL and contains also the macro parameters, \sphinxcode{\sphinxupquote{expr}} is a valid expression of GWFL (which may itself contain some macro definitions). For instance, a valid macro with no parameter is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.add\PYGZus{}macro(\PYGZdq{}my\PYGZus{}transformation\PYGZdq{}, \PYGZdq{}[cos(alpha)*X(1);sin(alpha)*X(2)]\PYGZdq{});
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{alpha}} should be a valid declared variable or data. A valid macro with two parameters is for instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.add\PYGZus{}macro(\PYGZdq{}ps(a,b)\PYGZdq{}, \PYGZdq{}a.b\PYGZdq{});
\end{sphinxVerbatim}

The following assembly string is then valid (if \sphinxcode{\sphinxupquote{u}} is a valid variable):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}Def ps(a,b):=a.b; ps(Grad\PYGZus{}u, Grad\PYGZus{}Test\PYGZus{}u)\PYGZdq{}
\end{sphinxVerbatim}

Parameter are allowed to be post\sphinxhyphen{}fixed to \sphinxcode{\sphinxupquote{Grad\_}}, \sphinxcode{\sphinxupquote{Hess\_}}, \sphinxcode{\sphinxupquote{Test\_}} and \sphinxcode{\sphinxupquote{Test2\_}} prefixes, so that the following assembly string is valid:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}Def psgrad(a,b):=Grad\PYGZus{}a.Grad\PYGZus{}b; psgrad(u, Test\PYGZus{}u)\PYGZdq{}
\end{sphinxVerbatim}

or with an imbrication of two macros:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}Def ps(a,b):=a.b; Def psgrad(a,b):=ps(Grad\PYGZus{}a,Grad\PYGZus{}b); psgrad(u, Test\PYGZus{}u)\PYGZdq{}
\end{sphinxVerbatim}

A macro can be deleted from a ga\_workspace or model object as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.del\PYGZus{}macro(name)
model.del\PYGZus{}macro(name)
\end{sphinxVerbatim}

Note that a macro defined at the begining of an assembly string is only defined in the assembly string and cannot be used later without being added in a model or ga\_workspace object.

The macros are expanded inline at the lexical analysis phase. Note that a the compilation phase, the repeated expressions are automatically factorized and computed only once.


\section{Explicit Differentiation}
\label{\detokenize{userdoc/gasm_high:explicit-differentiation}}
The workspace object automatically differentiate terms that are of lower deriation order. However, it is also allowed to explicitly differentiate an expression with respect to a variable. One interest is that the automatic differentiation performs a derivative with respect to all the declared variables of model/workspace but this is not necessarily the expected behavior when using a potential energy, for instance. The syntax is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Diff(expression, variable)
\end{sphinxVerbatim}

For instance, the following expression:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Diff(u.u, u)
\end{sphinxVerbatim}

will result in:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
2*(u.Test\PYGZus{}u)
\end{sphinxVerbatim}

So that:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Grad\PYGZus{}u:Grad\PYGZus{}test\PYGZus{}u + Diff(u.u, u)
\end{sphinxVerbatim}

is a valid expression. A third argument can be added to the \sphinxcode{\sphinxupquote{Diff}} command to specify the direction:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Diff(expression, variable, direction)
\end{sphinxVerbatim}

in that case, it replaces the \sphinxcode{\sphinxupquote{Test\_variable}} by the expression \sphinxcode{\sphinxupquote{direction}} which has to be of the same dimension as \sphinxcode{\sphinxupquote{variable}}. It computes the derivative of \sphinxcode{\sphinxupquote{expression}} with respect to \sphinxcode{\sphinxupquote{variable}} in the direction \sphinxcode{\sphinxupquote{direction}}.
For instance:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Diff(u.u, u, v)
\end{sphinxVerbatim}

will result in:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
2*(u.v)
\end{sphinxVerbatim}

if \sphinxcode{\sphinxupquote{v}} is any valid expression of the same dimension than \sphinxcode{\sphinxupquote{u}}.


\section{Explicit Gradient}
\label{\detokenize{userdoc/gasm_high:explicit-gradient}}
It is possible to ask for symbolic computation of the gradient of an expression with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Grad(expression)
\end{sphinxVerbatim}

It will be computed as far as it is possible. The limitations come from the fact that \sphinxstyleemphasis{GetFEM} is limited to second order derivative of shape function and nonlinear operators are supposed to provide only first and second order derivatives.

Of course:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Grad(u)
\end{sphinxVerbatim}

is equivalent to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Grad\PYGZus{}u
\end{sphinxVerbatim}

for a varible \sphinxcode{\sphinxupquote{u}}.


\section{Interpolate transformations}
\label{\detokenize{userdoc/gasm_high:interpolate-transformations}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high-transf}}
The \sphinxcode{\sphinxupquote{Interpolate}} operation allows to compute integrals between quantities which are either defined on different part of a mesh or even on different meshes. It is a powerful operation which allows to compute mortar matrices or take into account periodic conditions. However, one have to remember that it is based on interpolation which may have a non\sphinxhyphen{}negligible computational cost.

In order to use this functionality, the user have first to declare to the workspace or to the model object an interpolate transformation which described the map between the current integration point and the point lying on the same mesh or on another mesh.

Different kind of transformations can be described. Several kinds of transformations has been implemented. The first one, described hereafter is a transformation described by an expression. A second one corresponds to the raytracing contact detection (see {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-model-contact-friction-raytrace-inter-trans}]{\sphinxcrossref{\DUrole{std,std-ref}{Raytracing interpolate transformation}}}}). Some other transformations (neighbor element and element extrapolation) are describe in the next sections.

The transformation defined by an expression can be added to the workspace or the model thanks to the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}interpolate\PYGZus{}transformation\PYGZus{}from\PYGZus{}expression
  (workspace, transname, source\PYGZus{}mesh, target\PYGZus{}mesh, expr);
\end{sphinxVerbatim}

or:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}interpolate\PYGZus{}transformation\PYGZus{}from\PYGZus{}expression
  (model, transname, source\PYGZus{}mesh, target\PYGZus{}mesh, expr);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{workspace}} is a workspace object, \sphinxcode{\sphinxupquote{model}} a model object, \sphinxcode{\sphinxupquote{transname}} is the name given to the transformation, \sphinxcode{\sphinxupquote{source\_mesh}} the mesh on which the integration occurs, \sphinxcode{\sphinxupquote{target\_mesh}} the mesh on which the interpolation is performed and \sphinxcode{\sphinxupquote{expr}} is a regular expression of GWFL which may contains reference to the variables of the workspace/model.

For instance, an expression:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}interpolate\PYGZus{}transformation\PYGZus{}from\PYGZus{}expression
  (model, \PYGZdq{}my\PYGZus{}transformation\PYGZdq{}, my\PYGZus{}mesh, my\PYGZus{}mesh, \PYGZdq{}X\PYGZhy{}[1;0]\PYGZdq{});
\end{sphinxVerbatim}

will allow to integrate some expressions at the current position with a shift of \sphinxhyphen{}1 with respect to the first coordinate. This simple kind of transformation can be used to prescribe a periodic condition.

Of course, one may used more complex expressions such as:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}interpolate\PYGZus{}transformation\PYGZus{}from\PYGZus{}expression
  (model, \PYGZdq{}my\PYGZus{}transformation\PYGZdq{}, my\PYGZus{}mesh, my\PYGZus{}second\PYGZus{}mesh, \PYGZdq{}[X[1]cos(X[2]); X[1]sin(X[2])]\PYGZdq{});

add\PYGZus{}interpolate\PYGZus{}transformation\PYGZus{}from\PYGZus{}expression
  (model, \PYGZdq{}my\PYGZus{}transformation\PYGZdq{}, my\PYGZus{}mesh, my\PYGZus{}mesh, \PYGZdq{}X+u\PYGZdq{});
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{u}} is a vector variable of the workspace/model.

Once a transformation is defined in the workspace/model, one can interpolate a variable or test functions, the position or the unit normal vector to a boundary thanks to one of these expressions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Interpolate(Normal, transname)
Interpolate(X, transname)
Interpolate(u, transname)
Interpolate(Grad\PYGZus{}u, transname)
Interpolate(Div\PYGZus{}u, transname)
Interpolate(Hess\PYGZus{}u, transname)
Interpolate(Test\PYGZus{}u, transname)
Interpolate(Grad\PYGZus{}Test\PYGZus{}u, transname)
Interpolate(Div\PYGZus{}Test\PYGZus{}u, transname)
Interpolate(Hess\PYGZus{}Test\PYGZus{}u, transname)
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{u}} is the name of the variable to be interpolated.

For instance, the assembly expression to prescribe the equality of a variable \sphinxcode{\sphinxupquote{u}} with its interpolation (for instance for prescribing a periodic boundary condition) thanks to a multiplier \sphinxcode{\sphinxupquote{lambda}} could be written:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Interpolate(u,my\PYGZus{}transformation)\PYGZhy{}u)*lambda
\end{sphinxVerbatim}

(see \sphinxcode{\sphinxupquote{demo\_periodic\_laplacian.m}} in \sphinxcode{\sphinxupquote{interface/tests/matlab\sphinxhyphen{}octave}} directory).

In some situations, the interpolation of a point may fail if the transformed point is outside the target mesh. Both in order to treat this case and to allow the transformation to differentiate some other cases (see {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-model-contact-friction-raytrace-inter-trans}]{\sphinxcrossref{\DUrole{std,std-ref}{Raytracing interpolate transformation}}}} for the differentiation between rigid bodies and deformable ones in the Raytracing\_interpolate\_transformation) the transformation returns an integer identifier to the weak form language. A value 0 of this identifier means that no corresponding location on the target mesh has been found. A value of 1 means that a corresponding point has been found. This identifier can be used thanks to the following special command of GWFL:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Interpolate\PYGZus{}filter(transname, expr, i)
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{transname}} is the name of the transformation, \sphinxcode{\sphinxupquote{expr}} is the expression to be evaluated and \sphinxcode{\sphinxupquote{i}} value of the returned integer identifier for which the expression have to be computed. Note that \sphinxcode{\sphinxupquote{i}} can be ommited, in that case, the expression is evaluated for a nonzero identifier (i.e. when a corresponding point has been found). For instance, the previous assembly expression to prescribe the equality of a variable \sphinxcode{\sphinxupquote{u}} with its interpolation could be writtne:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Interpolate\PYGZus{}filter(transmane, Interpolate(u,my\PYGZus{}transformation)\PYGZhy{}u)*lambda)
+ Interpolate\PYGZus{}filter(transmane, lambda*lambda, 0)
\end{sphinxVerbatim}

In that case, the equality will only be prescribed in the part of the domain where the transformation succeed and in the other part, the mulitplier is enforced to vanish.

\sphinxstylestrong{CAUTION}: You have to think that when some variables are used in the transformation, the computation of the tangent system takes into account these dependence. However, the second derivative of a transformation with respect to a variable used has not been implemented. Thus, such a transformation is not allowed in the definition of a potential since it cannot be derived twice.


\section{Element extrapolation transformation}
\label{\detokenize{userdoc/gasm_high:element-extrapolation-transformation}}
A specific transformation (see previous section) is defined in order to allows the evaluation of certain quantities by extrapolation with respect to another element (in general a neighbor element). This is not strictly speaking a transformation since the point location remain unchanged, but the evaluation is made on another element extrapolating the shape functions outside it. This transformation is used for stabilization term in fictitious domain applications (with cut elements) where it is more robust to extrapolate some quantities on a neighbor element having a sufficiently large intersection with the real domain than evaluating them on the current element if it has a small intersection with the real domain. The functions allowing to add such a transformation to a model or a workspace are:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}element\PYGZus{}extrapolation\PYGZus{}transformation
(model, transname, my\PYGZus{}mesh, std::map\PYGZlt{}size\PYGZus{}type, size\PYGZus{}type\PYGZgt{} \PYGZam{}elt\PYGZus{}corr);

add\PYGZus{}element\PYGZus{}extrapolation\PYGZus{}transformation
(workspace, transname, my\PYGZus{}mesh, std::map\PYGZlt{}size\PYGZus{}type, size\PYGZus{}type\PYGZgt{} \PYGZam{}elt\PYGZus{}corr);
\end{sphinxVerbatim}

The map elt\_corr should contain the correspondences between the elements where the transformation is to be applied and the respective elements where the extrapolation has to be made. On the element not listed in the map, no transformation is applied and the evaluation is performed normally on the current element.

The following functions allow to change the element correspondence of a previously added element extrapolation transformation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
set\PYGZus{}element\PYGZus{}extrapolation\PYGZus{}correspondence
(model, transname, std::map\PYGZlt{}size\PYGZus{}type, size\PYGZus{}type\PYGZgt{} \PYGZam{}elt\PYGZus{}corr);

set\PYGZus{}element\PYGZus{}extrapolation\PYGZus{}correspondence
(workspace, transname, std::map\PYGZlt{}size\PYGZus{}type, size\PYGZus{}type\PYGZgt{} \PYGZam{}elt\PYGZus{}corr);
\end{sphinxVerbatim}


\section{Evaluating discontinuities across inter\sphinxhyphen{}element edges/faces}
\label{\detokenize{userdoc/gasm_high:evaluating-discontinuities-across-inter-element-edges-faces}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high-inter-elt-disc}}
A specific interpolate transformation (see previous sections), called \sphinxcode{\sphinxupquote{neighbor\_element}} is defined by default in all models. This transformation can only be used when a computation is made on an internal edge/face of a mesh, i.e. an element face shared at least by two elements. It aims to compute discontinuity jumps of a variable across inter\sphinxhyphen{}element faces. It is particularly suitable to implement Discontinuous Galerkin and interior penalty methods, Ghost penalty terms or a posteriori estimators. The expressions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Interpolate(Normal, neighbor\PYGZus{}element)
Interpolate(X, neighbor\PYGZus{}element)
Interpolate(u, neighbor\PYGZus{}element)
Interpolate(Grad\PYGZus{}u, neighbor\PYGZus{}element)
Interpolate(Div\PYGZus{}u, neighbor\PYGZus{}element)
Interpolate(Hess\PYGZus{}u, neighbor\PYGZus{}element)
Interpolate(Test\PYGZus{}u, neighbor\PYGZus{}element)
Interpolate(Grad\PYGZus{}Test\PYGZus{}u, neighbor\PYGZus{}element)
Interpolate(Div\PYGZus{}Test\PYGZus{}u, neighbor\PYGZus{}element)
Interpolate(Hess\PYGZus{}Test\PYGZus{}u, neighbor\PYGZus{}element)
\end{sphinxVerbatim}

are available (as with any other interpolate transformation) and compute a field on the current point but on the neighbor element. Of course, \sphinxcode{\sphinxupquote{Interpolate(X, neighbor\_element)}} as no specific interest since it returns the same result as \sphinxcode{\sphinxupquote{X}}. Similarly, in most cases, \sphinxcode{\sphinxupquote{Interpolate(Normal, neighbor\_element)}} will return the opposite of \sphinxcode{\sphinxupquote{Normal}} except for instance for 2D shell element in a 3D mesh where it has an interest.

The jump on a variable \sphinxcode{\sphinxupquote{u}} can be computed with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
u\PYGZhy{}Interpolate(u, neighbor\PYGZus{}element)
\end{sphinxVerbatim}

and a penalisation term of the jump can be written:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(u\PYGZhy{}Interpolate(u, neighbor\PYGZus{}element))*(Test\PYGZus{}u\PYGZhy{}Interpolate(Test\PYGZus{}u, neighbor\PYGZus{}element))
\end{sphinxVerbatim}

Note that the region representing the set of all internal faces of a mesh can be obtained thanks to the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
mr\PYGZus{}internal\PYGZus{}face = inner\PYGZus{}faces\PYGZus{}of\PYGZus{}mesh(my\PYGZus{}mesh, mr)
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mr}} is an optional mesh region. If \sphinxcode{\sphinxupquote{mr}} is specified only the face internal with respect to this region are returned. An important aspect is that  each face is represented only once and is arbitrarily chosen between the two neighbor elements.

See for instance \sphinxcode{\sphinxupquote{interface/tests/python/demo\_laplacian\_DG.py}} or \sphinxcode{\sphinxupquote{interface/tests/matlab\sphinxhyphen{}octave/demo\_laplacian\_DG.m}} for an example of use.

Compared to other interpolate transformations, this transformation is more optimized and benefits from finite element and geometric transformation pre\sphinxhyphen{}computations.


\section{Double domain integrals or terms (convolution \sphinxhyphen{} Kernel \sphinxhyphen{} Exchange integrals)}
\label{\detokenize{userdoc/gasm_high:double-domain-integrals-or-terms-convolution-kernel-exchange-integrals}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high-secondary-dom}}
In some very special cases, it can be interesting to compute an integral on the direct product of two domains, i.e. a double integral such as for instance
\begin{equation*}
\begin{split}\int_{\Omega_1}\int_{\Omega_2}k(x,y)u(x)v(y)dydx,\end{split}
\end{equation*}
where \(k(x,y)\) is a given kernel, \(u\) a quantity defined on \(\Omega_1\) and  \(v\) a quantity defined on \(\Omega_2\), eventually with  \(\Omega_1\) and \(\Omega_2\) the same domain. This can be interesting either to compute such an integral or to define an interaction term between two variables defined on two different domains.

CAUTION: Of course, this kind of term have to be used with great care, since it naturally leads to fully populated stiffness or tangent matrices.

GWFL furnishes a mechanism to compute such a term. First, the secondary domain has to be declared in the workspace/model with its integration methods. The addition of a standard secondary domain can be done with one of the two following functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}standard\PYGZus{}secondary\PYGZus{}domain(model, domain\PYGZus{}name, mim, region);

add\PYGZus{}standard\PYGZus{}secondary\PYGZus{}domain(workspace, domain\PYGZus{}name, mim, region);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{model}} or \sphinxcode{\sphinxupquote{workspace}} is the model or workspace where the secondary domain has to be declared, \sphinxcode{\sphinxupquote{domain\_name}} is a string for the identification of this domain together with the mesh region and integration method, \sphinxcode{\sphinxupquote{mim}} the integration method and \sphinxcode{\sphinxupquote{region}} a mesh region. Note that with these standard secondary domains, the integration is done on the whole region for each element of the primary domain. It can be interesting to implement specific secondary domains restricting the integration to the necessary elements with respect to the element of the primary domain. A structure is dedicated to this in \sphinxstyleemphasis{GetFEM}.

Once a secondary domain has been declared, it can be specified that a GWFL expression has to be assembled on the direct product of a current domain and a secondary domain, adding the name of the secondary domain to the \sphinxcode{\sphinxupquote{add\_expression}} method of the workspace object or using \sphinxcode{\sphinxupquote{add\_linear\_twodomain\_term}}, \sphinxcode{\sphinxupquote{add\_nonlinear\_twodomain\_term}} or \sphinxcode{\sphinxupquote{add\_twodomain\_source\_term}} functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
workspace.add\PYGZus{}expression(expr, mim, region, derivative\PYGZus{}order, secondary\PYGZus{}domain)
add\PYGZus{}twodomain\PYGZus{}source\PYGZus{}term(model, mim, expr, region, secondary\PYGZus{}domain)
add\PYGZus{}linear\PYGZus{}twodomain\PYGZus{}term(model, mim, expr, region, secondary\PYGZus{}domain)
add\PYGZus{}nonlinear\PYGZus{}twodomain\PYGZus{}term(model, mim, expr, region, secondary\PYGZus{}domain)
\end{sphinxVerbatim}

For the utilisation with the Python/Scilab/Octave/Matlab interface, see the documentation on \sphinxcode{\sphinxupquote{gf\_asm}} command and the \sphinxcode{\sphinxupquote{model}} object.

Inside an expression of GWFL, one can refer to the unit normal vector to a boundary, to the current position or to the value of a variable thanks to the expressions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Secondary\PYGZus{}domain(Normal)
Secondary\PYGZus{}domain(X)
Secondary\PYGZus{}domain(u)
Secondary\PYGZus{}domain(Grad\PYGZus{}u)
Secondary\PYGZus{}domain(Div\PYGZus{}u)
Secondary\PYGZus{}domain(Hess\PYGZus{}u)
Secondary\PYGZus{}domain(Test\PYGZus{}u)
Secondary\PYGZus{}domain(Grad\PYGZus{}Test\PYGZus{}u)
Secondary\PYGZus{}domain(Div\PYGZus{}Test\PYGZus{}u)
Secondary\PYGZus{}domain(Hess\PYGZus{}Test\PYGZus{}u)
\end{sphinxVerbatim}

For instance, a term like
\begin{equation*}
\begin{split}\int_{\Omega_1}\int_{\Omega_1}e^{-\|x-y\|}u(x)u(y)dydx,\end{split}
\end{equation*}
would correspond to the following weak form language expression:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
exp(Norm(X\PYGZhy{}Secondary\PYGZus{}domain(X)))*u*Secondary\PYGZus{}domain(u)
\end{sphinxVerbatim}


\section{Elementary transformations}
\label{\detokenize{userdoc/gasm_high:elementary-transformations}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high-elem-trans}}
An elementary transformation is a linear transformation of the shape
functions given by a matrix which may depend on the element which is applied
to the local degrees of freedom at the element level. an example of definition
of elementary transformation can be found in the file
\sphinxcode{\sphinxupquote{src/getfem\_linearized\_plates.cc}}. It aims for instance to define a local
projection of a finite element on a lower level element to perform a
reduction such as the one used in MITC elements.

Once a transformation is defined, it can be added to the model/workspace with
the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.add\PYGZus{}elementary\PYGZus{}transformation(transname, pelementary\PYGZus{}transformation)
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{pelementary\_transformation}} is a pointer to an object deriving from \sphinxcode{\sphinxupquote{virtual\_elementary\_transformation}}. Once it is added to the model/workspace, it is possible to use the following expressions in GWFL:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Elementary\PYGZus{}transformation(u, transname[, dest])
Elementary\PYGZus{}transformation(Grad\PYGZus{}u, transname[, dest])
Elementary\PYGZus{}transformation(Div\PYGZus{}u, transname[, dest])
Elementary\PYGZus{}transformation(Hess\PYGZus{}u, transname[, dest])
Elementary\PYGZus{}transformation(Test\PYGZus{}u, transname[, dest])
Elementary\PYGZus{}transformation(Grad\PYGZus{}Test\PYGZus{}u, transname[, dest])
Elementary\PYGZus{}transformation(Div\PYGZus{}Test\PYGZus{}u, transname[, dest])
Elementary\PYGZus{}transformation(Hess\PYGZus{}Test\PYGZus{}u, transname[, dest])
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{u}} is one of the FEM variables of the model/workspace, and \sphinxcode{\sphinxupquote{dest}} is an optional parameter which should be a variable or data name of the model and will correspond to the target fem of the transformation. If omitted, by default, the transformation is from the fem of the first variable to itself.

A typical transformation is the the one for the projection on rotated RT0 element for two\sphinxhyphen{}dimensional elements which is an ingredient of the MITC plate element. It can be added thanks to the function (defined in \sphinxcode{\sphinxupquote{src/getfem/getfem\_linearized\_plates.h}}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}2D\PYGZus{}rotated\PYGZus{}RT0\PYGZus{}projection(model, transname)
\end{sphinxVerbatim}

Some other transformations are available for the use into Hybrid High\sphinxhyphen{}Order methods (HHO methods, see {\hyperref[\detokenize{userdoc/hho:ud-hho}]{\sphinxcrossref{\DUrole{std,std-ref}{Tools for HHO (Hybrid High\sphinxhyphen{}Order) methods}}}} for more information). These transformations correspond to the reconstruction of the gradient of a variable or the variable itself, the HHO methods having separated discretizations on the interior of the element and on its faces. The different transformations can be added with the functions (defined in \sphinxcode{\sphinxupquote{src/getfem/getfem\_HHO.h}}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}gradient(model, transname);
add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}symmetrized\PYGZus{}gradient(model, transname);

void add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}value(model, transname);
void add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}symmetrized\PYGZus{}value(model, transname);

void add\PYGZus{}HHO\PYGZus{}stabilization(model, transname);
void add\PYGZus{}HHO\PYGZus{}symmetrized\PYGZus{}stabilization(model, transname);
\end{sphinxVerbatim}


\section{Xfem discontinuity evaluation (with mesh\_fem\_level\_set)}
\label{\detokenize{userdoc/gasm_high:xfem-discontinuity-evaluation-with-mesh-fem-level-set}}\label{\detokenize{userdoc/gasm_high:ud-gasm-high-xfem}}
When using a fem cut by a level\sphinxhyphen{}set (using fem\_level\_set or mesh\_fem\_level\_set objects), it is often interesting to integrate the discontinuity jump of a variable, or the jump in gradient or the average value. For this purpose, GWFL furnishes the following expressions for \sphinxcode{\sphinxupquote{u}} a FEM variable:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Xfem\PYGZus{}plus(u)
Xfem\PYGZus{}plus(Grad\PYGZus{}u)
Xfem\PYGZus{}plus(Div\PYGZus{}u)
Xfem\PYGZus{}plus(Hess\PYGZus{}u)
Xfem\PYGZus{}plus(Test\PYGZus{}u)
Xfem\PYGZus{}plus(Test\PYGZus{}Grad\PYGZus{}u)
Xfem\PYGZus{}plus(Test\PYGZus{}Div\PYGZus{}u)
Xfem\PYGZus{}plus(Test\PYGZus{}Hess\PYGZus{}u)

Xfem\PYGZus{}minus(u)
Xfem\PYGZus{}minus(Grad\PYGZus{}u)
Xfem\PYGZus{}minus(Div\PYGZus{}u)
Xfem\PYGZus{}minus(Hess\PYGZus{}u)
Xfem\PYGZus{}minus(Test\PYGZus{}u)
Xfem\PYGZus{}minus(Test\PYGZus{}Grad\PYGZus{}u)
Xfem\PYGZus{}minus(Test\PYGZus{}Div\PYGZus{}u)
Xfem\PYGZus{}minus(Test\PYGZus{}Hess\PYGZus{}u)
\end{sphinxVerbatim}

which are only available when the evaluation (integration) is made on the curve/surface separating two zones of continuity, i.e. on the zero level\sphinxhyphen{}set of a considered level\sphinxhyphen{}set function (using a \sphinxcode{\sphinxupquote{mesh\_im\_level\_set}} object). For instance, a jump in the variable \sphinxcode{\sphinxupquote{u}} will be given by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Xfem\PYGZus{}plus(u)\PYGZhy{}Xfem\PYGZus{}minus(u)
\end{sphinxVerbatim}

and the average by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(Xfem\PYGZus{}plus(u)+Xfem\PYGZus{}minus(u))/2
\end{sphinxVerbatim}

The value \sphinxcode{\sphinxupquote{Xfem\_plus(u)}} is the value of \sphinxcode{\sphinxupquote{u}} on the side where the corresponding level\sphinxhyphen{}set function is positive and \sphinxcode{\sphinxupquote{Xfem\_minus(u)}} the value of \sphinxcode{\sphinxupquote{u}} on the side where the level\sphinxhyphen{}set function is negative.

Additionally, note that, when integrating on a level\sphinxhyphen{}set with a \sphinxcode{\sphinxupquote{mesh\_im\_level\_set}} object, \sphinxcode{\sphinxupquote{Normal}} stands for the normal unit vector to the level\sphinxhyphen{}set in the direction of the gradient of the level\sphinxhyphen{}set function.


\section{Storage of sub\sphinxhyphen{}expressions in a getfem::im\_data object during assembly}
\label{\detokenize{userdoc/gasm_high:storage-of-sub-expressions-in-a-getfem-im-data-object-during-assembly}}
It is possible to store in a vector depending on a getfem::im\_data object a part of an assembly computation, for instance in order to use this computation in another assembly. This is an alternative to the interpolation functions which allows not to compute twice the same expression.

The method to add such an assignment in the assembly is the following for a model or a ga\_workspace:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.add\PYGZus{}assembly\PYGZus{}assignments(dataname, expr, region = size\PYGZus{}type(\PYGZhy{}1),
                               order = 1, before = false);

workspace.add\PYGZus{}assignment\PYGZus{}expression(dataname, expr,
          region = mesh\PYGZus{}region::all\PYGZus{}convexes(), order = 1, before = false)
\end{sphinxVerbatim}

It adds expression \sphinxtitleref{expr} to be evaluated at assembly time and being
assigned to the data \sphinxtitleref{dataname} which has to be of im\_data type.
\sphinxtitleref{order} represents the order of assembly where this assignement has to be
done (potential(0), weak form(1) or tangent system(2) or at each
order(\sphinxhyphen{}1)). The default value is 1.
If before = 1, the the assignement is performed before the computation
of the other assembly terms, such that the data can be used in the
remaining of the assembly as an intermediary result (be careful that it is
still considered as a data, no derivation of the expression is performed for
the tangent system).
If before = 0 (default), the assignement is done after the assembly terms.

Additionally, In a model, the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
model.clear\PYGZus{}assembly\PYGZus{}assignments()
\end{sphinxVerbatim}

allows to cancel all the assembly assignments previously added.

\index{asm@\spxentry{asm}}\index{generic assembly@\spxentry{generic assembly}}\ignorespaces 

\chapter{Compute arbitrary terms \sphinxhyphen{} low\sphinxhyphen{}level generic assembly procedures (deprecated)}
\label{\detokenize{userdoc/gasm_low:compute-arbitrary-terms-low-level-generic-assembly-procedures-deprecated}}\label{\detokenize{userdoc/gasm_low:ud-gasm-low}}\label{\detokenize{userdoc/gasm_low:index-0}}\label{\detokenize{userdoc/gasm_low::doc}}
This section present the first version of generic assembly procedure which has been implemented in \sphinxstyleemphasis{GetFEM} and is now considered as deprecated. It allows to make the assembly of arbitrary matrices in the linear case. In the nonlinear case, some special “non\_linear\_term” object have to be implemented, which could be a bit tricky and obliges to use very low\sphinxhyphen{}level internal tools of \sphinxstyleemphasis{GetFEM}. The generic weak form language (GWFL) has been developed to circumvent these difficulties (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high}]{\sphinxcrossref{\DUrole{std,std-ref}{Compute arbitrary terms \sphinxhyphen{} high\sphinxhyphen{}level generic assembly procedures \sphinxhyphen{} Generic Weak\sphinxhyphen{}Form Language (GWFL)}}}}).

As it can be seen in the file \sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}}, all the
previous assembly procedures use a \sphinxcode{\sphinxupquote{getfem::generic\_assembly}} object and provide it an adequate
description of what must be done. For example, the assembly of a volumic source
term for a scalar FEM is done with the following excerpt of code:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{generic\PYGZus{}assembly} \PYG{n}{assem}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}im}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}mf}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}mf}\PYG{p}{(}\PYG{n}{mfdata}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}data}\PYG{p}{(}\PYG{n}{F}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}vec}\PYG{p}{(}\PYG{n}{B}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Z=data(\PYGZsh{}2);}\PYG{l+s}{\PYGZdq{}}
          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{V(\PYGZsh{}1)+=comp(Base(\PYGZsh{}1).Base(\PYGZsh{}2))(:,j).Z(j);}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{assembly}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The first instructions declare the object, and set the data that it will use: a
\sphinxtitleref{mesh\_im} object which holds the integration methods, two \sphinxtitleref{mesh\_fem} objects, the input data
\sphinxcode{\sphinxupquote{F}}, and the destination vector \sphinxcode{\sphinxupquote{B}}.

The input data is the vector \(F\), defined on \sphinxcode{\sphinxupquote{mfdata}}. One wants to
evaluate \(\sum_{j} f_j (\int_\Omega \phi^i \psi^j)\). The instruction must be
seen as something that will be executed for each convex \sphinxcode{\sphinxupquote{cv}} of the mesh. The
terms \sphinxcode{\sphinxupquote{\#1}} and \sphinxcode{\sphinxupquote{\#2}} refer to the first \sphinxtitleref{mesh\_fem} and the second one (i.e. \sphinxcode{\sphinxupquote{mf}}
and \sphinxcode{\sphinxupquote{mfdata}}).  The instruction \sphinxcode{\sphinxupquote{Z=data(\#2);}} means that for each convex, the
“tensor” \sphinxcode{\sphinxupquote{Z}} will receive the values of the first data argument provided with
\sphinxcode{\sphinxupquote{push\_data}}, at indexes corresponding to the degrees of freedom attached to the
convex of the second (\sphinxcode{\sphinxupquote{\#2}}) \sphinxtitleref{mesh\_fem} (here, \sphinxcode{\sphinxupquote{Z =
F{[}mfdata.ind\_dof\_of\_element(cv){]}}}).

The part \sphinxcode{\sphinxupquote{V(\#1)+=...}} means that the result of the next expression will be
accumulated into the output vector (provided with \sphinxcode{\sphinxupquote{push\_vec}}). Here again,
\sphinxcode{\sphinxupquote{\#1}} means that we will write the result at indexes corresponding to the degrees
of freedom of the current convex with respect to the first (\sphinxcode{\sphinxupquote{\#1}}) \sphinxtitleref{mesh\_fem}.

The right hand side \sphinxcode{\sphinxupquote{comp(Base(\#1).Base(\#2))(:,j).Z(j)}} contains two operations.
The first one is a computation of a tensor on the convex:
\sphinxcode{\sphinxupquote{comp(Base(\#1).Base(\#2))}} is evaluated as a 2\sphinxhyphen{}dimensions tensor,
\(\int\phi^i \psi^j\), for all degrees of freedom \(i\) of \sphinxcode{\sphinxupquote{mf}} and
\(j\) of \sphinxcode{\sphinxupquote{mfdata}} attached to the current convex. The next part is a
reduction operation, \sphinxcode{\sphinxupquote{C(:,j).Z(j)}}: each named index (here \(j\)) is summed,
i.e. the result is \(\sum_j c_{i,j} z_j\).

The integration method used inside \sphinxcode{\sphinxupquote{comp(Base(\#1).Base(\#2))}} is taken from
\sphinxcode{\sphinxupquote{mim}}. If you need to use integration methods from another \sphinxtitleref{mesh\_im} object, you can
specify it as the first argument of \sphinxcode{\sphinxupquote{comp}}, for example \sphinxcode{\sphinxupquote{comp(\textbackslash{}\%2,
Base(\#1).Grad(\#2))}} will use the second \sphinxtitleref{mesh\_im} object (New in getfem++\sphinxhyphen{}2.0).

An other example is the assembly of the stiffness matrix for a vector Laplacian:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{generic\PYGZus{}assembly} \PYG{n}{assem}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}im}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}mf}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}mf}\PYG{p}{(}\PYG{n}{mfdata}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}data}\PYG{p}{(}\PYG{n}{A}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}mat}\PYG{p}{(}\PYG{n}{SM}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{a=data\PYGZdl{}1(\PYGZsh{}2);}\PYG{l+s}{\PYGZdq{}}
          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{M\PYGZdl{}1(\PYGZsh{}1,\PYGZsh{}1)+=sym(comp(vGrad(\PYGZsh{}1).vGrad(\PYGZsh{}1).Base(\PYGZsh{}2))(:,j,k,:,j,k,p).a(p))}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{assembly}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Now the output is written in a sparse matrix, inserted with
\sphinxcode{\sphinxupquote{assem.push\_mat(SM)}}. The \sphinxcode{\sphinxupquote{\$1}} in \sphinxcode{\sphinxupquote{M\$1(\#1,\#1)}} just indicates that we refer
to the first matrix “pushed” (it is optional, but if the assembly builds two
matrices, the second one must be referred this way). The \sphinxcode{\sphinxupquote{sym}} function ensure
that the result is symmetric (if this is not done, some round\sphinxhyphen{}off errors may
cancel the symmetricity, and the assembly will be a little bit slower). Next, the
\sphinxcode{\sphinxupquote{comp}} part evaluates a 7D tensor,
\begin{equation*}
\begin{split}\int\partial_k\varphi^{i}_{j}\partial_n\varphi^l_m\psi^p,\end{split}
\end{equation*}
where \(\varphi^i_j\) is a \(jth\) component of the \(ith\) base
function of \sphinxcode{\sphinxupquote{mf}} and \(\psi^p\) is a (scalar) base function of the second
\sphinxtitleref{mesh\_fem}. Since we want to assemble
\begin{equation*}
\begin{split}\int a(x).\nabla\phi^i.\nabla\phi^j,
\quad\text{with}\quad
a(x)=\sum_p a^p \psi^p(x),\end{split}
\end{equation*}
the reduction is:
\begin{equation*}
\begin{split}\sum_{j,k,p}\left(
\int \partial_k\varphi^{i}_{j} \partial_k\varphi^m_j \psi^p
\right)a^p\end{split}
\end{equation*}
In the \sphinxcode{\sphinxupquote{comp}} function, \sphinxcode{\sphinxupquote{vGrad}} was used instead of \sphinxcode{\sphinxupquote{Grad}} since we said
that we were assembling a \sphinxstyleemphasis{vector} Laplacian: that is why each \sphinxcode{\sphinxupquote{vGrad}} part has
three dimensions (dof number, component number, and derivative number). For a
scalar Laplacian, we could have used
\sphinxcode{\sphinxupquote{comp(Grad(\#1).Grad(\#1).Base(\#2))(:,k,:,k,p).a(p)}}. But the vector form has the
advantage to work in both vector and scalar case.

The last instruction, \sphinxcode{\sphinxupquote{assem.assembly()}}, does evaluate the expression on each
convex. For an assembly over a boundary just call \sphinxcode{\sphinxupquote{assem.assembly(rg)}}, where
\sphinxcode{\sphinxupquote{rg}} is a \sphinxcode{\sphinxupquote{getfem::mesh\_region}} object.  \sphinxcode{\sphinxupquote{rg}} might also be a number, in that case the mesh
region taken into account is \sphinxcode{\sphinxupquote{mim.linked\_mesh().region(rg)}}.

The third example shows how to compute the \(L^2\) norm of a scalar or vector
field on a mesh boundary:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}im}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}mf}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}data}\PYG{p}{(}\PYG{n}{U}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{scalar\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{v}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{push\PYGZus{}vec}\PYG{p}{(}\PYG{n}{v}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u=data(\PYGZsh{}1);}\PYG{l+s}{\PYGZdq{}}
          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{V()+=u(i).u(j).comp(vBase(\PYGZsh{}1).vBase(\PYGZsh{}1))(i,k,j,k)}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{assembly}\PYG{p}{(}\PYG{n}{boundary\PYGZus{}number}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This one is easy to read. When \sphinxcode{\sphinxupquote{assembly}} returns, \sphinxcode{\sphinxupquote{v{[}0{]}}} will contain
\begin{equation*}
\begin{split}\sum_{i,j,k}\left(\int_{boundary} u_i \varphi^{i}_{k} u_j \varphi^j_k \right)\end{split}
\end{equation*}
The fourth and last example shows an (sub\sphinxhyphen{}optimal) assembly of the linear
elasticity problem with a complete Hooke tensor:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{assem}\PYG{p}{.}\PYG{n}{set}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{h=data\PYGZdl{}1(qdim(\PYGZsh{}1),qdim(\PYGZsh{}1),qdim(\PYGZsh{}1),qdim(\PYGZsh{}1),\PYGZsh{}2);}\PYG{l+s}{\PYGZdq{}}
          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{t=comp(vGrad(\PYGZsh{}1).vGrad(\PYGZsh{}1).Base(\PYGZsh{}2));}\PYG{l+s}{\PYGZdq{}}
          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{e=(t\PYGZob{}:,2,3,:,5,6,:\PYGZcb{}+t\PYGZob{}:,3,2,:,5,6,:\PYGZcb{}+t\PYGZob{}:,2,3,:,6,5,:\PYGZcb{}+t\PYGZob{}:,3,2,:,6,5,:\PYGZcb{})/4;}\PYG{l+s}{\PYGZdq{}}
          \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{M(\PYGZsh{}1,\PYGZsh{}1)+= sym(e(:,j,k,:,m,n,p).h(j,k,m,n,p))}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The original equations are:
\begin{equation*}
\begin{split}\int\varepsilon(\varphi^i):\sigma(\phi^j),
\quad\text{with}\quad
\sigma(u)_{ij}=\sum_{kl} h_{ijkl}(x) \varepsilon_{kl}(u)\end{split}
\end{equation*}
where \(h\) is the Hooke tensor, and \(:\) means the scalar product
between matrices. Since we assume it is not constant, \(h\) is given on the
second \sphinxtitleref{mesh\_fem}: \(h_{ijkl}(x)=\sum_p h_{ijkl}^p \psi^p\). Hence the first line
declares that the first data “pushed” is indeed a five\sphinxhyphen{}dimensions tensor, the
first fourth ones being all equal to the target dimension of the first \sphinxtitleref{mesh\_fem}, and
the last one being equal to the number of degrees of freedom of the second \sphinxtitleref{mesh\_fem}.
The \sphinxcode{\sphinxupquote{comp}} part still computes the same 7D tensor than for the vector Laplacian
case. From this tensor, one evaluates
\(\varepsilon(\varphi^i)_{jk}\varepsilon(\phi^l)_{mn}\psi^p\) via
permutations, and finally the expression is reduced against the hook tensor.


\section{available operations inside the \sphinxstyleliteralintitle{\sphinxupquote{comp}} command}
\label{\detokenize{userdoc/gasm_low:available-operations-inside-the-comp-command}}\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Base(\#i)}}: evaluate the value of the base functions of the \sphinxstyleemphasis{ith} \sphinxtitleref{mesh\_fem}

\item {} 
\sphinxcode{\sphinxupquote{Grad(\#i)}}: evaluate the value of the gradient of the base functions of the
\sphinxstyleemphasis{ith} \sphinxtitleref{mesh\_fem}

\item {} 
\sphinxcode{\sphinxupquote{Hess(\#i)}}: evaluate the value of the Hessian of the base functions of the
\sphinxstyleemphasis{ith} \sphinxtitleref{mesh\_fem}

\item {} 
\sphinxcode{\sphinxupquote{Normal()}}: evaluate the unit normal (should not be used for volumic
integrations !)

\item {} 
\sphinxcode{\sphinxupquote{NonLin\$x(\#mf1,... \#mfn)}}: evaluate the \sphinxstyleemphasis{xth} non\sphinxhyphen{}linear term (inserted
with \sphinxcode{\sphinxupquote{push\_nonlinear\_term(pnonlinear\_elem\_term)}}) using the listed \sphinxtitleref{mesh\_fem}
objects.

\item {} 
\sphinxcode{\sphinxupquote{GradGT()}}, \sphinxcode{\sphinxupquote{GradGTInv()}}: evaluate the gradient (and its inverse) of the
geometric transformation of the current convex.

\end{itemize}

\begin{sphinxadmonition}{note}{Note:}
you may reference any data object inside the \sphinxcode{\sphinxupquote{comp}} command, and perform
reductions inside the \sphinxcode{\sphinxupquote{comp()}}. This feature is mostly interesting for
speeding up assembly of nonlinear terms (see the file
\sphinxcode{\sphinxupquote{getfem/getfem\_nonlinear\_elasticity.h}} for an example of use).
\end{sphinxadmonition}


\section{others operations}
\label{\detokenize{userdoc/gasm_low:others-operations}}
Slices may be mixed with reduction operations \sphinxcode{\sphinxupquote{t(:,4,i,i)}} takes a slice at
index 4 of the second dimension, and reduces the diagonal of dimension 3 and 4.
\sphinxstyleemphasis{Please note that index numbers for slices start at 1 and not 0 !!}

\sphinxcode{\sphinxupquote{mdim(\#2)}} is evaluated as the mesh dimension associated to the second \sphinxtitleref{mesh\_fem},
while \sphinxcode{\sphinxupquote{qdim(\#2)}} is the target dimension of the \sphinxtitleref{mesh\_fem}.

The diagonal of a tensor can be obtained with \sphinxcode{\sphinxupquote{t\{:,:,3,3\}}} (which is strictly
equivalent to \sphinxcode{\sphinxupquote{t\{1,2,3,3\}}}: the colon is just here to improve the readability).
This is the same operator than for permutation operations. Note that
\sphinxcode{\sphinxupquote{t\{:,:,1,1\}}} or \sphinxcode{\sphinxupquote{t\{:,:,4,4\}}} are not valid operations.

The \sphinxcode{\sphinxupquote{print}} command can be used to see the tensor: \sphinxcode{\sphinxupquote{"print comp(Base(\#1));"}}
will print the integrals of the base functions for each convex.

If there is more than one data array, output array or output sparse
matrix, one can use \sphinxcode{\sphinxupquote{data\$2}}, \sphinxcode{\sphinxupquote{data\$3}}, \sphinxcode{\sphinxupquote{V\$2}}, \sphinxcode{\sphinxupquote{M\$2}},…


\chapter{Some Standard assembly procedures (low\sphinxhyphen{}level generic assembly)}
\label{\detokenize{userdoc/asm:some-standard-assembly-procedures-low-level-generic-assembly}}\label{\detokenize{userdoc/asm:ud-asm}}\label{\detokenize{userdoc/asm::doc}}
Procedures defined in the file \sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}} allow the
assembly of stiffness matrices, mass matrices and boundary conditions for a few
amount of classical partial differential equation problems. All the procedures
have vectors and matrices template parameters in order to be used with any matrix library.

CAUTION: The assembly procedures do not clean the matrix/vector at the begining of the assembly in order to keep the possibility to perform several assembly operations on the same matrix/vector. Consequently, one has to clean the matrix/vector before the first assembly operation.


\section{Laplacian (Poisson) problem}
\label{\detokenize{userdoc/asm:laplacian-poisson-problem}}
An assembling procedure is defined to solve the problem:
\begin{equation*}
\begin{split}-\mbox{div}(a(x)\cdot\mbox{grad}(u(x))) &= f(x)\ \mbox{ in }\Omega,  \\
u(x) & = U(x)\ \mbox{ on }\Gamma_D, \\
\frac{\partial u}{\partial\eta}(x) & = F(x)\ \mbox{ on }\Gamma_N,\end{split}
\end{equation*}
where \(\Omega\) is an open domain of arbitrary dimension, \(\Gamma_{D}\)
and \(\Gamma_{N}\) are parts of the boundary of \(\Omega\), \(u(x)\)
is the unknown, \(a(x)\) is a given coefficient, \(f(x)\) is a given
source term, \(U(x)\) the prescribed value of \(u(x)\) on
\(\Gamma_{D}\) and \(F(x)\) is the prescribed normal derivative of
\(u(x)\) on \(\Gamma_{N}\). The function to be called to assemble the
stiffness matrix is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}stiffness\PYGZus{}matrix\PYGZus{}for\PYGZus{}laplacian}\PYG{p}{(}\PYG{n}{SM}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,} \PYG{n}{mfd}\PYG{p}{,} \PYG{n}{A}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{SM}} is a matrix of any type having the right dimension (i.e.
\sphinxcode{\sphinxupquote{mfu.nb\_dof()}}),

\item {} 
\sphinxcode{\sphinxupquote{mim}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_im}} defining the integration method used,

\item {} 
\sphinxcode{\sphinxupquote{mfu}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} and should define the finite element
method for the solution,

\item {} 
\sphinxcode{\sphinxupquote{mfd}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} (possibly equal to \sphinxcode{\sphinxupquote{mfu}}) describing the
finite element method on which the coefficient \(a(x)\) is defined,

\item {} 
\sphinxcode{\sphinxupquote{A}} is the (real or complex) vector of the values of this coefficient on each
degree of freedom of \sphinxcode{\sphinxupquote{mfd}}.

\end{itemize}

Both \sphinxtitleref{mesh\_fem} should use the same mesh (i.e. \sphinxcode{\sphinxupquote{\&mfu.linked\_mesh() ==
\&mfd.linked\_mesh()}}).

It is important to pay attention to the fact that the integration methods stored
in \sphinxcode{\sphinxupquote{mim}}, used to compute the elementary matrices, have to be chosen of
sufficient order. The order has to be determined considering the polynomial
degrees of element in \sphinxcode{\sphinxupquote{mfu}}, in \sphinxcode{\sphinxupquote{mfd}} and the geometric transformations for
non\sphinxhyphen{}linear cases. For example, with linear geometric transformations, if \sphinxcode{\sphinxupquote{mfu}}
is a \(P_{K}\) FEM, and \sphinxcode{\sphinxupquote{mfd}} is a \(P_{L}\) FEM, the integration will
have to be chosen of order \(\geq 2(K-1) + L\), since the elementary integrals
computed during the assembly of \sphinxcode{\sphinxupquote{SM}} are
\(\int\nabla\varphi_i\nabla\varphi_j\psi_k\) (with \(\varphi_i\) the basis
functions for \sphinxcode{\sphinxupquote{mfu}} and \(\psi_i\) the basis functions for \sphinxcode{\sphinxupquote{mfd}}).

To assemble the source term, the function to be called is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{B}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,} \PYG{n}{mfd}\PYG{p}{,} \PYG{n}{V}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{B}} is a vector of any type having the correct dimension (still
\sphinxcode{\sphinxupquote{mfu.nb\_dof()}}), \sphinxcode{\sphinxupquote{mim}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_im}} defining the integration
method used, \sphinxcode{\sphinxupquote{mfd}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} (possibly equal to \sphinxcode{\sphinxupquote{mfu}})
describing the finite element method on which \(f(x)\) is defined, and \sphinxcode{\sphinxupquote{V}}
is the vector of the values of \(f(x)\) on each degree of freedom of \sphinxcode{\sphinxupquote{mfd}}.

The function \sphinxcode{\sphinxupquote{asm\_source\_term}} also has an optional argument, which is a
reference to a \sphinxcode{\sphinxupquote{getfem::mesh\_region}} (or just an integer \sphinxcode{\sphinxupquote{i}}, in which case
\sphinxcode{\sphinxupquote{mim.linked\_mesh().region(i)}} will be considered). Hence for the Neumann
condition on \(\Gamma_{N}\), the same function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{B}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,} \PYG{n}{mfd}\PYG{p}{,} \PYG{n}{V}\PYG{p}{,} \PYG{n}{nbound}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

is used again, with \sphinxcode{\sphinxupquote{nbound}} is the index of the boundary \(\Gamma_{N}\) in
the linked mesh of \sphinxcode{\sphinxupquote{mim}}, \sphinxcode{\sphinxupquote{mfu}} and \sphinxcode{\sphinxupquote{mfd}}.

There is two manner (well not really, since it is also possible to use Lagrange
multipliers, or to use penalization) to take into account the Dirichlet condition
on \(\Gamma_{D}\), changing the linear system or explicitly reduce to the
kernel of the Dirichlet condition. For the first manner, the following function is
defined:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{assembling\PYGZus{}Dirichlet\PYGZus{}condition}\PYG{p}{(}\PYG{n}{SM}\PYG{p}{,} \PYG{n}{B}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,} \PYG{n}{nbound}\PYG{p}{,} \PYG{n}{R}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{nbound}} is the index of the boundary \(\Gamma_D\) where the Dirichlet
condition is applied, \sphinxcode{\sphinxupquote{R}} is the vector of the values of \(R(x)\) on each
degree of freedom of \sphinxcode{\sphinxupquote{mfu}}. This operation should be the last one because it
transforms the stiffness matrix \sphinxcode{\sphinxupquote{SM}}. It works only for Lagrange elements. At
the end, one obtains the discrete system:
\begin{equation*}
\begin{split}[SM] U = B,\end{split}
\end{equation*}
where \(U\) is the discrete unknown.

For the second manner, one should use the more general:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}dirichlet\PYGZus{}constraints}\PYG{p}{(}\PYG{n}{H}\PYG{p}{,} \PYG{n}{R}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,}
                                  \PYG{n}{mf\PYGZus{}r}\PYG{p}{,} \PYG{n}{r}\PYG{p}{,} \PYG{n}{nbound}\PYG{p}{)}\PYG{p}{.}
\end{sphinxVerbatim}

See the Dirichlet condition as a general linear constraint that must satisfy the
solution \(u\). This function does the assembly of Dirichlet conditions of
type \(\int_{\Gamma} u(x)v(x) = \int_{\Gamma}r(x)v(x)\) for all \(v\) in
the space of multiplier defined by \sphinxcode{\sphinxupquote{mf\_mult}}. The fem \sphinxcode{\sphinxupquote{mf\_mult}} could be often
chosen equal to \sphinxcode{\sphinxupquote{mf\_u}} except when \sphinxcode{\sphinxupquote{mf\_u}} is too “complex”.

This function just assemble these constraints into a new linear system \(H
u=R\), doing some additional simplification in order to obtain a “simple”
constraints matrix.

Then, one should call:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ncols} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{Dirichlet\PYGZus{}nullspace}\PYG{p}{(}\PYG{n}{H}\PYG{p}{,} \PYG{n}{N}\PYG{p}{,} \PYG{n}{R}\PYG{p}{,} \PYG{n}{Ud}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which will return a vector \(U_d\) which satisfies the Dirichlet condition,
and an orthogonal basis \(N\) of the kernel of \(H\). Hence, the discrete
system that must be solved is:
\begin{equation*}
\begin{split}(N'[SM]N) U_{int}=N'(B-[SM]U_d),\end{split}
\end{equation*}
and the solution is \$U=N U\_\{int\}+U\_d\$. The output matrix \(N\) should be a
\(nbdof \times nbdof\) (sparse) matrix but should be resized to \sphinxcode{\sphinxupquote{ncols}}
columns. The output vector \(U_d\) should be a \(nbdof\) vector. A big
advantage of this approach is to be generic, and do not prescribed for the finite
element method \sphinxcode{\sphinxupquote{mf\_u}} to be of Lagrange type. If \sphinxcode{\sphinxupquote{mf\_u}} and \sphinxcode{\sphinxupquote{mf\_d}} are
different, there is implicitly a projection (with respect to the \(L^2\) norm)
of the data on the finite element \sphinxcode{\sphinxupquote{mf\_u}}.

If you want to treat the more general scalar elliptic equation
\(\mbox{div}(A(x)\nabla u)\), where \(A(x)\) is square matrix, you should
use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}stiffness\PYGZus{}matrix\PYGZus{}for\PYGZus{}scalar\PYGZus{}elliptic}\PYG{p}{(}\PYG{n}{M}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,}
                                                 \PYG{n}{mfdata}\PYG{p}{,} \PYG{n}{A}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The matrix data \sphinxcode{\sphinxupquote{A}} should be defined on \sphinxcode{\sphinxupquote{mfdata}}. It is expected as a vector
representing a \(n \times n \times nbdof\) tensor (in Fortran order), where
\(n\) is the mesh dimension of \sphinxcode{\sphinxupquote{mfu}}, and \(nbdof\) is the number of dof
of \sphinxcode{\sphinxupquote{mfdata}}.


\section{Linear Elasticity problem}
\label{\detokenize{userdoc/asm:linear-elasticity-problem}}
The following function assembles the stiffness matrix for linear elasticity:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}stiffness\PYGZus{}matrix\PYGZus{}for\PYGZus{}linear\PYGZus{}elasticity}\PYG{p}{(}\PYG{n}{SM}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,}
                                                   \PYG{n}{mfd}\PYG{p}{,} \PYG{n}{LAMBDA}\PYG{p}{,} \PYG{n}{MU}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{SM}} is a matrix of any type having the right dimension (i.e. here
\sphinxcode{\sphinxupquote{mfu.nb\_dof()}}), \sphinxcode{\sphinxupquote{mim}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_im}} defining the integration
method used, \sphinxcode{\sphinxupquote{mfu}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} and should define the finite
element method for the solution, \sphinxcode{\sphinxupquote{mfd}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} (possibly
equal to \sphinxcode{\sphinxupquote{mfu}}) describing the finite element method on which the Lamé
coefficient are defined, \sphinxcode{\sphinxupquote{LAMBDA}} and \sphinxcode{\sphinxupquote{MU}} are vectors of the values of Lamé
coefficients on each degree of freedom of \sphinxcode{\sphinxupquote{mfd}}.

\begin{sphinxadmonition}{caution}{Caution:}
Linear elasticity problem is a vectorial problem, so the target dimension of
\sphinxcode{\sphinxupquote{mfu}} (see \sphinxcode{\sphinxupquote{mf.set\_qdim(Q)}}) should be the same as the dimension of the
mesh.
\end{sphinxadmonition}

In order to assemble source term, Neumann and Dirichlet conditions, same functions
as in previous section can be used.


\section{Stokes Problem with mixed finite element method}
\label{\detokenize{userdoc/asm:stokes-problem-with-mixed-finite-element-method}}
The assembly of the mixed term \(B = - \int p\nabla.v\) is done with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}stokes\PYGZus{}B}\PYG{p}{(}\PYG{n}{MATRIX} \PYG{o}{\PYGZam{}}\PYG{n}{B}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,}
                     \PYG{k}{const} \PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}p}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\section{Assembling a mass matrix}
\label{\detokenize{userdoc/asm:assembling-a-mass-matrix}}
Assembly of a mass matrix between two finite elements:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}mass\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{M}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf1}\PYG{p}{,} \PYG{n}{mf2}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is also possible to obtain mass matrix on a boundary with the same function:
\begin{quote}

getfem::asm\_mass\_matrix(M, mim, mf1, mf2, nbound);
\end{quote}

where \sphinxcode{\sphinxupquote{nbound}} is the region index in \sphinxcode{\sphinxupquote{mim.linked\_mesh()}}, or a
\sphinxcode{\sphinxupquote{mesh\_region}} object.


\chapter{Interpolation of arbitrary quantities}
\label{\detokenize{userdoc/interMM:interpolation-of-arbitrary-quantities}}\label{\detokenize{userdoc/interMM:ud-intermm}}\label{\detokenize{userdoc/interMM::doc}}
Once a solution has been computed, it is quite easy to extract any quantity of interest on it with the interpolation functions for instance for post\sphinxhyphen{}treatment.


\section{Basic interpolation}
\label{\detokenize{userdoc/interMM:basic-interpolation}}
The file \sphinxcode{\sphinxupquote{getfem/getfem\_interpolation.h}} defines the function
\sphinxcode{\sphinxupquote{getfem::interpolation(...)}} to interpolate a solution from a given mesh/finite
element method on another mesh and/or another Lagrange finite element method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::interpolation(mf1, mf2, U, V, extrapolation = 0);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mf1}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} and describes the finite element
method on which the source field \sphinxcode{\sphinxupquote{U}} is defined, \sphinxcode{\sphinxupquote{mf2}} is the finite element
method on which \sphinxcode{\sphinxupquote{U}} will be interpolated. \sphinxcode{\sphinxupquote{extrapolation}} is an optional
parameter. The values are \sphinxcode{\sphinxupquote{0}} not to allow the extrapolation, \sphinxcode{\sphinxupquote{1}} for an
extrapolation of the exterior points near the boundary and \sphinxcode{\sphinxupquote{2}} for the
extrapolation of all exterior points (could be expensive).

The dimension of \sphinxcode{\sphinxupquote{U}} should be a multiple of \sphinxcode{\sphinxupquote{mf1.nb\_dof()}}, and the
interpolated data \sphinxcode{\sphinxupquote{V}} should be correctly sized (multiple of \sphinxcode{\sphinxupquote{mf2.nb\_dof()}}).

… important:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
``mf2`` should be of Lagrange type for the interpolation to make sense but the
meshes linked to ``mf1`` and ``mf2`` may be different (and this is the
interest of this function). There is no restriction for the dimension of the
domain (you can interpolate a 2D mesh on a line etc.).
\end{sphinxVerbatim}

If you need to perform more than one interpolation between the same finite element
methods, it might be more efficient to use the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::interpolation(mf1, mf2, M, extrapolation = 0);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{M}} is a row matrix which will be filled with the linear map representing
the interpolation (i.e. such that \sphinxcode{\sphinxupquote{V = MU}}). The matrix should have the correct
dimensions (i.e. \sphinxcode{\sphinxupquote{mf2.nb\_dof()\textasciigrave{}\textasciigrave{}x\textasciigrave{}\textasciigrave{}mf1.nb\_dof()}}). Once this matrix is built,
the interpolation is done with a simple matrix multiplication:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
gmm::mult(M, U, V);
\end{sphinxVerbatim}


\section{Interpolation based on the generic weak form language (GWFL)}
\label{\detokenize{userdoc/interMM:interpolation-based-on-the-generic-weak-form-language-gwfl}}
It is possible to extract some arbitrary expressions on possibly several fields thanks to GWFL and the interpolation functions.

This is specially dedicated to the model object (but it can also be used with a ga\_workspace object). For instance if \sphinxcode{\sphinxupquote{md}} is a valid object containing some defined variables \sphinxcode{\sphinxupquote{u}} (vectorial) and \sphinxcode{\sphinxupquote{p}} (scalar), one can interpolate on a Lagrange finite element method an expression such as \sphinxcode{\sphinxupquote{p*Trace(Grad\_u)}}. The resulting expression can be scalar, vectorial or tensorial. The size of the resulting vector is automatically adapted.

The high\sphinxhyphen{}level generic interpolation functions are defined in the file \sphinxcode{\sphinxupquote{getfem/getfem\_generic\_assembly.h}}.

There is different interpolation functions corresponding to the interpolation on a Lagrange fem on the same mesh, the interpolation on a cloud on points or on a \sphinxcode{\sphinxupquote{getfem::im\_data}} object.

Interpolation on a Lagrange fem:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void getfem::ga\PYGZus{}interpolation\PYGZus{}Lagrange\PYGZus{}fem(workspace, mf, result);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{workspace}} is a \sphinxcode{\sphinxupquote{getfem::ga\_workspace}} object which aims to store the different variables and data (see  {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high}]{\sphinxcrossref{\DUrole{std,std-ref}{Compute arbitrary terms \sphinxhyphen{} high\sphinxhyphen{}level generic assembly procedures \sphinxhyphen{} Generic Weak\sphinxhyphen{}Form Language (GWFL)}}}}), \sphinxcode{\sphinxupquote{mf}} is the \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object reresenting the Lagrange fem on which the interpolation is to be done and \sphinxcode{\sphinxupquote{result}} is a \sphinxcode{\sphinxupquote{beot::base\_vector}} which store the interpolatin. Note that the workspace should contain the epression to be interpolated.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void getfem::ga\PYGZus{}interpolation\PYGZus{}Lagrange\PYGZus{}fem(md, expr, mf, result, rg=mesh\PYGZus{}region::all\PYGZus{}convexes());
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is a \sphinxcode{\sphinxupquote{getfem::model}} object (containing the variables and data), \sphinxcode{\sphinxupquote{expr}} (std::string object) is the expression to be interpolated, \sphinxcode{\sphinxupquote{mf}} is the \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object reresenting the Lagrange fem on which the interpolation is to be done, \sphinxcode{\sphinxupquote{result}} is the vector in which the interpolation is stored and \sphinxcode{\sphinxupquote{rg}} is the optional mesh region.

Interpolation on a cloud of points:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void getfem::ga\PYGZus{}interpolation\PYGZus{}mti(md, expr, mti, result, extrapolation = 0, rg=mesh\PYGZus{}region::all\PYGZus{}convexes(), nbpoints = size\PYGZus{}type(\PYGZhy{}1));
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is a \sphinxcode{\sphinxupquote{getfem::model}} object (containing the variables and data), \sphinxcode{\sphinxupquote{expr}} (std::string object) is the expression to be interpolated, \sphinxcode{\sphinxupquote{mti}} is a \sphinxcode{\sphinxupquote{getfem::mesh\_trans\_inv}} object which stores the cloud of points (see \sphinxcode{\sphinxupquote{getfem/getfem\_interpolation.h}}), \sphinxcode{\sphinxupquote{result}} is the vector in which the interpolation is stored, \sphinxcode{\sphinxupquote{extrapolation}} is an option for extrapolating the field outside the mesh for outside points, \sphinxcode{\sphinxupquote{rg}} is the optional mesh region and \sphinxcode{\sphinxupquote{nbpoints}} is the optional maximal number of points.

Interpolation on an im\_data object (on the Gauss points of an integration method):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void getfem::ga\PYGZus{}interpolation\PYGZus{}im\PYGZus{}data(md, expr, im\PYGZus{}data \PYGZam{}imd,
 base\PYGZus{}vector \PYGZam{}result, const mesh\PYGZus{}region \PYGZam{}rg=mesh\PYGZus{}region::all\PYGZus{}convexes());
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is a \sphinxcode{\sphinxupquote{getfem::model}} object (containing the variables and data), \sphinxcode{\sphinxupquote{expr}} (std::string object) is the expression to be interpolated, \sphinxcode{\sphinxupquote{imd}} is a \sphinxcode{\sphinxupquote{getfem::im\_data}} object which refers to a integration method (see \sphinxcode{\sphinxupquote{getfem/getfem\_im\_data.h}}), \sphinxcode{\sphinxupquote{result}} is the vector in which the interpolation is stored and \sphinxcode{\sphinxupquote{rg}} is the optional mesh region.


\chapter{Incorporate new finite element methods in \sphinxstyleemphasis{GetFEM}}
\label{\detokenize{userdoc/ifem:incorporate-new-finite-element-methods-in-gf}}\label{\detokenize{userdoc/ifem:ud-ifem}}\label{\detokenize{userdoc/ifem::doc}}
Basically, It is sufficient to describe an element on the reference element, i.e.
to describe each base function of each degree of freedom. Intrinsically vectorial
elements are supported (see for instance Nedelec and Raviart\sphinxhyphen{}Thomas elements).
Finite element methods that are not equivalent via the geometric transformation
(not \(\tau\)\sphinxhyphen{}equivalent in \sphinxstyleemphasis{GetFEM} jargon, such as vectorial elements, Hermite
elements …) an additional linear transformation of the degrees of freedom
depending on the real element should be described (see the implementation of
Argyris element for instance).

Please read \DUrole{xref,std,std-ref}{dp} for more details and see the files
\sphinxcode{\sphinxupquote{getfem/getfem\_fem.h}}, \sphinxcode{\sphinxupquote{getfem\_fem.cc}} for practical implementation.


\chapter{Incorporate new approximated integration methods in \sphinxstyleemphasis{GetFEM}}
\label{\detokenize{userdoc/iinteg:incorporate-new-approximated-integration-methods-in-gf}}\label{\detokenize{userdoc/iinteg:ud-iinteg}}\label{\detokenize{userdoc/iinteg::doc}}
A perl script automatically incorporates new cubature methods from a description
file. You can see in the directory \sphinxcode{\sphinxupquote{cubature}} such description files (with
extension \sphinxcode{\sphinxupquote{.IM}}) . For instance for \sphinxcode{\sphinxupquote{IM\_TETRAHEDRON(5)}} the following file
describes the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{NAME} \PYG{o}{=} \PYG{n}{IM\PYGZus{}TETRAHEDRON}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{N} \PYG{o}{=} \PYG{l+m+mi}{3}
\PYG{n}{GEOTRANS} \PYG{o}{=} \PYG{n}{GT\PYGZus{}PK}\PYG{p}{(}\PYG{l+m+mi}{3}\PYG{p}{,}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{NBPT} \PYG{o}{=} \PYG{l+m+mi}{4}
\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.25}\PYG{p}{,} \PYG{l+m+mf}{0.008818342151675485}
\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.31979362782962991}\PYG{p}{,} \PYG{l+m+mf}{0.31979362782962991}\PYG{p}{,} \PYG{l+m+mf}{0.31979362782962991}\PYG{p}{,} \PYG{l+m+mf}{0.011511367871045398}
\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.091971078052723033}\PYG{p}{,} \PYG{l+m+mf}{0.091971078052723033}\PYG{p}{,} \PYG{l+m+mf}{0.091971078052723033}\PYG{p}{,} \PYG{l+m+mf}{0.01198951396316977}
\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.056350832689629156}\PYG{p}{,} \PYG{l+m+mf}{0.056350832689629156}\PYG{p}{,} \PYG{l+m+mf}{0.44364916731037084}\PYG{p}{,} \PYG{l+m+mf}{0.008818342151675485}
\PYG{n}{NBF} \PYG{o}{=} \PYG{l+m+mi}{4} \PYG{n}{IM\PYGZus{}TRIANGLE}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{IM\PYGZus{}TRIANGLE}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{IM\PYGZus{}TRIANGLE}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}
\PYG{n}{IM\PYGZus{}TRIANGLE}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{NAME}} is the name of the method in \sphinxstyleemphasis{GetFEM} (constant integer parameter are
allowed), \sphinxcode{\sphinxupquote{N}} is the dimension, \sphinxcode{\sphinxupquote{GEOTRANS}} describes a valid geometric
transformation of \sphinxstyleemphasis{GetFEM}. This geometric transformation just defines the reference
element on which the integration method is described. \sphinxcode{\sphinxupquote{NBPT}} is the number of
integration node definitions. Integration node definitions include a symmetry
definition such that the total number of integration nodes would be greater than
\sphinxcode{\sphinxupquote{NBPT}}.

Composition of the integration node definition:
\begin{itemize}
\item {} 
an integer: 0 = no symmetry, 1 = full symmetric (x6 for a triangle, x4 for a
quadrangle, x24 for a tetrahedron …),

\item {} 
the \sphinxcode{\sphinxupquote{N}} coordinates of the integration node,

\item {} 
the load.

\end{itemize}

\sphinxcode{\sphinxupquote{NBF}} is the number of faces of the reference element (should
correspond to \sphinxcode{\sphinxupquote{GEOTRANS}}). Then follows an already existing
integration method for each face (each on a line). This is necessary
to make integrations on boundaries.

The file format is inspired from \sphinxcite{biblio:encyclopcubature}.


\chapter{Level\sphinxhyphen{}sets, Xfem, fictitious domains, Cut\sphinxhyphen{}fem}
\label{\detokenize{userdoc/xfem:level-sets-xfem-fictitious-domains-cut-fem}}\label{\detokenize{userdoc/xfem:ud-xfem}}\label{\detokenize{userdoc/xfem::doc}}
Since v2.0, \sphinxstyleemphasis{GetFEM} offers a certain number of facilities to support Xfem
and fictitious domain methods with a cut\sphinxhyphen{}fem strategy. Most of these
tools have been initially mainly developed by Julien Pommier for the
study published in \sphinxcite{biblio:la-po-re-sa2005}.

The implementation is a fairly large generality, based on the use of
level\sphinxhyphen{}sets, as suggested in \sphinxcite{biblio:su-ch-mo-be2001} and allows simultaneous
use of a large number of level\sphinxhyphen{}sets which can cross.

The Xfem implementation for the discretization of the jump follows
the strategy of \sphinxcite{biblio:ha-ha2004} although we had no knowledge of this work
during implementation. This means that there is no degree of freedom
representing the jump across the level\sphinxhyphen{}set. Instead, the degrees of
freedom represent the displacement of each side of the level\sphinxhyphen{}set.
This is essential in any way in the presence of level\sphinxhyphen{}set that
intersect each other because it may exist more than two different
zones of continuity inside a single element.

The cut fem strategy for fictitious domain method has been used for
the first time with \sphinxstyleemphasis{GetFEM} for the study published in \sphinxcite{biblio:ha-re2009} where
a quite simple stabilization strategy is proposed. Here also, before
knowing the existence of the Work of
E. Burman and P. Hanbo \sphinxcite{biblio:bu-ha2010} on that topic.

The tools for Xfem have been then enriched by the PhD works
of J. Larsy (see for instance \sphinxcite{biblio:la-re-sa2010}) the one
of E. Chahine (see for instance \sphinxcite{biblio:ch-la-re2011}, \sphinxcite{biblio:ni-re-ch2011}),
of S. Amdouni  (see for instance \sphinxcite{biblio:am-mo-re2014}, \sphinxcite{biblio:am-mo-re2014b})
and of M. Fabre (see for instance  \sphinxcite{biblio:fa-po-re2015}).

\begin{sphinxadmonition}{important}{Important:}
All the tools listed below needs the package \sphinxhref{http://www.qhull.org}{qhull}
installed on your system. This package is widely available.
It computes convex hull and Delaunay triangulations in arbitrary dimension.
\end{sphinxadmonition}

The programs \sphinxcode{\sphinxupquote{tests/crack.cc}}, \sphinxcode{\sphinxupquote{interface/tests/matlab/crack.m}} and \sphinxcode{\sphinxupquote{interface/tests/python/crack.py}} are some good examples of use of these tools.


\section{Representation of level\sphinxhyphen{}sets}
\label{\detokenize{userdoc/xfem:representation-of-level-sets}}
Some structure are defined to manipulate level\sphinxhyphen{}set functions defined by
piecewise polynomial function on a mesh. In the file
\sphinxcode{\sphinxupquote{getfem/getfem\_levelset.h}} a level\sphinxhyphen{}set is represented by a
function defined on a Lagrange fem of a certain degree on a mesh.
The constructor to define a new \sphinxcode{\sphinxupquote{getfem::level\_set}} is the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{level\PYGZus{}set} \PYG{n}{ls}\PYG{p}{(}\PYG{n}{mesh}\PYG{p}{,} \PYG{n}{degree} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{with\PYGZus{}secondary} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mesh}} is a valid mesh of type \sphinxcode{\sphinxupquote{getfem::mesh}}, \sphinxcode{\sphinxupquote{degree}} is the degree of the
polynomials (1 is the default value), and \sphinxcode{\sphinxupquote{with\_secondary}} is a boolean whose
default value is false. The secondary level\sphinxhyphen{}set is used to represent
fractures (if \(p(x)\) is the primary level\sphinxhyphen{}set function and
\(s(x)\) is the secondary level\sphinxhyphen{}set function, the crack is defined
by \(p(x) = 0\) and \(s(x) \leq 0\): the role of the secondary
is to delimit the crack).

Each level\sphinxhyphen{}set function is defined by a \sphinxtitleref{mesh\_fem} \sphinxcode{\sphinxupquote{mf}} and the dof values
over this \sphinxtitleref{mesh\_fem}, in a vector. The object \sphinxcode{\sphinxupquote{getfem::level\_set}} contains a \sphinxtitleref{mesh\_fem} and the
vectors of dof for the corresponding function(s). The method
\sphinxcode{\sphinxupquote{ls.value(0)}} returns the vector of dof for the primary level\sphinxhyphen{}set
function, so that these values can be set. The method \sphinxcode{\sphinxupquote{ls.value(1)}}
returns the dof vector for the secondary level\sphinxhyphen{}set function if any.
The method \sphinxcode{\sphinxupquote{ls.get\_mesh\_fem()}} returns a reference on the \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object.

Note that, in applications, the level\sphinxhyphen{}set function often evolves thanks
to an Hamilton\sphinxhyphen{}Jacobi equation (for its re\sphinxhyphen{}initialization for instance).
See the {\hyperref[\detokenize{userdoc/convect:ud-convect}]{\sphinxcrossref{\DUrole{std,std-ref}{A pure convection method}}}} which can be used in the approximation of a
Hamilton\sphinxhyphen{}Jacobi equation.


\section{Mesh cut by level\sphinxhyphen{}sets}
\label{\detokenize{userdoc/xfem:mesh-cut-by-level-sets}}
In order to compute adapted integration methods and finite element methods to
represent a field which is discontinuous across one or several level\sphinxhyphen{}sets,
a certain number of pre\sphinxhyphen{}computations have to be done at the mesh level. In
\sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_level\_set.h}} is defined the object \sphinxcode{\sphinxupquote{getfem::mesh\_level\_set}} which
handles these pre\sphinxhyphen{}computations. The constructor of this object is the
following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}level\PYGZus{}set} \PYG{n}{mls}\PYG{p}{(}\PYG{n}{mesh}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mesh}} is a valid mesh of type \sphinxcode{\sphinxupquote{getfem::mesh}}. In order to indicate that
the mesh is cut by a level\sphinxhyphen{}set, one has to call the method
\sphinxcode{\sphinxupquote{mls.add\_level\_set(ls)}}, where \sphinxcode{\sphinxupquote{ls}} is an object of type \sphinxcode{\sphinxupquote{getfem::level\_set}}.
An arbitrary number of level\sphinxhyphen{}sets can be added. To initialize the object
or to actualize it when the value of the level\sphinxhyphen{}set function is modified,
one has to call the method \sphinxcode{\sphinxupquote{mls.adapt()}}.

In particular a subdivision of each element cut by the level\sphinxhyphen{}set is made with
simplices. Note that the whole cut\sphinxhyphen{}mesh is generally not conformal.

The cut\sphinxhyphen{}mesh can be obtained for instance for post\sphinxhyphen{}treatment thanks to \sphinxcode{\sphinxupquote{mls.global\_cut\_mesh(m)}} which fill \sphinxcode{\sphinxupquote{m}} with the cut\sphinxhyphen{}mesh.


\section{Adapted integration methods}
\label{\detokenize{userdoc/xfem:adapted-integration-methods}}
For fields which are discontinuous across a level\sphinxhyphen{}set, integration methods have
to be adapted. The object \sphinxcode{\sphinxupquote{getfem::mesh\_im\_level\_set}} defined in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_im\_level\_set.h}} defines a composite integration method
for the elements cut by the level\sphinxhyphen{}set. The constructor of this object is the
following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im\PYGZus{}level\PYGZus{}set} \PYG{n}{mim}\PYG{p}{(}\PYG{n}{mls}\PYG{p}{,} \PYG{n}{where}\PYG{p}{,} \PYG{n}{regular\PYGZus{}im} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{singular\PYGZus{}im} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mls}} is an object of type \sphinxcode{\sphinxupquote{getfem::mesh\_level\_set}}, \sphinxcode{\sphinxupquote{where}} is an enum for which
possible values are
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{getfem::mesh\_im\_level\_set::INTEGRATE\_INSIDE}} (integrate over \(p(x)<0\)),

\item {} 
\sphinxcode{\sphinxupquote{getfem::mesh\_im\_level\_set::INTEGRATE\_OUTSIDE}} (integrate over \(p(x)>0\)),

\item {} 
\sphinxcode{\sphinxupquote{getfem::mesh\_im\_level\_set::INTEGRATE\_ALL}},

\item {} 
\sphinxcode{\sphinxupquote{getfem::mesh\_im\_level\_set::INTEGRATE\_BOUNDARY}} (integrate over \(p(x)=0\)
and \(s(x)\leq 0\))

\end{itemize}

The argument \sphinxcode{\sphinxupquote{regular\_im}} should be of type \sphinxcode{\sphinxupquote{pintegration\_method}}, and will be
the integration method applied on each sub\sphinxhyphen{}simplex of the composite integration
for elements cut by the level\sphinxhyphen{}set. The optional \sphinxcode{\sphinxupquote{singular\_im}} should be also of
type \sphinxcode{\sphinxupquote{pintegration\_method}} and is used for crack singular functions: it is
applied to sub\sphinxhyphen{}simplices which share a vertex with the crack tip (the specific
integration method \sphinxcode{\sphinxupquote{IM\_QUASI\_POLAR(..)}} is well suited for this purpose).

The object \sphinxcode{\sphinxupquote{getfem::mesh\_im\_level\_set}} can be used as a classical \sphinxcode{\sphinxupquote{getfem::mesh\_im}} object (for instance the
method \sphinxcode{\sphinxupquote{mim.set\_integration\_method(...)}} allows to set the integration methods
for the elements which are not cut by the level\sphinxhyphen{}set).

To initialize the object or to actualize it when the value of the level\sphinxhyphen{}set
function is modified, one has to call the method \sphinxcode{\sphinxupquote{mim.adapt()}}.

When more than one level\sphinxhyphen{}set is declared on the \sphinxcode{\sphinxupquote{getfem::mesh\_level\_set}} object, it is possible to set more precisely the integration domain using the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mim}\PYG{p}{.}\PYG{n}{set\PYGZus{}level\PYGZus{}set\PYGZus{}boolean\PYGZus{}operations}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{desc}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where “desc” is a string containing the description of the boolean operation which defines the integration domain. The syntax is simple, for example if there are 3 different level\sphinxhyphen{}set,
\begin{quote}

“a*b*c” is the intersection of the domains defined by each
level\sphinxhyphen{}set (this is the default behavior if this function is not
called).

“a+b+c” is the union of their domains.

“c\sphinxhyphen{}(a+b)” is the domain of the third level\sphinxhyphen{}set minus the union of
the domains of the two others.

“!a” is the complementary of the domain of a (i.e. it is the
domain where a(x)\textgreater{}0)

The first level\sphinxhyphen{}set is always referred to with “a”, the second
with “b”, and so on.
\end{quote}


\section{Cut\sphinxhyphen{}fem}
\label{\detokenize{userdoc/xfem:cut-fem}}
The implementation of a cut finite element method such as described in \sphinxcite{biblio:bu-ha2010}, i.e. a finite element on a fictitious domain restricted to a smaller real domain, is possible just using the previous tools and mainly the adapted integration method. Several examples are available on \sphinxstyleemphasis{GetFEM} test programs. See for instance \sphinxcode{\sphinxupquote{interface/tests/python/demo\_fictitious\_domain.py}} or \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_fictitious\_domain.m}}.

In this context, one often needs to restrict the unknown finite element field to the degrees of freedom whose corresponding shape function supports have an intersection with the real domain. This can be done using the \sphinxcode{\sphinxupquote{partial\_mesh\_fem}} object. See for instance \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_structural\_optimization.m}}.

Note that often, a stabilization technique have to be considered in order to treat eventual locking phenomena due to element with very small intersection with the real domain for example when applying a Dirichlet condition. See for instance \sphinxcite{biblio:bu-ha2010},  \sphinxcite{biblio:ha-re2009} and \sphinxcite{biblio:fa-po-re2015}.


\section{Discontinuous field across some level\sphinxhyphen{}sets}
\label{\detokenize{userdoc/xfem:discontinuous-field-across-some-level-sets}}
The object \sphinxcode{\sphinxupquote{getfem::mesh\_fem\_level\_set}} is defined in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_fem\_level\_set.h}}. It is derived from \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object
and can be used in the same way. It defines a finite element method with
discontinuity across the level\sphinxhyphen{}sets (it can deal with an arbitrary number of
level\sphinxhyphen{}sets). The constructor is the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}level\PYGZus{}set} \PYG{n}{mfls}\PYG{p}{(}\PYG{n}{mls}\PYG{p}{,} \PYG{n}{mf}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mls}} is a valid mesh of type \sphinxcode{\sphinxupquote{getfem::mesh\_level\_set}} and \sphinxcode{\sphinxupquote{mf}} is the an object of type
\sphinxcode{\sphinxupquote{getfem::mesh\_fem}} which defines the finite element method used for elements which are not
cut by the level\sphinxhyphen{}sets.

To initialize the object or to actualize it when the value of the level\sphinxhyphen{}set
function is modified, one has to call the method \sphinxcode{\sphinxupquote{mfls.adapt()}}.

To represent discontinuous fields, the finite element method is enriched
with discontinuous functions which are the product of some Heaviside functions
by the shape functions of the finite element method represented by \sphinxcode{\sphinxupquote{mf}}
(see \sphinxcite{biblio:ha-ha2004} and \sphinxcite{biblio:xfem} for more details).


\section{Xfem}
\label{\detokenize{userdoc/xfem:xfem}}
The Xfem (see \sphinxcite{biblio:xfem}) consists not only in the enrichment with some Heaviside functions (which is done by the object \sphinxcode{\sphinxupquote{getfem::mesh\_fem\_level\_set}}) but also the enrichment with asymptotic displacement at the crack tip. There is several manner to enrich with an asymptotic displacement: enrichment only on the element containing the crack tip as in \sphinxcite{biblio:xfem}, enrichment in a fixed size zone as in \sphinxcite{biblio:la-po-re-sa2005} or \sphinxcite{biblio:be-mi-mo-bu2005}, enrichment with a cut\sphinxhyphen{}off function as in \sphinxcite{biblio:ch-la-re2008} or \sphinxcite{biblio:ni-re-ch2011} or with an integral matching condition between the enriched and non\sphinxhyphen{}enriched zones as in \sphinxcite{biblio:ch-la-re2011}. The choice in Getfem fell on maximum flexibility to easily implement all possibilities. As it is mainly a transformation of the finite element method itself, two tools have been defined to produce some enriched finite elements:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}product} \PYG{n}{mf\PYGZus{}asympt}\PYG{p}{(}\PYG{n}{mf\PYGZus{}part\PYGZus{}unity}\PYG{p}{,} \PYG{n}{mf\PYGZus{}sing}\PYG{p}{)}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}sum} \PYG{n}{mf\PYGZus{}sum}\PYG{p}{(}\PYG{n}{mf1}\PYG{p}{,} \PYG{n}{mf2}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mf\_sing}} should be a global ‘finite element method’, in fact just a collection of global functions (with or without a cut\sphinxhyphen{}off function) defined thanks to the object \sphinxcode{\sphinxupquote{getfem::mesh\_fem\_global\_function}} (see the file \sphinxcode{\sphinxupquote{src/getfem/getfem\_mesh\_fem\_global\_function.h}}) and \sphinxcode{\sphinxupquote{mf\_part\_unity}} a basic scalar finite element method. The resulting \textasciigrave{}\textasciigrave{} getfem::mesh\_fem\_product\textasciigrave{}\textasciigrave{} is the linear combination of all the product of the shape function of the two given finite element methods, possibly restricted to a sub\sphinxhyphen{}set of degrees of freedom of the first finite element method given by the method \sphinxcode{\sphinxupquote{mf\_asympt.set\_enrichment(enriched\_dofs)}}.

Once the asymptotic enrichment is defined, the object \sphinxcode{\sphinxupquote{getfem::mesh\_fem\_sum}} allows to produce the direct sum of two finite element methods. For instance of the one enriched by the Heaviside functions (\sphinxcode{\sphinxupquote{getfem::mesh\_fem\_level\_set}} object) and the asymptotic enrichment.

See \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_crack.m}}, \sphinxcode{\sphinxupquote{interface/tests/python/demo\_crack.py}} or \sphinxcode{\sphinxupquote{tests/crack.cc}} for some examples of use of these tools.

Additionally, GWFL, the generic weak form language, defines the two commands \sphinxcode{\sphinxupquote{Xfem\_plus}} and \sphinxcode{\sphinxupquote{Xfem\_minus}} allowing to take into account the jump of any field or derivative of any field across a level\sphinxhyphen{}set (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-xfem}]{\sphinxcrossref{\DUrole{std,std-ref}{Xfem discontinuity evaluation (with mesh\_fem\_level\_set)}}}}). This a priori allows to write any interface law easily.

Note also that some procedures are available in the file \sphinxcode{\sphinxupquote{src/getfem/getfem\_crack\_sif.h}} to compute the stress intensity factors in 2D (restricted to homogeneous isotropic linearized elasticity).


\section{Post treatment}
\label{\detokenize{userdoc/xfem:post-treatment}}
Several tools are available to represent the solution only on a side of a levels\sphinxhyphen{}set or on both taking into account the discontinuity (for Xfem approximation).

When a cut\sphinxhyphen{}mesh \sphinxcode{\sphinxupquote{mls}} is used (i.e. a \sphinxcode{\sphinxupquote{getfem::mesh\_level\_set}} object), is is possible to obtain the set of all sub\sphinxhyphen{}elements with the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mls}\PYG{p}{.}\PYG{n}{global\PYGZus{}cut\PYGZus{}mesh}\PYG{p}{(}\PYG{n}{mcut}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mcut}} has to be an empty mesh which will be fill by the sub\sphinxhyphen{}elements. Note that the resulting mesh is a non\sphinxhyphen{}regular one in the sense that the sub\sphinxhyphen{}mesh of all elements are not conformal at the element edges/faces. It is however possible to interolate on a Lagrange fem on this mesh and make a post\sphinxhyphen{}treatment with it to correctly represent a discontinuous field.

Another mean to represent only the interesting part of the solution when a fictitious domain method is used is to use the mesh slices defined by an isovalue level\sphinxhyphen{}set (see {\hyperref[\detokenize{userdoc/export:ud-export-slices}]{\sphinxcrossref{\DUrole{std,std-ref}{Producing mesh slices}}}}).

see for instance files \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_crack.m}}, \sphinxcode{\sphinxupquote{interface/tests/python/demo\_fictitious\_domain.py}} and \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_structural\_optimization.m}}.


\chapter{Tools for HHO (Hybrid High\sphinxhyphen{}Order) methods}
\label{\detokenize{userdoc/hho:tools-for-hho-hybrid-high-order-methods}}\label{\detokenize{userdoc/hho:ud-hho}}\label{\detokenize{userdoc/hho::doc}}
HHO method are hybrid methods in the sense that they have both degrees of freedom located on the element of a mesh and on the faces of the elements which represent separated approximations. HHO method are primal methods in the sense that both the degree of freedom in the element and on the faces represent the main unknown of the problem (no lagrange multipliers is introduced). The interest of these methods, first developped in  \sphinxcite{biblio:di-er2015}, \sphinxcite{biblio:di-er2017} is their accuracy and their great robustness, in particular with respect to the element shapes and their locking\sphinxhyphen{}free properties. Moreover, they can be extended without difficulty to the approximation of nonlinear problems (see \sphinxcite{biblio:ab-er-pi2018} for hyper\sphinxhyphen{}elasticity, \sphinxcite{biblio:ab-er-pi2019} for plasticity and \sphinxcite{biblio:ca-ch-er2019} for contact problems).

HHO methods can be applied to arbitrary shape elements. However, the implementation in \sphinxstyleemphasis{GetFEM} is for the moment limited to standard elements : simplices, quadrilaterals, hexahedrons, … Moreover this implementation is still experimental and not pretending to optimality. For the moment, there is no tool to make an automatic condensation of internal dofs.


\section{HHO elements}
\label{\detokenize{userdoc/hho:hho-elements}}
HHO elements are composite ones having a polynomial approximation space for the interior of the element and a polynomial approximation for each face of the element. Moreover, this is a discontinous approximation, in the sens that no continuity is prescribed between the approximation inside the element and the approximation on the faces, neither than between the approximations on two different faces of the element. However, when two neighbor elements share a face, the approximation on this face is shared by the two elements. \sphinxstyleemphasis{GetFEM} provide a specific method simply called \sphinxcode{\sphinxupquote{FEM\_HHO(fem\_int, fem\_face1, fem\_face2, ...)}} which allows to build an hybrid method from standard finite element spaces. For instance, on a triangle, a possible HHO method can be obtained with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{p}{:}\PYG{p}{:}\PYG{n}{pfem} \PYG{n}{pf} \PYG{o}{=} \PYG{n}{getfem}\PYG{p}{:}\PYG{p}{:}\PYG{n}{fem\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{HHO(FEM\PYGZus{}SIMPLEX\PYGZus{}IPK(2,2), FEM\PYGZus{}SIMPLEX\PYGZus{}CIPK(1,2))}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The first argument to \sphinxcode{\sphinxupquote{FEM\_HHO(...)}} is the fem for the interior of the element. It has to be a discontinuous FEM. The method \sphinxcode{\sphinxupquote{FEM\_SIMPLEX\_IPK(2,2)}} is a discontinous method having its degrees of freedom in the strict interior of the element, which ensure that no dof identification will be done. The second argument is the fem for the faces (if only one method is given, it will be applied to all faces, but it is also possible to give a different method for each face). Their is no verification on the fact that the given method are of discontinuous type (In fact, a method like \sphinxcode{\sphinxupquote{FEM\_HHO(FEM\_PK(2,2), FEM\_PK(1,2))}} will have no difference with \sphinxcode{\sphinxupquote{FEM\_PK(2,2)}} since the degree of freedom on the faces will be identified with the interior ones).

For the moment, the fursnished element for interior and faces are
\sphinxhyphen{} \sphinxcode{\sphinxupquote{FEM\_SIMPLEX\_IPK(n,k)}} : interior PK element of degree k for the simplices in dimension n (equivalent to \sphinxcode{\sphinxupquote{FEM\_PK\_DISCONTINUOUS(n,k,0.1)}}).
\sphinxhyphen{} \sphinxcode{\sphinxupquote{FEM\_QUAD\_IPK(n,k)}} : interior PK element of degree k for the quadrilaterals in dimension n.
\sphinxhyphen{} \sphinxcode{\sphinxupquote{FEM\_PRISM\_IPK(n,k)}} : interior PK element of degree k for the prisms in dimension n.
\sphinxhyphen{} \sphinxcode{\sphinxupquote{FEM\_SIMPLEX\_CIPK(n,k)}} : interior PK element on simplices which is additionnaly connectable. Designed to be use on HHO element face.
\sphinxhyphen{} \sphinxcode{\sphinxupquote{FEM\_QUAD\_CIPK(k)}} : interior PK element on a quadrilateral which is additionnaly connectable. Designed to be use on HHO element face.


\section{Reconstruction operators}
\label{\detokenize{userdoc/hho:reconstruction-operators}}
For a variable \sphinxcode{\sphinxupquote{u}}, we will note \(u_{T}\) its value in the interior of the element \(T\) and \(u_{\partial T}\) its value on the boundary of \(T\) (corresponding to the two different approximations). The reconstruction operators are implemeted in \sphinxstyleemphasis{GetFEM} as elementary transformations, as described in the section {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-elem-trans}]{\sphinxcrossref{\DUrole{std,std-ref}{Elementary transformations}}}}.


\subsection{Reconstructed gradient}
\label{\detokenize{userdoc/hho:reconstructed-gradient}}
The first reconstruction operator is the reconstructed gradient. Given a certain polynomial space \(V_G\), the reconstructed gradient \(G(u)\) will be the solution to the local problem
\begin{equation*}
\begin{split}\int_T G(u):\tau dx = \int_T \nabla u_T : \tau dx + \int_{\partial T} (u_{\partial T} - u_{T}).(\tau n_T) d\Gamma, ~~~ \forall \tau \in V_G\end{split}
\end{equation*}
where \(n_T\) is the outward unit normal to  \(T\) on  \(\partial T\). Note that the space \(V\) is a vector\sphinxhyphen{}valued one if \sphinxcode{\sphinxupquote{u}} is a scalar field variable (in that case, \(G(u):\tau\) reduces to \(G(u).\tau\)) and a matrix\sphinxhyphen{}valued one if \sphinxcode{\sphinxupquote{u}} is a vector field variable.

In order to be used, the elementary transformation corresponding to this operator has first to be added to the model by the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}gradient}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{transname}} is an arbitrary name which will designate the transformation in GWFL (the generic weak form language). Then, it will be possible to refer to the reconstructed gradient of a variable \sphinxcode{\sphinxupquote{u}} into GWFL as \sphinxcode{\sphinxupquote{Elementary\_transformation(u, HHO\_grad, Gu)}}, if \sphinxcode{\sphinxupquote{transname="HHO\_grad"}}. The third parameter of the transformation \sphinxcode{\sphinxupquote{Gu}} should be a fem variable or a data of the model. This variable will not be used on itself but will determine the finite element space of the reconstruction (the space \(V_G\)).

This is an example of use with the Python interface for a two\sphinxhyphen{}dimensional triangule mesh \sphinxcode{\sphinxupquote{m}}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mfu}   \PYG{o}{=} \PYG{n}{gf}\PYG{o}{.}\PYG{n}{MeshFem}\PYG{p}{(}\PYG{n}{m}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{mfgu}  \PYG{o}{=} \PYG{n}{gf}\PYG{o}{.}\PYG{n}{MeshFem}\PYG{p}{(}\PYG{n}{m}\PYG{p}{,} \PYG{n}{N}\PYG{p}{)}
\PYG{n}{mfu}\PYG{o}{.}\PYG{n}{set\PYGZus{}fem}\PYG{p}{(}\PYG{n}{gf}\PYG{o}{.}\PYG{n}{Fem}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{FEM\PYGZus{}HHO(FEM\PYGZus{}SIMPLEX\PYGZus{}IPK(2,2),FEM\PYGZus{}SIMPLEX\PYGZus{}CIPK(1,2))}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{mfgu}\PYG{o}{.}\PYG{n}{set\PYGZus{}fem}\PYG{p}{(}\PYG{n}{gf}\PYG{o}{.}\PYG{n}{Fem}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{FEM\PYGZus{}PK(2,2)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}

\PYG{n}{md} \PYG{o}{=} \PYG{n}{gf}\PYG{o}{.}\PYG{n}{Model}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{real}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{md}\PYG{o}{.}\PYG{n}{add\PYGZus{}fem\PYGZus{}variable}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{u}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{)}
\PYG{n}{md}\PYG{o}{.}\PYG{n}{add\PYGZus{}fem\PYGZus{}data}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Gu}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{mfgu}\PYG{p}{)}

\PYG{n}{md}\PYG{o}{.}\PYG{n}{add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}gradient}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HHO\PYGZus{}Grad}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{md}\PYG{o}{.}\PYG{n}{add\PYGZus{}macro}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HHO\PYGZus{}Grad\PYGZus{}u}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Elementary\PYGZus{}transformation(u, HHO\PYGZus{}Grad, Gu)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{md}\PYG{o}{.}\PYG{n}{add\PYGZus{}macro}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HHO\PYGZus{}Grad\PYGZus{}Test\PYGZus{}u}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Elementary\PYGZus{}transformation(Test\PYGZus{}u, HHO\PYGZus{}Grad, Gu)}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

The macro definitions allowing to use the gradient of the variable inside weak formulations as usual. For instance, the addition of a weak term for the Laplace equation can then be simply written:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{md}\PYG{o}{.}\PYG{n}{add\PYGZus{}linear\PYGZus{}term}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{HHO\PYGZus{}Grad\PYGZus{}u.HHO\PYGZus{}Grad\PYGZus{}Test\PYGZus{}u}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

Two complete examples of use are given in the test programs \sphinxcode{\sphinxupquote{interface/tests/demo\_laplacian\_HHO.py}} and \sphinxcode{\sphinxupquote{interface/tests/demo\_elasticity\_HHO.py}}.


\subsection{Reconstructed symmetrized gradient}
\label{\detokenize{userdoc/hho:reconstructed-symmetrized-gradient}}
The symmetrized gradient is only for vector field variables and additionally when the vector field dimension is the same as the domain dimension. This is usually the case for instance for elasticity problems. With the same notation as in the previous section, the reconstructed gradient \(G^s(u)\) will be the solution to the local problem
\begin{equation*}
\begin{split}\int_T G^s(u):\tau dx = \int_T \nabla^s u_T : \tau dx + \int_{\partial T} (u_{\partial T} - u_{T}).(\tau^s n_T) d\Gamma, ~~~ \forall \tau \in V_G\end{split}
\end{equation*}
where \(\nabla^s u_T = (\nabla u_T + (\nabla u_T)^T)/2\) and \(\tau^s = (\tau + \tau^T)/2\).

The elementary transformation corresponding to this operator can be added to the model by the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}symmetrized\PYGZus{}gradient}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and then be used into GWFL as \sphinxcode{\sphinxupquote{Elementary\_transformation(u, HHO\_sym\_grad, Gu)}}, if \sphinxcode{\sphinxupquote{transname="HHO\_sym\_grad"}}, with \sphinxcode{\sphinxupquote{Gu}} still determining the reconstruction space.


\subsection{Reconstructed variable}
\label{\detokenize{userdoc/hho:reconstructed-variable}}
A recontruction of higher order can be done using both the approximation on the interior and the approximation on the faces. The recontructed variable \(D(u)\) will be the solution to the local Neumann problem on a chosen space \(V_D\)
\begin{equation*}
\begin{split}\int_T \nabla D(u). \nabla v dx = \int_T \nabla u_T . \nabla v dx + \int_{\partial T} (u_{\partial T} - u_{T}).(\nabla v n_T) d\Gamma, ~~~ \forall v \in V_D\end{split}
\end{equation*}
with the additional constraint
\begin{equation*}
\begin{split}\int_T D(u) dx = \int_T u_T dx\end{split}
\end{equation*}
The corresponding elementary transformation can be added to the model by the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}value}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and used into GWFL as \sphinxcode{\sphinxupquote{Elementary\_transformation(u, HHO\_val, ud)}}, if \sphinxcode{\sphinxupquote{transname="HHO\_val"}}, with \sphinxcode{\sphinxupquote{ud}} determining the reconstruction space.


\subsection{Reconstructed variable with symmetrized gradient}
\label{\detokenize{userdoc/hho:reconstructed-variable-with-symmetrized-gradient}}
A variant of the recontruction of a variable is the one using a symmetrized gradient. It can be used only for vector field variables and additionally when the vector field dimension is the same as the domain dimension. The recontructed variable \(D(u)\) will be the solution to the local Neumann problem on a chosen space \(V_D\)
\begin{equation*}
\begin{split}\int_T \nabla^s D(u). \nabla^s v dx = \int_T \nabla^s u_T . \nabla^s v dx + \int_{\partial T} (u_{\partial T} - u_{T}).(\nabla^s v n_T) d\Gamma, ~~~ \forall v \in V_D\end{split}
\end{equation*}
with the additional constraints
\begin{align*}\!\begin{aligned}
& \int_T D(u) dx = \int_T u_T dx\\
&\int_T \mbox{Skew}(\nabla D(u)) dx = \int_{\partial T} (n_T \otimes u_{\partial T} - u_{\partial T} \otimes n_T)/2 d\Gamma\\
\end{aligned}\end{align*}
where \(\mbox{Skew}(\nabla D(u)) = (\nabla D(u) - (\nabla D(u))^T)/2\).

The corresponding elementary transformation can be added to the model by the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}HHO\PYGZus{}reconstructed\PYGZus{}value}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and used into GWFL as \sphinxcode{\sphinxupquote{Elementary\_transformation(u, HHO\_val, ud)}}, if \sphinxcode{\sphinxupquote{transname="HHO\_val"}}, with \sphinxcode{\sphinxupquote{ud}} determining the reconstruction space.


\section{Stabilization operators}
\label{\detokenize{userdoc/hho:stabilization-operators}}
The stabilization operators is an operator that measure in a sense the discontinuity of the approximation. A stabilization is obtained by a penalization term using this operator. The stabilization operator \(S(u)\) is defined on the boundary space \(V_{\partial T}\) of the element, with the formula
\begin{equation*}
\begin{split}S(u) = \Pi_{\partial T}(u_{\partial T} - D(u) - \Pi_{T}(u_T - D(u)))\end{split}
\end{equation*}
where \(D(u)\) is the reconstruction operator on a polynomial space one degree higher that the finite element space used for the variable, \(\Pi_{\partial T}\) is the \(L^2\) projection onto the space of the face approximations and  \(\Pi_{T}\) the \(L^2\) projection onto the space of the interior of the element.

For vector field variables having the same dimension as the domain, there exists also a stabilization operator using the symmetrized gradient, which is defined by
\begin{equation*}
\begin{split}S^s(u) = \Pi_{\partial T}(u_{\partial T} - D^s(u) - \Pi_{T}(u_T - D^s(u)))\end{split}
\end{equation*}
The corresponding elementary transformations can be added to the model by the two commands:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}HHO\PYGZus{}stabilization}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{add\PYGZus{}HHO\PYGZus{}symmetrized\PYGZus{}stabilization}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and used into GWFL as \sphinxcode{\sphinxupquote{Elementary\_transformation(u, HHO\_stab)}}, if \sphinxcode{\sphinxupquote{transname="HHO\_stab"}}. A third argument is optional to specify the target (HHO) space (the default is one of the variable itself). An example of use is also given in the test programs \sphinxcode{\sphinxupquote{interface/tests/demo\_laplacian\_HHO.py}} and \sphinxcode{\sphinxupquote{interface/tests/demo\_elasticity\_HHO.py}}.


\chapter{Interpolation/projection of a finite element method on non\sphinxhyphen{}matching meshes}
\label{\detokenize{userdoc/interNMM:interpolation-projection-of-a-finite-element-method-on-non-matching-meshes}}\label{\detokenize{userdoc/interNMM:ud-internmm}}\label{\detokenize{userdoc/interNMM::doc}}
A special finite element method is defined in
\sphinxcode{\sphinxupquote{getfem/getfem\_interpolated\_fem.h}} which is not a real finite element
method, but a pseudo\sphinxhyphen{}fem which interpolates a finite element method defined on
another mesh. If you need to assemble a matrix with finite element methods
defined on different meshes, you may use the “interpolated fem” or “projected
fem” for that purpose:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// interpolation within a volume}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{new\PYGZus{}interpolated\PYGZus{}fem}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{n}{mf}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{n}{mim}\PYG{p}{)}\PYG{p}{;}
\PYG{c+c1}{// projection on a surface}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{new\PYGZus{}projected\PYGZus{}fem}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{n}{mf}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{n}{mim}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Because each base function of the finite element method has to be interpolated,
such a computation can be a heavy procedure. By default, the interpolated fem
object store the interpolation data.

The interpolation is made on each Gauss point of the integration methods of
\sphinxcode{\sphinxupquote{mim}}, so only this integration method can be used in assembly
procedures.

For instance if you need to compute the mass matrix between two different finite
element methods defined on two different meshes, this is an example of code which
interpolate the second FEM. on the mesh of the first FEM., assuming that \sphinxcode{\sphinxupquote{mf}}
describes the finite element method and \sphinxcode{\sphinxupquote{mim}} is the chosen integration method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{n}{mf\PYGZus{}interpole}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{.}\PYG{n}{linked\PYGZus{}mesh}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{pfem} \PYG{n}{ifem} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{new\PYGZus{}interpolated\PYGZus{}fem}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{dal}\PYG{o}{:}\PYG{o}{:}\PYG{n}{bit\PYGZus{}vector} \PYG{n}{nn} \PYG{o}{=} \PYG{n}{mfu}\PYG{p}{.}\PYG{n}{convex\PYGZus{}index}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{mf\PYGZus{}interpole}\PYG{p}{.}\PYG{n}{set\PYGZus{}finite\PYGZus{}element}\PYG{p}{(}\PYG{n}{nn}\PYG{p}{,} \PYG{n}{ifem}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}mass\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{SM1}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mfu}\PYG{p}{,} \PYG{n}{mf\PYGZus{}interpole}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{del\PYGZus{}interpolated\PYGZus{}fem}\PYG{p}{(}\PYG{n}{ifem}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The object pointed by \sphinxcode{\sphinxupquote{ifem}} contains all the information concerning the
interpolation. It could use a lot of memory. As pfem is a shared\_ptr, the
interpolated fem will be automatically destroyed when the last pointer on it is
destroyed. To obtain a better accuracy, it is better to refine the integration
method (with \sphinxcode{\sphinxupquote{IM\_STRUCTURED\_COMPOSITE}} for instance) rather than increase its
order.


\section{mixed methods with different meshes}
\label{\detokenize{userdoc/interNMM:mixed-methods-with-different-meshes}}
Instead of using the previous tools (interpolated and projected fems), it is
possible to use a finite element variable defined on an another mesh than the one
on which an assembly is computed using the “interpolate transformation” tool
of GWFL (the generic weak form language, see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-transf}]{\sphinxcrossref{\DUrole{std,std-ref}{Interpolate transformations}}}} ),
the finite element
variables will be interpolated on each Gauss point. There is no restriction
on the dimensions of the mesh used, which means in particular that a
two\sphinxhyphen{}dimensional fem variable can be interpolated on a one\sphinxhyphen{}dimensional mesh
(allowing the coupling of shell and beam elements, for instance).
It is also possible to use some transformations like polar coordinates to
euclidean ones.


\section{mortar methods}
\label{\detokenize{userdoc/interNMM:mortar-methods}}
Mortar methods are supported by \sphinxstyleemphasis{GetFEM}. The coupling term between non matching
meshes can in particular be computed using the interpolate transformations of
GWFL (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-transf}]{\sphinxcrossref{\DUrole{std,std-ref}{Interpolate transformations}}}}).


\chapter{Compute \protect\(L^2\protect\) and \protect\(H^1\protect\) norms}
\label{\detokenize{userdoc/computeL2H1:compute-l-2-and-h-1-norms}}\label{\detokenize{userdoc/computeL2H1:ud-computel2h1}}\label{\detokenize{userdoc/computeL2H1::doc}}
The file \sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}} defines the functions to compute
\(L^2\) and \(H^1\) norms of a solution. The following functions compute
the different norms:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}L2\PYGZus{}norm}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{mesh\PYGZus{}region}\PYG{o}{:}\PYG{o}{:}\PYG{n}{all\PYGZus{}convexes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}H1\PYGZus{}semi\PYGZus{}norm}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{mesh\PYGZus{}region}\PYG{o}{:}\PYG{o}{:}\PYG{n}{all\PYGZus{}convexes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}H1\PYGZus{}norm}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{mesh\PYGZus{}region}\PYG{o}{:}\PYG{o}{:}\PYG{n}{all\PYGZus{}convexes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mim}} is a \sphinxcode{\sphinxupquote{getfem::mesh\_im}} used for the integration, \sphinxcode{\sphinxupquote{mf}} is a \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} and
describes the finite element method on which the solution is defined, \sphinxcode{\sphinxupquote{U}} is the
vector of values of the solution on each degree of freedom of \sphinxcode{\sphinxupquote{mf}} and \sphinxcode{\sphinxupquote{region}} is an optional parameter which specify the mesh region on which the norm is computed. The size of
\sphinxcode{\sphinxupquote{U}} should be \sphinxcode{\sphinxupquote{mf.nb\_dof()}}.

In order to compare two solutions, it is often simpler and faster to use the
following function than to interpolate one \sphinxtitleref{mesh\_fem} on another:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}L2\PYGZus{}dist}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf1}\PYG{p}{,} \PYG{n}{U1}\PYG{p}{,} \PYG{n}{mf2}\PYG{p}{,} \PYG{n}{U2}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{mesh\PYGZus{}region}\PYG{o}{:}\PYG{o}{:}\PYG{n}{all\PYGZus{}convexes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}H1\PYGZus{}dist}\PYG{p}{(}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf1}\PYG{p}{,} \PYG{n}{U1}\PYG{p}{,} \PYG{n}{mf2}\PYG{p}{,} \PYG{n}{U2}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{mesh\PYGZus{}region}\PYG{o}{:}\PYG{o}{:}\PYG{n}{all\PYGZus{}convexes}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

These functions return the \(L^2\) and \(H^1\) norms of \(u_1-u_2\).


\chapter{Compute derivatives}
\label{\detokenize{userdoc/computeD:compute-derivatives}}\label{\detokenize{userdoc/computeD:ud-computed}}\label{\detokenize{userdoc/computeD::doc}}
The file \sphinxcode{\sphinxupquote{getfem/getfem\_derivatives.h}} defines the following function to
compute the gradient of a solution:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}gradient}\PYG{p}{(}\PYG{n}{mf1}\PYG{p}{,} \PYG{n}{mf2}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{n}{V}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mf1}} is a variable of type \sphinxtitleref{mesh\_fem} and describes the finite element method
on which the solution is defined, \sphinxcode{\sphinxupquote{mf2}} describes the finite element method to
compute the gradient, \sphinxcode{\sphinxupquote{U}} is a vector representing the solution and should be
of size \sphinxcode{\sphinxupquote{mf1.nb\_dof()}}, \sphinxcode{\sphinxupquote{V}} is the vector on which the gradient will be
computed and should be of size \sphinxcode{\sphinxupquote{N * mf2.nb\_dof()}}, with \sphinxcode{\sphinxupquote{N}} the dimension of
the domain.


\chapter{Export and view a solution}
\label{\detokenize{userdoc/export:export-and-view-a-solution}}\label{\detokenize{userdoc/export:ud-export}}\label{\detokenize{userdoc/export::doc}}
There are essentially four ways to view the result of getfem computations:
\begin{itemize}
\item {} 
Scilab, Octave or Matlab, with the interface.

\item {} 
The open\sphinxhyphen{}source Paraview or Mayavi or any other VTK/VTU file viewer.

\item {} 
The open\sphinxhyphen{}source OpenDX program.

\item {} 
The open\sphinxhyphen{}source Gmsh program.

\end{itemize}

The objects that can be exported are, \sphinxtitleref{mesh}, \sphinxtitleref{mesh\_fem} objects, and \sphinxtitleref{stored\_mesh\_slice}.


\section{Saving mesh and mesh\_fem objects for the Matlab interface}
\label{\detokenize{userdoc/export:saving-mesh-and-mesh-fem-objects-for-the-matlab-interface}}
If you have installed the Scilab, Octave or Matlab interface, you can simply use
\sphinxcode{\sphinxupquote{mesh\_fem::write\_to\_file}} and save the solution as a plain text file, and then,
load them with the interface. For example, supposing you have a solution \sphinxcode{\sphinxupquote{U}} on a \sphinxtitleref{mesh\_fem}
\sphinxcode{\sphinxupquote{mf}},:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{fstream} \PYG{n}{f}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{solution.U}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ios}\PYG{o}{:}\PYG{o}{:}\PYG{n}{out}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{for} \PYG{p}{(}\PYG{k+kt}{unsigned} \PYG{n}{i}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{;} \PYG{n}{i} \PYG{o}{\PYGZlt{}} \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vect\PYGZus{}size}\PYG{p}{(}\PYG{n}{U}\PYG{p}{)}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{i}\PYG{p}{)}
  \PYG{n}{f} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{n}{U}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]} \PYG{o}{\PYGZlt{}}\PYG{o}{\PYGZlt{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s+se}{\PYGZbs{}v}\PYG{l+s}{erb+}\PYG{l+s}{\PYGZbs{}}\PYG{l+s}{+n}\PYG{l+s}{\PYGZdq{}}\PYG{p}{;}

\PYG{c+c1}{// when the 2nd arg is true, the mesh is saved with the |mf|}
\PYG{n}{mf}\PYG{p}{.}\PYG{n}{write\PYGZus{}to\PYGZus{}file}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{solution.mf}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and then, under Scilab, Octave or Matlab:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}}\PYG{o}{\PYGZgt{}} \PYG{n}{U}\PYG{p}{=}\PYG{n}{load}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{solution.U\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{o}{\PYGZgt{}}\PYG{o}{\PYGZgt{}} \PYG{n}{mf}\PYG{p}{=}\PYG{n}{gfMeshFem}\PYG{p}{(}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{load\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{solution.mf\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{o}{\PYGZgt{}}\PYG{o}{\PYGZgt{}} \PYG{n}{gf\PYGZus{}plot}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{,}\PYG{n}{U}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{mesh\PYGZsq{}}\PYG{p}{,}\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{on\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

See the getfem\sphinxhyphen{}matlab interface documentation for more details.

Four file formats are supported for export: the \sphinxhref{https://vtk.org/Wiki/VTK\_XML\_Formats}{VTK} and \sphinxhref{https://vtk.org/Wiki/VTK\_XML\_Formats}{VTU} file
formats, the\textasciigrave{}OpenDX\textasciigrave{}\_ file format and the \sphinxhref{http://www.geuz.org/gmsh}{Gmsh} post\sphinxhyphen{}processing file
format. All four can be used for exporting either a \sphinxcode{\sphinxupquote{getfem::mesh}} or \sphinxcode{\sphinxupquote{getfem::mesh\_fem}}, and
all except \sphinxhref{https://vtk.org/Wiki/VTK\_XML\_Formats}{VTU} can be used for exporting the more versatile \sphinxcode{\sphinxupquote{getfem::stored\_mesh\_slice}}.
The corresponding four classes: \sphinxcode{\sphinxupquote{getfem::vtk\_export}}, \sphinxcode{\sphinxupquote{getfem::vtu\_export}},
\sphinxcode{\sphinxupquote{getfem::dx\_export}} and \sphinxcode{\sphinxupquote{getfem::pos\_export}} are contained in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_export.h}}.

Examples of use can be found in the examples of the tests directory.


\section{Producing mesh slices}
\label{\detokenize{userdoc/export:producing-mesh-slices}}\label{\detokenize{userdoc/export:ud-export-slices}}
\sphinxstyleemphasis{GetFEM} provides “slicers” objects which are dedicated to generating post\sphinxhyphen{}treatment
data from meshes and solutions. These slicers, defined in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_slicers.h}} take a \sphinxtitleref{mesh} (and sometimes a \sphinxtitleref{mesh\_fem} with a
solution field) on input, and produce a set of simplices after applying some
operations such as \sphinxstyleemphasis{intersection with a plane}, \sphinxstyleemphasis{extraction of the mesh
boundary}, \sphinxstyleemphasis{refinement of each convex}, \sphinxstyleemphasis{extraction of isosurfaces}, etc. The
output of these slicers can be stored in a \sphinxcode{\sphinxupquote{getfem::stored\_mesh\_slice}} object (see the file
\sphinxcode{\sphinxupquote{getfem/getfem\_mesh\_slice.h}}). A \sphinxtitleref{stored\_mesh\_slice} object may be considered as a P1
discontinuous FEM on a non\sphinxhyphen{}conformal mesh with fast interpolation ability. Slices
are made of segments, triangles and tetrahedrons, so the convexes of the original
mesh are always simplexified.

All slicer operation inherit from \sphinxcode{\sphinxupquote{getfem::slicer\_action}}, it is very easy to create a new
slicer. Example of slicers are (some of them use a \sphinxcode{\sphinxupquote{getfem::mesh\_slice\_cv\_dof\_data\_base}} which is just a
reference to a \sphinxtitleref{mesh\_fem} \sphinxcode{\sphinxupquote{mf}} and a field \sphinxcode{\sphinxupquote{U}} on this \sphinxtitleref{mesh\_fem}).
\index{getfem::slicer\_none (C++ function)@\spxentry{getfem::slicer\_none}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem11slicer_noneEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_none}}}{}{}%
\pysigstopmultiline
empty slicer.

\end{fulllineitems}

\index{getfem::slicer\_boundary (C++ function)@\spxentry{getfem::slicer\_boundary}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem15slicer_boundaryERK4mesh5ldots}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_boundary}}}{\sphinxbfcode{\sphinxupquote{const}} mesh \&\sphinxstyleemphasis{m}, ldots}{}%
\pysigstopmultiline
extract the boundary of a mesh.

\end{fulllineitems}

\index{getfem::slicer\_apply\_deformation (C++ function)@\spxentry{getfem::slicer\_apply\_deformation}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem24slicer_apply_deformationER27mesh_slice_cv_dof_data_base}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_apply\_deformation}}}{mesh\_slice\_cv\_dof\_data\_base\&}{}%
\pysigstopmultiline
apply a deformation to the mesh , the deformation field is defined on a \sphinxtitleref{mesh\_fem}.

\end{fulllineitems}

\index{getfem::slicer\_half\_space (C++ function)@\spxentry{getfem::slicer\_half\_space}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem17slicer_half_spaceE9base_node9base_nodei}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_half\_space}}}{base\_node \sphinxstyleemphasis{x0}, base\_node \sphinxstyleemphasis{n}, int \sphinxstyleemphasis{orient}}{}%
\pysigstopmultiline
cut the mesh with a half space (if \sphinxcode{\sphinxupquote{orient}} = \sphinxhyphen{}1 or +1), or a plane (if
\sphinxcode{\sphinxupquote{orient}} = 0), \sphinxcode{\sphinxupquote{x0}} being a node of the plane, and \sphinxcode{\sphinxupquote{n}} being a normal
of the plane.

\end{fulllineitems}

\index{getfem::slicer\_sphere (C++ function)@\spxentry{getfem::slicer\_sphere}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem13slicer_sphereE9base_node11scalar_typei}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_sphere}}}{base\_node \sphinxstyleemphasis{x0}, scalar\_type \sphinxstyleemphasis{R}, int \sphinxstyleemphasis{orient}}{}%
\pysigstopmultiline
cut with the interior (\sphinxcode{\sphinxupquote{orient\textasciigrave{}\textasciigrave{}=\sphinxhyphen{}1), boundary (\textasciigrave{}\textasciigrave{}orient\textasciigrave{}\textasciigrave{}=0) or exterior
(\textasciigrave{}\textasciigrave{}orient\textasciigrave{}\textasciigrave{}=+1) or a sphere of center \textasciigrave{}\textasciigrave{}x0}} and radius \sphinxcode{\sphinxupquote{R}}.

\end{fulllineitems}

\index{getfem::slicer\_cylinder (C++ function)@\spxentry{getfem::slicer\_cylinder}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem15slicer_cylinderE9base_node9base_node11scalar_typei}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_cylinder}}}{base\_node \sphinxstyleemphasis{x0}, base\_node \sphinxstyleemphasis{x1}, scalar\_type \sphinxstyleemphasis{R}, int \sphinxstyleemphasis{orient}}{}%
\pysigstopmultiline
slice with the interior/boundary/exterior of a cylinder of axis \sphinxcode{\sphinxupquote{(x0,x1)}}
and radius \sphinxcode{\sphinxupquote{R}}.

\end{fulllineitems}

\index{getfem::slicer\_isovalues (C++ function)@\spxentry{getfem::slicer\_isovalues}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem16slicer_isovaluesERK27mesh_slice_cv_dof_data_base11scalar_typei}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_isovalues}}}{\sphinxbfcode{\sphinxupquote{const}} mesh\_slice\_cv\_dof\_data\_base \&\sphinxstyleemphasis{mfU}, scalar\_type \sphinxstyleemphasis{val}, int \sphinxstyleemphasis{orient}}{}%
\pysigstopmultiline
cut with the isosurface defined by the scalar field \sphinxcode{\sphinxupquote{mfU}} and \sphinxcode{\sphinxupquote{val}}.
Keep only simplices where :\(u(x)<val\) (\sphinxcode{\sphinxupquote{orient\textasciigrave{}\textasciigrave{}=\sphinxhyphen{}1), :math:\textasciigrave{}u(x)=val\textasciigrave{}
(\textasciigrave{}\textasciigrave{}orient=0}} or \(u(x)>val\).

\end{fulllineitems}

\index{getfem::slicer\_mesh\_with\_mesh (C++ function)@\spxentry{getfem::slicer\_mesh\_with\_mesh}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem21slicer_mesh_with_meshERK4mesh}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_mesh\_with\_mesh}}}{\sphinxbfcode{\sphinxupquote{const}} mesh \&\sphinxstyleemphasis{m2}}{}%
\pysigstopmultiline
cut the convexes with the convexes of the mesh \sphinxcode{\sphinxupquote{m2}}.

\end{fulllineitems}

\index{getfem::slicer\_union (C++ function)@\spxentry{getfem::slicer\_union}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem12slicer_unionERK13slicer_actionRK13slicer_action}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_union}}}{\sphinxbfcode{\sphinxupquote{const}} slicer\_action \&\sphinxstyleemphasis{sA}, \sphinxbfcode{\sphinxupquote{const}} slicer\_action \&\sphinxstyleemphasis{sB}}{}%
\pysigstopmultiline
merges the output of two slicer operations.

\end{fulllineitems}

\index{getfem::slicer\_intersect (C++ function)@\spxentry{getfem::slicer\_intersect}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem16slicer_intersectER13slicer_actionR13slicer_action}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_intersect}}}{slicer\_action \&\sphinxstyleemphasis{sA}, slicer\_action \&\sphinxstyleemphasis{sB}}{}%
\pysigstopmultiline
intersect the output of two slicer operations.

\end{fulllineitems}

\index{getfem::slicer\_complementary (C++ function)@\spxentry{getfem::slicer\_complementary}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem20slicer_complementaryER13slicer_action}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_complementary}}}{slicer\_action \&\sphinxstyleemphasis{s}}{}%
\pysigstopmultiline
return the complementary of a slicer operation.

\end{fulllineitems}

\index{getfem::slicer\_build\_edges\_mesh (C++ function)@\spxentry{getfem::slicer\_build\_edges\_mesh}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem23slicer_build_edges_meshER4mesh}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_build\_edges\_mesh}}}{mesh \&\sphinxstyleemphasis{edges\_m}}{}%
\pysigstopmultiline
slicer whose side\sphinxhyphen{}effect is to build the mesh \sphinxcode{\sphinxupquote{edges\_m}} with the edges of
the sliced mesh.

\end{fulllineitems}

\index{getfem::slicer\_build\_mesh (C++ function)@\spxentry{getfem::slicer\_build\_mesh}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem17slicer_build_meshER4mesh}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_build\_mesh}}}{mesh \&\sphinxstyleemphasis{m}}{}%
\pysigstopmultiline
in some (rare) occasions , it might be useful to build a mesh from a slice.
Note however that there is absolutely no guaranty that the mesh will be
conformal (although it is often the case).

\end{fulllineitems}

\index{getfem::slicer\_build\_stored\_mesh\_slice (C++ function)@\spxentry{getfem::slicer\_build\_stored\_mesh\_slice}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem30slicer_build_stored_mesh_sliceER17stored_mesh_slice}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_build\_stored\_mesh\_slice}}}{stored\_mesh\_slice \&\sphinxstyleemphasis{sl}}{}%
\pysigstopmultiline
record the output of the slicing operation into a \sphinxtitleref{stored\_mesh\_slice} object. Note that it
is often more convenient to use the \sphinxcode{\sphinxupquote{stored\_mesh\_slice::build(...)}} method to
achieve the same result.

\end{fulllineitems}

\index{getfem::slicer\_explode (C++ function)@\spxentry{getfem::slicer\_explode}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/export:_CPPv4N6getfem14slicer_explodeE1c}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{slicer\_explode}}}{c}{}%
\pysigstopmultiline
shrink or expand each convex with respect to its gravity center.

\end{fulllineitems}


In order to apply these slicers, a \sphinxcode{\sphinxupquote{getfem::mesh\_slicer(mesh\&)}} object should be
created, and the \sphinxcode{\sphinxupquote{getfem::slicer\_action}} are then stacked with
\sphinxcode{\sphinxupquote{mesh\_slicer::push\_back\_action(slicer\_action\&)}} and
\sphinxcode{\sphinxupquote{mesh\_slicer::push\_front\_action(slicer\_action\&)}}. The slicing operation is
finally executed with \sphinxcode{\sphinxupquote{mesh\_slicer::exec(int nrefine)}} (or
\sphinxcode{\sphinxupquote{mesh\_slicer::exec(int nrefine, const mesh\_region \&cvlst)}} to apply the operation
to a subset of the mesh, or its boundary etc.).

The \sphinxcode{\sphinxupquote{nrefine}} parameter is very important, as the “precision” of the final result
will depend on it: if the data that is represented on the final slice is just P1
data on convexes with a linear geometric transformation, \sphinxcode{\sphinxupquote{nrefine = 1}} is the
right choice, but for P2, P3, non linear transformation etc, it is better to refine
each convex of the original mesh during the slicing operation. This allows an
accurate representation of any finite element field onto a very simple structure
(linear segment/triangles/tetrahedrons with P1 discontinuous data on them) which is
what most visualization programs (gmsh, mayavi, opendx, scilab, octave, matlab, etc.) expect.

Example of use (cut the boundary of a mesh \sphinxcode{\sphinxupquote{m}} with a half\sphinxhyphen{}space, and save the
result into a \sphinxtitleref{stored\_mesh\_slice}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}boundary} \PYG{n}{a0}\PYG{p}{(}\PYG{n}{m}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}half\PYGZus{}space} \PYG{n}{a1}\PYG{p}{(}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{stored\PYGZus{}mesh\PYGZus{}slice} \PYG{n}{sl}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}build\PYGZus{}stored\PYGZus{}mesh\PYGZus{}slice} \PYG{n}{a2}\PYG{p}{(}\PYG{n}{sl}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}slicer} \PYG{n}{slicer}\PYG{p}{(}\PYG{n}{m}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{slicer}\PYG{p}{.}\PYG{n}{push\PYGZus{}back\PYGZus{}action}\PYG{p}{(}\PYG{n}{a1}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{slicer}\PYG{p}{.}\PYG{n}{push\PYGZus{}back\PYGZus{}action}\PYG{p}{(}\PYG{n}{a2}\PYG{p}{)}\PYG{p}{;}
\PYG{k+kt}{int} \PYG{n}{nrefine} \PYG{o}{=} \PYG{l+m+mi}{3}\PYG{p}{;}
\PYG{n}{slicer}\PYG{p}{.}\PYG{n}{exec}\PYG{p}{(}\PYG{n}{nrefine}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In order to build a \sphinxcode{\sphinxupquote{getfem::stored\_mesh\_slice}} object during the slicing operation, the \sphinxcode{\sphinxupquote{stored\_mesh\_slice::build()}} method is often more convenient than using explicitly the \sphinxcode{\sphinxupquote{slicer\_build\_stored\_mesh\_slice}} slicer:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{stored\PYGZus{}mesh\PYGZus{}slice} \PYG{n}{sl}\PYG{p}{;}
\PYG{n}{sl}\PYG{p}{.}\PYG{n}{build}\PYG{p}{(}\PYG{n}{m}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}boundary}\PYG{p}{(}\PYG{n}{m}\PYG{p}{)}\PYG{p}{,}
         \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}half\PYGZus{}space}\PYG{p}{(}\PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mi}{0}\PYG{p}{,}\PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{n}{base\PYGZus{}node}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{,}
         \PYG{n}{nrefine}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The simplest way to use these slices is to export them to \sphinxstyleemphasis{VTK},
\sphinxstyleemphasis{OpenDX}, or \sphinxstyleemphasis{Gmsh}.


\section{Exporting \sphinxtitleref{mesh}, \sphinxtitleref{mesh\_fem} or slices to VTK/VTU}
\label{\detokenize{userdoc/export:exporting-m-mf-or-slices-to-vtk-vtu}}
VTK/VTU files can handle data on segment, triangles, quadrangles,
tetrahedrons and hexahedrons of first or second degree.

For example, supposing that a \sphinxtitleref{stored\_mesh\_slice} \sphinxcode{\sphinxupquote{sl}} has already been built:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// an optional the 2nd argument can be set to true to produce}
\PYG{c+c1}{// a text file instead of a binary file}
\PYG{n}{vtk\PYGZus{}export} \PYG{n+nf}{exp}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{output.vtk}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{exporting}\PYG{p}{(}\PYG{n}{sl}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// will save the geometrical structure of the slice}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfp}\PYG{p}{,} \PYG{n}{P}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{pressure}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// write a scalar field}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{displacement}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// write a vector field}
\end{sphinxVerbatim}

In this example, the fields \sphinxcode{\sphinxupquote{P}} and \sphinxcode{\sphinxupquote{U}} are interpolated on the slice
nodes and then written into the VTK field.

It is also possible to export a \sphinxtitleref{mesh\_fem} \sphinxcode{\sphinxupquote{mfu}} without having to build a slice:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// an optional the 2nd argument can be set to true to produce}
\PYG{c+c1}{// a text file instead of a binary file}
\PYG{n}{vtk\PYGZus{}export} \PYG{n+nf}{exp}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{output.vtk}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{exporting}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfp}\PYG{p}{,} \PYG{n}{P}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{pressure}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// write a scalar field}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{displacement}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// write a vector field}
\end{sphinxVerbatim}

An \sphinxtitleref{mesh\_fem} \sphinxcode{\sphinxupquote{mfu}} can also be exported in the VTU format with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{// VTU export is limitted to ascii output and cannot be used for slices}
\PYG{n}{vtu\PYGZus{}export} \PYG{n+nf}{exp}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{output.vtu)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{exporting}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// will save the geometrical structure of the mesh\PYGZus{}fem}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfp}\PYG{p}{,} \PYG{n}{P}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{pressure}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// write a scalar field}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{displacement}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// write a vector field}
\end{sphinxVerbatim}

Note however that when exporing a \sphinxtitleref{mesh\_fem} with \sphinxcode{\sphinxupquote{vtk\_export}} or \sphinxcode{\sphinxupquote{vtu\_export}}
each convex/fem of \sphinxcode{\sphinxupquote{mfu}} will be mapped to a VTK/VTU element type. As
VTK/VTU does not handle elements of degree greater than 2, there will be a
loss of precision for higher degree FEMs.


\section{Exporting \sphinxtitleref{mesh}, \sphinxtitleref{mesh\_fem} or slices to OpenDX}
\label{\detokenize{userdoc/export:exporting-m-mf-or-slices-to-opendx}}
The OpenDX data file is more versatile than the VTK one. It is able to store more
that one mesh, any number of fields on these meshes etc. However, it does only
handle elements of degree 1 and 0 (segments, triangles, tetrahedrons, quadrangles
etc.). And each mesh can only be made of one type of element, it cannot mix
triangles and quadrangles in a same object. For that reason, it is generally
preferable to export \sphinxcode{\sphinxupquote{getfem::stored\_mesh\_slice}} objects (in which non simplex elements are
simplexified, and which allows refinement of elements) than \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} and \sphinxcode{\sphinxupquote{getfem::mesh}}
objects.

The basic usage is very similar to \sphinxcode{\sphinxupquote{getfem::vtk\_export}}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{dx\PYGZus{}export} \PYG{n}{exp}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{output.dx}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{exporting}\PYG{p}{(}\PYG{n}{sl}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mfu}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{displacement}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Moreover, \sphinxcode{\sphinxupquote{getfem::dx\_export}} is able to reopen a ‘.dx’ file and append new data into
it. Hence it is possible, if many time\sphinxhyphen{}steps are to be saved, to view intermediate
results in OpenDX during the computations. The prototype of the constructor is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dx\PYGZus{}export}\PYG{p}{(}\PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZam{}} \PYG{n}{filename}\PYG{p}{,} \PYG{k+kt}{bool} \PYG{n}{ascii} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{,} \PYG{k+kt}{bool} \PYG{n}{append} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{dx\PYGZus{}export}\PYG{p}{(}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{ostream} \PYG{o}{\PYGZam{}}\PYG{n}{os\PYGZus{}}\PYG{p}{,} \PYG{k+kt}{bool} \PYG{n}{ascii} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

An example of use, with multiple time steps (taken from
\sphinxcode{\sphinxupquote{tests/dynamic\_friction.cc}}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{stored\PYGZus{}mesh\PYGZus{}slice} \PYG{n}{sl}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{dx\PYGZus{}export} \PYG{n}{exp}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{output.dx}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{if} \PYG{p}{(}\PYG{n}{N} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{)} \PYG{n}{sl}\PYG{p}{.}\PYG{n}{build}\PYG{p}{(}\PYG{n}{mesh}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}none}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{else}        \PYG{n}{sl}\PYG{p}{.}\PYG{n}{build}\PYG{p}{(}\PYG{n}{mesh}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{slicer\PYGZus{}boundary}\PYG{p}{(}\PYG{n}{mesh}\PYG{p}{)}\PYG{p}{,}\PYG{l+m+mi}{4}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{exporting}\PYG{p}{(}\PYG{n}{sl}\PYG{p}{,}\PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// for each mesh object, a corresponding ``mesh\PYGZsq{}\PYGZsq{} object will be}
\PYG{c+c1}{// created in the data file for the edges of the original mesh}
\PYG{n}{exp}\PYG{p}{.}\PYG{n}{exporting\PYGZus{}mesh\PYGZus{}edges}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}

\PYG{k}{while} \PYG{p}{(}\PYG{n}{t} \PYG{o}{\PYGZlt{}}\PYG{o}{=} \PYG{n}{T}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}
  \PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{U0}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{exp}\PYG{p}{.}\PYG{n}{serie\PYGZus{}add\PYGZus{}object}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{deformation}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{exp}\PYG{p}{.}\PYG{n}{write\PYGZus{}point\PYGZus{}data}\PYG{p}{(}\PYG{n}{mf\PYGZus{}vm}\PYG{p}{,} \PYG{n}{VM}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{exp}\PYG{p}{.}\PYG{n}{serie\PYGZus{}add\PYGZus{}object}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{von\PYGZus{}mises\PYGZus{}stress}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

In this example, an OpenDX “time series” is created, for each time step, two data
fields are saved: a vector field called “deformation”, and a scalar field called
“von\_mises\_stress”.

Note also that the \sphinxcode{\sphinxupquote{dx\_export::exporting\_mesh\_edges()}} function has been called.
It implies that for each mesh exported, the edges of the original mesh are also
exported (into another OpenDX mesh). In this example, you have access in OpenDX to
4 data fields: “deformation”, “deformation\_edges”, “von\_mises\_stress” and
“von\_mises\_stress\_edges”.

The \sphinxcode{\sphinxupquote{tests/dynamic\_friction.net}} is an example of OpenDX program for these data
(run it with \sphinxcode{\sphinxupquote{cd tests; dx \sphinxhyphen{}edit dynamic\_friction.net}} , menu
“Execute/sequencer”).


\chapter{A pure convection method}
\label{\detokenize{userdoc/convect:a-pure-convection-method}}\label{\detokenize{userdoc/convect:ud-convect}}\label{\detokenize{userdoc/convect::doc}}
A method to compute a pure convection is defined in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_convect.h}}. The call of the function is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{convect}\PYG{p}{(}\PYG{n}{mf}\PYG{p}{,} \PYG{n}{U}\PYG{p}{,} \PYG{n}{mf\PYGZus{}v}\PYG{p}{,} \PYG{n}{V}\PYG{p}{,} \PYG{n}{dt}\PYG{p}{,} \PYG{n}{nt}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{n}{CONVECT\PYGZus{}EXTRAPOLATION}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{mf}} is a variable of type \sphinxcode{\sphinxupquote{getfem::mesh\_fem}}, \sphinxcode{\sphinxupquote{U}} is a vector which represent the
field to be convected, \sphinxcode{\sphinxupquote{mf\_v}} is a \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} for the velocity field, \sphinxcode{\sphinxupquote{V}} is the
dof vector for the velocity field, \sphinxcode{\sphinxupquote{dt}} is the pseudo time of convection and
\sphinxcode{\sphinxupquote{nt}} the number of iterations for the computation of characteristics. \sphinxcode{\sphinxupquote{option}} is an option for the boundary condition where there is a re\sphinxhyphen{}entrant convection. The possibilities are getfem::CONVECT\_EXTRAPOLATION (extrapolation of the field on the nearest element) or getfem::CONVECT\_UNCHANGED (no change of the value on the boundary).

The method integrate the partial differential equation
\begin{equation*}
\begin{split}\frac{\partial U}{\partial t} + V\cdot\nabla U = 0,\end{split}
\end{equation*}
on the time intervall \([0, dt]\).

The method used is of Galerkin\sphinxhyphen{}Characteristic kind. It is a very simple version
which is inconditionnally stable but rather dissipative. See \sphinxcite{biblio:zt1989} and also the Freefem++ documentation on convect
command.

The defined method works only if \sphinxcode{\sphinxupquote{mf}} is a pure Lagrange finite element method
for the moment. The principle is to convect backward the finite element nodes by solving the ordinary differential equation:
\begin{equation*}
\begin{split}\frac{d X}{d t} = -V(X),\end{split}
\end{equation*}
with an initial condition corresponding to each node. This convection is made with \sphinxcode{\sphinxupquote{nt}} steps. Then the solution is interploated on
the convected nodes.

In order to make the extrapolation not too expensive, the product \(dt\times V\)
should not be too large.

Note that this method can be used to solve convection dominant problems coupling it with a splitting scheme.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\chapter{The model description and basic model bricks}
\label{\detokenize{userdoc/model:the-model-description-and-basic-model-bricks}}\label{\detokenize{userdoc/model:ud-model}}\label{\detokenize{userdoc/model:index-0}}\label{\detokenize{userdoc/model::doc}}
The model description of \sphinxstyleemphasis{GetFEM} allows
to quickly build some fem applications on complex linear or nonlinear PDE coupled
models. The principle is to propose predefined bricks which can be assembled to
describe a complex situation. A brick can describe either an equation (Poisson
equation, linear elasticity …) or a boundary condition (Dirichlet, Neumann …)
or any relation between two variables. Once a brick is written, it is possible to
use it in very different situations. This allows a reusability of the produced
code and the possibility of a growing library of bricks. An effort has been made in
order to facilitate as much as possible the definition of a new brick. A brick is
mainly defined by its contribution in the tangent linear system to be solved.

This model description is an evolution of the model bricks of previous versions of
\sphinxstyleemphasis{GetFEM}. Compared to the old system, it is more flexible, more general, allows the
coupling of model (multiphysics) in a easier way and facilitates the writing of new
components. It also facilitate the write of time integration schemes for evolving
PDEs.

The kernel of the model description is contained in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_models.h}}. The two main objects are the \sphinxtitleref{model} and the \sphinxtitleref{brick}.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{The model object}
\label{\detokenize{userdoc/model_object:the-model-object}}\label{\detokenize{userdoc/model_object:ud-model-object}}\label{\detokenize{userdoc/model_object:index-0}}\label{\detokenize{userdoc/model_object::doc}}
The aim of the \sphinxtitleref{model} object, defined in file \sphinxcode{\sphinxupquote{getfem/getfem\_models.h}}, is to
globally describe a PDE model. It mainly contains two lists: a list of variables
(related or not to the \sphinxtitleref{mesh\_fem} objects) and data (also related or not to the \sphinxtitleref{mesh\_fem}
objects) and a list of bricks. The role of the \sphinxtitleref{model} object is to coordinate the
module and make them produce a linear system of equations. If the model is
linear, this will simply be the linear system of equation on the corresponding
dofs. If the model is nonlinear, this will be the tangent linear system. There are two versions of the \sphinxtitleref{model} object: a real one and complex one.

The declaration of a model object is done by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{n}{md}\PYG{p}{(}\PYG{n}{complex\PYGZus{}version} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The parameter of the constructor is a boolean which determines whether the model deals with
complex number or real numbers. The default is false for a model dealing with real
numbers.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{getfemuserlinearsys}.png}
\caption{The (tangent) linear system}\label{\detokenize{userdoc/model_object:id1}}\label{\detokenize{userdoc/model_object:ud-fig-syslin}}\end{figure}

There are different kinds of variables/data in the model. The variables are the
unknown of the model. They will be (generally) computed by solving the (tangent)
linear system built by the model. Generally, the model will have several
variables. Each variable has a certain size (number of degrees of freedom) and the
different variables are sorted in alphanumeric order to form the global unknown
(\(U\) in Fig. {\hyperref[\detokenize{userdoc/model_object:ud-fig-syslin}]{\sphinxcrossref{\DUrole{std,std-ref}{The (tangent) linear system}}}}). Each variable will be associated to an
interval \(I = [n_1, n_2]\) which will represent the degrees of freedom
indices corresponding to this variable in the global system. The model stores also
some data (in the same format as the variables). The difference between data
and variables is that data is not an unknown of the model. The value of the
data should be provided. In some cases (nonlinear models) some variables can be
considered as some data for certain terms. Variables and data are of two kinds.
They can have a fixed size, or they can depend on a finite element method (be the
d.o.f. of a finite element method).

For instance, in the situation described in Fig. {\hyperref[\detokenize{userdoc/model_object:ud-fig-syslin}]{\sphinxcrossref{\DUrole{std,std-ref}{The (tangent) linear system}}}}, there are four variables in the model, namely \(X, Y, V\) and \(W\). The role of
the model object will be to assemble the linear system, i.e. to fill the sub
matrices corresponding to each variable (\(R_{X,X}, R_{Y,Y}, R_{V,V}\), and
\(R_{W,W}\)) and the coupling terms between two variables (\(R_{X,Y},
R_{X,V}, R_{W,V}, \cdots\)). This different contributions will be given by the
different bricks added to the model.

The main useful methods on a \sphinxtitleref{model} object are
\index{getfem::model::is\_complex (C++ function)@\spxentry{getfem::model::is\_complex}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model10is_complexEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{is\_complex}}}{}{}%
\pysigstopmultiline
A boolean which says if the model deals with real or complex unknowns and data.

\end{fulllineitems}

\index{getfem::model::add\_fixed\_size\_variable (C++ function)@\spxentry{getfem::model::add\_fixed\_size\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model23add_fixed_size_variableE4name4size5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_fixed\_size\_variable}}}{name, size, niter = 1}{}%
\pysigstopmultiline
Add a variable of fixed size. \sphinxcode{\sphinxupquote{name}} is a string which designate the
variable. \sphinxcode{\sphinxupquote{niter}} is the number of copy of the variable.

\end{fulllineitems}

\index{getfem::model::add\_fixed\_size\_variable (C++ function)@\spxentry{getfem::model::add\_fixed\_size\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model23add_fixed_size_variableE4name5sizes5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_fixed\_size\_variable}}}{name, sizes, niter = 1}{}%
\pysigstopmultiline
Add a variable of fixed size. \sphinxcode{\sphinxupquote{name}} is a string which designate the
variable. \sphinxcode{\sphinxupquote{sizes}} is a vector of dimension for matrix or tensor fixed
size variables. \sphinxcode{\sphinxupquote{niter}} is the number of copy of the variable.

\end{fulllineitems}

\index{getfem::model::add\_fixed\_size\_data (C++ function)@\spxentry{getfem::model::add\_fixed\_size\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model19add_fixed_size_dataE4name4size5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_fixed\_size\_data}}}{name, size, niter = 1}{}%
\pysigstopmultiline
Add a data of fixed size. \sphinxcode{\sphinxupquote{name}} is a string which designate the data.
\sphinxcode{\sphinxupquote{niter}} is the number of copy of the data.

\end{fulllineitems}

\index{getfem::model::add\_fixed\_size\_data (C++ function)@\spxentry{getfem::model::add\_fixed\_size\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model19add_fixed_size_dataE4name5sizes5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_fixed\_size\_data}}}{name, sizes, niter = 1}{}%
\pysigstopmultiline
Add a data of fixed size. \sphinxcode{\sphinxupquote{name}} is a string which designate the data.
\sphinxcode{\sphinxupquote{sizes}} is a vector of dimension for matrix or tensor fixed
size variables. \sphinxcode{\sphinxupquote{niter}} is the number of copy of the data.

\end{fulllineitems}

\index{getfem::model::add\_initialized\_fixed\_size\_data (C++ function)@\spxentry{getfem::model::add\_initialized\_fixed\_size\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model31add_initialized_fixed_size_dataE4name1V}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_initialized\_fixed\_size\_data}}}{name, V}{}%
\pysigstopmultiline
Add a data of fixed size initialized with the given vector \sphinxcode{\sphinxupquote{V}}. \sphinxcode{\sphinxupquote{name}} is a
string which designate the data.

\end{fulllineitems}

\index{getfem::model::add\_initialized\_scalar\_data (C++ function)@\spxentry{getfem::model::add\_initialized\_scalar\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model27add_initialized_scalar_dataE4name1e}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_initialized\_scalar\_data}}}{name, e}{}%
\pysigstopmultiline
Add a data of size 1 initialized with the given scalar value \sphinxcode{\sphinxupquote{e}}. \sphinxcode{\sphinxupquote{name}} is
a string which designate the data.

\end{fulllineitems}

\index{getfem::model::add\_fem\_variable (C++ function)@\spxentry{getfem::model::add\_fem\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model16add_fem_variableE4name2mf5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_fem\_variable}}}{name, mf, niter = 1}{}%
\pysigstopmultiline
Add a variable being the dofs of a finite element method \sphinxcode{\sphinxupquote{mf}}. \sphinxcode{\sphinxupquote{name}} is a
string which designate the variable. \sphinxcode{\sphinxupquote{niter}} is the number of copy of the
variable.

\end{fulllineitems}

\index{getfem::model::add\_filtered\_fem\_variable (C++ function)@\spxentry{getfem::model::add\_filtered\_fem\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model25add_filtered_fem_variableE4name2mf6region}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_filtered\_fem\_variable}}}{name, mf, region}{}%
\pysigstopmultiline
Add a variable being the dofs of a finite element method \sphinxcode{\sphinxupquote{mf}} only
specific to a given region.
(The standard way to define \sphinxcode{\sphinxupquote{mf}} in \sphinxstyleemphasis{GetFEM} is to define in the whole domain.)
\sphinxcode{\sphinxupquote{name}} is a string which designate the variable. \sphinxcode{\sphinxupquote{region}} is the region
number. This function will select the degree of freedom whose shape
function is non\sphinxhyphen{}zero on the given region. Internally, a \sphinxcode{\sphinxupquote{partial\_mesh\_fem}}
object will be used. The method \sphinxcode{\sphinxupquote{mesh\_fem\_of\_variable(\textquotesingle{}name\textquotesingle{})}} allows to
access to the \sphinxcode{\sphinxupquote{partial\_mesh\_fem}} built.

\end{fulllineitems}

\index{getfem::model::add\_fem\_data (C++ function)@\spxentry{getfem::model::add\_fem\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model12add_fem_dataE4name2mf5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_fem\_data}}}{name, mf, niter = 1}{}%
\pysigstopmultiline
Add a data being the dofs of a finite element method \sphinxcode{\sphinxupquote{mf}}. \sphinxcode{\sphinxupquote{name}} is a
string which designate the data. \sphinxcode{\sphinxupquote{niter}} is the number of copy of the data.

\end{fulllineitems}

\index{getfem::model::add\_initialized\_fem\_data (C++ function)@\spxentry{getfem::model::add\_initialized\_fem\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model24add_initialized_fem_dataE4name2mf1V5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_initialized\_fem\_data}}}{name, mf, V, niter = 1}{}%
\pysigstopmultiline
Add a data being the dofs of a finite element method \sphinxcode{\sphinxupquote{mf}} initialized with
the given vector \sphinxcode{\sphinxupquote{V}}. \sphinxcode{\sphinxupquote{name}} is a string which designate the data.
\sphinxcode{\sphinxupquote{niter}} is the number of copy of the data.

\end{fulllineitems}

\index{getfem::model::add\_multiplier (C++ function)@\spxentry{getfem::model::add\_multiplier}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model14add_multiplierE4name2mf11primal_name5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_multiplier}}}{name, mf, primal\_name, niter = 1}{}%
\pysigstopmultiline
Add a special variable linked to the finite element method \sphinxcode{\sphinxupquote{mf}} and being a
multiplier for certain constraints (Dirichlet condition for instance) on a
primal variable \sphinxcode{\sphinxupquote{primal\_name}}. The most important is that the degrees of
freedom will be filtered thanks to a \sphinxcode{\sphinxupquote{partial\_mesh\_fem}} object in order to
retain only a set of linearly independent constraints. To ensure this, a call
to the bricks having a term linking the multiplier and the primal variable is
done and a special algorithm is called to extract independent constraints. This
algorithm is optimized for boundary multipliers (see gmm::range\_basis). Use it
with care for volumic multipliers. \sphinxcode{\sphinxupquote{niter}} is the number of copy of the
variable. Note that for complex terms, only
the real part is considered to filter the multiplier.

\end{fulllineitems}

\index{getfem::model::add\_im\_variable (C++ function)@\spxentry{getfem::model::add\_im\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model15add_im_variableE4name3imd}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_im\_variable}}}{name, imd}{}%
\pysigstopmultiline
Add a variable defined on the integration points of the \sphinxcode{\sphinxupquote{im\_data}} object imd.
The variable can be scalar\sphinxhyphen{}valued, vector\sphinxhyphen{}valued or tensor\sphinxhyphen{}valued depending on
the dimension of imd.
It increases the model degrees of freedom by the number of integration points
time the size of the variable at one integration point.

\end{fulllineitems}

\index{getfem::model::add\_internal\_im\_variable (C++ function)@\spxentry{getfem::model::add\_internal\_im\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model24add_internal_im_variableE4name3imd}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_internal\_im\_variable}}}{name, imd}{}%
\pysigstopmultiline
Add a variable defined on the integration points of the \sphinxcode{\sphinxupquote{im\_data}} object
\sphinxcode{\sphinxupquote{imd}} that will be statically condensed out during the linearization of the
problem. The variable can be scalar\sphinxhyphen{}valued, vector\sphinxhyphen{}valued or tensor\sphinxhyphen{}valued
depending on the dimension of imd.
It does not add degrees of freedom to the model.

\end{fulllineitems}

\index{getfem::model::add\_im\_data (C++ function)@\spxentry{getfem::model::add\_im\_data}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model11add_im_dataE4name3imd}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{add\_im\_data}}}{name, imd}{}%
\pysigstopmultiline
Add a data object deignated with the string \sphinxcode{\sphinxupquote{name}}, defined at all
integration points of the \sphinxcode{\sphinxupquote{im\_data}} object \sphinxcode{\sphinxupquote{imd}}.
The data can be scalar\sphinxhyphen{}valued, vector\sphinxhyphen{}valued or tensor\sphinxhyphen{}valued depending on
the dimension of imd.

\end{fulllineitems}

\index{getfem::model::real\_variable (C++ function)@\spxentry{getfem::model::real\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model13real_variableE4name5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{real\_variable}}}{name, niter = 1}{}%
\pysigstopmultiline
Gives the access to the vector value of a variable or data. Real version.

\end{fulllineitems}

\index{getfem::model::complex\_variable (C++ function)@\spxentry{getfem::model::complex\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model16complex_variableE4name5niter}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{complex\_variable}}}{name, niter = 1}{}%
\pysigstopmultiline
Gives the access to the vector value of a variable or data. Complex version.

\end{fulllineitems}

\index{getfem::model::mesh\_fem\_of\_variable (C++ function)@\spxentry{getfem::model::mesh\_fem\_of\_variable}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model20mesh_fem_of_variableE4name}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{mesh\_fem\_of\_variable}}}{name}{}%
\pysigstopmultiline
Gives a reference on the \sphinxtitleref{mesh\_fem} on which the variable is defined. Throw an
exception if this is not a fem variable.

\end{fulllineitems}

\index{getfem::model::real\_tangent\_matrix (C++ function)@\spxentry{getfem::model::real\_tangent\_matrix}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model19real_tangent_matrixEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{real\_tangent\_matrix}}}{}{}%
\pysigstopmultiline
Gives the access to tangent matrix. Real version. A computation of the tangent
system have to be done first.

\end{fulllineitems}

\index{getfem::model::complex\_tangent\_matrix (C++ function)@\spxentry{getfem::model::complex\_tangent\_matrix}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model22complex_tangent_matrixEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{complex\_tangent\_matrix}}}{}{}%
\pysigstopmultiline
Gives the access to tangent matrix. Complex version. A computation of the
tangent system have to be done first.

\end{fulllineitems}

\index{getfem::model::real\_rhs (C++ function)@\spxentry{getfem::model::real\_rhs}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model8real_rhsEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{real\_rhs}}}{}{}%
\pysigstopmultiline
Gives the access to right hand side vector of the linear system. real version.
A computation of the tangent system have to be done first.

\end{fulllineitems}

\index{getfem::model::complex\_rhs (C++ function)@\spxentry{getfem::model::complex\_rhs}\spxextra{C++ function}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{userdoc/model_object:_CPPv4N6getfem5model11complex_rhsEv}}%
\pysigstartmultiline
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{getfem::model\sphinxcode{\sphinxupquote{::}}}}\sphinxbfcode{\sphinxupquote{complex\_rhs}}}{}{}%
\pysigstopmultiline
Gives the access to right hand side vector of the linear system. Complex
version. A computation of the tangent system have to be done first.

\end{fulllineitems}



\section{The \sphinxtitleref{brick} object}
\label{\detokenize{userdoc/model_object:the-br-object}}
A model brick is an object that is supposed to represent a part of a model. It
aims to represent some integral terms in a weak formulation of a PDE model. The
model object will contain a list of bricks. All the terms described by the brick
will be finally assembled to build the linear system to be solved (the tangent
linear system for a nonlinear problem). For instance if a term \(\Delta u\) is
present on the pde model (Laplacian of \(u\)) then the weak formulation will
contain the term \(\int_{\Omega}\nabla u\cdot\nabla v\ dx\), where \(v\)
is the test function corresponding to \(u\). Then the role of the
corresponding brick is to assemble the term \(\int_{\Omega}\nabla\varphi_i
\cdot\nabla\varphi_j\ dx\), where \(\varphi_i\) and \(\varphi_j\) are the
shape functions of the finite element method describing \(u\). This term will
be added by the model object to the global linear system on a diagonal block
corresponding to the variable \(u\). The only role of the brick is thus to
call the corresponding assembly procedure when the model object asks for it. The
construction of a brick for such a linear term is thus very simple.

Basically, the brick object will derive from the object \sphinxcode{\sphinxupquote{virtual\_brick}} defined
in \sphinxcode{\sphinxupquote{getfem/getfem\_models.h}} and should redefine the method
\sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}} or \sphinxcode{\sphinxupquote{asm\_complex\_tangent\_terms}} depending on whether
it is a real term or an intrinsic complex term.


\section{How to build a new brick}
\label{\detokenize{userdoc/model_object:how-to-build-a-new-brick}}
Note first that the design of a new brick is only necessary for special terms
not covered by existing bricks and not covered by the wide range of accessible
terms (including complex coupling terms) of the generic assembly brick
(see {\hyperref[\detokenize{userdoc/model_generic_assembly:ud-model-generic-assembly}]{\sphinxcrossref{\DUrole{std,std-ref}{Generic assembly bricks}}}}).

According to the spirit in which the brick has been designed, a brick should avoid
as much as possible to store additional data. The parameters of a brick should be
contained in the variable and data of the model. For instance, the parameters of a
linear elasticity brick are the elasticity coefficient. This coefficients have to
be some data of the model. When the brick is called by the model object, a list of
variables and data is given to the brick. The great majority of the predefined
bricks do not store any data. This allows to instantiate such a bricks only once.

An example of a brick corresponding to the laplacian term is the following (other
examples can be found in the file \sphinxcode{\sphinxupquote{getfem\_models.cc}} which contains the
very standard bricks):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{struct} \PYG{n+nc}{my\PYGZus{}Laplacian\PYGZus{}brick}\PYG{o}{:} \PYG{k}{public} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{virtual\PYGZus{}brick} \PYG{p}{\PYGZob{}}

  \PYG{k+kt}{void} \PYG{n+nf}{asm\PYGZus{}real\PYGZus{}tangent\PYGZus{}terms}\PYG{p}{(}\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{ib}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{o}{\PYGZam{}}\PYG{n}{varl}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{o}{\PYGZam{}}\PYG{n}{datal}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mimlist} \PYG{o}{\PYGZam{}}\PYG{n}{mims}\PYG{p}{,}
                              \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{real\PYGZus{}matlist} \PYG{o}{\PYGZam{}}\PYG{n}{matl}\PYG{p}{,}
                              \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{real\PYGZus{}veclist} \PYG{o}{\PYGZam{}}\PYG{n}{vecl}\PYG{p}{,}
                              \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{real\PYGZus{}veclist} \PYG{o}{\PYGZam{}}\PYG{n}{vecl\PYGZus{}sym}\PYG{p}{,}
                              \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{,} \PYG{n}{build\PYGZus{}version} \PYG{n}{nl}\PYG{p}{)} \PYG{k}{const} \PYG{p}{\PYGZob{}}
    \PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Laplacian brick has one and only one term}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{mims}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Laplacian brick need one and only one mesh\PYGZus{}im}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}} \PYG{n}{datal}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,}
                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Wrong number of variables for my Laplacian brick}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}u} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}of\PYGZus{}variable}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim} \PYG{o}{=} \PYG{o}{*}\PYG{n}{mims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{;}

    \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{clear}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}stiffness\PYGZus{}matrix\PYGZus{}for\PYGZus{}homogeneous\PYGZus{}laplacian}
    \PYG{p}{(}\PYG{n}{matl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}

  \PYG{n}{my\PYGZus{}Laplacian\PYGZus{}brick}\PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)}
  \PYG{p}{\PYGZob{}} \PYG{n}{set\PYGZus{}flags}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Laplacian brick}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{true} \PYG{c+cm}{/* linear */}\PYG{p}{,}
                                    \PYG{n+nb}{true} \PYG{c+cm}{/* symmetric */}\PYG{p}{,}
                                    \PYG{n+nb}{true} \PYG{c+cm}{/* coercivity */}\PYG{p}{,}
                                    \PYG{n+nb}{true} \PYG{c+cm}{/* real version defined */}\PYG{p}{,}
                                    \PYG{n+nb}{false} \PYG{c+cm}{/* no complex version*/}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\end{sphinxVerbatim}

The constructor of a brick should call the method \sphinxcode{\sphinxupquote{set\_flags}}. The first
parameter of this method is a name for the brick (this allows to list the bricks
of a model and facilitate their identification). The other parameters are some
flags, respectively:
\begin{itemize}
\item {} 
if the brick terms are all linear or not.

\item {} 
if the brick terms are globally symmetric (conjugated in the complex version) or
at least do not affect the symmetry. The terms corresponding to two different
variables and declared symmetric are added twice in the global linear system
(the term and the transpose of the term).

\item {} 
if the terms do not affect the coercivity.

\item {} 
if the terms have a real version or not. If yes, the method
\sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}} should be redefined.

\item {} 
if the terms have a complex version or not. If yes, the method
\sphinxcode{\sphinxupquote{asm\_complex\_tangent\_terms}} should be redefined.

\end{itemize}

The method \sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}} will be called by the model object for the
assembly of the tangent system. The model object gives the whole framework to the
brick to build its terms. The parameter \sphinxcode{\sphinxupquote{md}} of the \sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}}
method is the model that called the brick, \sphinxcode{\sphinxupquote{ib}} being the brick number in the
model. The parameter \sphinxcode{\sphinxupquote{varl}} is an array of variable/data names defined in this
model and needed in the brick. \sphinxcode{\sphinxupquote{mims}} is an array of \sphinxtitleref{mesh\_im} pointers. It
corresponds to the integration methods needed to assemble the terms. \sphinxcode{\sphinxupquote{matl}} is
an array of matrices to be computed. \sphinxcode{\sphinxupquote{vecl}} is an array of vectors to be
computed (rhs or residual vectors).  \sphinxcode{\sphinxupquote{vecl\_sym}} is an array of vectors to be
computed only for symmetric terms and corresponding to the rhs of the second
variable. A brick can have an arbitrary number of terms. For each term, at least
the corresponding matrix or the corresponding vector has to be filled (or both the
two, but only in the nonlinear case, see the description of the terms below, next
section). \sphinxcode{\sphinxupquote{region}} is a mesh region number indicated that the terms have to be
assembled on a certain region. \sphinxcode{\sphinxupquote{nl}} is for nonlinear bricks only. It says if the
tangent matrix or the residual or both the two are to be computed (for linear
bricks, all is to be computed at each call).

For the very simple Laplacian brick defined above, only one variable is used and
no data and there is only one term. The lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
            \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Laplacian brick has one and only one term}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{mims}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
            \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Laplacian brick need one and only one mesh\PYGZus{}im}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}} \PYG{n}{datal}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{,}
            \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Wrong number of variables for my Laplacian brick}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

are not mandatory and just verify that the good number of terms (1), integration
methods (1), variables(1), data(0) are passed to the \sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}}
method.

The lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}u} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}of\PYGZus{}variable}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim} \PYG{o}{=} \PYG{o}{*}\PYG{n}{mims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{;}
\end{sphinxVerbatim}

takes the \sphinxtitleref{mesh\_fem} object from the variable on which the Laplacian term will be added
and the \sphinxtitleref{mesh\_im} object in the list of integrations methods. Finally, the lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{clear}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}stiffness\PYGZus{}matrix\PYGZus{}for\PYGZus{}homogeneous\PYGZus{}laplacian}
\PYG{p}{(}\PYG{n}{matl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

call a standard assembly procedure for the Laplacian term defined in the file
\sphinxcode{\sphinxupquote{getfem/getfem\_assembling.h}}. The clear method is necessary because
although it is guaranteed that the matrices in \sphinxcode{\sphinxupquote{matl}} have good sizes they
maybe not cleared before the call of \sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}}.

Note that this simple brick has only one term and is linear. In the case of a
linear brick, either the matrix or the right hand side vector have to be filled
but not both the two. Depending on the declaration of the term. See below the
integration of the brick to the model.

Let us see now a second example of a simple brick which prescribes a Dirichlet
condition thanks to the use of a Lagrange multiplier. The Dirichlet condition is
of the form
\begin{equation*}
\begin{split}u = u_D \text{ on } \Gamma,\end{split}
\end{equation*}
where \(u\) is the variable, \(u_D\) is a given value and \(\Gamma\)
is a part on the boundary of the considered domain. The weak terms corresponding
to this condition prescribed with a Lagrange multiplier are
\begin{equation*}
\begin{split}\int_{\Gamma} u \mu\ d\Gamma = \int_{\Gamma} u_D \mu\ d\Gamma, \forall \mu \in M,\end{split}
\end{equation*}
where \(M\) is an appropriate multiplier space. The contributions to the
global linear system can be viewed in Fig. {\hyperref[\detokenize{userdoc/model_object:ud-fig-syslindir}]{\sphinxcrossref{\DUrole{std,std-ref}{Contributions of the simple Dirichlet brick}}}}. The matrix
\(B\) is the “mass matrix” between the finite element space of the variable
\(u\) and the finite element space of the multiplier \(\mu\).
\(L_{u}\) is the right hand side corresponding to the data \(u_D\).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[width=7cm]{{getfemuserlinsysDir}.png}
\caption{Contributions of the simple Dirichlet brick}\label{\detokenize{userdoc/model_object:id2}}\label{\detokenize{userdoc/model_object:ud-fig-syslindir}}\end{figure}

The brick can be defined as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{struct} \PYG{n+nc}{my\PYGZus{}Dirichlet\PYGZus{}brick}\PYG{o}{:} \PYG{k}{public} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{virtual\PYGZus{}brick} \PYG{p}{\PYGZob{}}

  \PYG{k+kt}{void} \PYG{n+nf}{asm\PYGZus{}real\PYGZus{}tangent\PYGZus{}terms}\PYG{p}{(}\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{ib}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{o}{\PYGZam{}}\PYG{n}{varl}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{o}{\PYGZam{}}\PYG{n}{datal}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mimlist} \PYG{o}{\PYGZam{}}\PYG{n}{mims}\PYG{p}{,}
                              \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{real\PYGZus{}matlist} \PYG{o}{\PYGZam{}}\PYG{n}{matl}\PYG{p}{,}
                              \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{real\PYGZus{}veclist} \PYG{o}{\PYGZam{}}\PYG{n}{vecl}\PYG{p}{,}
                              \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{real\PYGZus{}veclist} \PYG{o}{\PYGZam{}}\PYG{n}{vecl\PYGZus{}sym}\PYG{p}{,}
                              \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{,} \PYG{n}{build\PYGZus{}version} \PYG{n}{nl}\PYG{p}{)} \PYG{k}{const} \PYG{p}{\PYGZob{}}
    \PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Dirichlet brick has one and only one term}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{mims}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Dirichlet brick need one and only one mesh\PYGZus{}im}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{GMM\PYGZus{}ASSERT1}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{2} \PYG{o}{\PYGZam{}}\PYG{o}{\PYGZam{}} \PYG{n}{datal}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)} \PYG{o}{=}\PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
                \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Wrong number of variables for my Laplacian brick}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}u} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}of\PYGZus{}variable}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}mult} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{mesh\PYGZus{}fem\PYGZus{}of\PYGZus{}variable}\PYG{p}{(}\PYG{n}{varl}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim} \PYG{o}{=} \PYG{o}{*}\PYG{n}{mims}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{;}
    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model\PYGZus{}real\PYGZus{}plain\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{A} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{real\PYGZus{}variable}\PYG{p}{(}\PYG{n}{datal}\PYG{p}{[}\PYG{n}{ind}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{o}{*}\PYG{n}{mf\PYGZus{}data} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{pmesh\PYGZus{}fem\PYGZus{}of\PYGZus{}variable}\PYG{p}{(}\PYG{n}{datal}\PYG{p}{[}\PYG{n}{ind}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}

    \PYG{k}{if} \PYG{p}{(}\PYG{n}{mf\PYGZus{}data}\PYG{p}{)}
      \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{vecl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{o}{*}\PYG{n}{mf\PYGZus{}data}\PYG{p}{,} \PYG{n}{A}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
    \PYG{k}{else}
      \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}homogeneous\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{vecl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{n}{A}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}

    \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{clear}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
    \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}mass\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{matl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}

  \PYG{n}{my\PYGZus{}Dirichlet\PYGZus{}brick}\PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)}
  \PYG{p}{\PYGZob{}} \PYG{n}{set\PYGZus{}flags}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Dirichlet brick}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n+nb}{true} \PYG{c+cm}{/* linear */}\PYG{p}{,}
                                    \PYG{n+nb}{true} \PYG{c+cm}{/* symmetric */}\PYG{p}{,}
                                    \PYG{n+nb}{false} \PYG{c+cm}{/* coercivity */}\PYG{p}{,}
                                    \PYG{n+nb}{true} \PYG{c+cm}{/* real version defined */}\PYG{p}{,}
                                    \PYG{n+nb}{false} \PYG{c+cm}{/* no complex version */}\PYG{p}{)}\PYG{p}{;}
  \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}\PYG{p}{;}
\end{sphinxVerbatim}

This brick has again only one term but defines both the matrix and the right hand
side parts. Two variables are concerned, the primal variable on which the
Dirichlet condition is prescribed, and the multiplier variable which should be
defined on a mesh region corresponding to a boundary (it should be added to the
model with the method \sphinxcode{\sphinxupquote{add\_multiplier}}). The term of the brick will be declared
symmetric (see the next section).

The lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model\PYGZus{}real\PYGZus{}plain\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{A} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{real\PYGZus{}variable}\PYG{p}{(}\PYG{n}{datal}\PYG{p}{[}\PYG{n}{ind}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}fem} \PYG{o}{*}\PYG{n}{mf\PYGZus{}data} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{pmesh\PYGZus{}fem\PYGZus{}of\PYGZus{}variable}\PYG{p}{(}\PYG{n}{datal}\PYG{p}{[}\PYG{n}{ind}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

allow to have the access to the value of the data corresponding to the right hand
side of the Dirichlet condition and to the \sphinxtitleref{mesh\_fem} on which this data is defined. If
the data is constant (not described on a fem) then \sphinxcode{\sphinxupquote{mf\_data}} is a null pointer.

The lines:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{if} \PYG{p}{(}\PYG{n}{mf\PYGZus{}data}\PYG{p}{)}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{vecl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{o}{*}\PYG{n}{mf\PYGZus{}data}\PYG{p}{,} \PYG{n}{A}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{else}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{asm\PYGZus{}homogeneous\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{vecl}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{n}{A}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

make the assembly of the right hand side. The two versions correspond to a data
defined on a finite element method or constant size data.

( + some example with a nonlinear term … )


\section{How to add the brick to a model}
\label{\detokenize{userdoc/model_object:how-to-add-the-brick-to-a-model}}
In order to add a brick to a model, a certain information have to be passed to the
model:
\begin{itemize}
\item {} 
A pointer to the brick itself.

\item {} 
The set of variable names concerned with the terms of the brick.

\item {} 
The set of data names concerned with the terms of the brick.

\item {} 
A list of terms description.

\item {} 
A list of integration methods.

\item {} 
Eventually the concerned mesh region.

\end{itemize}

This is done by the call of the \sphinxtitleref{model} object method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{md}\PYG{p}{.}\PYG{n}{add\PYGZus{}brick}\PYG{p}{(}\PYG{n}{pbr}\PYG{p}{,} \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{o}{\PYGZam{}}\PYG{n}{varnames}\PYG{p}{,}
                  \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{o}{\PYGZam{}}\PYG{n}{datanames}\PYG{p}{,}
                  \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{termlist} \PYG{o}{\PYGZam{}}\PYG{n}{terms}\PYG{p}{,}
                  \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mimlist} \PYG{o}{\PYGZam{}}\PYG{n}{mims}\PYG{p}{,}
                  \PYG{k+kt}{size\PYGZus{}t} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The method returns the index of the brick in the model. The call of this method is
rather complex because it can be adapted to many situations. The construction of a
new brick should be accompagned to the definition of a function that adds the new
brick to the model calling this method and more simple to use.

For instance, for the simple Laplacian brick described above, this function can be
defined as folows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{size\PYGZus{}t} \PYG{n+nf}{add\PYGZus{}my\PYGZus{}Laplacian\PYGZus{}brick}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,}
                              \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
                              \PYG{k+kt}{size\PYGZus{}t} \PYG{n}{region} \PYG{o}{=} \PYG{k+kt}{size\PYGZus{}t}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pbrick} \PYG{n}{pbr} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{make\PYGZus{}shared}\PYG{o}{\PYGZlt{}}\PYG{n}{my\PYGZus{}Laplacian\PYGZus{}brick}\PYG{o}{\PYGZgt{}}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{termlist} \PYG{n}{tl}\PYG{p}{;}

  \PYG{n}{tl}\PYG{p}{.}\PYG{n}{push\PYGZus{}back}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{term\PYGZus{}description}\PYG{p}{(}\PYG{n}{varname}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{k}{return} \PYG{n}{md}\PYG{p}{.}\PYG{n}{add\PYGZus{}brick}\PYG{p}{(}\PYG{n}{pbr}\PYG{p}{,} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{)}\PYG{p}{,}
                      \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{tl}\PYG{p}{,}
                      \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mimlist}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{)}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

This function will be called by the user of your brick. The type
\sphinxcode{\sphinxupquote{getfem::model::varnamelist}} is a \sphinxcode{\sphinxupquote{std::vector\textless{}std::string\textgreater{}}} and represent an
array of variable names. The type \sphinxcode{\sphinxupquote{getfem::model::mimlist}} is a
\sphinxcode{\sphinxupquote{std::vector\textless{}const getfem::mesh\_im *\textgreater{}}} and represent an array of pointers to
integration methods. The type \sphinxcode{\sphinxupquote{getfem::model::termlist}} is an array of terms
description. There is two kind of terms. The terms adding only a right hand side
to the linear (tangent) system which have to be added to the list by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tl}\PYG{p}{.}\PYG{n}{push\PYGZus{}back}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{term\PYGZus{}description}\PYG{p}{(}\PYG{n}{varname}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

and the terms having a contribution to the matrix of the linear system which have
to be added to the list by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{tl}\PYG{p}{.}\PYG{n}{push\PYGZus{}back}\PYG{p}{(}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{term\PYGZus{}description}\PYG{p}{(}\PYG{n}{varname1}\PYG{p}{,} \PYG{n}{varname2}\PYG{p}{,} \PYG{n+nb}{true}\PYG{o}{/}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In this case, the matrix term is added in the rows corresponding to the variable
\sphinxcode{\sphinxupquote{varname1}} and the columns corresponding to the variable \sphinxcode{\sphinxupquote{varname2}}. The
boolean being the third parameter is to declare whether the term is symmetric or not.
If it is symmetric and if the two variables are different then the assembly
procedure adds the corresponding term AND its transpose. The number of terms is
arbitrary. For each term declared, the brick has to fill the corresponding right
hand side vector (parameter \sphinxcode{\sphinxupquote{vecl}} of \sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}} above) or/and
the matrix term (parameter \sphinxcode{\sphinxupquote{matl}} of \sphinxcode{\sphinxupquote{asm\_real\_tangent\_terms}}) depending on
the declaration of the term. Note that for nonlinear bricks, both the matrix and
the right hand side vectors have to be filled. For linear bricks, if the right
hand side is filled for a term declared to be a matrix term, it is IGNORED.

The variable names and the data names are given in two separate arrays because the
dependence of the brick is not the same in both cases. A linear term has to be
recomputed if the value of a data is changed but not if the value of a variable is
changed.

The function allowing to add the simple Dirichlet brick described above can be
defined as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{size\PYGZus{}t} \PYG{n+nf}{add\PYGZus{}my\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,}
                                        \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
                                        \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{multname}\PYG{p}{,}
                                        \PYG{k+kt}{size\PYGZus{}t} \PYG{n}{region}\PYG{p}{,}
                                        \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{n}{pbrick} \PYG{n}{pbr} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{make\PYGZus{}shared}\PYG{o}{\PYGZlt{}}\PYG{n}{my\PYGZus{}Dirichlet\PYGZus{}brick}\PYG{o}{\PYGZgt{}}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{termlist} \PYG{n}{tl}\PYG{p}{;}
  \PYG{n}{tl}\PYG{p}{.}\PYG{n}{push\PYGZus{}back}\PYG{p}{(}\PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{term\PYGZus{}description}\PYG{p}{(}\PYG{n}{multname}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{n}{vl}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{vl}\PYG{p}{.}\PYG{n}{push\PYGZus{}back}\PYG{p}{(}\PYG{n}{multname}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{varnamelist} \PYG{n}{dl}\PYG{p}{;}
  \PYG{k}{if} \PYG{p}{(}\PYG{n}{dataname}\PYG{p}{.}\PYG{n}{size}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)} \PYG{n}{dl}\PYG{p}{.}\PYG{n}{push\PYGZus{}back}\PYG{p}{(}\PYG{n}{dataname}\PYG{p}{)}\PYG{p}{;}
  \PYG{k}{return} \PYG{n}{md}\PYG{p}{.}\PYG{n}{add\PYGZus{}brick}\PYG{p}{(}\PYG{n}{pbr}\PYG{p}{,} \PYG{n}{vl}\PYG{p}{,} \PYG{n}{dl}\PYG{p}{,} \PYG{n}{tl}\PYG{p}{,} \PYG{n}{model}\PYG{o}{:}\PYG{o}{:}\PYG{n}{mimlist}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{)}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Again, here, the term is declared symmetric and then the matrix term and its
transpose will be added.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Generic assembly bricks}
\label{\detokenize{userdoc/model_generic_assembly:generic-assembly-bricks}}\label{\detokenize{userdoc/model_generic_assembly:ud-model-generic-assembly}}\label{\detokenize{userdoc/model_generic_assembly:index-0}}\label{\detokenize{userdoc/model_generic_assembly::doc}}
A mean to add a term either on one variable or on several ones is to directly use GWFL, the generic weak form language described in Section {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high}]{\sphinxcrossref{\DUrole{std,std-ref}{Compute arbitrary terms \sphinxhyphen{} high\sphinxhyphen{}level generic assembly procedures \sphinxhyphen{} Generic Weak\sphinxhyphen{}Form Language (GWFL)}}}}. The more general way is to use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{size\PYGZus{}type} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}nonlinear\PYGZus{}term}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{expr}\PYG{p}{,}
                      \PYG{n}{region} \PYG{o}{=} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{,} \PYG{n}{is\PYGZus{}sym} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{,} \PYG{n}{is\PYGZus{}coercive} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This adds a brick to the model \sphinxcode{\sphinxupquote{md}}, using the integration method \sphinxcode{\sphinxupquote{mim}}, the assembly string \sphinxcode{\sphinxupquote{expr}} on the mesh region \sphinxcode{\sphinxupquote{region}}. If the result is symmetric, you can specify it on the 5th argument and if it is coercive on the 6th argument. The latter indications of symmetry and coercivness are used to determine the right linear solver. If you are not so sure, it is preferable not to indicate anything.

However, this brick consider that the expression is nonlinear. This brick is especially indicated to obtain nonlinear coupled terms between several variables. This means in particular that the assembly of the term is performed at each call of the assembly of the model and that a Newton algorithm will be used to solve the problem. If the term is indeed linear, you should use instead:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{size\PYGZus{}type} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}linear\PYGZus{}term}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{expr}\PYG{p}{,}
                       \PYG{n}{region} \PYG{o}{=} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{,} \PYG{n}{is\PYGZus{}sym} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{,} \PYG{n}{is\PYGZus{}coercive} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

with the same arguments. Conversely, this brick alway assume that the term corresponding to \sphinxcode{\sphinxupquote{expr}} is linear and the assembly will be performed only once if the data used do not change. Thus, you have to care that your expression is indeed linear (affine in fact) with respect to each variable. Otherwise, the result is of course not guaranted. Source terms in the expression are taken into account. Still for linear problem, it is possible to perform the assembly of a sole source term thanks to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{size\PYGZus{}type} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{expr}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

with again the same arguments except the symmetry and coercivness. This brick performs the assembly of the corresponding order 1 term (residual vector) and add it as a right hand side to the problem. The assembly will be performed only once, so the term should not depend on the variables of the model (but could depend of course on the constants).

For instance, if one wants to solve a Poisson problem on a predefined variable \sphinxcode{\sphinxupquote{u}} of the model, one may use the corresponding pre\sphinxhyphen{}defined bricks (see below) or simply use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}nonlinear\PYGZus{}term}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Grad\PYGZus{}u.Grad\PYGZus{}Test\PYGZus{}u \PYGZhy{} F*Test\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{F}} is a pre\sphinxhyphen{}defined constant of the model representing the right hand side. Of course, doing so, Newton’s algorithms will be called. So, the more appropriate manner is to use the linear bricks as follows:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}linear\PYGZus{}term}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Grad\PYGZus{}u.Grad\PYGZus{}Test\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{,} \PYG{n+nb}{true}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}source\PYGZus{}term}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{F*Test\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Note that for the moment, the use of GWFL is not possible for complex valued problems.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Generic elliptic brick}
\label{\detokenize{userdoc/model_generic_elliptic:generic-elliptic-brick}}\label{\detokenize{userdoc/model_generic_elliptic:ud-model-generic-elliptic}}\label{\detokenize{userdoc/model_generic_elliptic:index-0}}\label{\detokenize{userdoc/model_generic_elliptic::doc}}
This brick adds an elliptic term on a variable of a model.  The shape of the
elliptic term depends both on the variable and a given coefficient. This
corresponds to a term:
\begin{equation*}
\begin{split}-\text{div}(a\nabla u),\end{split}
\end{equation*}
where \(a\) is the coefficient and \(u\) the variable. The coefficient can
be a scalar, a matrix or an order four tensor. The variable can be vector valued
or not. This means that the brick treats several different situations. If the
coefficient is a scalar or a matrix and the variable is vector valued then the
term is added componentwise. An order four tensor coefficient is allowed for
vector valued variable only.  The coefficient can be constant or described on a
FEM. Of course, when the coefficient is a tensor described on a finite element
method (a tensor field) the corresponding data can be a huge vector. The
components of the matrix/tensor have to be stored with the fortran order
(columnwise) in the data vector corresponding to the coefficient (compatibility
with BLAS). The symmetry and coercivity of the given matrix/tensor is not verified
(but assumed).

This brick can be added to a model \sphinxcode{\sphinxupquote{md}} thanks to two functions. The first one
is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{size\PYGZus{}type} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Laplacian\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

that adds an elliptic term relatively to the variable \sphinxcode{\sphinxupquote{varname}} of the model
with a constant coefficient equal to \(1\) (a Laplacian term). This
corresponds to the Laplace operator. \sphinxcode{\sphinxupquote{mim}} is the integration method which will
be used to compute the term. \sphinxcode{\sphinxupquote{region}} is an optional region number. If it is
omitted, it is assumed that the term will be computed on the whole mesh. The
result of the function is the brick index in the model.

The second function is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{size\PYGZus{}type} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}generic\PYGZus{}elliptic\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataexpr}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It adds a term with an arbitrary coefficient given by the expression \sphinxcode{\sphinxupquote{dataexpr}} which has to be a regular expression of GWFL, the generic weak form language (like “1”, “sin(X{[}0{]})” or “Norm(u)” for instance) even depending on model variables (except for the complex version where it has to be a declared data of the model)

Note that very general equations can be obtained with this brick. For instance,
linear anisotropic elasticity can be obtained with a tensor data. When an order
four tensor is used, the corresponding weak term is the following
\begin{equation*}
\begin{split}\int_{\Omega} \sum_{i,j,k,l} a_{i,j,k,l}\partial_i u_j \partial_k v_l dx\end{split}
\end{equation*}
where \(a_{i,j,k,l}\) is the order four tensor and \(\partial_i u_j\) is
the partial derivative with respect to the \(i^{th}\) variable of the
component \(j\) of the unknown \(k\). \(v\) is the test function.
However, for linear isotropic elasticity, a more adapted brick is available (see
below).

The brick has a working complex version.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Dirichlet condition brick}
\label{\detokenize{userdoc/model_dirichlet:dirichlet-condition-brick}}\label{\detokenize{userdoc/model_dirichlet:ud-model-dirichlet}}\label{\detokenize{userdoc/model_dirichlet:index-0}}\label{\detokenize{userdoc/model_dirichlet::doc}}
The aim of the Dirichlet condition brick is to prescribe a Dirichlet condition on
a part of the boundary of the domain for a variable of the model. This means that
the value of this variable is prescribed on the boundary. There is three versions of
this brick (see also the section {\hyperref[\detokenize{userdoc/model_Nitsche:ud-model-nitsche}]{\sphinxcrossref{\DUrole{std,std-ref}{Nitsche’s method for dirichlet and contact boundary conditions}}}}). The first version prescribe the Dirichlet thank to a multiplier. The
associated weak form of the term is the following:
\begin{equation*}
\begin{split}\int_{\Gamma} u \mu d\Gamma = \int_{\Gamma} u_D \mu d\Gamma, \forall \mu \in M.\end{split}
\end{equation*}
where \(u\) is the variable, \(M\) is the space of multipliers, \(u_D\)
is the variable and \(\Gamma\) the Dirichlet boundary. For this version, an
additional variable have to be added to represent the multiplier. It can be done
directly to the model or thanks to the functions below. There are three functions
allowing to add a Dirichlet condition prescribed with a multiplier. The first one
is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                         \PYG{n}{multname}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                         \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

adding a Dirichlet condition on \sphinxcode{\sphinxupquote{varname}} thanks to a multiplier variable
\sphinxcode{\sphinxupquote{multname}} on the mesh region \sphinxcode{\sphinxupquote{region}} (which should be a boundary). The value
of the variable on that boundary is described by the data \sphinxcode{\sphinxupquote{dataname}} which
should be previously defined in the model. If the data is omitted, the Dirichlet
condition is assumed to be an homogeneous one (vanishing variable on the
boundary). The data can be constant or described on an FEM. It can also be scalar
or vector valued, depending on the variable. The variable \sphinxcode{\sphinxupquote{multname}} should be
added to the model by the method \sphinxcode{\sphinxupquote{add\_multiplier}}. The function returns the
brick index in the model. The second function is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                         \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                         \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The only difference is that \sphinxcode{\sphinxupquote{multname}} is replaced by \sphinxcode{\sphinxupquote{mf\_mult}} which means
that only the finite element on which the multiplier will be built is given. The
function adds itself the multiplier variable to the model. The third function is
very similar:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                         \PYG{n}{degree}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                         \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The parameter \sphinxcode{\sphinxupquote{mf\_mult}} is replaced by an integer \sphinxcode{\sphinxupquote{degree}} indicating that the
multiplier will be built on a classical finite element method of that degree.

Note, that in all the cases, when a variable is added by the method
\sphinxcode{\sphinxupquote{add\_multiplier}} of the model object, the \sphinxtitleref{mesh\_fem} will be filtered (thank to a
\sphinxcode{\sphinxupquote{partial\_mesh\_fem\_object}} in order to retain only the degrees of freedom having
a non vanishing contribution on the considered boundary.

Finally, the variable name of the multiplier can be obtained thank to the
function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{mult\PYGZus{}varname\PYGZus{}Dirichlet}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{ind\PYGZus{}brick}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{ind\_brick}} is the brick index in the model. This function has an
undefined behavior if it applied to another kind of brick.

The second version of the Dirichlet condition brick is the one with penalization.
The function allowing to add this brick is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}penalization}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                          \PYG{n}{penalization\PYGZus{}coeff}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                          \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
                                          \PYG{o}{*}\PYG{n}{mf\PYGZus{}mult} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The penalization consists in computing the mass matrix of the variable and add it
multiplied by the penalization coefficient to the stiffness matrix.
The parameter \sphinxtitleref{mf\_mult} (a pointer to a \sphinxcode{\sphinxupquote{getfem::mesh\_fem}} object) is optional. It allows to weaken the Dirichlet condition for locking situations. In that case, the penalization matrix is of the form \(B^TB\) where \(B\) is the “mass matrix” on the boundary between the shape functions of the variable \sphinxtitleref{varname} and the shape function of the multiplier space.
The penalization coefficient is added as a data of the model and can be
changed thanks to the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{change\PYGZus{}penalization\PYGZus{}coeff}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{ind\PYGZus{}brick}\PYG{p}{,} \PYG{n}{penalisation\PYGZus{}coeff}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The third version of the Dirichlet condition brick use a simplification of the linear system (tangent linear system for nonlinear problems). Basically, it enforces a 1 on the diagonal components of the lines corresponding to prescribed degrees of freedom, it completes the lines with some zeros (for symmetric problems, it also complete the columns with some zeros) and it adapts the right\sphinxhyphen{}hand side accordingly. This is a rather simple and economic way to prescribe a Dirichlet condition. However, it can only be applied when one can identify the degrees of freedom prescribed by the the Dirichlet condition. So, it has to be use with care with reduced finite element methods, Hermite element methods and cannot be applied for a normal (or generalized) Dirichlet condition on vectorial problems. The function allowing to add this brick is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}simplification}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                          \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

If \sphinxtitleref{dataname} is ommited, an homogeneous Dirichlet condition is applied. If \sphinxtitleref{dataname} is given, the constraint is that it has to be constant or described on the same finite element method as the variable \sphinxtitleref{varname} on which the Dirichlet condition is applied. Additionaly, If \sphinxtitleref{dataname} is constant, it can only be applied to Lagrange finite element methods.


\section{Generalized Dirichlet condition brick}
\label{\detokenize{userdoc/model_dirichlet:generalized-dirichlet-condition-brick}}
The generalized Dirichlet condition is a boundary condition of a vector field u of
the type
\begin{equation*}
\begin{split}H u  = r\end{split}
\end{equation*}
where \(H\) is a matrix field. The functions adding the corresponding bricks
are similar to the ones of the standard Dirichlet condition except that they need
the supplementary parameter \sphinxtitleref{Hname} which gives the name of the data corresponding
to \(H\). This data can be a matrix field described on a scalar fem or a
constant matrix.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}generalized\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                         \PYG{n}{multname}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                         \PYG{n}{dataname}\PYG{p}{,} \PYG{n}{Hname}\PYG{p}{)}\PYG{p}{;}


\PYG{n}{add\PYGZus{}generalized\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                         \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                         \PYG{n}{dataname}\PYG{p}{,} \PYG{n}{Hname}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{add\PYGZus{}generalized\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                         \PYG{n}{degree}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                         \PYG{n}{dataname}\PYG{p}{,} \PYG{n}{Hname}\PYG{p}{)}\PYG{p}{;}


\PYG{n}{add\PYGZus{}generalized\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}penalization}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                          \PYG{n}{penalization\PYGZus{}coeff}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
                                          \PYG{n}{dataname}\PYG{p}{,} \PYG{n}{Hname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\section{Pointwise constraints brick}
\label{\detokenize{userdoc/model_dirichlet:pointwise-constraints-brick}}
The pointwise constraints brick is a Dirichlet condition like brick which allows to prescribe the value of an unknown on given points of the domain. These points are not necessarily some vertex of the mesh or some points corresponding to degrees of freedom of the finite element method on which the unknown is described.

For scalar field variables, given a set of \(N_p\) points \(x_i, i = 1\cdots N_p\), the brick allows to prescribe the value of the variable on these points, i.e. to enforce the condition
\begin{equation*}
\begin{split}u(x_i) = l_i, ~~~ i = 1\cdots N_p,\end{split}
\end{equation*}
where \(u\) is the scalar field and \(l_i\) the value to be prescribed on the point \(x_i\).

For vector field variables, given a set of \(N_p\) points \(x_i, i = 1\cdots N_p\), the brick allows to prescribe the value of one component of the variable on these points, i.e. to enforce the condition
\begin{equation*}
\begin{split}u(x_i)\cdot n_i = l_i, ~~~ i = 1\cdots N_p,\end{split}
\end{equation*}
where \(n_i\) is the vector such that \(u(x_i)\cdot n_i\) represent the component to be prescribed.

The brick has two versions: a penalized version and a version with multipliers. The call is the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}pointwise\PYGZus{}constraints\PYGZus{}with\PYGZus{}penalization}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{penalisation\PYGZus{}coeff}\PYG{p}{,}
              \PYG{n}{dataname\PYGZus{}pt}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}unitv} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
              \PYG{n}{dataname\PYGZus{}val} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{add\PYGZus{}pointwise\PYGZus{}constraints\PYGZus{}with\PYGZus{}given\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{multname}\PYG{p}{,}
              \PYG{n}{dataname\PYGZus{}pt}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}unitv} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
              \PYG{n}{dataname\PYGZus{}val} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{add\PYGZus{}pointwise\PYGZus{}constraints\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}pt}\PYG{p}{,}
              \PYG{n}{dataname\PYGZus{}unitv} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}val} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

respectively for the penalized version, the one with a given multiplier fixed size variable and the one which automatically adds a multiplier variable of the right size to the model. The data \sphinxtitleref{dataname\_pt}, \sphinxtitleref{dataname\_unitv} and \sphinxtitleref{dataname\_val} should be added first to the model. \sphinxtitleref{dataname\_pt} should be a vector containing the coordinates of the points where to prescribed the value of the variable \sphinxtitleref{varname}. It is thus of size \(N N_p\) where \(N\) is the dimension of the mesh. \sphinxtitleref{dataname\_unitv} is ignored for a scalar field variable. For a vector field variable, it should contain the vector \(n_i\). In that case, it size should be \(Q N_p\) where \(Q\) is the dimension of the vector field. \sphinxtitleref{dataname\_val} is optional and represent the right hand side, it should contain the components \(l_i\). The default value for \(l_i\) is 0.

This brick is mainly designed to prescribe the rigid displacements for pure Neumann problems.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Source term bricks (and Neumann condition)}
\label{\detokenize{userdoc/model_source_term:source-term-bricks-and-neumann-condition}}\label{\detokenize{userdoc/model_source_term:ud-model-source-term}}\label{\detokenize{userdoc/model_source_term:index-0}}\label{\detokenize{userdoc/model_source_term::doc}}
This brick adds a source term, i.e. a term which occurs only in the right hand side
of the linear (tangent) system build by the model. If \(f\) denotes the value
of the source term, the weak form of such a term is
\begin{equation*}
\begin{split}\int_{\Omega} f v\ dx\end{split}
\end{equation*}
where \(v\) is the test function. The value \(f\) can be constant or
described on a finite element method.

It can also represent a Neumann condition if it is applied on a boundary of the
domain.

The function to add a source term to a model is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}source\PYGZus{}term\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,}
                      \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataexpr}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{,}
                      \PYG{n}{directdataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md\textasciigrave{}\textasciigrave{}is the model object, \textasciigrave{}\textasciigrave{}mim}} is the integration method, \sphinxcode{\sphinxupquote{varname}} is
the variable of the model for which the source term is added, \sphinxcode{\sphinxupquote{dataexpr}} has to be  a regular expression of GWFL, the generic weak form language (except for the complex version where it has to be a declared data of the model). It has to be
scalar or vector valued depending on the fact that the variable is scalar or
vector valued itself. \sphinxcode{\sphinxupquote{region}} is a mesh region on which the term is added. If
the region corresponds to a boundary, the source term will represent a Neumann
condition. \sphinxcode{\sphinxupquote{directdataname}} is an optional additional data which will directly
be added to the right hand side without assembly.

The brick has a working complex version.

A slightly different brick, especially dedicated to deal with a Neumann condition,
is added by the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}normal\PYGZus{}source\PYGZus{}term\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,}
                             \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataexpr}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The difference compared to the basic source term brick is that the data should be
a vector field (a matrix field if the variable \sphinxcode{\sphinxupquote{varname}} is itself vector
valued) and a scalar product with the outward unit normal is performed on it.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Predefined solvers}
\label{\detokenize{userdoc/model_solvers:predefined-solvers}}\label{\detokenize{userdoc/model_solvers:ud-model-solvers}}\label{\detokenize{userdoc/model_solvers:index-0}}\label{\detokenize{userdoc/model_solvers::doc}}
Although it will be more convenient to build a specific
solver for some problems, a generic solver is available to test your models quickly. It
can also be taken as an example to build your own solver. It is defined in
\sphinxcode{\sphinxupquote{src/getfem/getfem\_model\_solvers.h}} and \sphinxcode{\sphinxupquote{src/getfem\_model\_solvers.cc}} and the call is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is the model object and \sphinxcode{\sphinxupquote{iter}} is an iteration object from \sphinxstyleemphasis{Gmm++}.
See also the next section for an example of use.

Note that \sphinxstyleemphasis{SuperLU} is used as a default linear solver on “small” problems. You can also link \sphinxstyleemphasis{MUMPS} with \sphinxstyleemphasis{GetFEM} (see section {\hyperref[\detokenize{userdoc/linalg:ud-linalg}]{\sphinxcrossref{\DUrole{std,std-ref}{Linear algebra procedures}}}}) and use the parallel version. For nonlinear problems, A Newton method (also called Newton\sphinxhyphen{}Raphson method) is used.

Note also that it is possible to disable some variables
(with the method md.disable\_variable(varname) of the model object) in order to
solve the problem only with respect to a subset of variables (the
disabled variables are the considered as data) for instance to
replace the global Newton strategy with a fixed point one.

Let us recall that a standard initialization for the iter object is the folowwing (see Gmm++ documentation on \DUrole{xref,std,std-ref}{gmm\sphinxhyphen{}iter}):

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{iteration} \PYG{n}{iter}\PYG{p}{(}\PYG{l+m+mf}{1E\PYGZhy{}7}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{200}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{1E\sphinxhyphen{}7}} is the relative tolerance for the stopping criterion, \sphinxtitleref{1} is the noisy option and \sphinxtitleref{200} is the maximum number of iterations. The stopping criterion of Newton’s method is build as follows. For a relative tolerance \(\varepsilon\), the algorithm stops when:
\begin{equation*}
\begin{split}\min\left( \|F(u)\|_1 / \max(L, 10^{-25}) ~, ~~ \|h\|_1 / \max(\|u\|_1, 10^{-25})\right) < \varepsilon\end{split}
\end{equation*}
where \(F(u)\) is the residual vector, \(\|\cdot\|_1\) is the classical 1\sphinxhyphen{}norm in \(\rm I\hspace{-0.15em}R^n\), \(h\) is the search direction given by Newton’s algorithm, \(L\) is the norm of an estimated external loads (coming from source term and Dirichlet bricks) and \(u\) is the current state of the searched variable. The maximum taken with \(10^{-25}\) is to avoid pathological cases when \(L\) and/or \(u\) are vanishing.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Example of a complete Poisson problem}
\label{\detokenize{userdoc/model_poisson:example-of-a-complete-poisson-problem}}\label{\detokenize{userdoc/model_poisson:ud-model-poisson}}\label{\detokenize{userdoc/model_poisson:index-0}}\label{\detokenize{userdoc/model_poisson::doc}}
The following example is a part of the test program
\sphinxcode{\sphinxupquote{tests/laplacian\_with\_bricks.cc}}. Construction of the mesh and finite
element methods are omitted. It is assumed that a mesh is build and two finite
element methods \sphinxcode{\sphinxupquote{mf\_u}} and \sphinxcode{\sphinxupquote{mf\_rhs}} are build on this mesh. Is is also
assumed that \sphinxcode{\sphinxupquote{NEUMANN\_BOUNDARY\_NUM}} and \sphinxcode{\sphinxupquote{DIRICHLET\_BOUNDARY\_NUM}} are two
valid boundary indices on that mesh. The code begins by the definition of three
functions which are interpolated on \sphinxcode{\sphinxupquote{mf\_rhs}} in order to build the data for the
source term, the Neumann condition and the Dirichlet condition. Follows the
declaration of the model object, the addition of the bricks and the solving of
the problem:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{using} \PYG{n}{bgeot}\PYG{o}{:}\PYG{o}{:}\PYG{n}{base\PYGZus{}small\PYGZus{}vector}\PYG{p}{;}
\PYG{c+c1}{// Exact solution. Allows an interpolation for the Dirichlet condition.}
\PYG{n}{scalar\PYGZus{}type} \PYG{n+nf}{sol\PYGZus{}u}\PYG{p}{(}\PYG{k}{const} \PYG{n}{base\PYGZus{}node} \PYG{o}{\PYGZam{}}\PYG{n}{x}\PYG{p}{)} \PYG{p}{\PYGZob{}} \PYG{k}{return} \PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{+}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;} \PYG{p}{\PYGZcb{}}
\PYG{c+c1}{// Right hand side. Allows an interpolation for the source term.}
\PYG{n}{scalar\PYGZus{}type} \PYG{n+nf}{sol\PYGZus{}f}\PYG{p}{(}\PYG{k}{const} \PYG{n}{base\PYGZus{}node} \PYG{o}{\PYGZam{}}\PYG{n}{x}\PYG{p}{)} \PYG{p}{\PYGZob{}} \PYG{k}{return} \PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{sin}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{+}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;} \PYG{p}{\PYGZcb{}}
\PYG{c+c1}{// Gradient of the solution. Allows an interpolation for the Neumann term.}
\PYG{n}{base\PYGZus{}small\PYGZus{}vector} \PYG{n+nf}{sol\PYGZus{}grad}\PYG{p}{(}\PYG{k}{const} \PYG{n}{base\PYGZus{}node} \PYG{o}{\PYGZam{}}\PYG{n}{x}\PYG{p}{)}
\PYG{p}{\PYGZob{}} \PYG{k}{return} \PYG{n}{base\PYGZus{}small\PYGZus{}vector}\PYG{p}{(}\PYG{n}{cos}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{+}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{cos}\PYG{p}{(}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{+}\PYG{n}{x}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{;} \PYG{p}{\PYGZcb{}}

\PYG{k+kt}{int} \PYG{n+nf}{main}\PYG{p}{(}\PYG{k+kt}{void}\PYG{p}{)} \PYG{p}{\PYGZob{}}

  \PYG{c+c1}{// ... definition of a mesh}
  \PYG{c+c1}{// ... definition of a finite element method mf\PYGZus{}u}
  \PYG{c+c1}{// ... definition of a finite element method mf\PYGZus{}rhs}
  \PYG{c+c1}{// ... definition of an integration method mim}
  \PYG{c+c1}{// ... definition of boundaries NEUMANN\PYGZus{}BOUNDARY\PYGZus{}NUM}
  \PYG{c+c1}{//                        and DIRICHLET\PYGZus{}BOUNDARY\PYGZus{}NUM}

  \PYG{c+c1}{// Model object}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{n}{laplacian\PYGZus{}model}\PYG{p}{;}

  \PYG{c+c1}{// Main unknown of the problem}
  \PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}fem\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// Laplacian term on u.}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Laplacian\PYGZus{}brick}\PYG{p}{(}\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// Volumic source term.}
  \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{scalar\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{F}\PYG{p}{(}\PYG{n}{mf\PYGZus{}rhs}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{interpolation\PYGZus{}function}\PYG{p}{(}\PYG{n}{mf\PYGZus{}rhs}\PYG{p}{,} \PYG{n}{F}\PYG{p}{,} \PYG{n}{sol\PYGZus{}f}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}initialized\PYGZus{}fem\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VolumicData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}rhs}\PYG{p}{,} \PYG{n}{F}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}source\PYGZus{}term\PYGZus{}brick}\PYG{p}{(}\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VolumicData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// Neumann condition.}
  \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{resize}\PYG{p}{(}\PYG{n}{F}\PYG{p}{,} \PYG{n}{mf\PYGZus{}rhs}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{o}{*}\PYG{n}{N}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{interpolation\PYGZus{}function}\PYG{p}{(}\PYG{n}{mf\PYGZus{}rhs}\PYG{p}{,} \PYG{n}{F}\PYG{p}{,} \PYG{n}{sol\PYGZus{}grad}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}initialized\PYGZus{}fem\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{NeumannData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}rhs}\PYG{p}{,} \PYG{n}{F}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}normal\PYGZus{}source\PYGZus{}term\PYGZus{}brick}
  \PYG{p}{(}\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{NeumannData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{NEUMANN\PYGZus{}BOUNDARY\PYGZus{}NUM}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// Dirichlet condition.}
  \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{resize}\PYG{p}{(}\PYG{n}{F}\PYG{p}{,} \PYG{n}{mf\PYGZus{}rhs}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{interpolation\PYGZus{}function}\PYG{p}{(}\PYG{n}{mf\PYGZus{}rhs}\PYG{p}{,} \PYG{n}{F}\PYG{p}{,} \PYG{n}{sol\PYGZus{}u}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}initialized\PYGZus{}fem\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DirichletData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}rhs}\PYG{p}{,} \PYG{n}{F}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}
  \PYG{p}{(}\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{DIRICHLET\PYGZus{}BOUNDARY\PYGZus{}NUM}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{DirichletData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

  \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{iteration} \PYG{n}{iter}\PYG{p}{(}\PYG{n}{residual}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{40000}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}

  \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{scalar\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{U}\PYG{p}{(}\PYG{n}{mf\PYGZus{}u}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{copy}\PYG{p}{(}\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{real\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{U}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// ... doing something with the solution ...}

  \PYG{k}{return} \PYG{l+m+mi}{0}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Note that the brick can be added in an arbitrary order.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\index{Nitsche\textquotesingle{}s method@\spxentry{Nitsche\textquotesingle{}s method}}\ignorespaces 

\section{Nitsche’s method for dirichlet and contact boundary conditions}
\label{\detokenize{userdoc/model_Nitsche:nitsche-s-method-for-dirichlet-and-contact-boundary-conditions}}\label{\detokenize{userdoc/model_Nitsche:ud-model-nitsche}}\label{\detokenize{userdoc/model_Nitsche:index-0}}\label{\detokenize{userdoc/model_Nitsche::doc}}
\sphinxstyleemphasis{GetFEM} provides a generic implementation of Nitche’s method which allows to account for Dirichlet type or contact with friction boundary conditions in a weak sense without the use of Lagrange multipliers.
The method is very attractive because it transforms a Dirichlet boundary condition into a weak term similar to a Neumann boundary condition.
However, this advantage is at the cost that the implementation of Nitche’s method is model dependent, since it requires an approximation of the corresponding Neumann term.
In order to add a boundary condition with Nitsche’s method on a variable of a model, the corresponding brick needs to have access to an approximation of the Neumann term of all partial differential terms applied to this variable.
In the following, considering a variable \(u\), we will denote by
\begin{equation*}
\begin{split}G\end{split}
\end{equation*}
the sum of all Neumann terms on this variable.
Note that the Neumann term \(G\) will often depend on the variable \(u\) but it may also depend on other variables of the model.
This is the case for instance for mixed formulations of incompressible elasticity.
The Neumann terms depend also frequently on some parameters of the model (elasticity coefficients …) but this is assumed to be contained in its expression.

For instance, if there is a Laplace term (\(\Delta u\)), applied on the variable \(u\), the Neumann term will be \(G = \dfrac{\partial u}{\partial n}\) where \(n\) is the outward unit normal on the considered boundary.
If \(u\) represents the displacements of a deformable body, the Neumann term will be \(G = \sigma(u)n\), where \(\sigma(u)\) is the stress tensor depending on the constitutive law.
Of course, in that case \(G\) also depends on some material parameters.
If additionally a mixed incompressibility brick is added with a variable \(p\) denoting the pressure, the Neumann term on \(u\) will depend on \(p\) in the following way:
\(G = \sigma(u)n - pn\)

In order to allow a generic implementation in which the brick imposing Nitsche’s method will work for every partial differential term applied to the concerned variables, each brick adding a partial differential term to a model is required to give its expression via a GWFL (generic weak form language) expression.

These expressions are utilized in a special method of the model object:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{expr} \PYG{o}{=} \PYG{n}{md}\PYG{p}{.}\PYG{n}{Neumann\PYGZus{}term}\PYG{p}{(}\PYG{n}{variable}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}
\end{sphinxVerbatim}

which allows to automatically derive an expression for the sum of all Neumann terms, by scanning the expressions provided by all partial differential term bricks and performing appropriate manipulations.
Of course it is required that all volumic bricks were added to the model prior to the call of this method.
The derivation of the Neumann term works only for second order partial differential equations.
A generic implementation for higher order pde would be more complicated.


\subsection{Generic Nitsche’s method for a Dirichlet condition}
\label{\detokenize{userdoc/model_Nitsche:generic-nitsche-s-method-for-a-dirichlet-condition}}
Assume that the variable \(u\) is considered and that one wants to prescribe the condition
\begin{equation*}
\begin{split}Hu = g\end{split}
\end{equation*}
on a part \(\Gamma_D\)  of the boundary of the considered domain.
Here \(H\) is considered equal to one in the scalar case or can be either the identity matrix in the vectorial case either a singular matrix having only 1 or 0 as eigenvalues.
This allow here to prescribe only the normal or tangent component of \(u\).
For instance if one wants to prescribe only the normal component, \(H\) will be chosen to be equal to \(nn^T\) where \(n\) is the outward unit normal on \(\Gamma_D\).

Nitsche’s method for prescribing this Dirichlet condition consists in adding the following term to the weak formulation of the problem
\begin{equation*}
\begin{split}\int_{\Gamma_D} \dfrac{1}{\gamma}(Hu-g-\gamma HG).(Hv) - \theta(Hu-g).(HD_uG[v])d\Gamma,\end{split}
\end{equation*}
where \(\gamma\) and \(\theta\) are two parameters of Nitsche’s method and \(v\) is the test function corresponding to \(u\).
The parameter \(\theta\) can be chosen positive or negative. \(\theta = 1\) corresponds to the more standard method which leads to a symmetric tangent term in standard situations, \(\theta = 0\) corresponds to a non\sphinxhyphen{}symmetric method which has the advantage of a reduced number of terms and not requiring the second derivatives of \(G\) in the nonlinear case, and \(\theta = -1\) is a kind of skew\sphinxhyphen{}symmetric method which ensures an inconditonal coercivity (which means independent of \(\gamma\)) at least in standard situations.
The parameter \(\gamma\) is a kind of penalization parameter (although the method is consistent) which is taken to be \(\gamma = \gamma_0 h_T\) where \(\gamma_0\) is taken uniform on the mesh and \(h_T\) is the diameter of the element \(T\).
Note that, in standard situations, except for \(\theta = -1\) the parameter \(\gamma_0\) has to be taken sufficiently small in order to ensure the convergence of Nitsche’s method.

The bricks adding a Dirichlet condition with Nitsche’s method to a model are the following:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}Nitsche\PYGZus{}method}
   \PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{Neumannterm}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{gamma0name}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{,}
    \PYG{n}{scalar\PYGZus{}type} \PYG{n}{theta} \PYG{o}{=} \PYG{n}{scalar\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a Dirichlet condition on the variable \sphinxtitleref{varname} and the mesh
region \sphinxtitleref{region}. This region should be a boundary. \sphinxtitleref{Neumannterm}
is the expression of the Neumann term (obtained by the Green formula)
described as an expression of GWFL. This term can be obtained with
md.Neumann\_term(varname, region) once all volumic bricks have
been added to the model. The Dirichlet
condition is prescribed with Nitsche’s method. \sphinxtitleref{dataname} is the optional
right hand side of the Dirichlet condition. It could be constant or
described on a fem; scalar or vector valued, depending on the variable
on which the Dirichlet condition is prescribed. \sphinxtitleref{gamma0name} is the
Nitsche’s method parameter. \sphinxtitleref{theta} is a scalar value which can be
positive or negative. \sphinxtitleref{theta = 1} corresponds to the standard symmetric
method which is conditionally coercive for  \sphinxtitleref{gamma0} small.
\sphinxtitleref{theta = \sphinxhyphen{}1} corresponds to the skew\sphinxhyphen{}symmetric method which is
inconditionally coercive. \sphinxtitleref{theta = 0} is the simplest method
for which the second derivative of the Neumann term is not necessary
even for nonlinear problems. Returns the brick index in the model.

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}normal\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}Nitsche\PYGZus{}method}
   \PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{Neumannterm}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{gamma0name}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{,}
    \PYG{n}{scalar\PYGZus{}type} \PYG{n}{theta} \PYG{o}{=} \PYG{n}{scalar\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a Dirichlet condition to the normal component of the vector
(or tensor) valued variable \sphinxtitleref{varname} and the mesh region \sphinxtitleref{region}.
This region should be a boundary. \sphinxtitleref{Neumannterm}
is the expression of the Neumann term (obtained by the Green formula)
described as an expression of GWFL. This term can be obtained with
md.Neumann\_term(varname, region) once all volumic bricks have
been added to the model. The Dirichlet
condition is prescribed with Nitsche’s method. \sphinxtitleref{dataname} is the optional
right hand side of the Dirichlet condition. It could be constant or
described on a fem. \sphinxtitleref{gamma0name} is the
Nitsche’s method parameter. \sphinxtitleref{theta} is a scalar value which can be
positive or negative. \sphinxtitleref{theta = 1} corresponds to the standard symmetric
method which is conditionally coercive for  \sphinxtitleref{gamma0} small.
\sphinxtitleref{theta = \sphinxhyphen{}1} corresponds to the skew\sphinxhyphen{}symmetric method which is
inconditionally coercive. \sphinxtitleref{theta = 0} is the simplest method
for which the second derivative of the Neumann term is not necessary
even for nonlinear problems. Returns the brick index in the model.
(This brick is not fully tested)

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}generalized\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}Nitsche\PYGZus{}method}
   \PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{Neumannterm}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{gamma0name}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{,} \PYG{n}{scalar\PYGZus{}type} \PYG{n}{theta}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{Hname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a Dirichlet condition on the variable \sphinxtitleref{varname} and the mesh
region \sphinxtitleref{region}.
This version is for vector field. It prescribes a condition
\(Hu = r\) where \(H\) is a matrix field. The region should be a
boundary. This region should be a boundary. \sphinxtitleref{Neumannterm}
is the expression of the Neumann term (obtained by the Green formula)
described as an expression of GWFL. This term can be obtained with
md.Neumann\_term(varname, region) once all volumic bricks have
been added to the model. The Dirichlet
condition is prescribed with Nitsche’s method.
CAUTION : the matrix H should have all eigenvalues equal to 1 or 0.
\sphinxtitleref{dataname} is the optional
right hand side of the Dirichlet condition. It could be constant or
described on a fem. \sphinxtitleref{gamma0name} is the
Nitsche’s method parameter. \sphinxtitleref{theta} is a scalar value which can be
positive or negative. \sphinxtitleref{theta = 1} corresponds to the standard symmetric
method which is conditionally coercive for  \sphinxtitleref{gamma0} small.
\sphinxtitleref{theta = \sphinxhyphen{}1} corresponds to the skew\sphinxhyphen{}symmetric method which is
inconditionally coercive. \sphinxtitleref{theta = 0} is the simplest method
for which the second derivative of the Neumann term is not necessary
even for nonlinear problems. \sphinxtitleref{Hname} is the data
corresponding to the matrix field \sphinxtitleref{H}. It has to be a constant matrix
or described on a scalar fem. Returns the brick index in the model.
(This brick is not fully tested)


\subsection{Generic Nitsche’s method for contact with friction condition}
\label{\detokenize{userdoc/model_Nitsche:generic-nitsche-s-method-for-contact-with-friction-condition}}\label{\detokenize{userdoc/model_Nitsche:nitsche-contact-small-def-section}}
We describe here the use of Nitsche’s method to prescribe a contact with Coulomb friction condition in the small deformations framework. This corresponds to a weak integral contact condition which as some similarity with the ones which use Lagrange multipliers describe in the corresponding section, see {\hyperref[\detokenize{userdoc/model_contact_friction:weak-integral-contact-section}]{\sphinxcrossref{\DUrole{std,std-ref}{Weak integral contact condition}}}}

In order to simplify notations, let use denote by \(P_{n,\mathscr{F}}\) the following map which corresponds to a couple of projections:
\begin{equation*}
\begin{split}P_{n,\mathscr{F}}(x) = -(x.n)_- n + P_{B(0,\mathscr{F}(x.n)_-)}(x - (x.n)n)\end{split}
\end{equation*}
This application make the projection of the normal part of \(x\) on \(\rm I\hspace{-0.15em}R_-\) and the tangential part on the ball of center \(0\) and radius \(\mathscr{F}(x.n)_-\), where \(\mathscr{F}\) is the friction coefficient.

Using this, and considering that the sliding velocity is approximated by \(\alpha(u_{_T} - w_{_T})\) where the expression of \(\alpha\) and \(w_{_T}\) depend on the time integration scheme used (see {\hyperref[\detokenize{userdoc/model_contact_friction:weak-integral-contact-section}]{\sphinxcrossref{\DUrole{std,std-ref}{Weak integral contact condition}}}}), Nitsche’s term for contact with friction reads as:
\begin{equation*}
\begin{split}&-\int_{\Gamma_C} \theta \gamma G\cdot D_u G[v] d\Gamma \\
&+\int_{\Gamma_C} \gamma P_{n,\mathscr{F}}(G - \dfrac{Au}{\gamma} + \dfrac{gap}{\gamma}n + \dfrac{\alpha w_{_T}}{\gamma})\cdot(\theta D_u G[v] - \dfrac{v}{\gamma}) d\Gamma.\end{split}
\end{equation*}
where \(\Gamma_C\) is the contact boundary, \(G\) is the Neumann term which represents here \(\sigma n\) the stress at the contact boundary and \(A\) is the \(d\times d\) matrix
\begin{equation*}
\begin{split}A = \alpha I_d + (1-\alpha)n n^T\end{split}
\end{equation*}
Note that for the variant with \(\theta=0\) a majority of terms vanish.

The following function adds a contact condition with or without Coulomb
friction on the variable
\sphinxtitleref{varname\_u} and the mesh boundary \sphinxtitleref{region}.  \sphinxtitleref{Neumannterm}
is the expression of the Neumann term (obtained by the Green formula)
described as an expression of GWFL. This term can be obtained with
md.Neumann\_term(varname, region) once all volumic bricks have
been added to the model. The contact condition
is prescribed with Nitsche’s method. The rigid obstacle should
be described with the data \sphinxtitleref{dataname\_obstacle} being a signed distance to
the obstacle (interpolated on a finite element method).
\sphinxtitleref{gamma0name} is the Nitsche’s method parameter.
\sphinxtitleref{theta} is a scalar value which can be
positive or negative. \sphinxtitleref{theta = 1} corresponds to the standard symmetric
method which is conditionally coercive for  \sphinxtitleref{gamma0} small.
\sphinxtitleref{theta = \sphinxhyphen{}1} corresponds to the skew\sphinxhyphen{}symmetric method which is
inconditionally coercive. \sphinxtitleref{theta = 0} is the simplest method
for which the second derivative of the Neumann term is not necessary.
The optional parameter \sphinxtitleref{dataexpr\_friction\_coeff} is the friction
coefficient which could be any expression of GWFL.
Returns the brick index in the model.:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Nitsche\PYGZus{}contact\PYGZus{}with\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}brick}
\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname\PYGZus{}u}\PYG{p}{,}
 \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{Neumannterm}\PYG{p}{,}
 \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{expr\PYGZus{}obs}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname\PYGZus{}gamma0}\PYG{p}{,}
 \PYG{n}{scalar\PYGZus{}type} \PYG{n}{theta\PYGZus{}}\PYG{p}{,}
 \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{dataexpr\PYGZus{}friction\PYGZus{}coeff}\PYG{p}{,}
 \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname\PYGZus{}alpha}\PYG{p}{,}
 \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname\PYGZus{}wt}\PYG{p}{,}
 \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Constraint brick}
\label{\detokenize{userdoc/model_constraint:constraint-brick}}\label{\detokenize{userdoc/model_constraint:ud-model-constraint}}\label{\detokenize{userdoc/model_constraint:index-0}}\label{\detokenize{userdoc/model_constraint::doc}}
The constraint brick allows to add an explicit constraint on a variable. Explicit
means that no integration is done. if \(U\) is a variable then a constraint of
the type
\begin{equation*}
\begin{split}BU = L,\end{split}
\end{equation*}
can be added with the two following functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{indbrick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}constraint\PYGZus{}with\PYGZus{}penalization}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                                    \PYG{n}{penalisation\PYGZus{}coeff}\PYG{p}{,} \PYG{n}{B}\PYG{p}{,} \PYG{n}{L}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{indbrick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}constraint\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                                   \PYG{n}{multname}\PYG{p}{,} \PYG{n}{B}\PYG{p}{,} \PYG{n}{L}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

In the second case, a (fixed size) variable which will serve as a multiplier
should be first added to the model.

For the penalized version \sphinxcode{\sphinxupquote{B}} should not contain a plain row, otherwise the
whole tangent matrix will be plain. The penalization parameter can be changed
thanks to the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{change\PYGZus{}penalization\PYGZus{}coeff}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{ind\PYGZus{}brick}\PYG{p}{,} \PYG{n}{penalisation\PYGZus{}coeff}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It is possible to change the constraints at any time thanks to the two following
functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}private\PYGZus{}data\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{,} \PYG{n}{B}\PYG{p}{)}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}private\PYGZus{}data\PYGZus{}rhs}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{,} \PYG{n}{L}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{indbrick}} is the index of the brick in the model.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Other “explicit” bricks}
\label{\detokenize{userdoc/model_explicit:other-explicit-bricks}}\label{\detokenize{userdoc/model_explicit:ud-model-explicit}}\label{\detokenize{userdoc/model_explicit:index-0}}\label{\detokenize{userdoc/model_explicit::doc}}
Two (very simple) bricks allow to add some explicit terms to the tangent system.

The function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{indbrick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}explicit\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname1}\PYG{p}{,} \PYG{n}{varname2}\PYG{p}{,} \PYG{n}{B}
                                       \PYG{n}{issymmetric} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{,}
                                       \PYG{n}{iscoercive} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

adds a brick which just adds the matrix \sphinxcode{\sphinxupquote{B}} to the tangent system relatively to
the variables \sphinxcode{\sphinxupquote{varname1}} and \sphinxcode{\sphinxupquote{varname2}}. The given matrix should have as many
rows as the dimension of \sphinxcode{\sphinxupquote{varname1}} and as many columns as the dimension of
\sphinxcode{\sphinxupquote{varname2}}. If the two variables are different and if \sphinxcode{\sphinxupquote{issymmetric}} is set to
true then the transpose of the matrix is also added to the tangent system (default
is false). Set \sphinxcode{\sphinxupquote{iscoercive}} to true if the term does not affect the coercivity
of the tangent system (default is false). The matrix can be changed by the
command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}private\PYGZus{}data\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{,} \PYG{n}{B}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}explicit\PYGZus{}rhs}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{L}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

adds a brick which just add the vector \sphinxcode{\sphinxupquote{L}} to the right hand side of the tangent
system relatively to the variable \sphinxcode{\sphinxupquote{varname}}. The given vector should have the
same size as the variable \sphinxcode{\sphinxupquote{varname}}. The value of the vector can by changed by
the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{set\PYGZus{}private\PYGZus{}data\PYGZus{}rhs}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{,} \PYG{n}{L}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Helmholtz brick}
\label{\detokenize{userdoc/model_helmholtz:helmholtz-brick}}\label{\detokenize{userdoc/model_helmholtz:ud-model-helmholtz}}\label{\detokenize{userdoc/model_helmholtz:index-0}}\label{\detokenize{userdoc/model_helmholtz::doc}}
This brick represents the complex or real Helmholtz problem:
\begin{equation*}
\begin{split}\Delta u + k^2 u = \ldots\end{split}
\end{equation*}
where \(k\) the wave number is a real or complex value. For a complex
version, a complex model has to be used (see \sphinxcode{\sphinxupquote{tests/helmholtz.cc}}).

The function adding a Helmholtz brick to a model is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Helmholtz\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataexpr}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{varname}} is the variable on which the Helmholtz term is added and
\sphinxcode{\sphinxupquote{dataexpr}} is the wave number.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Fourier\sphinxhyphen{}Robin brick}
\label{\detokenize{userdoc/model_fourier_robin:fourier-robin-brick}}\label{\detokenize{userdoc/model_fourier_robin:ud-model-fourier-robin}}\label{\detokenize{userdoc/model_fourier_robin:index-0}}\label{\detokenize{userdoc/model_fourier_robin::doc}}
This brick can be used to add boundary conditions of Fourier\sphinxhyphen{}Robin type like:
\begin{equation*}
\begin{split}\frac{\partial u}{\partial \nu} = Qu\end{split}
\end{equation*}
for scalar problems, or
\begin{equation*}
\begin{split}\sigma\cdot \nu = Qu\end{split}
\end{equation*}
for linearized elasticity problems. \sphinxcode{\sphinxupquote{Q}} is a scalar field in the scalar case or
a matrix field in the vectorial case. This brick works for both real or complex
terms in scalar or vectorial problems.

The function adding this brick to a model is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Fourier\PYGZus{}Robin\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataexpr}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{dataexpr}} is the data of the model which represents the coefficient
\(Q\).  It can be an arbitrary valid expression of GWFL, the generic weak form language (except for the complex version for which it should be a data of the model)

Note that an additional right hand side can be added with a source term brick.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Isotropic linearized elasticity brick}
\label{\detokenize{userdoc/model_linear_elasticity:isotropic-linearized-elasticity-brick}}\label{\detokenize{userdoc/model_linear_elasticity:ud-model-linear-elasticity}}\label{\detokenize{userdoc/model_linear_elasticity:index-0}}\label{\detokenize{userdoc/model_linear_elasticity::doc}}
This brick represents a term
\begin{equation*}
\begin{split}-div(\sigma) = \ldots\end{split}
\end{equation*}
with
\begin{equation*}
\begin{split}\sigma &= \lambda\mbox{tr}(\varepsilon(u))I + 2\mu\varepsilon(u) \\
\varepsilon(u) &= (\nabla u + \nabla u^T)/2\end{split}
\end{equation*}
\(\varepsilon(u)\) is the small strain tensor, \(\sigma\) is the stress
tensor, \(\lambda\) and \(\mu\) are the Lamé coefficients. This represents
the system of linearized isotropic elasticity. It can also be used with
\(\lambda=0\) together with the linear incompressible brick to build the
Stokes problem.

Let us recall that the relation between the Lamé coefficients an Young modulus \(E\) and Poisson ratio \(\nu\) is
\begin{equation*}
\begin{split}\lambda = \dfrac{E\nu}{(1+\nu)(1-2\nu)}, ~~~ \mu = \dfrac{E}{2(1+\nu)},\end{split}
\end{equation*}
except for the plane stress approximation (2D model) where
\begin{equation*}
\begin{split}\lambda^* = \dfrac{E\nu}{(1-\nu^2)}, ~~~ \mu = \dfrac{E}{2(1+\nu)},\end{split}
\end{equation*}
The function which adds this brick to a model and parametrized with the Lamé coefficients is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind\PYGZus{}brick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}elasticity\PYGZus{}brick}
            \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{data\PYGZus{}lambda}\PYG{p}{,} \PYG{n}{data\PYGZus{}mu}\PYG{p}{,}
             \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{dataname\_lambda}} and \sphinxcode{\sphinxupquote{dataname\_mu}} are the data of the model
representing the Lamé coefficients.

The function which adds this brick to a model and parametrized with Young modulus and Poisson ratio is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind\PYGZus{}brick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}elasticity\PYGZus{}brick\PYGZus{}pstrain}
            \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{data\PYGZus{}E}\PYG{p}{,} \PYG{n}{data\PYGZus{}nu}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This brick represent a plane strain approximation when it is applied to a 2D mesh (and a standard model on a 3D mesh). In order to obtain a plane stress approximation for 2D meshes, one can use:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind\PYGZus{}brick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}elasticity\PYGZus{}brick\PYGZus{}pstress}
            \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{data\PYGZus{}E}\PYG{p}{,} \PYG{n}{data\PYGZus{}nu}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

For 3D meshes, the two previous bricks give the same result.

The function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}Von\PYGZus{}Mises\PYGZus{}or\PYGZus{}Tresca}
  \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}lambda}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}mu}\PYG{p}{,} \PYG{n}{mf\PYGZus{}vm}\PYG{p}{,} \PYG{n}{VM}\PYG{p}{,} \PYG{n}{tresca\PYGZus{}flag} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

compute the Von Mises criterion (or Tresca if \sphinxcode{\sphinxupquote{tresca\_flag}} is set to true) on
the displacement field stored in \sphinxcode{\sphinxupquote{varname}}. The stress is evaluated on the \sphinxtitleref{mesh\_fem}
\sphinxcode{\sphinxupquote{mf\_vm}} and stored in the vector \sphinxcode{\sphinxupquote{VM}}. It is not valid for 2D plane stress approximation and is parametrized with Lamé coefficients. The functions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}Von\PYGZus{}Mises}
  \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{data\PYGZus{}E}\PYG{p}{,} \PYG{n}{data\PYGZus{}nu}\PYG{p}{,} \PYG{n}{mf\PYGZus{}vm}\PYG{p}{,} \PYG{n}{VM}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}Von\PYGZus{}Mises}
  \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{data\PYGZus{}E}\PYG{p}{,} \PYG{n}{data\PYGZus{}nu}\PYG{p}{,} \PYG{n}{mf\PYGZus{}vm}\PYG{p}{,} \PYG{n}{VM}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

compute the Von Mises stress, parametrized with Young modulus and Poisson ratio, the second one being valid for 2D plane stress approximation when it is applied on a 2D mesh (the two functions give the same result for 3D problems).

The program \sphinxcode{\sphinxupquote{tests/elastostatic.cc}} can be taken as a model of use of a linearized isotropic elasticity brick.


\section{Linear incompressibility (or nearly incompressibility) brick}
\label{\detokenize{userdoc/model_linear_elasticity:linear-incompressibility-or-nearly-incompressibility-brick}}
This brick adds a linear incompressibility condition (or a nearly incompressible
condition) in a problem of type:
\begin{equation*}
\begin{split}\mbox{div}(u) = 0,\quad (\mbox{ or } \mbox{div}(u) = \varepsilon p)\end{split}
\end{equation*}
This constraint is enforced with Lagrange multipliers representing the pressure,
introduced in a mixed formulation.

The function adding this incompressibility condition is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind\PYGZus{}brick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}linear\PYGZus{}incompressibility}
            \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{multname\PYGZus{}pressure}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{,}
             \PYG{n}{dataexpr\PYGZus{}penal\PYGZus{}coeff} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{varname}} is the variable on which the incompressibility condition is
prescribed, \sphinxcode{\sphinxupquote{multname\_pressure}} is a variable which should be described on a
scalar fem representing the multiplier (the pressure) and \sphinxcode{\sphinxupquote{dataexpr\_penal\_coeff}}
is an optional penalization coefficient for the nearly incompressible condition.

In nearly incompressible homogeneous linearized elasticity, one has
\(\varepsilon = 1 / \lambda\) where \(\lambda\) is one of the Lamé
coefficient and \(\varepsilon\) the penalization coefficient.

For instance, the following program defines a Stokes problem with a source term
and an homogeneous Dirichlet condition on boundary 0. \sphinxcode{\sphinxupquote{mf\_u}}, \sphinxcode{\sphinxupquote{mf\_data}} and
\sphinxcode{\sphinxupquote{mf\_p}} have to be valid finite element description on the same mesh. \sphinxcode{\sphinxupquote{mim}}
should be a valid integration method on the same mesh:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{typedef} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{scalar\PYGZus{}type}\PYG{o}{\PYGZgt{}} \PYG{n}{plain\PYGZus{}vector}\PYG{p}{;}
\PYG{n}{size\PYGZus{}type} \PYG{n}{N} \PYG{o}{=} \PYG{n}{mf\PYGZus{}u}\PYG{p}{.}\PYG{n}{linked\PYGZus{}mesh}\PYG{p}{(}\PYG{p}{)}\PYG{p}{.}\PYG{n}{dim}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{n}{Stokes\PYGZus{}model}\PYG{p}{;}

\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}fem\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{scalar\PYGZus{}type} \PYG{n}{mu} \PYG{o}{=} \PYG{l+m+mf}{1.0}\PYG{p}{;}
\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}initialized\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{lambda}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{plain\PYGZus{}vector}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mf}{0.0}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}initialized\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{plain\PYGZus{}vector}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{mu}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}elasticity\PYGZus{}brick}\PYG{p}{(}\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,}
                                                  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{lambda}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{laplacian\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}fem\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{p}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}p}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}linear\PYGZus{}incompressibility}\PYG{p}{(}\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{p}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{plain\PYGZus{}vector} \PYG{n+nf}{F}\PYG{p}{(}\PYG{n}{mf\PYGZus{}data}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{o}{*}\PYG{n}{N}\PYG{p}{)}\PYG{p}{;}
\PYG{k}{for} \PYG{p}{(}\PYG{k+kt}{int} \PYG{n}{i} \PYG{o}{=} \PYG{l+m+mi}{0}\PYG{p}{;} \PYG{n}{i} \PYG{o}{\PYGZlt{}} \PYG{n}{mf\PYGZus{}data}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{o}{*}\PYG{n}{N}\PYG{p}{;} \PYG{o}{+}\PYG{o}{+}\PYG{n}{i}\PYG{p}{)} \PYG{n}{F}\PYG{p}{(}\PYG{n}{i}\PYG{p}{)} \PYG{o}{=} \PYG{p}{.}\PYG{p}{.}\PYG{p}{.}\PYG{p}{;}
\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{.}\PYG{n}{add\PYGZus{}initialized\PYGZus{}fem\PYGZus{}data}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VolumicData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}data}\PYG{p}{,} \PYG{n}{F}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}source\PYGZus{}term\PYGZus{}brick}\PYG{p}{(}\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{VolumicData}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}\PYG{p}{(}\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,}
                                                 \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{iteration} \PYG{n}{iter}\PYG{p}{(}\PYG{n}{residual}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{40000}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{plain\PYGZus{}vector} \PYG{n+nf}{U}\PYG{p}{(}\PYG{n}{mf\PYGZus{}u}\PYG{p}{.}\PYG{n}{nb\PYGZus{}dof}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{copy}\PYG{p}{(}\PYG{n}{Stokes\PYGZus{}model}\PYG{p}{.}\PYG{n}{real\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} \PYG{n}{U}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

An example for a nearly incompressibility condition can be found in the program
\sphinxcode{\sphinxupquote{tests/elastostatic.cc}}.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Mass brick}
\label{\detokenize{userdoc/model_mass:mass-brick}}\label{\detokenize{userdoc/model_mass:ud-model-mass}}\label{\detokenize{userdoc/model_mass:index-0}}\label{\detokenize{userdoc/model_mass::doc}}
This brick represents a weak term of the form
\begin{equation*}
\begin{split}\int_{\Omega} \rho u\cdot v\ dx + \ldots\end{split}
\end{equation*}
It mainly represents a mass term for transient problems but can also be used for
other applications (it can be used on a boundary). Basically, this brick adds a
mass matrix on the tangent linear system with respect to a certain variable.

The function which adds this brick to a model is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind\PYGZus{}brick} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}mass\PYGZus{}brick}
            \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataexpr\PYGZus{}rho}\PYG{o}{=}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{dataexpr\_rho}} is an optional expression representing the density
\(\rho\). If it is omitted, the density is assumed to be equal to one.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Bilaplacian and Kirchhoff\sphinxhyphen{}Love plate bricks}
\label{\detokenize{userdoc/model_bilaplacian:bilaplacian-and-kirchhoff-love-plate-bricks}}\label{\detokenize{userdoc/model_bilaplacian:ud-model-bilaplacian}}\label{\detokenize{userdoc/model_bilaplacian:index-0}}\label{\detokenize{userdoc/model_bilaplacian::doc}}
The following function

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind} \PYG{o}{=} \PYG{n}{add\PYGZus{}bilaplacian\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataname}\PYG{p}{,}
                            \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

adds a bilaplacian brick on the variable \sphinxtitleref{varname} and on the mesh region \sphinxtitleref{region}. This represent a term \(\Delta(D \Delta u)\). where \(D(x)\) is a coefficient determined by \sphinxtitleref{dataname} which could be constant or described on a f.e.m. The corresponding weak form is \(\int D(x)\Delta u(x) \Delta v(x) dx\).

For the Kirchhoff\sphinxhyphen{}Love plate model, the weak form is a bit different (and more stable than the previous one). the function to add that term is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind} \PYG{o}{=} \PYG{n}{add\PYGZus{}bilaplacian\PYGZus{}brick\PYGZus{}KL}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{dataname1}\PYG{p}{,} \PYG{n}{dataname2}\PYG{p}{,}
                               \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

It adds a bilaplacian brick on the variable \sphinxtitleref{varname} and on the mesh region \sphinxtitleref{region}. This represent a term \(\Delta(D \Delta u)\) where \(D(x)\)
is a the flexion modulus determined by \sphinxtitleref{dataname1}. The term is
integrated by part following a Kirchhoff\sphinxhyphen{}Love plate model
with \sphinxtitleref{dataname2} the poisson ratio.

There is specific bricks to add appropriate boundary conditions for fourth order partial differential equations. The first one is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind} \PYG{o}{=}  \PYG{n}{add\PYGZus{}normal\PYGZus{}derivative\PYGZus{}source\PYGZus{}term\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
                                               \PYG{n}{dataname}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which adds a normal derivative source term brick
\(F = \int b.\partial_n v\) on the variable \sphinxtitleref{varname} and on the
mesh region \sphinxtitleref{region}. It updates the right hand side of the linear
system. \sphinxtitleref{dataname} represents \sphinxtitleref{b} and \sphinxtitleref{varname} represents \sphinxtitleref{v}.

A Neumann term can be added thanks to the following bricks

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind} \PYG{o}{=} \PYG{n}{add\PYGZus{}Kirchhoff\PYGZus{}Love\PYGZus{}Neumann\PYGZus{}term\PYGZus{}brick}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,}
 \PYG{n}{dataname1}\PYG{p}{,} \PYG{n}{dataname2}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which adds a Neumann term brick for Kirchhoff\sphinxhyphen{}Love model
on the variable \sphinxtitleref{varname} and the mesh region \sphinxtitleref{region}.
\sphinxtitleref{dataname1} represents the bending moment tensor and  \sphinxtitleref{dataname2}
its divergence.

And a Dirichlet condition on the normal derivative can be prescribed thanks to the following bricks

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind} \PYG{o}{=} \PYG{n}{add\PYGZus{}normal\PYGZus{}derivative\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}
      \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{multname}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,} \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
      \PYG{n}{R\PYGZus{}must\PYGZus{}be\PYGZus{}derivated} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{ind} \PYG{o}{=} \PYG{n}{add\PYGZus{}normal\PYGZus{}derivative\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}
      \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{mf\PYGZus{}mult}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,} \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
      \PYG{n}{R\PYGZus{}must\PYGZus{}be\PYGZus{}derivated} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{ind} \PYG{o}{=} \PYG{n}{add\PYGZus{}normal\PYGZus{}derivative\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}
      \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{degree}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,} \PYG{n}{dataname} \PYG{o}{=} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,}
      \PYG{n}{R\PYGZus{}must\PYGZus{}be\PYGZus{}derivated} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

These bricks add a Dirichlet condition on the normal derivative of the variable
\sphinxtitleref{varname} and on the mesh region \sphinxtitleref{region} (which should be a boundary).
The general form is \(\int \partial_n u(x)v(x) = \int r(x)v(x) \forall v\)
where \(r(x)\) is the right hand side for the Dirichlet condition (0 for
homogeneous conditions) and \(v\) is in a space of multipliers
defined by the variable \sphinxtitleref{multname} (first version) or defined on the finite element method \sphinxtitleref{mf\_mult} (second version) or simply on a Lagrange finite element method of degree \sphinxtitleref{degree} (third version) on the part of boundary determined
by \sphinxtitleref{region}. \sphinxtitleref{dataname} is an optional parameter which represents
the right hand side of the Dirichlet condition.
If \sphinxtitleref{R\_must\_be\_derivated} is set to \sphinxtitleref{true} then the normal
derivative of \sphinxtitleref{dataname} is considered.

The test program \sphinxcode{\sphinxupquote{bilaplacian.cc}} is a good example of the use of the previous bricks.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Mindlin\sphinxhyphen{}Reissner plate model}
\label{\detokenize{userdoc/model_Mindlin_plate:mindlin-reissner-plate-model}}\label{\detokenize{userdoc/model_Mindlin_plate:ud-model-mindlin-plate}}\label{\detokenize{userdoc/model_Mindlin_plate:index-0}}\label{\detokenize{userdoc/model_Mindlin_plate::doc}}
This brick implements the classical Mindlin\sphinxhyphen{}Reissner bending model for isotropic plates.


\subsection{The Mindlin\sphinxhyphen{}Reissner plate model}
\label{\detokenize{userdoc/model_Mindlin_plate:the-mindlin-reissner-plate-model}}
Let \(\Omega \subset \rm I\hspace{-0.15em}R^2\) be the reference configuration of the mid\sphinxhyphen{}plane of a plate of thickness \(\epsilon\).

The weak formulation of the Mindlin\sphinxhyphen{}Reissner model for isotropic material can be written as follows for \(u_3\) the transverse displacement and \(\theta\) the rotation of fibers normal to the mid\sphinxhyphen{}plane:
\begin{equation*}
\begin{split}& \int_{\Omega} D \epsilon^3\left((1-v)\gamma(\theta):\gamma(\psi) + \nu \mbox{div}(\theta)\mbox{div}(\psi)\right) dx \\
& ~~~~~~~~~~~~~~ + \int_{\Omega}G\epsilon (\nabla u_3 - \theta)\cdot(\nabla v_3 - \psi)dx = \int_{\Omega} F_3v_3 + M.\psi dx,\end{split}
\end{equation*}
for all admissible test functions \(v_3 : \Omega \rightarrow \rm I\hspace{-0.15em}R,$ $\psi : \Omega \rightarrow \rm I\hspace{-0.15em}R^2\) and where:
\begin{equation*}
\begin{split}& D = \dfrac{E}{12(1-\nu^2)}, ~~ G = \dfrac{E\kappa}{2(1+\nu)}, \\
& \gamma(\theta) = (\nabla \theta + \nabla \theta^T)/2, \\
& F_3 = \int_{-\epsilon/2}^{\epsilon/2} f_3dx_3 + g_3^+ + g_3^-, \\
& M_{\alpha} = \epsilon(g^+_{\alpha} - g^-_{\alpha})/2 +  \int_{-\epsilon/2}^{\epsilon/2} x_3 f_{\alpha}dx_3, \alpha \in \{1, 2\},\end{split}
\end{equation*}
\(f\) being a volumic force applied inside the three dimensional plate, \(g^+\) and \(g^-\) a force applied on the top and bottom surface of the plate, \(E\) Young’s modulus, \(\nu\) Poisson’s ratio and \(\kappa\) the shear correction factor (usually set to 5/6).

The classical boundary conditions are the following:
\begin{itemize}
\item {} 
Simple support :  a dirichlet condition on \(u_3\).

\item {} 
Clamped support : a dirichlet condition on both \(u_3\) and \(\theta\).

\item {} 
Prescribed transverse force : boundary source term on \(u_3\).

\item {} 
Prescribed moment : boundary source term on \(\theta\).

\end{itemize}

An important issue of this model is that it is subjected to the so called shear locking so that a direct Galerkin procedure do not give a satisfactory approximation. There is several ways to circumvent the shear locking problem : reduced integration, projection of the transverse shear term, mixed methods. The two first method are proposed.


\subsubsection{Reduced integration of the transverse shear term}
\label{\detokenize{userdoc/model_Mindlin_plate:reduced-integration-of-the-transverse-shear-term}}
This strategy consists simply to use a lower order integration method to numerically compute the term
\begin{equation*}
\begin{split}\int_{\Omega}G\epsilon (\nabla u_3 - \theta)\cdot(\nabla v_3 - \psi)dx\end{split}
\end{equation*}
This strategy is working properly at least when both the rotation and the transverse displacement is approximated with Q1 quadrilateral element with a degree one reduced integration method (the so\sphinxhyphen{}called QUAD4 element).


\subsubsection{Projection of the transverse shear term}
\label{\detokenize{userdoc/model_Mindlin_plate:projection-of-the-transverse-shear-term}}
Another strategy comes from the MITC elements (Mixed Interpolation of Tensorial Components) which correspond to a re\sphinxhyphen{}interpretation in terms of projection of some mixed methods. The most popular element of this type is the MITC4 which correspond to the quadrilateral element Q1 with a projection of the transverse shear term on a rotated Raviart\sphinxhyphen{}Thomas element of lowest degree (RT0) (see \sphinxcite{biblio:ba-dv1985}, \sphinxcite{biblio:br-ba-fo1989}). This means that the transverse shear term becomes
\begin{equation*}
\begin{split}\int_{\Omega}G\epsilon P^h(\nabla u_3 - \theta)\cdot P^h(\nabla v_3 - \psi)dx\end{split}
\end{equation*}
where \(P^h(T)\) is the elementwize \(L^2\)\sphinxhyphen{}projection onto the rotated RT0 space.  For the moment, the only projection implemented is the previous described one (projection on rotated RT0 space for quadrilateral element). Higher degree elements and triangular elements can be found in the litterature (see \sphinxcite{biblio:mi-zh2002}, \sphinxcite{biblio:br-ba-fo1989}, \sphinxcite{biblio:duan2014}) and will be under consideration for a future implementation. Note also that since \(P^h(\nabla u_3) = \nabla u_3\), the term reduces to
\begin{equation*}
\begin{split}\int_{\Omega}G\epsilon (\nabla u_3 - P^h(\theta))\cdot(\nabla v_3 - P^h(\psi))dx\end{split}
\end{equation*}
The principle of the definition of an elementary projection is explained if the description of GWFL, the generic weak form language (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-elem-trans}]{\sphinxcrossref{\DUrole{std,std-ref}{Elementary transformations}}}}) and an example can be found in the file \sphinxcode{\sphinxupquote{src/getfem\_linearized\_plates.cc}}.


\subsection{Add a Mindlin\sphinxhyphen{}Reissner plate model brick to a model}
\label{\detokenize{userdoc/model_Mindlin_plate:add-a-mindlin-reissner-plate-model-brick-to-a-model}}
The following function defined in \sphinxcode{\sphinxupquote{src/getfem/getfem\_linearized\_plates.h}} allows to add a Mindlin\sphinxhyphen{}Reissner plate model term to a transverse displacement \sphinxtitleref{u3} and a rotation \sphinxtitleref{theta}:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{size\PYGZus{}type} \PYG{n}{add\PYGZus{}Mindlin\PYGZus{}Reissner\PYGZus{}plate\PYGZus{}brick}
\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mim\PYGZus{}reduced}\PYG{p}{,} \PYG{n}{name\PYGZus{}u3}\PYG{p}{,} \PYG{n}{name\PYGZus{}theta}\PYG{p}{,} \PYG{n}{param\PYGZus{}E}\PYG{p}{,}
 \PYG{n}{param\PYGZus{}nu}\PYG{p}{,} \PYG{n}{param\PYGZus{}epsilon}\PYG{p}{,} \PYG{n}{param\PYGZus{}kappa}\PYG{p}{,} \PYG{n}{variant} \PYG{o}{=} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxtitleref{name\_u3} is name of the variable which represents the transverse displacmenent, \sphinxtitleref{name\_theta} the variable which represents the rotation, \sphinxtitleref{param\_E} the Young Modulus, \sphinxtitleref{param\_nu} the poisson ratio, \sphinxtitleref{param\_epsilon} the plate thickness, \sphinxtitleref{param\_kappa} the shear correction factor. Note that since this brick
uses GWFL, the parameter can be regular expression of this language.
There are three variants.
\sphinxtitleref{variant = 0} corresponds to the an
unreduced formulation and in that case only the integration
method \sphinxtitleref{mim} is used. Practically this variant is not usable since
it is subject to a strong locking phenomenon.
\sphinxtitleref{variant = 1} corresponds to a reduced integration where \sphinxtitleref{mim} is
used for the rotation term and \sphinxtitleref{mim\_reduced} for the transverse
shear term. \sphinxtitleref{variant = 2} (default) corresponds to the projection onto
a rotated RT0 element of the transverse shear term. For the moment, this
is adapted to quadrilateral only (because it is not sufficient to
remove the locking phenomenon on triangle elements). Note also that if
you use high order elements, the projection on RT0 will reduce the order
of the approximation.
Returns the brick index in the model.

The projection on rotated RTO element can be added to a model thanks to the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n+nf}{add\PYGZus{}2D\PYGZus{}rotated\PYGZus{}RT0\PYGZus{}projection}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{transname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{The model tools for the integration of transient problems}
\label{\detokenize{userdoc/model_time_integration:the-model-tools-for-the-integration-of-transient-problems}}\label{\detokenize{userdoc/model_time_integration:ud-model-time-integration}}\label{\detokenize{userdoc/model_time_integration:index-0}}\label{\detokenize{userdoc/model_time_integration::doc}}
Although time integration scheme can be written directly using the model object by describing the problem to be solved at each iteration, the model object furnishes some basic tools to facilitate the writing of such schemes. These tools are based on the following basic principles:
\begin{itemize}
\item {} 
The original variables of the model represent the state of the system to be solved at the current time step (say step n). This is the case even for a middle point scheme, mainly because if one needs to apply different schemes to different variables of the system, all variable should describe the system at a unique time step.

\item {} 
Some data are added to the model to represent the state of the system at previous time steps. For classical one\sphinxhyphen{}step schemes (for the moment, only one\sphinxhyphen{}step schemes are provided), only the previous time step is stored. For instance if \sphinxtitleref{u} is a variable (thus represented at step n), \sphinxtitleref{Previous\_u}, \sphinxtitleref{Previous2\_u}, \sphinxtitleref{Previous3\_u} will be the data representing the state of the variable at the previous time step (step n\sphinxhyphen{}1, n\sphinxhyphen{}2 and n\sphinxhyphen{}3).

\item {} 
Some intermediate variables are added to the model to represent the time derivative (and the second order time derivative for second order problem). For instance, if \sphinxtitleref{u} is a variable, \sphinxtitleref{Dot\_u} will represent the first order time derivative of \sphinxtitleref{u} and \sphinxtitleref{Dot2\_u} the second order one. One can refer to these variables in the model to add a brick on it or to use it in GWFL, the generic weak form language. However, these are not considered to be independent variables, they will be linked to their corresponding original variable (in an affine way) by the time integration scheme. Most of the schemes need also the time derivative at the previous time step and add the data \sphinxtitleref{Previous\_Dot\_u} and possibly \sphinxtitleref{Previous\_Dot2\_u} to the model.

\item {} 
A different time integration scheme can be applied on each variable of the model. Note that most of the time, multiplier variable and more generally variables for which no time derivative is used do not need a time integration scheme.

\item {} 
The data \sphinxtitleref{t} represent the time parameter and can be used (either in GWFL or as parameter of some bricks). Before the assembly of the system, the data \sphinxtitleref{t} is automatically updated to the time step \sphinxtitleref{n}.

\item {} 
The problem to be solved at each iteration correspond to the formulation of the transient problem in its natural (weak) formulation in which the velocity and the acceleration are expressed by the intermediate variables introduced. For instance, the translation into GWFL of the problem
\begin{equation*}
\begin{split}\dot{u}(t,x) - \Delta u(t,x) = \sin(t)\end{split}
\end{equation*}
can simply be:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Dot\PYGZus{}u}\PYG{o}{*}\PYG{n}{Test\PYGZus{}u} \PYG{o}{+} \PYG{n}{Grad\PYGZus{}u}\PYG{p}{.}\PYG{n}{Grad\PYGZus{}Test\PYGZus{}u} \PYG{o}{\PYGZhy{}} \PYG{n}{sin}\PYG{p}{(}\PYG{n}{t}\PYG{p}{)}\PYG{o}{*}\PYG{n}{Test\PYGZus{}u}
\end{sphinxVerbatim}

(even though, of course, in this situation, the use of linear bricks is preferable for efficiency reasons)

\item {} 
For all implemented one\sphinxhyphen{}step schemes, the time step can be changed from an iteration to another for both order one and order two in time problems (or even quasi\sphinxhyphen{}static problems).

\item {} 
A scheme for second order in time problem (resp. first order in time) can be applied to a second or first order in time or even to a quasi\sphinxhyphen{}static problem (resp. to a first order or quasi\sphinxhyphen{}static problem) without any problem except that the initial data corresponding to the velocity/displacement have to be initialized with respect ot the order of the scheme. Conversely, of course, a scheme for first order problem cannot be applied to a second order in time problem.

\end{itemize}


\subsection{The implicit theta\sphinxhyphen{}method for first\sphinxhyphen{}order problems}
\label{\detokenize{userdoc/model_time_integration:the-implicit-theta-method-for-first-order-problems}}
For a problem which reads
\begin{equation*}
\begin{split}M\dot{U} = F(U)\end{split}
\end{equation*}
where \(F(U)\) might be nonlinear (and may depend on some other variables for coupled problems), for \(dt\) a time step, \(V = \dot{U}\) and \(U^n, V^n\) the approximation of \(U, V\) at time \(ndt\), theta\sphinxhyphen{}method reads
\begin{equation*}
\begin{split}\left\{ \begin{array}{l}
U^n = U^{n-1} + dt(\theta V^n + (1-\theta) V^{n-1}), \\
MV^n = F(U^n),
\end{array}\right.\end{split}
\end{equation*}
for \(\theta \in (0, 1]\) the parameter of the theta\sphinxhyphen{}method (for \(\theta = 0\), the method corresponds to the forward Euler method and is not an implicit scheme) and for \(U^{n-1}, V^{n-1}\) given.

Before the first time step, \(U^0\) should be initialized, however, \(V^0\) is also needed (except for \(\theta = 1\)). In this example, it should correspond to \(M^{-1}F(U^0)\). For a general coupled problem where \(M\) might be singular, a generic precomputation of \(V^0\) is difficult to obtain. Thus \(V^0\) have to be furnisded also. Alternatively (see below) the model object (and the standard solve) furnishes a mean to evaluate them thanks to the application of a Backward Euler scheme on a (very) small time step.

The following formula can be deduced for the time derivative:
\begin{equation*}
\begin{split}V^n = \frac{U^n - U^{n-1}}{\theta dt} - \frac{1-\theta}{\theta}V^{n-1}\end{split}
\end{equation*}
When applying this scheme to a variable “u” of the model, the following affine dependent variable is added to the model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which represent the time derivative of the variable and can be used in some brick definition.

The following data are also added:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which correspond to the values of “u” and “Dot\_u” at the previous time step.

Before the solve, the data  “Previous\_u” (corresponding to \(U^0\) in the example) has to be initialized (except for \(\theta = 1\)). Again, “Previous\_Dot\_u” has to be either initialized or pre\sphinxhyphen{}computed as described in the next section. The affine dependence of “Dot\_u” is thus given by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Dot\PYGZus{}u} \PYG{o}{=} \PYG{p}{(}\PYG{n}{u} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}u}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{theta}\PYG{o}{*}\PYG{n}{dt}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}Dot\PYGZus{}u}\PYG{o}{*}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{theta}\PYG{p}{)}\PYG{o}{/}\PYG{n}{theta}
\end{sphinxVerbatim}

Which means that “Dot\_u” will be replaced at assembly time by its expression in term of “u” (multipied by \(1/(\theta*dt)\)) and in term of a constant remaining part depending on the previous time step.
The addition of this scheme to a variable is to be done thanks to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}theta\PYGZus{}method\PYGZus{}for\PYGZus{}first\PYGZus{}order}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,} \PYG{n}{scalar\PYGZus{}type} \PYG{n}{theta}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Precomputation of velocity/acceleration}
\label{\detokenize{userdoc/model_time_integration:precomputation-of-velocity-acceleration}}\label{\detokenize{userdoc/model_time_integration:precomp-time-der-section}}
Most of the time integration schemes (except, for instance, the backward Euler scheme) needs the pre\sphinxhyphen{}computation of the first or second order time derivative before the initial time step (for instance \(V^0\) for the theta\sphinxhyphen{}method for first order problems, \(A^0\) for second order problems …).

The choice is let to the user to either initialize these derivative or to ask to the model to automatically approximate them.

The method used (for the moment) to approximate the supplementary derivatives may be explained in the example of the solve of
\begin{equation*}
\begin{split}M\dot{U} = F(U)\end{split}
\end{equation*}
with a theta\sphinxhyphen{}method (see the previous section). In order to approximate \(V_0\), the theta\sphinxhyphen{}method is applied for \(\theta = 1\) (i.e. a backward Euler scheme) on a very small time step. This is possible since the  backward Euler do not need an initial time derivative. Then the time derivative computed thanks to the  backward Euler at the end of the very small time step is simply used as an approximation of the initial time derivative.

For a model \sphinxtitleref{md}, the following instructions:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{p}{.}\PYG{n}{perform\PYGZus{}init\PYGZus{}time\PYGZus{}derivative}\PYG{p}{(}\PYG{n}{ddt}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

allows to perform automatically the approximation of the initial time derivative. The parameter \sphinxtitleref{ddt} corresponds to the small time step used to perform the aproximation. Typically, \sphinxtitleref{ddt = dt/20} could be used where  \sphinxtitleref{dt} is the time step used to approximate the transient problem (see the example below).


\subsection{The implicit theta\sphinxhyphen{}method for second\sphinxhyphen{}order problems}
\label{\detokenize{userdoc/model_time_integration:the-implicit-theta-method-for-second-order-problems}}
For a problem which reads
\begin{equation*}
\begin{split}M\ddot{U} = F(U)\end{split}
\end{equation*}
where \(F(U)\) might be nonlinear (and may depend on some othere variables for coupled problems), for \(dt\) a time step, \(V = \dot{U}\), \(A = \ddot{U}\) and \(U^n, V^n, A^n\) the approximation of \(U, V, A\) at time \(ndt\), the first oder theta\sphinxhyphen{}method reads
\begin{equation*}
\begin{split}\left\{ \begin{array}{l}
U^n = U^{n-1} + dt(\theta V^n + (1-\theta) V^{n-1}), \\
V^n = V^{n-1} + dt(\theta A^n + (1-\theta) A^{n-1}), \\
MA^n = F(U^n),
\end{array}\right.\end{split}
\end{equation*}
for \(\theta \in (0, 1]\) the parameter of the theta\sphinxhyphen{}method (for \(\theta = 0\), the method correspond to the forward Euler method and is not an implicit scheme) and for \(U^{n-1}, V^{n-1}, A^{n-1}\) given.

At the first time step, \(U^0, V^0\) should be given and \(A^0\) is to be given or pre\sphinxhyphen{}computed (except for \(\theta = 1\)).

The following formula can be deduced for the time derivative:
\begin{align*}\!\begin{aligned}
V^n = \frac{U^n - U^{n-1}}{\theta dt} - \frac{1-\theta}{\theta}V^{n-1}\\
A^n = \frac{U^n - U^{n-1}}{\theta^2 dt^2} - \frac{1}{\theta^2dt}V^{n-1} - \frac{1-\theta}{\theta}A^{n-1}\\
\end{aligned}\end{align*}
When aplying this scheme to a variable “u” of the model, the following affine dependent variables are added to the model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot2\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which represent the first and second order time derivative of the variable and can be used in some brick definition.

The following data are also added:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}Dot2\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which correspond to the values of “u”, “Dot\_u”  and “Dot2\_u” at the previous time step.

Before the solve, the data  “Previous\_u” and “Previous\_Dot\_u” (corresponding to \(U^0\) in the example) have to be initialized and “Previous\_Dot2\_u” should be either initialized or precomputed (see the previous section, and except for \(\theta = 1\)). The affine dependences are thus given by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Dot\PYGZus{}u} \PYG{o}{=} \PYG{p}{(}\PYG{n}{u} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}u}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{theta}\PYG{o}{*}\PYG{n}{dt}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}Dot\PYGZus{}u}\PYG{o}{*}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{theta}\PYG{p}{)}\PYG{o}{/}\PYG{n}{theta}
\PYG{n}{Dot2\PYGZus{}u} \PYG{o}{=} \PYG{p}{(}\PYG{n}{u} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}u}\PYG{p}{)}\PYG{o}{/}\PYG{p}{(}\PYG{n}{theta}\PYG{o}{*}\PYG{n}{theta}\PYG{o}{*}\PYG{n}{dt}\PYG{o}{*}\PYG{n}{dt}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}Dot\PYGZus{}u}\PYG{o}{/}\PYG{p}{(}\PYG{n}{theta}\PYG{o}{*}\PYG{n}{theta}\PYG{o}{*}\PYG{n}{dt}\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{n}{Previous\PYGZus{}Dot2\PYGZus{}u}\PYG{o}{*}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{theta}\PYG{p}{)}\PYG{o}{/}\PYG{n}{theta}
\end{sphinxVerbatim}

The addition of this scheme to a variable is to be done thanks to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}theta\PYGZus{}method\PYGZus{}for\PYGZus{}second\PYGZus{}order}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
                                  \PYG{n}{scalar\PYGZus{}type} \PYG{n}{theta}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{The implicit Newmark scheme for second order problems}
\label{\detokenize{userdoc/model_time_integration:the-implicit-newmark-scheme-for-second-order-problems}}
For a problem which reads
\begin{equation*}
\begin{split}M\ddot{U} = F(U)\end{split}
\end{equation*}
where \(F(U)\) might be nonlinear (and may depend on some othere variables for coupled problems), for \(dt\) a time step, \(V = \dot{U}\), \(A = \ddot{U}\) and \(U^n, V^n, A^n\) the approximation of \(U, V, A\) at time \(ndt\), the first oder theta\sphinxhyphen{}method reads
\begin{equation*}
\begin{split}\left\{ \begin{array}{l}
U^n = U^{n-1} + dtV^n + \frac{dt^2}{2}(2\beta V^n + (1-2\beta) V^{n-1}), \\
V^n = V^{n-1} + dt(\gamma A^n + (1-\gamma) A^{n-1}), \\
MA^n = F(U^n),
\end{array}\right.\end{split}
\end{equation*}
for \(\beta \in (0, 1]\) and \(\gamma \in [1/2, 1]\) are the parameters of the Newmark scheme and for \(U^{n-1}, V^{n-1}, A^{n-1}\) given.

At the first time step, \(U^0, V^0\) should be given and \(A^0\) is to be given or pre\sphinxhyphen{}computed (except for \(\beta = 1/2, \gamma = 1\)).

The following formula can be deduced for the time derivative:
\begin{align*}\!\begin{aligned}
V^n = \frac{\gamma}{\beta dt}(U^n - U^{n-1}) + \frac{\beta-\gamma}{\beta}V^{n-1} + dt(1-\frac{\gamma}{2\beta})A^{n-1}\\
A^n = \frac{U^n - U^{n-1}}{\beta dt^2} - \frac{1}{\beta dt}V^{n-1} - (1/2-\beta)A^{n-1}\\
\end{aligned}\end{align*}
When aplying this scheme to a variable “u” of the model, the following affine dependent variables are added to the model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot2\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which represent the first and second order time derivative of the variable and can be used in some brick definition.

The following data are also added:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}Dot2\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which correspond to the values of “u”, “Dot\_u”  and “Dot2\_u” at the previous time step.

Before the first solve, the data  “Previous\_u” and “Previous\_Dot\_u” (corresponding to \(U^0\) in the example) have to be initialized. The data “Previous\_Dot2\_u” is to be given or precomputed (see {\hyperref[\detokenize{userdoc/model_time_integration:precomp-time-der-section}]{\sphinxcrossref{\DUrole{std,std-ref}{Precomputation of velocity/acceleration}}}} and except for \(\beta = 1/2, \gamma = 1\)).

The addition of this scheme to a variable is to be done thanks to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Newmark\PYGZus{}scheme}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{,}
                   \PYG{n}{scalar\PYGZus{}type} \PYG{n}{beta}\PYG{p}{,} \PYG{n}{scalar\PYGZus{}type} \PYG{n}{gamma}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{The implicit Houbolt scheme}
\label{\detokenize{userdoc/model_time_integration:the-implicit-houbolt-scheme}}
For a problem which reads
\begin{equation*}
\begin{split}(K+\frac{11}{6 dt}C+\frac{2}{dt^2}M) u_{n} = F_{n} + (\frac{5}{dt^2} M + \frac{3}{  dt} C) u_{n-1}
                                                   - (\frac{4}{dt^2} M + \frac{3}{2 dt} C) u_{n-2}
                                                   + (\frac{1}{dt^2} M + \frac{1}{3 dt} C) u_{n-3}\end{split}
\end{equation*}
where \(dt\) means a time step, \(M\) the matrix in term of “Dot2\_u”, \(C\) the matrix in term of “Dot\_u” and \(K\) the matrix in term of “u”.
The affine dependences are thus given by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Dot\PYGZus{}u}  \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{o}{/}\PYG{p}{(}\PYG{l+m+mi}{6}\PYG{o}{*}\PYG{n}{dt}\PYG{p}{)}\PYG{o}{*}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{o}{*}\PYG{n}{u}\PYG{l+m+mi}{\PYGZhy{}18}\PYG{o}{*}\PYG{n}{Previous\PYGZus{}u}\PYG{o}{+}\PYG{l+m+mi}{9}\PYG{o}{*}\PYG{n}{Previous2\PYGZus{}u}\PYG{l+m+mi}{\PYGZhy{}2}\PYG{o}{*}\PYG{n}{Previous3\PYGZus{}u}\PYG{p}{)}
\PYG{n}{Dot2\PYGZus{}u} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{o}{/}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{*}\PYG{o}{*}\PYG{l+m+mi}{2}\PYG{p}{)}\PYG{o}{*}\PYG{p}{(}\PYG{l+m+mi}{2}\PYG{o}{*}\PYG{n}{u}\PYG{l+m+mi}{\PYGZhy{}5}\PYG{o}{*}\PYG{n}{Previous\PYGZus{}u}\PYG{o}{+}\PYG{l+m+mi}{4}\PYG{o}{*}\PYG{n}{Previous2\PYGZus{}u}\PYG{o}{\PYGZhy{}}\PYG{n}{Previous3\PYGZus{}u}\PYG{p}{)}
\end{sphinxVerbatim}

When aplying this scheme to a variable “u” of the model, the following affine dependent variables are added to the model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot2\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which represent the first and second order time derivative of the variable and can be used in some brick definition.

The following data are also added:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous2\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous3\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}
\end{sphinxVerbatim}

which correspond to the values of “u” at the time step n\sphinxhyphen{}1, n\sphinxhyphen{}2 n\sphinxhyphen{}3.

Before the solve, the data “Previous\_u”, “Previous2\_u” and “Previous3\_u” (corresponding to \(U^0\) in the example) have to be initialized.

The addition of this scheme to a variable is to be done thanks to:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}Houbolt\PYGZus{}scheme}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{varname}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Transient terms}
\label{\detokenize{userdoc/model_time_integration:transient-terms}}
As it has been explained in previous sections, some intermediate variables are added to the model in order to represent the time derivative of the variables on which the scheme is applied. Once again, if “u” is such a variable, “Dot\_u” will represent the time derivative of “u” approximated by the used scheme.

This also mean that “Dot\_u” (and “Dot2\_u” in order two in time problems) can be used to express the transient terms. In GWFL, the term:
\begin{equation*}
\begin{split}\int_{\Omega} \dot{u} v dx\end{split}
\end{equation*}
can be simply expressed by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Dot\PYGZus{}u}\PYG{o}{*}\PYG{n}{Test\PYGZus{}u}
\end{sphinxVerbatim}

Similarly, every existing model brick of \sphinxstyleemphasis{GetFEM} can be applied to “Dot\_u”. This is the case for instance with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}mass\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

which adds the same transient term.

VERY IMPORTANT: When adding an existing model brick applied to an affine dependent variable such as “Dot\_u”, it is always assumed that the corresponding test function is the one of the corresponding original variable (i.e. “Test\_u” here). In other words, “Test\_Dot\_u”, the test variable corresponding to the velocity, is not used. This corresponds to the choice made to solve the problem in term of the original variable, so that the test function corresponds to the original variable.

Another example of model brick which can be used to account for a Kelvin\sphinxhyphen{}Voigt linearized viscosity term is the linearized elasticity brick:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}isotropic\PYGZus{}linearized\PYGZus{}elasticity\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{lambda\PYGZus{}viscosity}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu\PYGZus{}viscosity}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

when applied to an order two transient elasticity problem.


\subsection{Computation on the sequence of time steps}
\label{\detokenize{userdoc/model_time_integration:computation-on-the-sequence-of-time-steps}}
Typically, the solve on the different time steps will take the following form:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{for} \PYG{p}{(}\PYG{n}{scalar\PYGZus{}type} \PYG{n}{t} \PYG{o}{=} \PYG{l+m+mf}{0.}\PYG{p}{;} \PYG{n}{t} \PYG{o}{\PYGZlt{}} \PYG{n}{T}\PYG{p}{;} \PYG{n}{t} \PYG{o}{+}\PYG{o}{=} \PYG{n}{dt}\PYG{p}{)} \PYG{p}{\PYGZob{}} \PYG{c+c1}{// time loop}

  \PYG{c+c1}{// Eventually compute here some time dependent terms}

  \PYG{n}{iter}\PYG{p}{.}\PYG{n}{init}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// + Do something with the solution (plot or store it)}

  \PYG{n}{model}\PYG{p}{.}\PYG{n}{shift\PYGZus{}variables\PYGZus{}for\PYGZus{}time\PYGZus{}integration}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}

Note that the call of the method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{model}\PYG{p}{.}\PYG{n}{shift\PYGZus{}variables\PYGZus{}for\PYGZus{}time\PYGZus{}integration}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

is needed between two time step since it will copy the current value of the variables (\sphinxtitleref{u} and \sphinxtitleref{Dot\_u} for instance) to the previous ones (\sphinxtitleref{Previous\_u} and \sphinxtitleref{Previous\_Dot\_u}).


\subsection{Boundary conditions}
\label{\detokenize{userdoc/model_time_integration:boundary-conditions}}
Standard boundary conditions can of course be applied normally to the different variables of the unknown. By default, applying Dirichlet, Neumann or contact boundary conditions to the unknown simply means that the conditions are prescribed on the variable at the current time step n.


\subsection{Small example: heat equation}
\label{\detokenize{userdoc/model_time_integration:small-example-heat-equation}}
The complete compilable program corresponds to the test program \sphinxcode{\sphinxupquote{tests/heat\_equation.cc}} of \sphinxstyleemphasis{GetFEM} distribution. See also \sphinxcode{\sphinxupquote{/interface/tests/matlab/demo\_wave\_equation.m}} for an example of order two in time problem with the Matlab interface.

Assuming that \sphinxtitleref{mf\_u} and \sphinxtitleref{mim} are valid finite element and integration methods defined on a valid mesh, the following code will perform the approximation of the evolution of the temperature on the mesh assuming a unitary diffusion coefficient:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{model} \PYG{n}{model}\PYG{p}{;}
\PYG{n}{model}\PYG{p}{.}\PYG{n}{add\PYGZus{}fem\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Main unknown of the problem}

\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}generic\PYGZus{}elliptic\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;} \PYG{c+c1}{// Laplace term}

\PYG{c+c1}{// Volumic source term.}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}source\PYGZus{}term\PYGZus{}generic\PYGZus{}assembly\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{sin(t)*Test\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}


\PYG{c+c1}{// Dirichlet condition.}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Dirichlet\PYGZus{}condition\PYGZus{}with\PYGZus{}multipliers}
    \PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{mf\PYGZus{}u}\PYG{p}{,} \PYG{n}{DIRICHLET\PYGZus{}BOUNDARY\PYGZus{}NUM}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// transient part.}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}theta\PYGZus{}method\PYGZus{}for\PYGZus{}first\PYGZus{}order}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{theta}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}mass\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dot\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{iteration} \PYG{n}{iter}\PYG{p}{(}\PYG{n}{residual}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{40000}\PYG{p}{)}\PYG{p}{;}

\PYG{n}{model}\PYG{p}{.}\PYG{n}{set\PYGZus{}time}\PYG{p}{(}\PYG{l+m+mf}{0.}\PYG{p}{)}\PYG{p}{;}        \PYG{c+c1}{// Init time is 0 (not mandatory)}
\PYG{n}{model}\PYG{p}{.}\PYG{n}{set\PYGZus{}time\PYGZus{}step}\PYG{p}{(}\PYG{n}{dt}\PYG{p}{)}\PYG{p}{;}   \PYG{c+c1}{// Init of the time step.}

\PYG{c+c1}{// Null initial value for the temperature.}
\PYG{n}{gmm}\PYG{o}{:}\PYG{o}{:}\PYG{n}{clear}\PYG{p}{(}\PYG{n}{model}\PYG{p}{.}\PYG{n}{set\PYGZus{}real\PYGZus{}variable}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Previous\PYGZus{}u}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}

\PYG{c+c1}{// Automatic computation of Previous\PYGZus{}Dot\PYGZus{}u}
\PYG{n}{model}\PYG{p}{.}\PYG{n}{perform\PYGZus{}init\PYGZus{}time\PYGZus{}derivative}\PYG{p}{(}\PYG{n}{dt}\PYG{o}{/}\PYG{l+m+mf}{20.}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{iter}\PYG{p}{.}\PYG{n}{init}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}


\PYG{c+c1}{// Iterations in time}
\PYG{k}{for} \PYG{p}{(}\PYG{n}{scalar\PYGZus{}type} \PYG{n}{t} \PYG{o}{=} \PYG{l+m+mf}{0.}\PYG{p}{;} \PYG{n}{t} \PYG{o}{\PYGZlt{}} \PYG{n}{T}\PYG{p}{;} \PYG{n}{t} \PYG{o}{+}\PYG{o}{=} \PYG{n}{dt}\PYG{p}{)} \PYG{p}{\PYGZob{}}

  \PYG{n}{iter}\PYG{p}{.}\PYG{n}{init}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
  \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{standard\PYGZus{}solve}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{iter}\PYG{p}{)}\PYG{p}{;}

  \PYG{c+c1}{// + Do something with the solution (plot or store it)}

  \PYG{c+c1}{// Copy the current variables \PYGZdq{}u\PYGZdq{} and \PYGZdq{}Dot\PYGZus{}u\PYGZdq{} into \PYGZdq{}Previous\PYGZus{}u\PYGZdq{}}
  \PYG{c+c1}{// and \PYGZdq{}Previous\PYGZus{}Dot\PYGZus{}u\PYGZdq{}.}
  \PYG{n}{model}\PYG{p}{.}\PYG{n}{shift\PYGZus{}variables\PYGZus{}for\PYGZus{}time\PYGZus{}integration}\PYG{p}{(}\PYG{p}{)}\PYG{p}{;}
\PYG{p}{\PYGZcb{}}
\end{sphinxVerbatim}


\subsection{Implicit/explicit some terms}
\label{\detokenize{userdoc/model_time_integration:implicit-explicit-some-terms}}
…


\subsection{Explicit schemes}
\label{\detokenize{userdoc/model_time_integration:explicit-schemes}}
…


\subsection{Time step adaptation}
\label{\detokenize{userdoc/model_time_integration:time-step-adaptation}}
…


\subsection{Quasi\sphinxhyphen{}static problems}
\label{\detokenize{userdoc/model_time_integration:quasi-static-problems}}
…

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Small sliding contact with friction bricks}
\label{\detokenize{userdoc/model_contact_friction:small-sliding-contact-with-friction-bricks}}\label{\detokenize{userdoc/model_contact_friction:ud-model-contact-friction}}\label{\detokenize{userdoc/model_contact_friction:index-0}}\label{\detokenize{userdoc/model_contact_friction::doc}}
The aim of these bricks is to take into account a contact condition with or without friction of an elastic structure on a rigid foundation or between two elastic structures. These bricks are restricted to small deformation approximation of contact (this may include large deformations on a flat obstacle).


\subsection{Approximation of contact}
\label{\detokenize{userdoc/model_contact_friction:approximation-of-contact}}
For small deformation problems submitted
a simple (compared to large deformation !) expression of the contact with friction condition is usually used where the tangential displacement do not influence the normal one. This is an approximation in the sense that if an obstacle is not perfectly flat, the tangential displacement of course influence the point where the contact holds. This will not be the case in small deformation where the contact condition can be considered to be described on the reference configuration.

There are mainly two largely used discretizations of the contact with friction condition in this framework: a direct nodal contact condition (usually prescribed on the displacement finite element nodes) or a weak nodal contact condition (usually prescribed on the multiplier finite element nodes). The two discretization leads to similar system. However, the interpretation of quantities is not the same. A third approach is developed on Getfem contact bricks: a weak integral contact condition. It needs the computation of a non\sphinxhyphen{}linear integral on the contact boundary at each iteration but the numerical resolution is potentially more scalable because it derives directly from continuous principles.

More details can be found for instance in \sphinxcite{biblio:ki-od1988}, \sphinxcite{biblio:kh-po-re2006} and \sphinxcite{biblio:la-re2006}.


\subsection{Direct nodal contact condition}
\label{\detokenize{userdoc/model_contact_friction:direct-nodal-contact-condition}}
A nodal contact condition consists in a certain number of contact nodes \(a_i\), \(i=1..N_c\) on which a contact with (or without) friction condition is applied. The contact condition reads
\begin{equation*}
\begin{split}u_N(a_i)-\text{gap}_i \le 0, ~~ \lambda_N^i \le 0,  ~~ (u_N(a_i)-\text{gap}_i) \lambda_N^i = 0,\end{split}
\end{equation*}
where \(\lambda_N^i\) is the equivalent nodal contact force on \(a_i\) and \(u_N(a_i)\) is the normal relative displacement between the elastic solid and an obstacle or between two elastic solids. The term \(\text{gap}_i\) represents the normal gap between the two solids in the reference configuration. The friction condition reads
\begin{align*}\!\begin{aligned}
\|\lambda_T^i\| \le -{\mathscr F} \lambda_N^i,\\
\lambda_T^i = {\mathscr F} \lambda_N^i \frac{\dot{u}_T}{\|\dot{u}_T\|} ~~~ \text{ when } \dot{u}_T \ne 0,\\
\end{aligned}\end{align*}
where \(\dot{u}_T\) is the relative slip velocity, \({\mathscr F}\) is the friction coefficient and \(\lambda_T^i\) the equivalent nodal friction force on \(a_i\). The friction condition can be summarized by the inclusion
\begin{equation*}
\begin{split}\lambda_T^i \in {\mathscr F} \lambda_N^i \text{Dir}(\dot{u}_T),\end{split}
\end{equation*}
where \(\text{Dir}(\dot{u}_T)\) is the multivalued map being the sub\sphinxhyphen{}differential of \(x \mapsto \|x_T\|\) (i.e. \(\text{Dir}(x) = \frac{x}{\|x\|}\) when \(x \ne 0\) and \(\text{Dir}(0)\) the closed unit ball). For two dimensional cases, \(\text{Dir}(\dot{u}_T)\) reduces to \(\text{Sign}(\dot{u}_T)\) where \(\text{Sign}\) is the multivalued sign map.

A complete linearized elasticity problem with contact with friction reads as

Given an augmentation parameter \(r\), the contact and friction conditions can be equivalently expressed in term of projection as
\begin{align*}\!\begin{aligned}
\frac{1}{r}(\lambda_N^i - P_{]-\infty, 0]}(\lambda_N^i - r (u_N(a_i) - \text{gap}_i))) = 0,\\
\frac{1}{r}(\lambda_T^i - P_{{\mathscr B}(-{\mathscr F}P_{]-\infty, 0]}(\lambda_N^i - r(u_N(a_i) - \text{gap}_i))}(\lambda_T^i - r \dot{u}_T(a_i))) = 0,\\
\end{aligned}\end{align*}
where \(P_K\) is the projection on the convex \(K\) and \({\mathscr B}(-{\mathscr F}\lambda_N^i)\) is the ball of center \(0\) and radius \(-{\mathscr F}\lambda_N^i\).
These expressions will be used to perform a semi\sphinxhyphen{}smooth Newton method.

Suppose now that you approximate a linearized elasticity problem submitted to contact with friction. Then, if \(U\) is the vector of the unknown for the displacement you will be able to express the matrices \(B_N\) and \(B_T\) such that
\begin{align*}\!\begin{aligned}
u_N(a_i) = (B_N U)_i,\\
(\dot{u}_T(a_i))_k = (B_T \dot{U})_{(d-1)(i-1)+k},\\
\end{aligned}\end{align*}
where \(d\) is the dimension of the domain and \(k = 1..d-1\). The expression of the elasticity problem with contact with friction can be written as
\begin{align*}\!\begin{aligned}
K U = L + B_N^T \lambda_N + B_T^T \lambda_T,\\
-\frac{1}{r\alpha_i}(\lambda_N^i - P_{]-\infty, 0]}(\lambda_N^i - \alpha_i r ((B_N U)_i - \text{gap}_i))) = 0, ~~ i = 1..N_c,\\
-\frac{1}{r\alpha_i}(\lambda_T^i - P_{{\mathscr B}(-{\mathscr F}P_{]-\infty, 0]}(\lambda_N^i - \alpha_i r ((B_N U)_i - \text{gap}_i))))}(\lambda_T^i - \alpha_i r (B_T U - B_T U^{0})_i)) = 0, ~~ i = 1..N_c,\\
\end{aligned}\end{align*}
where \(\alpha_i\) is a parameter which can be added for the homogenization of the augmentation parameter, \((B_T U)_i\) denotes here the sub\sphinxhyphen{}vector of indices from \((d-1)(i-1)+1\) to \((d-1)i\) for the sake of simplicity and the sliding velocity \(B_T \dot{U}\) have been discretized into \(\frac{(B_T U - B_T U^{0})}{\Delta t}\) with \(U^{0}\) the displacement at the previous time step. Note that of course another discretization of the sliding velocity is possible and that the time step \(\Delta t\) do not appear in the expression of the friction condition since it does not influence the direction of the sliding velocity.

In that case, the homogenization coefficient \(\alpha_i\) can be taken proportional to \(h^{d-2}\) (\(h\) being the diameter of the element). In this way, the augmentation parameter \(r\) can be expressed in \(N/m^2\) and chosen closed to the Young modulus of the elastic body. Note that the solution is not sensitive to the value of the augmentation parameter.


\subsection{Weak nodal contact condition}
\label{\detokenize{userdoc/model_contact_friction:weak-nodal-contact-condition}}
The direct nodal condition may have some drawback : locking phenomena, over\sphinxhyphen{}constraint. It is in fact often more stable and for the same accuracy to use multiplier of reduced order compared to the displacement (the direct nodal contact condition corresponds more or less to a multiplier described on the same finite element method than the displacement).

Let \(\varphi_i\) be the shapes functions of the finite element describing the displacement and \(\psi_i\) be the shape functions of a finite element describing a multiplier on the contact boundary \(\Gamma_c\). It is assumed that the set of admissible multiplier describing the normal stress will be
\begin{equation*}
\begin{split}\Lambda_N^h = \{ \mu^h_N = \sum \mu^j_N \psi_j : \mu^h_N(a_i) \le 0, ~i = 1..N_c \}\end{split}
\end{equation*}
where \(a_i\), \(~~i=1..N_c\) are the finite element nodes corresponding to the multiplier. The discrete contact condition is now expressed in a weak form by
\begin{equation*}
\begin{split}\int_{\Gamma_c} (\mu_N^h - \lambda_N^h) (u_N - \text{gap}) d\Gamma \ge 0 ~~ \forall \mu_N^h \in \Lambda_N^h.\end{split}
\end{equation*}
In that case, the component \(\lambda_N^i\) is a contact stress (\(N/m^2\)) and the matrix \(B_N\) can be written
\begin{equation*}
\begin{split}(B_N)_{ij} = \int_{\Gamma_c} \psi_i \varphi_j d\Gamma.\end{split}
\end{equation*}
The matrix \(B_T\) can also be written in a similar way. The friction condition can be written in a weak form
\begin{equation*}
\begin{split}\int_{\Gamma_c} (\mu_T^h - \lambda_T^h) \dot{u}_T d\Gamma \ge 0 ~~ \forall \mu_T^h \in \Lambda_T^h({\mathscr F}\lambda_N^h),\end{split}
\end{equation*}
where \(\Lambda_T^h({\mathscr F}\lambda_N^h)\) is the discrete set of admissible friction stress.

Finally, the expression of the direct nodal contact condition are recovered
\begin{align*}\!\begin{aligned}
K U = L + B_N^T \lambda_N + B_T^T \lambda_T,\\
-\frac{1}{r\alpha_i}(\lambda_N^i - P_{]-\infty, 0]}(\lambda_N^i - \alpha_i r ((B_N U)_i - \text{gap}_i))) = 0, ~~ i = 1..N_c,\\
-\frac{1}{r\alpha_i}(\lambda_T^i - P_{{\mathscr B}(-{\mathscr F}P_{]-\infty, 0]}(\lambda_N^i - \alpha_i r ((B_N U)_i - \text{gap}_i)))}(\lambda_T^i - \alpha_i r (B_T U - B_T U^{0})_i)) = 0, ~~ i = 1..N_c,\\
\end{aligned}\end{align*}
except that now \(\lambda_N^i\) and \(\lambda_T^i\) are force densities, and \(\alpha_i\) has to be now chosen proportional to \(1/h^d\) such that the augmentation parameter \(r\) can still be chosen close to the Young modulus of the elastic body.

Note that without additional stabilization technique (see \sphinxcite{biblio:hi-re2010}) an inf\sphinxhyphen{}sup condition have to be satisfied between the finite element of the displacement and the one for the multipliers. This means in particular that the finite element for the multiplier have to be “less rich” than the one for the displacement.


\subsection{Weak integral contact condition}
\label{\detokenize{userdoc/model_contact_friction:weak-integral-contact-condition}}\label{\detokenize{userdoc/model_contact_friction:weak-integral-contact-section}}
The weak integral contact formulation allows not to explicitly describe the discrete set of admissible stress. See also {\hyperref[\detokenize{userdoc/model_Nitsche:nitsche-contact-small-def-section}]{\sphinxcrossref{\DUrole{std,std-ref}{Generic Nitsche’s method for contact with friction condition}}}}. The contact stress (including the friction one) is described on a finite element space \(W^h\) on the contact boundary \(\Gamma_c\):
\begin{equation*}
\begin{split}\lambda^h \in W^h = \left\{ \sum \lambda_i \psi_i, \lambda_i \in I\hspace{-0.2em}R^d \right\}\end{split}
\end{equation*}
where \(d\) is the dimension of the problem and \(\psi_i\) still the shapes functions on which the contact stress is developed. Now, given a outward unit vector \(n\) on the contact boundary \(\Gamma_c\) (usually the normal to the obstacle), we make the standard decompositions:
\begin{equation*}
\begin{split}\lambda_N^h = \lambda^h \cdot n, ~~~~ \lambda_T^h = \lambda^h - \lambda_N^h n, ~~~~
u_N^h = u^h \cdot n, ~~~~ u_T^h = u^h - u_N^h n,\end{split}
\end{equation*}
where \(u^h\) is the displacement field approximated on a finite element space \(V^h\). This allows to express the contact condition in the following way
\begin{equation*}
\begin{split}\displaystyle \int_{\Gamma_c} (\lambda^h_N + (\lambda^h_N - r(u^h_N-gap))_-)\mu^h_N d\Gamma = 0 ~~~~ \forall \mu^h \in W^h,\end{split}
\end{equation*}
where \(gap\) is a given initial gap in reference configuration, \(r\) is an augmentation parameter and \((\cdot)_-:I\hspace{-0.2em}R\rightarrow I\hspace{-0.2em}R_+\) is the negative part. The friction condition can similarly be written:
\begin{equation*}
\begin{split}\displaystyle \int_{\Gamma_c} (\lambda^h_T -P_{B(\mathscr F(\lambda^h_N - r(u^h_N-gap))_-)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)))\cdot \mu^h_T d\Gamma = 0 ~~~~ \forall \mu^h \in W^h,\end{split}
\end{equation*}
where \(B(\rho)\) is the closed ball of center  \(0\) and radius \(\rho\) and \(P_{B(\rho)}\) is the orthogonal projection on it (By convenyion, the ball reduces to the origin dor \(\rho \le 0\)). The term \(\alpha(u^h_T-w^h_T)\) represent here an approximation of the sliding velocity. The parameter \(\alpha\) and the field \(w^h_T\) have to be adapted with respect to the chosen approximation. For instance, if the standard finite difference
\begin{equation*}
\begin{split}(\dot{u}^h_T)^{n+1} \approx \displaystyle \frac{(u^h_T)^{n+1} - (u^h_T)^{n}}{dt}\end{split}
\end{equation*}
is chosen, then one has to take \(\alpha = 1/dt\) and \(w^h_T = (u^h_T)^{n}\). Note that due to the symmetry of the ball, the parameter \(\alpha\) do not play an important role in the formulation. It can simply be viewed as a scaling between the augmentation parameter for the contact condition and the one for the friction condition. Note also that contrarily to the previous formulations of contact, here there is not a strict independance of the conditions with respect to the augmentation parameter (the independance only occurs at the continuous level).

GetFEM bricks implement four versions of the contact condition derived from the Alart\sphinxhyphen{}Curnier augmented Lagrangian formulation \sphinxcite{biblio:al-cu1991}. The first one corresponds to the non\sphinxhyphen{}symmetric version. It consists in solving:
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
a(u^h, v^h) + \displaystyle \int_{\Gamma_c} \lambda^h \cdot v^h d\Gamma = \ell(v^h) ~~~~ \forall v^h \in V^h, \\
\displaystyle -\frac{1}{r}\int_{\Gamma_c} (\lambda^h_N + (\lambda^h_N - r(u^h_N-gap))_-)\mu^h_N d\Gamma \\
~~~~~~~~~~\displaystyle -\frac{1}{r}\int_{\Gamma_c} (\lambda^h_T -P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)))\cdot \mu^h_T d\Gamma = 0 ~~~~ \forall \mu^h \in W^h,
\end{array}\right.\end{split}
\end{equation*}
where \(a(\cdot, \cdot)\) and \(\ell(v)\) represent the remaining parts of the problem in  \(u\), for instance linear elasticity and \(\rho={\mathscr F}(\lambda^h_N - r(u^h_N-gap))_-\). Note that in this case, the mathematical analysis leads to choose a value for the augmentation parameter of the kind \(r = r_0 / r\) with \(r_0\) having the dimension of a elasticity modulus (a classical choice is the value of Young’s modulus). In order to write a Newton iteration, one has to derive the tangent system. It can be written, reporting only the contact and friction terms and not the right hand side:
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
\cdots - \displaystyle \int_{\Gamma_c} \delta_{\lambda} \cdot v d\Gamma = \cdots  ~~~~ \forall v^h \in V^h, \\
\displaystyle -\frac{1}{r}\int_{\Gamma_c}(1-H(r(u^h_N-gap)-\lambda_N))\delta_{\lambda_N}\mu^h_N d\Gamma
\displaystyle -\int_{\Gamma_c}H(r(u^h_N-gap)-\lambda_N)\delta_{u_N}\mu^h_N d\Gamma \\
~~~~~~\displaystyle -\frac{1}{r}\int_{\Gamma_c}(\delta_{\lambda_T} - D_xP_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{\lambda_T})\cdot\mu^h_T d\Gamma \\
~~~~~~\displaystyle -\int_{\Gamma_c}\alpha D_xP_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{u_T}\cdot\mu^h_T d\Gamma \\
~~~~~~ \displaystyle +\int_{\Gamma_c}({\mathscr F} D_{\rho}P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{u_N})\cdot\mu^h_T d\Gamma \\
~~~~~~ \displaystyle -\int_{\Gamma_c}(\frac{\mathscr F}{r} D_{\rho}P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{\lambda_N})\cdot\mu^h_T d\Gamma = \cdots ~~~ \forall \mu^h \in W^h,
\end{array}\right.\end{split}
\end{equation*}
where \(H(\cdot)\) is the Heaviside function (0 for a negative argument and 1 for a non\sphinxhyphen{}negative argument), \(D_xP_{B(\rho)}(x)\) and \(D_{\rho}P_{B(\rho)}(x)\) are the derivatives of the projection on \(B(\rho)\) (assumed to vanish for \(\rho \le 0\)) and \(\delta_{\lambda}\) and \(\delta_{u}\) are the unknown corresponding to the tangent problem.

The second version corresponds to the “symmetric” version. It is in fact symmetric in the frictionless case only (because in this case it directly derives from the augmented Lagrangian formulation). It reads:
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
a(u^h, v^h) + \displaystyle \int_{\Gamma_c} (\lambda^h_N - r(u^h_N-gap))_- v^h_N d\Gamma \\
~~~~~~ - \displaystyle \int_{\Gamma_c} P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)))\cdot v^h_T d\Gamma = \ell(v^h) ~~~~ \forall v^h \in V^h, \\
\displaystyle -\frac{1}{r}\int_{\Gamma_c} (\lambda^h_N + (\lambda^h_N - r(u^h_N-gap))_-)\mu^h_N d\Gamma \\
~~~~~~~~~~\displaystyle -\frac{1}{r}\int_{\Gamma_c} (\lambda^h_T -P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)))\cdot \mu^h_T d\Gamma = 0 ~~~~ \forall \mu^h \in W^h,
\end{array}\right.\end{split}
\end{equation*}
and the tangent system:
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
\cdots + \displaystyle \int_{\Gamma_c} rH(r(u^h_N-gap)-\lambda_N)\delta_{u_N} v_N -  H(r(u^h_N-gap)-\lambda_N)\delta_{\lambda_N} v_N d\Gamma \\
~~~~~~+ \displaystyle \int_{\Gamma_c} r \alpha D_xP_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)) \delta_{u_T}\cdot v^h_T d\Gamma \\
~~~~~~- \displaystyle \int_{\Gamma_c} D_xP_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)) \delta_{\lambda_T}\cdot v^h_T d\Gamma \\
~~~~~~- \displaystyle \int_{\Gamma_c} (r{\mathscr F} D_{\rho}P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)) \delta_{u_N})\cdot v^h_T d\Gamma \\
~~~~~~- \displaystyle \int_{\Gamma_c} ({\mathscr F} D_{\rho}P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T)) \delta_{\lambda_N})\cdot v^h_T d\Gamma = \cdots  ~~~~ \forall v^h \in V^h, \\
\displaystyle -\frac{1}{r}\int_{\Gamma_c}(1-H(r(u^h_N-gap)-\lambda_N))\delta_{\lambda_N}\mu^h_N d\Gamma
\displaystyle -\int_{\Gamma_c}H(r(u^h_N-gap)-\lambda_N)\delta_{u_N}\mu^h_N d\Gamma \\
~~~~~~\displaystyle -\frac{1}{r}\int_{\Gamma_c}(\delta_{\lambda_T} - D_xP_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{\lambda_T})\cdot\mu^h_T d\Gamma \\
~~~~~~\displaystyle -\int_{\Gamma_c}\alpha D_xP_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{u_T}\cdot\mu^h_T d\Gamma \\
~~~~~~ \displaystyle +\int_{\Gamma_c}({\mathscr F} D_{\rho}P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{u_N})\cdot\mu^h_T d\Gamma \\
~~~~~~ \displaystyle -\int_{\Gamma_c}(\frac{\mathscr F}{r} D_{\rho}P_{B(\rho)}(\lambda^h_T - r\alpha(u^h_T-w^h_T))\delta_{\lambda_N})\cdot\mu^h_T d\Gamma = \cdots ~~~ \forall \mu^h \in W^h,
\end{array}\right.\end{split}
\end{equation*}
still with \(\rho={\mathscr F}(\lambda^h_N - r(u^h_N-gap))_-\).

The third version corresponds to a penalized contact and friction condition. It does not require the use of a multiplier. In this version, the parameter \(r\) is a penalization parameter and as to be large enough to perform a good approximation of the non\sphinxhyphen{}penetration and the Coulomb friction conditions. The formulation reads:
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
a(u^h, v^h) + \displaystyle \int_{\Gamma_c} r(u^h_N-gap)_+ v^h_N d\Gamma \\
~~~~~~ + \displaystyle \int_{\Gamma_c} P_{B(\mathscr F r(u^h_N-gap)_+)}(r\alpha(u^h_T-w^h_T))\cdot v^h_T d\Gamma = \ell(v^h) ~~~~ \forall v^h \in V^h,
\end{array}\right.\end{split}
\end{equation*}
and the tangent system:
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
\cdots + \displaystyle \int_{\Gamma_c} rH(u^h_N-gap)\delta_{u_N} v_N d\Gamma \\
~~~~~~- \displaystyle \int_{\Gamma_c} r \alpha D_xP_{B(\mathscr F r(u^h_N-gap)_+)}(r\alpha(u^h_T-w^h_T)) \delta_{u_T}\cdot v^h_T d\Gamma \\
~~~~~~+ \displaystyle \int_{\Gamma_c} ({r\mathscr F} H(u^h_N-gap) D_{\rho}P_{B(\mathscr F r(u^h_N-gap)_+)}(r\alpha(u^h_T-w^h_T)) \delta_{u_N})\cdot v^h_T d\Gamma = \cdots  ~~~~ \forall v^h \in V^h,
\end{array}\right.\end{split}
\end{equation*}

\subsection{Numerical continuation}
\label{\detokenize{userdoc/model_contact_friction:numerical-continuation}}
In addition, \sphinxstyleemphasis{GetFEM} develops a method of numerical continuation for finding numerical solutions of discretized evolutionary contact problems based on the weak integral contact condition (see {\hyperref[\detokenize{userdoc/model_continuation:ud-model-continuation}]{\sphinxcrossref{\DUrole{std,std-ref}{Numerical continuation and bifurcation}}}} for a general introduction). For this purpose, a parameter\sphinxhyphen{}dependent sliding velocity may be added to the friction condition so that it becomes:
\begin{equation*}
\begin{split}\displaystyle \int_{\Gamma_c} \Bigl(\lambda^h_T -P_{B(-\mathscr F\lambda^h_N)}\bigl(\lambda^h_T - r\bigl(\alpha(u^h_T-w^h_T)+(1-\gamma)z^h_T\bigr)\bigr)\Bigr)\cdot \mu^h_T d\Gamma = 0 ~~~~ \forall \mu^h \in W^h.\end{split}
\end{equation*}
Here, \(\gamma\) is a parameter and \(z^h_T\) is an initial sliding velocity. It is worth mentioning that if one chooses
\begin{equation*}
\begin{split}\displaystyle \alpha = \frac{1}{dt},\quad w^h_T = (u^h_T)^{n},\quad z^h_T = \frac{(u^h_T)^{n} - (u^h_T)^{n-1}}{dt},\end{split}
\end{equation*}
then he recovers the standard friction condition at time \(t_{n}\) and \(t_{n+1}\) for \(\gamma\) equal to 0 and 1, respectively.


\subsection{Friction law}
\label{\detokenize{userdoc/model_contact_friction:friction-law}}
Apart from pure Coulomb friction \(\rho = {\mathscr F} \left| \sigma_n \right|\),
the weak integral contact framework in \sphinxstyleemphasis{GetFEM} also supports a more generic friction
law description:
\begin{equation*}
\begin{split}\displaystyle \rho = \left\{\begin{array}{ll}
\tau_{adh} + {\mathscr F} \left| \sigma_n \right| &
~~~\mbox{if } ~~ \tau_{adh} + {\mathscr F} \left| \sigma_n \right| < \tau_{tresca} \\
\tau_{tresca} & ~~~\mbox{otherwise}
\end{array}\right.\end{split}
\end{equation*}
In this equation \(\rho\) is the admissible friction stress for a given
normal stress \(\sigma_n\), \({\mathscr F}\) is the coefficient of friction,
\(\tau_{adh}\) is an adhesional (load\sphinxhyphen{}independent) shear stress and
\(\tau_{tresca}\) is a maximum shear stress limit.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{getfemuserfrictionlaw}.png}
\end{figure}


\subsection{Add a contact with or without friction to a model}
\label{\detokenize{userdoc/model_contact_friction:add-a-contact-with-or-without-friction-to-a-model}}

\subsection{Frictionless basic contact brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-basic-contact-brick}}
In order to add a frictionless contact brick you call the model object method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}basic\PYGZus{}contact\PYGZus{}brick}
     \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u}\PYG{p}{,} \PYG{n}{multname\PYGZus{}n}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,} \PYG{n}{BN}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}gap}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}alpha}\PYG{p}{,} \PYG{n}{aug\PYGZus{}version}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a frictionless contact brick on \sphinxcode{\sphinxupquote{varname\_u}} thanks to a multiplier variable \sphinxcode{\sphinxupquote{multname\_n}}. If \(U\) is the vector of degrees of freedom on which the unilateral constraint is applied, the matrix \(B_N\) have to be such that this condition is defined by \(B_N U \le 0\). The constraint is prescribed thank to a multiplier \sphinxcode{\sphinxupquote{multname\_n}} whose dimension should be equal to the number of lines of \(B_N\). The variable \sphinxcode{\sphinxupquote{dataname\_r}} is the name of the augmentation parameter \(r\) should be chosen in a range of acceptable values. \sphinxcode{\sphinxupquote{dataname\_gap}} is an optional parameter representing the initial gap. It can be a single value or a vector of value. \sphinxcode{\sphinxupquote{dataname\_alpha}} is an optional homogenization parameter for the augmentation parameter.

The parameter \sphinxtitleref{aug\_version} indicates the augmentation strategy : 1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian, 2 for the symmetric one, 3 for the unsymmetric method based on augmented multipliers.

Note that is possible to change the basic contact matrix \(B_N\) by using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{contact\PYGZus{}brick\PYGZus{}set\PYGZus{}BN}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Basic contact brick with friction}
\label{\detokenize{userdoc/model_contact_friction:basic-contact-brick-with-friction}}\begin{quote}
\begin{description}
\item[{getfem::add\_basic\_contact\_brick}] \leavevmode
(md, varname\_u, multname\_n, multname\_t, dataname\_r, BN, dataname\_friction\_coeff, dataname\_gap, dataname\_alpha, aug\_version);

\end{description}
\end{quote}

This function adds a contact brick with friction on \sphinxcode{\sphinxupquote{varname\_u}} thanks to two
multiplier variables \sphinxcode{\sphinxupquote{multname\_n}} and \sphinxcode{\sphinxupquote{multname\_t}}. If \sphinxcode{\sphinxupquote{U}} is the vector
of degrees of freedom on which the condition is applied,
the matrix \sphinxcode{\sphinxupquote{B\_N}} has to be such that the contact condition is defined
by \(B_N U \le gap\) and \sphinxcode{\sphinxupquote{B\_T}} have to be such that the relative
tangential
displacement is \(B_T U\). The matrix \sphinxcode{\sphinxupquote{B\_T}} should have as many rows as
\sphinxcode{\sphinxupquote{B\_N}} multiplied by \(d-1\) where \(d\) is the domain dimension.
The contact condition is prescribed thank to a multiplier
\sphinxcode{\sphinxupquote{multname\_n}} whose dimension should be equal to the number of rows of
\sphinxcode{\sphinxupquote{B\_N}} and the friction condition by a multiplier \sphinxcode{\sphinxupquote{multname\_t}} whose
size should be the number of rows of \sphinxcode{\sphinxupquote{B\_T}}.
The parameter \sphinxcode{\sphinxupquote{dataname\_friction\_coeff}} describes the friction
coefficient. It could be a scalar or a vector describing the
coefficient on each contact condition.
The augmentation parameter \sphinxcode{\sphinxupquote{r}} should be chosen in a range of acceptable values
(see Getfem user documentation). \sphinxcode{\sphinxupquote{dataname\_gap}} is an
optional parameter representing the initial gap. It can be a single value
or a vector of value. \sphinxcode{\sphinxupquote{dataname\_alpha}} is an optional homogenization
parameter for the augmentation parameter.

The parameter \sphinxtitleref{aug\_version} indicates the augmentation strategy :
1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian,
2 for the symmetric one,
3 for the unsymmetric method based on augmented multipliers and
4 for the unsymmetric method based on augmented multipliers with De Saxce projection.

Note that is possible to change the basic contact matrices \(B_N\) and \(B_T\) by using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{contact\PYGZus{}brick\PYGZus{}set\PYGZus{}BN}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{)}\PYG{p}{;}
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{contact\PYGZus{}brick\PYGZus{}set\PYGZus{}BT}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Frictionless nodal contact with a rigid obstacle brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-nodal-contact-with-a-rigid-obstacle-brick}}\begin{quote}
\begin{description}
\item[{getfem::add\_nodal\_contact\_with\_rigid\_obstacle\_brick}] \leavevmode
(md, mim, varname\_u, multname\_n, dataname\_r, region, obstacle, aug\_version);

\end{description}
\end{quote}

This function adds a direct nodal frictionless contact condition with a rigid obstacle to the model. The condition is applied on the variable \sphinxcode{\sphinxupquote{varname\_u}}
on the boundary corresponding to \sphinxcode{\sphinxupquote{region}}. The rigid obstacle should
be described with the string \sphinxcode{\sphinxupquote{obstacle}} being a signed distance to
the obstacle. This string should be an expression where the coordinates
are ‘x’, ‘y’ in 2D and ‘x’, ‘y’, ‘z’ in 3D. For instance, if the rigid
obstacle correspond to \(z \le 0\), the corresponding signed distance will
be simply ‘z’. \sphinxcode{\sphinxupquote{multname\_n}} should be a fixed size variable whose size is
the number of degrees of freedom on boundary \sphinxcode{\sphinxupquote{region}}. It represents the
contact equivalent nodal forces.
The augmentation parameter \sphinxcode{\sphinxupquote{r}} should be chosen in a
range of acceptable values (close to the Young modulus of the elastic
body, see Getfem user documentation). 1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian, 2 for the symmetric one, 3 for the unsymmetric method based on augmented multipliers.


\subsection{Nodal contact with a rigid obstacle brick with friction}
\label{\detokenize{userdoc/model_contact_friction:nodal-contact-with-a-rigid-obstacle-brick-with-friction}}\begin{quote}
\begin{description}
\item[{getfem::add\_nodal\_contact\_with\_rigid\_obstacle\_brick}] \leavevmode
(md, mim, varname\_u, multname\_n, multname\_t, dataname\_r,
dataname\_friction\_coeff, region, obstacle, aug\_version);

\end{description}
\end{quote}

This function adds a direct nodal contact with friction condition with a rigid
obstacle to the model. The condition is applied on the variable \sphinxcode{\sphinxupquote{varname\_u}}
on the boundary corresponding to \sphinxcode{\sphinxupquote{region}}. The rigid obstacle should
be described with the string \sphinxcode{\sphinxupquote{obstacle}} being a signed distance to
the obstacle. This string should be an expression where the coordinates
are ‘x’, ‘y’ in 2D and ‘x’, ‘y’, ‘z’ in 3D. For instance, if the rigid
obstacle correspond to \(z \le 0\), the corresponding signed distance will
be simply ‘z’. \sphinxcode{\sphinxupquote{multname\_n}} should be a fixed size variable whose size is
the number of degrees of freedom on boundary \sphinxcode{\sphinxupquote{region}}. It represents the
contact equivalent nodal forces.
\sphinxcode{\sphinxupquote{multname\_t}} should be a fixed size variable whose size is
the number of degrees of freedom on boundary \sphinxcode{\sphinxupquote{region}} multiplied by
\(d-1\) where \(d\) is the domain dimension. It represents the
friction equivalent nodal forces.
The augmentation parameter \sphinxcode{\sphinxupquote{r}} should be chosen in a
range of acceptable values (close to the Young modulus of the elastic
body, see Getfem user documentation). \sphinxcode{\sphinxupquote{dataname\_friction\_coeff}} is
the friction coefficient. It could be a scalar or a vector of values
representing the friction coefficient on each contact node.

The parameter \sphinxtitleref{aug\_version} indicates the augmentation strategy :
1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian,
2 for the symmetric one,
3 for the unsymmetric method based on augmented multipliers and
4 for the unsymmetric method based on augmented multipliers with De Saxce projection.


\subsection{Frictionless nodal contact between non\sphinxhyphen{}matching meshes brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-nodal-contact-between-non-matching-meshes-brick}}\begin{quote}
\begin{description}
\item[{getfem::add\_nodal\_contact\_between\_nonmatching\_meshes\_brick}] \leavevmode
(md, mim1, mim2, varname\_u1, varname\_u2, multname\_n, dataname\_r,
rg1, rg2, slave1=true, slave2=false, aug\_version=1);

\end{description}
\end{quote}

This function adds a frictionless contact condition between two faces of one
or two elastic bodies. The condition is applied on the variable \sphinxtitleref{varname\_u} or
the variables \sphinxtitleref{varname\_u1} and \sphinxtitleref{varname\_u2} depending if a single or
two distinct displacement fields are given. Vectors \sphinxtitleref{rg1} and \sphinxtitleref{rg2}
contain pairs of regions expected to come in contact with each other. In
case of a single region per side, \sphinxtitleref{rg1} and \sphinxtitleref{rg2} can be given as normal
integers. In the single displacement variable case the regions defined in
both \sphinxtitleref{rg1} and \sphinxtitleref{rg2} refer to the variable \sphinxtitleref{varname\_u}. In the case of
two displacement variables, \sphinxtitleref{rg1} refers to \sphinxtitleref{varname\_u1} and \sphinxtitleref{rg2} refers
to \sphinxtitleref{varname\_u2}. \sphinxtitleref{multname\_n} should be a fixed size variable whose size
is the number of degrees of freedom on those regions among the ones
defined in \sphinxtitleref{rg1} and \sphinxtitleref{rg2} which are characterized as “slaves”. It
represents the contact equivalent nodal forces. The augmentation
parameter \sphinxtitleref{r} should be chosen in a range of acceptable values (close to
the Young modulus of the elastic body, see Getfem user documentation).
The optional parameters \sphinxtitleref{slave1} and \sphinxtitleref{slave2} declare if the regions
defined in \sphinxtitleref{rg1} and \sphinxtitleref{rg2} are correspondingly considered as “slaves”.
By default \sphinxtitleref{slave1} is true and \sphinxtitleref{slave2} is false, i.e. \sphinxtitleref{rg1} contains
the slave surfaces, while \sphinxtitleref{rg2} the master surfaces. Preferably only
one of \sphinxtitleref{slave1} and \sphinxtitleref{slave2} is set to true.

The parameter \sphinxtitleref{aug\_version} indicates the augmentation strategy :
1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian,
2 for the symmetric one,
3 for the unsymmetric method with augmented multiplier.

Basically, this brick computes the matrix \(B_N\) and the vectors
gap and alpha and calls the basic contact brick.


\subsection{Nodal contact between non\sphinxhyphen{}matching meshes brick with friction}
\label{\detokenize{userdoc/model_contact_friction:nodal-contact-between-non-matching-meshes-brick-with-friction}}\begin{quote}
\begin{description}
\item[{getfem::add\_nodal\_contact\_between\_nonmatching\_meshes\_brick}] \leavevmode\begin{description}
\item[{(md, mim1, mim2, varname\_u1, varname\_u2, multname\_n, multname\_t,}] \leavevmode
dataname\_r, dataname\_friction\_coeff, rg1, rg2, slave1=true,
slave2=false, aug\_version=1);

\end{description}

\end{description}
\end{quote}

This function adds a contact with friction condition between two faces of
one or two elastic bodies. The condition is applied on the variable
\sphinxtitleref{varname\_u} or the variables \sphinxtitleref{varname\_u1} and \sphinxtitleref{varname\_u2} depending if a
single or two distinct displacement fields are given. Vectors \sphinxtitleref{rg1} and \sphinxtitleref{rg2}
contain pairs of regions expected to come in contact with each other. In
case of a single region per side, \sphinxtitleref{rg1} and \sphinxtitleref{rg2} can be given as normal
integers. In the single displacement variable case the regions defined in
both \sphinxtitleref{rg1} and \sphinxtitleref{rg2} refer to the variable \sphinxtitleref{varname\_u}. In the case of
two displacement variables, \sphinxtitleref{rg1} refers to \sphinxtitleref{varname\_u1} and \sphinxtitleref{rg2} refers
to \sphinxtitleref{varname\_u2}. \sphinxtitleref{multname\_n} should be a fixed size variable whose size
is the number of degrees of freedom on those regions among the ones
defined in \sphinxtitleref{rg1} and \sphinxtitleref{rg2} which are characterized as “slaves”. It
represents the contact equivalent nodal normal forces. \sphinxtitleref{multname\_t}
should be a fixed size variable whose size corresponds to the size of
\sphinxtitleref{multname\_n} multiplied by qdim \sphinxhyphen{} 1 . It represents the contact
equivalent nodal tangent (frictional) forces. The augmentation parameter
\sphinxtitleref{r} should be chosen in a range of acceptable values (close to the Young
modulus of the elastic body, see Getfem user documentation). The friction
coefficient stored in the parameter \sphinxtitleref{friction\_coeff} is either a single
value or a vector of the same size as \sphinxtitleref{multname\_n}. The optional
parameters \sphinxtitleref{slave1} and \sphinxtitleref{slave2} declare if the regions defined in \sphinxtitleref{rg1}
and \sphinxtitleref{rg2} are correspondingly considered as “slaves”. By default \sphinxtitleref{slave1}
is true and \sphinxtitleref{slave2} is false, i.e. \sphinxtitleref{rg1} contains the slave surfaces,
while \sphinxtitleref{rg2} the master surfaces. Preferably only one of \sphinxtitleref{slave1} and
\sphinxtitleref{slave2} is set to true.

The parameter \sphinxtitleref{aug\_version} indicates the augmentation strategy :
1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian,
2 for the symmetric one,
3 for the unsymmetric method with augmented multiplier and
4 for the unsymmetric method with augmented multiplier and De Saxce projection.

Basically, this brick computes the matrices \(B_N\) and \(B_T\)
as well the vectors gap and alpha and calls the basic contact brick.


\subsection{Hughes stabilized frictionless contact condition}
\label{\detokenize{userdoc/model_contact_friction:hughes-stabilized-frictionless-contact-condition}}
In order to add a Hughes stabilized frictionless contact brick you call the model object method:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}Hughes\PYGZus{}stab\PYGZus{}basic\PYGZus{}contact\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u}\PYG{p}{,} \PYG{n}{multname\PYGZus{}n}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,} \PYG{n}{BN}\PYG{p}{,} \PYG{n}{DN}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}gap}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}alpha}\PYG{p}{,} \PYG{n}{aug\PYGZus{}version}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a Hughes stabilized frictionless contact brick on \sphinxcode{\sphinxupquote{varname\_u}} thanks to a multiplier variable \sphinxcode{\sphinxupquote{multname\_n}}. If we take \(U\) is the vector of degrees of freedom on which the unilateral constraint is applied, and \(\lambda\) the multiplier Vector of contact force. Then Hughes stabilized frictionless contact condition is defined by the matrix \(B_N\) and \(D_N\) have to be such that this condition is defined by \(B_N U - D_N \lambda \le 0\). Where \(D_N\) is the mass matrix relative to stabilized term. The variable \sphinxcode{\sphinxupquote{dataname\_r}} is the name of the augmentation parameter \(r\) should be chosen in a range of acceptable values. \sphinxcode{\sphinxupquote{dataname\_gap}} is an optional parameter representing the initial gap. It can be a single value or a vector of value. \sphinxcode{\sphinxupquote{dataname\_alpha}} is an optional homogenization parameter for the augmentation parameter.

The parameter \sphinxtitleref{aug\_version} indicates the augmentation strategy :  1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier augmented Lagrangian, 2 for the symmetric one, 3 for the unsymmetric method based on augmented multipliers.

Note that the matrix \(D_N\) is a sum of the basic contact term and the Hughes stabilised term. You can change it with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{contact\PYGZus{}brick\PYGZus{}set\PYGZus{}DN}\PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{indbrick}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}


\subsection{Frictionless integral contact with a rigid obstacle brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-integral-contact-with-a-rigid-obstacle-brick}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}integral\PYGZus{}contact\PYGZus{}with\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u}\PYG{p}{,} \PYG{n}{multname\PYGZus{}n}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}obs}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a frictionless contact condition with a rigid obstacle
to the model, which is defined in an integral way. It is the direct
approximation of an augmented Lagrangian formulation defined at the
continuous level. The advantage should be a better scalability:
the number of
Newton iterations should be more or less independent of the mesh size.
The condition is applied on the variable \sphinxcode{\sphinxupquote{varname\_u}}
on the boundary corresponding to \sphinxcode{\sphinxupquote{region}}. The rigid obstacle should
be described with the data \sphinxcode{\sphinxupquote{dataname\_obstacle}} being a signed distance to
the obstacle (interpolated on a finite element method).
\sphinxcode{\sphinxupquote{multname\_n}} should be a fem variable representing the contact stress.
An inf\sphinxhyphen{}sup condition between \sphinxcode{\sphinxupquote{multname\_n}} and \sphinxcode{\sphinxupquote{varname\_u}} is required.
The augmentation parameter \sphinxcode{\sphinxupquote{dataname\_r}} should be chosen in a
range of acceptable values.

Possible values for \sphinxtitleref{option} is 1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier
augmented Lagrangian method, 2 for the symmetric one, 3 for the
non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier method with an additional augmentation
and 4 for a new unsymmetric method. The default value is 1.

\sphinxcode{\sphinxupquote{mim}} represents of course the integration method. Note that it should
be accurate enough to integrate efficiently the nonlinear terms involved.


\subsection{Integral contact with a rigid obstacle brick with friction}
\label{\detokenize{userdoc/model_contact_friction:integral-contact-with-a-rigid-obstacle-brick-with-friction}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}integral\PYGZus{}contact\PYGZus{}with\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u}\PYG{p}{,} \PYG{n}{multname\PYGZus{}n}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}obs}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,}
     \PYG{n}{dataname\PYGZus{}friction\PYGZus{}coeffs}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}alpha} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
     \PYG{n}{dataname\PYGZus{}wt} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}gamma} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}vt} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a contact with friction condition with a rigid obstacle
to the model, which is defined in an integral way. It is the direct
approximation of an augmented Lagrangian formulation defined at the
continuous level.
The advantage should be a better scalability: the number of Newton
iterations should be more or less independent of the mesh size.
The condition is applied on the variable \sphinxcode{\sphinxupquote{varname\_u}}
on the boundary corresponding to \sphinxcode{\sphinxupquote{region}}. The rigid obstacle should
be described with the data \sphinxcode{\sphinxupquote{dataname\_obstacle}} being a signed distance to
the obstacle (interpolated on a finite element method).
\sphinxcode{\sphinxupquote{multname\_n}} should be a fem variable representing the contact stress.
An inf\sphinxhyphen{}sup condition between \sphinxcode{\sphinxupquote{multname\_n}} and \sphinxcode{\sphinxupquote{varname\_u}} is required.
The augmentation parameter \sphinxcode{\sphinxupquote{dataname\_r}} should be chosen in a
range of acceptable values.

The parameter \sphinxtitleref{dataname\_friction\_coeffs} contains the Coulomb friction
coefficient and optionally an adhesional shear stress threshold and the
tresca limit shear stress. For constant coefficients its size is from
1 to 3. For coefficients described on a finite element method, this
vector contains a number of single values, value pairs or triplets
equal to the number of the corresponding mesh\_fem’s basic dofs.

Possible values for \sphinxtitleref{option} is 1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier
augmented Lagrangian method, 2 for the symmetric one, 3 for the
non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier method with an additional augmentation
and 4 for a new unsymmetric method. The default value is 1.
Option 4, assumes pure Coulomb friction and ignores any adhesional stress
and tresca limit coefficients.

\sphinxcode{\sphinxupquote{dataname\_alpha}} and \sphinxcode{\sphinxupquote{dataname\_wt}} are optional parameters to solve
evolutionary friction problems. \sphinxcode{\sphinxupquote{dataname\_gamma}} and \sphinxcode{\sphinxupquote{dataname\_vt}} denote
optional data for adding a parameter\sphinxhyphen{}dependent sliding velocity to the friction
condition. \sphinxcode{\sphinxupquote{mim}} represents of course the integration method. Note that it
should be accurate enough to integrate efficiently the nonlinear terms involved.


\subsection{Frictionless integral contact between non\sphinxhyphen{}matching meshes brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-integral-contact-between-non-matching-meshes-brick}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}integral\PYGZus{}contact\PYGZus{}between\PYGZus{}nonmatching\PYGZus{}meshes\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u1}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u2}\PYG{p}{,} \PYG{n}{multname\PYGZus{}n}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,}
     \PYG{n}{region1}\PYG{p}{,} \PYG{n}{region2}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a frictionless contact condition between nonmatching meshes
to the model, which is defined in an integral way. It is the direct
approximation of an augmented Lagrangian formulation defined at the
continuous level.
The advantage should be a better scalability: the number of Newton
iterations should be more or less independent of the mesh size.
The condition is applied on the variables \sphinxcode{\sphinxupquote{varname\_u1}} and
\sphinxcode{\sphinxupquote{varname\_u2}} on the boundaries corresponding to \sphinxcode{\sphinxupquote{region1}} and
\sphinxcode{\sphinxupquote{region2}}.
\sphinxcode{\sphinxupquote{multname\_n}} should be a fem variable representing the contact stress.
An inf\sphinxhyphen{}sup condition between \sphinxcode{\sphinxupquote{multname\_n}} and \sphinxcode{\sphinxupquote{varname\_u1}} and
\sphinxcode{\sphinxupquote{varname\_u2}} is required.
The augmentation parameter \sphinxcode{\sphinxupquote{dataname\_r}} should be chosen in a
range of acceptable values.

Possible values for \sphinxtitleref{option} is 1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier
augmented Lagrangian method, 2 for the symmetric one, 3 for the
non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier method with an additional augmentation
and 4 for a new unsymmetric method. The default value is 1.

\sphinxcode{\sphinxupquote{mim}} represents of course the integration method. Note that it should
be accurate enough to integrate efficiently the nonlinear terms involved.


\subsection{Integral contact between non\sphinxhyphen{}matching meshes brick with friction}
\label{\detokenize{userdoc/model_contact_friction:integral-contact-between-non-matching-meshes-brick-with-friction}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}integral\PYGZus{}contact\PYGZus{}between\PYGZus{}nonmatching\PYGZus{}meshes\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u1}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u2}\PYG{p}{,} \PYG{n}{multname}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,}
     \PYG{n}{dataname\PYGZus{}friction\PYGZus{}coeffs}\PYG{p}{,} \PYG{n}{region1}\PYG{p}{,} \PYG{n}{region2}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,}
     \PYG{n}{dataname\PYGZus{}alpha} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}wt1} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}wt2} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a contact with friction condition between nonmatching meshes
to the model. This brick adds a contact which is defined in an integral way.
It is the direct approximation of an augmented Lagrangian formulation
defined at the continuous level. The advantage should be a better scalability:
the number of Newton iterations should be more or less independent of the mesh size.
The condition is applied on the variables \sphinxcode{\sphinxupquote{varname\_u1}} and \sphinxcode{\sphinxupquote{varname\_u2}}
on the boundaries corresponding to \sphinxcode{\sphinxupquote{region1}} and \sphinxcode{\sphinxupquote{region2}}.
\sphinxcode{\sphinxupquote{multname}} should be a fem variable representing the contact and friction stress.
An inf\sphinxhyphen{}sup condition between \sphinxcode{\sphinxupquote{multname}} and \sphinxcode{\sphinxupquote{varname\_u1}} and
\sphinxcode{\sphinxupquote{varname\_u2}} is required.
The augmentation parameter \sphinxcode{\sphinxupquote{dataname\_r}} should be chosen in a
range of acceptable values.

The parameter \sphinxtitleref{dataname\_friction\_coeffs} contains the Coulomb friction
coefficient and optionally an adhesional shear stress threshold and the
tresca limit shear stress. For constant coefficients its size is from
1 to 3. For coefficients described on a finite element method on the
same mesh as \sphinxcode{\sphinxupquote{varname\_u1}}, this vector contains a number of single values,
value pairs or triplets equal to the number of the corresponding mesh\_fem’s
basic dofs.

Possible values for \sphinxtitleref{option} is 1 for the non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier
augmented Lagrangian method, 2 for the symmetric one, 3 for the
non\sphinxhyphen{}symmetric Alart\sphinxhyphen{}Curnier method with an additional augmentation
and 4 for a new unsymmetric method. The default value is 1.
\sphinxcode{\sphinxupquote{dataname\_alpha}}, \sphinxcode{\sphinxupquote{dataname\_wt1}} and \sphinxcode{\sphinxupquote{dataname\_wt2}} are optional
parameters to solve evolutionary friction problems.
\sphinxcode{\sphinxupquote{mim}} represents the integration method on the same mesh as \sphinxcode{\sphinxupquote{varname\_u1}}.
Note that it should be accurate enough to integrate efficiently the nonlinear
terms involved.


\subsection{Frictionless penalized contact with a rigid obstacle brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-penalized-contact-with-a-rigid-obstacle-brick}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}penalized\PYGZus{}contact\PYGZus{}with\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}obs}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,} \PYG{n}{region}\PYG{p}{,}
     \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}lambda\PYGZus{}n} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a frictionless penalized contact condition
with a rigid obstacle to the model.
The condition is applied on the variable \sphinxcode{\sphinxupquote{varname\_u}}
on the boundary corresponding to \sphinxcode{\sphinxupquote{region}}. The rigid obstacle should
be described with the data \sphinxcode{\sphinxupquote{dataname\_obstacle}} being a signed distance to
the obstacle (interpolated on a finite element method).
The penalization parameter \sphinxcode{\sphinxupquote{dataname\_r}} should be chosen
large enough to prescribe an approximate non\sphinxhyphen{}penetration condition
but not too large not to deteriorate too much the conditioning of
the tangent system. \sphinxcode{\sphinxupquote{dataname\_n}} is an optional parameter used if option
is 2. In that case, the penalization term is shifted by \sphinxcode{\sphinxupquote{lambda\_n}} (this
allows the use of an Uzawa algorithm on the corresponding augmented
dLagrangian formulation)


\subsection{Penalized contact with a rigid obstacle brick with friction}
\label{\detokenize{userdoc/model_contact_friction:penalized-contact-with-a-rigid-obstacle-brick-with-friction}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}penalized\PYGZus{}contact\PYGZus{}with\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}obs}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}friction\PYGZus{}coeffs}\PYG{p}{,}
     \PYG{n}{region}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}lambda} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}alpha} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
     \PYG{n}{dataname\PYGZus{}wt} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a penalized contact condition with Coulomb friction with a
rigid obstacle to the model.
The condition is applied on the variable \sphinxcode{\sphinxupquote{varname\_u}}
on the boundary corresponding to \sphinxcode{\sphinxupquote{region}}. The rigid obstacle should
be described with the data \sphinxtitleref{dataname\_obstacle} being a signed distance to
the obstacle (interpolated on a finite element method).

The parameter \sphinxtitleref{dataname\_friction\_coeffs} contains the Coulomb friction
coefficient and optionally an adhesional shear stress threshold and the
tresca limit shear stress. For constant coefficients its size is from
1 to 3. For coefficients described on a finite element method, this
vector contains a number of single values, value pairs or triplets
equal to the number of the corresponding mesh\_fem’s basic dofs.

The penalization parameter \sphinxcode{\sphinxupquote{dataname\_r}} should be chosen
large enough to prescribe approximate non\sphinxhyphen{}penetration and friction
conditions but not too large not to deteriorate too much the
conditioning of the tangent system.
\sphinxcode{\sphinxupquote{dataname\_lambda}} is an optional parameter used if \sphinxcode{\sphinxupquote{option}}
is 2. In that case, the penalization term is shifted by \sphinxcode{\sphinxupquote{lambda}} (this
allows the use of an Uzawa algorithm on the corresponding augmented
Lagrangian formulation).
\sphinxcode{\sphinxupquote{dataname\_alpha}} and \sphinxcode{\sphinxupquote{dataname\_wt}} are optional parameters to solve
evolutionary friction problems.


\subsection{Frictionless penalized contact between non\sphinxhyphen{}matching meshes brick}
\label{\detokenize{userdoc/model_contact_friction:frictionless-penalized-contact-between-non-matching-meshes-brick}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}penalized\PYGZus{}contact\PYGZus{}between\PYGZus{}nonmatching\PYGZus{}meshes\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u1}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u2}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,}
     \PYG{n}{region1}\PYG{p}{,} \PYG{n}{region2}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}lambda\PYGZus{}n} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a penalized contact frictionless condition between nonmatching
meshes to the model.
The condition is applied on the variables \sphinxcode{\sphinxupquote{varname\_u1}} and \sphinxcode{\sphinxupquote{varname\_u2}}
on the boundaries corresponding to \sphinxcode{\sphinxupquote{region1\textasciigrave{} and \textasciigrave{}\textasciigrave{}region2\textasciigrave{}.
The penalization parameter \textasciigrave{}\textasciigrave{}dataname\_r}} should be chosen
large enough to prescribe an approximate non\sphinxhyphen{}penetration condition
but not too large not to deteriorate too much the conditionning of
the tangent system. \sphinxcode{\sphinxupquote{dataname\_n}} is an optional parameter used if
option is 2. In that case, the penalization term is shifted by \sphinxcode{\sphinxupquote{lambda\_n}}
(this allows the use of an Uzawa algorithm on the corresponding augmented
Lagrangian formulation)


\subsection{Penalized contact between non\sphinxhyphen{}matching meshes brick with friction}
\label{\detokenize{userdoc/model_contact_friction:penalized-contact-between-non-matching-meshes-brick-with-friction}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}penalized\PYGZus{}contact\PYGZus{}between\PYGZus{}nonmatching\PYGZus{}meshes\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u1}\PYG{p}{,} \PYG{n}{varname\PYGZus{}u2}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}r}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}friction\PYGZus{}coeffs}\PYG{p}{,}
     \PYG{n}{region1}\PYG{p}{,} \PYG{n}{region2}\PYG{p}{,} \PYG{n}{option} \PYG{o}{=} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}lambda} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
     \PYG{n}{dataname\PYGZus{}alpha} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}wt1} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{dataname\PYGZus{}wt2} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This function adds a penalized contact condition with Coulomb friction between
nonmatching meshes to the model.
The condition is applied on the variables \sphinxcode{\sphinxupquote{varname\_u1}} and \sphinxcode{\sphinxupquote{varname\_u2}}
on the boundaries corresponding to \sphinxcode{\sphinxupquote{region1\textasciigrave{} and \textasciigrave{}\textasciigrave{}region2\textasciigrave{}.
The penalization parameter \textasciigrave{}\textasciigrave{}dataname\_r}} should be chosen
large enough to prescribe an approximate non\sphinxhyphen{}penetration condition
but not too large not to deteriorate too much the conditionning of
the tangent system.

The parameter \sphinxtitleref{dataname\_friction\_coeffs} contains the Coulomb friction
coefficient and optionally an adhesional shear stress threshold and the
tresca limit shear stress. For constant coefficients its size is from
1 to 3. For coefficients described on a finite element method on the
same mesh as \sphinxtitleref{varname\_u1}, this vector contains a number of single
values, value pairs or triplets equal to the number of the
corresponding mesh\_fem’s basic dofs.

\sphinxcode{\sphinxupquote{dataname\_lambda}} is an optional parameter used if \sphinxcode{\sphinxupquote{option}} is 2.
In that case, the penalization term is shifted by \sphinxcode{\sphinxupquote{lambda}}
(this allows the use of an Uzawa algorithm on the corresponding augmented
Lagrangian formulation)
\sphinxcode{\sphinxupquote{dataname\_alpha}}, \sphinxcode{\sphinxupquote{dataname\_wt1}} and \sphinxcode{\sphinxupquote{dataname\_wt2}} are optional
parameters to solve evolutionary friction problems.
\sphinxcode{\sphinxupquote{mim}} represents the integration method on the same mesh as \sphinxcode{\sphinxupquote{varname\_u1}}.
Note that it should be accurate enough to integrate efficiently the nonlinear
terms involved.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\section{Large sliding/large deformation contact with friction bricks}
\label{\detokenize{userdoc/model_contact_friction_large_sliding:large-sliding-large-deformation-contact-with-friction-bricks}}\label{\detokenize{userdoc/model_contact_friction_large_sliding:ud-model-contact-friction-large}}\label{\detokenize{userdoc/model_contact_friction_large_sliding:index-0}}\label{\detokenize{userdoc/model_contact_friction_large_sliding::doc}}
The basic tools to deal with large sliding/large deformation contact of deformable structures are accessible in GWFL (the generic weak form language). Some interpolate transformations (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-transf}]{\sphinxcrossref{\DUrole{std,std-ref}{Interpolate transformations}}}}) are defined to perform the contact detection and allow to integrate from a contacct bondary to the opposite contact boundary. Some other useful tools such as the unit normal vector in the real configuration and projections to take into account contact with Coulomb friction are also defined as operators in GWFL.

Of course, the computational cost of large sliding/large deformation contact algorithms is greatly higher than small sliding\sphinxhyphen{}small deformation ones.


\subsection{Raytracing interpolate transformation}
\label{\detokenize{userdoc/model_contact_friction_large_sliding:raytracing-interpolate-transformation}}\label{\detokenize{userdoc/model_contact_friction_large_sliding:ud-model-contact-friction-raytrace-inter-trans}}
In order to incorporate the contact detection in the high\sphinxhyphen{}level generic assembly, a specific interpolate transformation has been defined (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-transf}]{\sphinxcrossref{\DUrole{std,std-ref}{Interpolate transformations}}}} for more explanations on interpolate transformations). It is based on a raytracing contact detection has described in \sphinxcite{biblio:ko-re2014} and uses the criteria described below. The interpolate transformation stores the different potential contact surfaces. On most of methods, potential contact surface are classified into two categories: master and slave surface (see  {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-fig-masterslave}]{\sphinxcrossref{\DUrole{std,std-ref}{figure}}}}).

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.45]{{getfemusermodelmasterslave}.png}
\end{figure}

The slave surface is the “contactor” and the master one the “target”. Rigid obstacle are also considered. They are always master surfaces.  The basic rule is that the contact is considered between a slave surface and a master one. However, the multi\sphinxhyphen{}contact frame object and the \sphinxstyleemphasis{GetFEM} bricks allow multi\sphinxhyphen{}contact situations, including contact between two master surfaces, self\sphinxhyphen{}contact of a master surface and an arbitrary number of slave and master surfaces.

Basically, in order to detect the contact pairs, Gauss points or f.e.m. nodes of slave surfaces are projected on master surfaces (see  {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-fig-masterslave}]{\sphinxcrossref{\DUrole{std,std-ref}{figure}}}}). If self\sphinxhyphen{}contact is considered, Gauss points or f.e.m. nodes of master surface are also projected on master surfaces.

The addition of a raytracing transformation to a model:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kt}{void} \PYG{n}{add\PYGZus{}raytracing\PYGZus{}transformation}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{transname}\PYG{p}{,}
                                    \PYG{n}{scalar\PYGZus{}type} \PYG{n}{d}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{transname}} is a name given to the transformation which allows to refer to it in GWFL and \sphinxcode{\sphinxupquote{d}} is the release distance (see above).

The raytracing transformation is added without any slave or master contact boundary. The following functions allows to add some boundaries to the transformation:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}master\PYGZus{}contact\PYGZus{}boundary\PYGZus{}to\PYGZus{}raytracing\PYGZus{}transformation}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,}
           \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{transname}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh} \PYG{o}{\PYGZam{}}\PYG{n}{m}\PYG{p}{,}
           \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dispname}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{)}

\PYG{n}{add\PYGZus{}slave\PYGZus{}contact\PYGZus{}boundary\PYGZus{}to\PYGZus{}raytracing\PYGZus{}transformation}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,}
           \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{transname}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh} \PYG{o}{\PYGZam{}}\PYG{n}{m}\PYG{p}{,}
           \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dispname}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{dispname}} is the variable name which represent the displacement on that contact
boundary. The difference between master and slave contact boundary is that the contact detection is to be performed starting from a slave or master boundary toward a master boundary. The contact detection is not performed toward a slave boundary. Consequently, only the influence boxes of the elements of the master surfaces are computed and stored.

It is also possible to add a rigid obstacle (considered as a master surface) thanks to the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}to\PYGZus{}raytracing\PYGZus{}transformation}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,}
           \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{transname}\PYG{p}{,}
           \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{expr}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{N}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{expr}} is the expression of a signed distance to the obstacle using the syntax of GWFL (\sphinxcode{\sphinxupquote{X}} being the current position, \sphinxcode{\sphinxupquote{X(0)}}, \sphinxcode{\sphinxupquote{X(1)}} … the corresponding components). For instance an expression \sphinxcode{\sphinxupquote{X(0) + 5}} will correspond to a flat obstacle lying on the right of the position \sphinxcode{\sphinxupquote{\sphinxhyphen{}5}} of the first coordinate. Be aware that the expression have to be close to a signed distance, which in particular means that the gradient norm have to be close to 1.

In order to distinguish between non\sphinxhyphen{}contact situations and the occurence of a contact with another deformable body or with a rigid obstacle, the transformation returns an integer identifier which can be used by the \sphinxtitleref{Interpolate\_filter} command of GWFL (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high-transf}]{\sphinxcrossref{\DUrole{std,std-ref}{Interpolate transformations}}}}). The different values:
\begin{itemize}
\item {} 
0 : no contact found on this Gauss point

\item {} 
1 : contact occurs on this Gauss point with a deformable body

\item {} 
2 : contact occurs on this Gauss point with a rigid obstacle.

\end{itemize}

such that it is possible to differentiate the treatment of these three cases using:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{Interpolate\PYGZus{}filter}\PYG{p}{(}\PYG{n}{transname}\PYG{p}{,} \PYG{n}{expr1}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{)}
\PYG{n}{Interpolate\PYGZus{}filter}\PYG{p}{(}\PYG{n}{transname}\PYG{p}{,} \PYG{n}{expr2}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{Interpolate\PYGZus{}filter}\PYG{p}{(}\PYG{n}{transname}\PYG{p}{,} \PYG{n}{expr3}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{)}
\end{sphinxVerbatim}

in GWFL, where \sphinxcode{\sphinxupquote{expr1}}, \sphinxcode{\sphinxupquote{expr2}} and \sphinxcode{\sphinxupquote{expr3}} correspond to the different terms to be computed. The matlab interface demo program \sphinxcode{\sphinxupquote{/interface/tests/matlab/demo\_large\_sliding\_contact.m}} presents an example of use.

Note that the transformation could also be directly used with a \sphinxtitleref{ga\_workspace} object if model object are not used. See \sphinxcode{\sphinxupquote{getfem/getfem\_contact\_and\_friction\_common.h}} for more details. Note also that in the framework of the model object, a interfaced use of this transformation is allowed by the model bricks described below.


\subsection{The contact pair detection algorithm}
\label{\detokenize{userdoc/model_contact_friction_large_sliding:the-contact-pair-detection-algorithm}}
A contact pair is formed by a point of a slave (or master in case of self\sphinxhyphen{}contact) surface and a projected point on the nearest master surface (or rigid obstacle). The Algorithm used is summerized in {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-fig-algodetect}]{\sphinxcrossref{\DUrole{std,std-ref}{figure}}}}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{getfemusermodeldetectcontact}.png}
\end{figure}

It is impossible to distinguish without fail between valid and invalid contact situations without a global topological criterion (such as in \sphinxcite{biblio:pantz2008}), a fortiori for self\sphinxhyphen{}contact detection. However, this kind of criterion can be very costly to implement. Thus, one generally implements some simple heuristic criteria which cannot cover all the possible cases. We present such a set of criteria here. They are of course perfectible and subject to change. First, in {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-fig-invalidcontact}]{\sphinxcrossref{\DUrole{std,std-ref}{figure}}}} one can see a certain number of situations of valid or invalid contact that criteria have to distinguish.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{getfemusermodelfalsecontact1}.png}
\end{figure}

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.5]{{getfemusermodelfalsecontact2}.png}
\end{figure}

Some details on the algorithm:
\begin{itemize}
\item {} 
\sphinxstylestrong{Computation of influence boxes.} The influence box of an element is just
an offset to its bounding box at a distance equal to the release distance.
If this strategy is used, the release distance should not be too large
compared to the element size. Otherwise, a point would correspond to a
a large number of influence box which can considerably slow down the search
of contact pairs. The influence boxes are stored in a region tree object
in order to find the boxes containing a point with an algorithm having
a mean complexity in \(O(log(N))\).

\item {} 
\sphinxstylestrong{What is a potential contact pair.} A potential contact pair is a pair
slave point \sphinxhyphen{} master element face which will be investigated.
The projection of the slave point on the master surface will be done
and criteria will be applied.

\item {} 
\sphinxstylestrong{Projection algorithm.} The projection of the slave point onto a
master element face is done by a parametrization of the surface on the
reference element via the geometric transformation and the displacement
field. During the projection, no constraint is applied to remain inside
the element face, which means that the element face is prolongated
analytically. The projection is performed by minimizing the distance
between the slave point and the projected one using the parametrization
and Newton’s and/or BFGS algorithms. If \sphinxcode{\sphinxupquote{raytrace}} is set to true, then
no projection is computed. Instead a ray tracing from the point x in
the direction of the unit normal vector at x to find y. This means
the reverse of the usual situation (x will be the projection of y).

\end{itemize}

The list of criteria:
\begin{itemize}
\item {} 
\sphinxstylestrong{Criterion 1: the unit normal cone/vector should be compatible, and the
two points do not share the same element.}
Two unit normal vector are compatible if their scalar product are
non\sphinxhyphen{}positive. In case of f.e.m. node contact, since a fem node is shared
generally by several elements, a normal cone constituted of the unit normal
vectors of each element is considered. Two normal cones are compatible if
at least one pair of unit normal vector have their scalar product
non\sphinxhyphen{}positive. In order to simplify the computation, a normal cone is
reduced to a mean normal vector if the solid angle of the normal cone is
less than \sphinxcode{\sphinxupquote{cut\_angle}} a parameter of the multi\sphinxhyphen{}contact frame object.
This criterion allows to treat cases (B) and (K1).

\item {} 
\sphinxstylestrong{Criterion 2: the contact pair is eliminated when the search of the
projection/raytrace point do not converge.}
When Newton’s algorithms (and BFGS one for projection) used to compute the
projection/raytrace of the slave point on the master element surface
fails to converge, the pair is not considered. A warning is generated.

\item {} 
\sphinxstylestrong{Criterion 3 : the projected point should be inside the element.}
The slave point is projected on the surface of the master element
without the constraint to remain inside the face
(which means that the face is prolongated). If the orthogonal
projection is outside the face, the pair is not considered. This
is the present state, however, to treat case (J3) an aditional
treatment will have to be considered (projection on the face with
the constraint to remain inside it and test of the normal cone at
this point)
This criterion allows to treat cases (F2), (K2), (M1) and (M2).

\item {} 
\sphinxstylestrong{Criterion 4 : the release distance is applied.}
If the distance between the slave point and its projection on the master
surface is greater than the release distance, the contact pair is not
considered. This can treat cases (C), (E), (F1), (G), (H) if the release
distance is adapted and the deformation not too important.

\item {} 
\sphinxstylestrong{Criterion 5 : comparison with rigid obstacles.}
If the signed distance between the slave point and its projection on
the master surface is greater than the one with a rigid obstacle
(considering that the release distance is also first applied to rigid
obstacle) then the contact pair is not considered.

\item {} 
\sphinxstylestrong{Criterion 6 : for self\sphinxhyphen{}contact only : apply a test on
unit normals in reference configuration.}
In case of self contact, a contact pair is eliminated when the slave point
and the master element belong to the same mesh and if the slave point is
behind the master surface (with respect to its unit outward normal vector)
and not four times farther than the release distance.
This can treat cases (A), (C), (D), (H).

\item {} 
\sphinxstylestrong{Criterion 7 : smallest signed distance on contact pairs.}
Between the retained contact pairs (or rigid obstacle) the one
corresponding to the smallest signed distance is retained.

\end{itemize}


\subsubsection{Nodal contact brick with projection}
\label{\detokenize{userdoc/model_contact_friction_large_sliding:nodal-contact-brick-with-projection}}
Notations: \(\Omega \subset \rm I\hspace{-0.15em}R^d\) denotes the reference configuration of a deformable body, possibly constituted by several unconnected parts (see  {\hyperref[\detokenize{userdoc/model_contact_friction_large_sliding:ud-fig-masterslave}]{\sphinxcrossref{\DUrole{std,std-ref}{figure}}}}). \(\Omega_t\) is the deformed configuration and \(\varphi^h: \Omega \rightarrow \Omega_t\) is the approximated deformation on a finite element space \(V^h\). The displacement  \(u^h: \Omega \rightarrow \rm I\hspace{-0.15em}R^d\) is defined by \(\varphi^h(X) = X + u^h(X)\). A generic point of the reference configuration \(\Omega\) is denoted by \(X\) while the corresponding point of the deformed configuration is denoted by \(x = \varphi^h(X)\). \(\Gamma^S\) denotes a slave boundary of \(\Omega\) and \(\Gamma^M\) a master one. The corresponding boundaries on the deformed configuration are \(\Gamma_t^S\) and \(\Gamma_t^M\), respectively. The outward unit normal vector to the boundary (in the deformed configuration) at a point \(x = \varphi^h(X)\) of that boundary is denoted by \(n_x\). Finally, the notation \(\delta A[B]\) denotes the directional derivative of the quantity \(A\) with respect to the deformation and in the direction \(B\). Similarly, The notation \(\delta^2 A[B,C]\) is the second derivative in the directions  \(B\) and \(C\).

Let \(J(\varphi^h)\) be the potential energy of the system, without taking into account contact and friction contributions. Typically, it includes elastic and external load potential energy. Let \(X_i\) for  \(i \in I_{\text{nodes}}\) the set of finite element nodes on the slave boundary in the reference configuration. Let \(X_i\) for  \(i \in I_{\text{def}}\) be the contact nodes in potential contact with the master surface of a deformable body. Let  \(X_i\) for  \(i \in I_{\text{rig}}\) be the contact nodes in potential contact with a rigid obstacle.

We denote by \(x_i = \varphi^h(X_i)\) the corresponding node on the deformed configuration and \(y_i\) the projection on the master surface (or rigid obstacle) on the deformed configuration. Let \(Y_i\) the point on the master surface verifying \(y_i = \varphi^h(Y_i)\). This allows to define the normal gap as
\begin{equation*}
\begin{split}g_i = n_y . (\varphi^h(X_i) - \varphi^h(Y_i)) = \|\varphi^h(X_i) - \varphi^h(Y_i)\| \text{Sign}(n_y . (\varphi^h(X_i) - \varphi^h(Y_i))),\end{split}
\end{equation*}
where \(n_y\) is the outward unit normal vector of the master surface at \(y\).

Considering only stationnary rigid obstacles and applying the principle of Alart\sphinxhyphen{}Curnier augmented Lagrangian \sphinxcite{biblio:al-cu1991}, the problem with nodal contact with friction condition can be expressed as follows in an unsymmetric version (see \sphinxcite{biblio:renard2013} for the linear elasticity case)
\begin{equation*}
\begin{split}\left\{\begin{array}{l}
\mbox{Find } \varphi^h \in V^h \mbox{ such that } \\
\displaystyle \delta J(\varphi^h)[\delta u^h] - \sum_{i \in I_{\text{def}}} \lambda_i \cdot (\delta u^h(X_i) - \delta u^h(Y_i)) - \sum_{i \in I_{\text{rig}}} \lambda_i \delta u^h(X_i) = 0 ~~~ \forall \delta u^h \in V^h, \\
\displaystyle \dfrac{1}{r} \left[\lambda_i + P_{n_y, {\mathscr F}}(\lambda_i + r\left(g_i n_y - \alpha(\varphi^h(X_i) - \varphi^h(Y_i) - W_T(X_i)+W_T(Y_i)))\right)\right]= 0  ~~\forall i \in I_{\text{def}}, \\[1em]
\displaystyle \dfrac{1}{r} \left[\lambda_i + P_{n_y, {\mathscr F}}(\lambda_i + r\left(g_i n_y - \alpha(\varphi^h(X_i) - W_T(X_i)))\right)\right]= 0  ~~\forall i \in I_{\text{rig}},
\end{array}\right.\end{split}
\end{equation*}
where \(W_T, \alpha, P_{n_y, {\mathscr F}}\) … + tangent system

Sorry, for the moment the brick is not working.


\subsection{Tools of the high\sphinxhyphen{}level generic assembly for contact with friction}
\label{\detokenize{userdoc/model_contact_friction_large_sliding:tools-of-the-high-level-generic-assembly-for-contact-with-friction}}
The following nonlinear operators are defined in GWFL (see {\hyperref[\detokenize{userdoc/gasm_high:ud-gasm-high}]{\sphinxcrossref{\DUrole{std,std-ref}{Compute arbitrary terms \sphinxhyphen{} high\sphinxhyphen{}level generic assembly procedures \sphinxhyphen{} Generic Weak\sphinxhyphen{}Form Language (GWFL)}}}}):
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{Transformed\_unit\_vector(Grad\_u, n)}} where \sphinxcode{\sphinxupquote{Grad\_u}} is the gradient of a
displacement field and \sphinxcode{\sphinxupquote{n}} a unit vector in the reference configuration.
This nonlinear operator corresponds to
\begin{equation*}
\begin{split}n_{trans} = \dfrac{(I+ \nabla u)^{-T} n}{\|(I+\nabla u)^{-T} n\|}\end{split}
\end{equation*}
with the following partial derivatives
\begin{align*}\!\begin{aligned}
\partial_{u} n_{trans}[\delta u] = -(I - n_{trans}\otimes n_{trans})(I+ \nabla u)^{-T}(\nabla \delta u)^T n_{trans}\\
\partial_{n} n_{trans}[\delta n] = \dfrac{(I+ \nabla u)^{-T}\delta n - n_{trans}(n_{trans}\cdot \delta n)}{\|(I+\nabla u)^{-T} n\|}\\
\end{aligned}\end{align*}
\item {} 
\sphinxcode{\sphinxupquote{Coulomb\_friction\_coupled\_projection(lambda, n, Vs, g, f, r)}}
where \sphinxcode{\sphinxupquote{lambda}} is the contact force, \sphinxcode{\sphinxupquote{n}} is a unit normal vector, \sphinxcode{\sphinxupquote{Vs}}
is the sliding velocity, \sphinxcode{\sphinxupquote{g}} is the gap, \sphinxcode{\sphinxupquote{f}} the friction coefficient
and \sphinxcode{\sphinxupquote{r}} a positive augmentation parameter. The expression of the operator is
\begin{align*}\!\begin{aligned}
P(\lambda, n, V_s, g, f, r) = -(\lambda\cdot n + rg)_- n + P_{B(n,\tau)}(\lambda - rV_s)\\
\mbox{with } \tau = \mbox{min}(f_3 + f_1(\lambda\cdot n + rg)_-, f_2)\\
\end{aligned}\end{align*}
where \((\cdot)_-\) is the negative part (\((x)_- = (-x)_+\)) and \(f_1, f_2, f_3\) are the three components of the friction coefficient. Note that the components \(f_2, f_3\) are optional. If a scalar fiction coefficient is given (only \(f_1\)) then this corresponds to the classical Coulomb friction law. If a vector of two components is given  (only \(f_1, f_2\)) then this corresponds to a Coulomb friction with a given threshold. Finally, if a vector of three components is given, the friction law correspongs to the expression of \(\tau\) given above.

The expression \(P_{B(n,\tau)}(q)\) refers to the orthogonal projection (this is link to the return mapping algorithm) on the tangential ball (with respect to \(n\) of radius \(\tau\).

The derivatives can be expressed as follows with \(T_n = (I - n \otimes n)\) and \(q_{_T} = T_n q\):
\begin{align*}\!\begin{aligned}
\partial_q P_{B(n,\tau)}(q) =
\left\{\begin{array}{cl}
0 & \mbox{for } \tau \le 0 \\
\mathbf{T}_n & \mbox{for } \|q_{_T}\| \le \tau \\
\dfrac{\tau}{\|q_{_T}\|}
\left(\mathbf{T}_n - \dfrac{q_{_T}}{\|q_{_T}\|}\otimes \dfrac{q_{_T}}{\|q_{_T}\|}
\right) & \mbox{otherwise }
\end{array} \right.\\
\partial_{\tau} P_{B(n,\tau)}(q) =
\left\{\begin{array}{cl}
0 & \mbox{for } \tau \le 0 \mbox{ or } \|q_{_T}\| \le \tau \\
\dfrac{q_{_T}}{\|q_{_T}\|} & \mbox{otherwise}
\end{array} \right.\\
\partial_n P_{B(n,\tau)}(q) =
\left\{
\begin{array}{cl}
0 & \mbox{for } \tau \le 0 \\
-q \cdot n~\mathbf{T}_n - n \otimes q_{_T}
& \mbox{for } \|q_{_T}\| \le \tau \\
-\dfrac{\tau}{\|q_{_T}\|}
\left( q \cdot n
\left(\mathbf{T}_n - \dfrac{q_{_T}}{\|q_{_T}\|}\otimes \dfrac{q_{_T}}{\|q_{_T}\|}
\right)
+ n \otimes q_{_T}
\right) & \mbox{otherwise.}
\end{array} \right.\\
\partial_{\lambda} P(\lambda, n, V_s, g, f, r) = \partial_q P_{B(n,\tau)}
+\partial_{\tau}P_{B(n,\tau)} \otimes  \partial_{\lambda} \tau
+H(-\lambda\cdot n - r\,g)~n \otimes n,\\
\partial_{n} P(\lambda, n, V_s, g, f, r) =
\left|\begin{array}{l} \partial_n P_{B(n,\tau)}
+\partial_{\tau} P_{B(n,\tau)} \otimes \partial_n \tau \\
\hspace*{3em}+H(-\lambda\cdot n - r\,g) ~
\left(n \otimes \lambda -
(2~\lambda\cdot n + r\,g)~n \otimes n +
(\lambda\cdot n + r\,g)~\mathbf{I}\right),
\end{array}\right.\\
\partial_{g} P(\lambda, n, V_s, g, f, r) =
\partial_{\tau} P_{B(n,\tau)} ~ \partial_g \tau
+H(-\lambda\cdot n - r\,g)~r~n\\
\partial_{f} P(\lambda, n, V_s, g, f, r) =
\partial_{\tau} P_{B(n,\tau)} \partial_{f} \tau\\
\partial_{r} P(\lambda, n, V_s, g, f, r) =
 H(-\lambda\cdot n - r\,g)gn + \partial_q P_{B(n,\tau)}V_s
 +\partial_{\tau} P_{B(n,\tau)} \partial_r \tau\\
\end{aligned}\end{align*}
\end{itemize}


\subsection{Integral contact brick with raytrace}
\label{\detokenize{userdoc/model_contact_friction_large_sliding:integral-contact-brick-with-raytrace}}\label{\detokenize{userdoc/model_contact_friction_large_sliding:ud-model-contact-friction-large-hlgav}}
Add of the brick:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{indbrick} \PYG{o}{=} \PYG{n}{add\PYGZus{}integral\PYGZus{}large\PYGZus{}sliding\PYGZus{}contact\PYGZus{}brick\PYGZus{}raytracing}
  \PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname\PYGZus{}r}\PYG{p}{,}
   \PYG{n}{scalar\PYGZus{}type} \PYG{n}{release\PYGZus{}distance}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname\PYGZus{}friction\PYGZus{}coeff} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{dataname\PYGZus{}alpha} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{1}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

This brick allows to deal with a multi\sphinxhyphen{}contact situation. It adds to the model a raytracing interpolate transformation as described in a previous section whose name can be obtained by the command:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{transformation\PYGZus{}name\PYGZus{}of\PYGZus{}large\PYGZus{}sliding\PYGZus{}contact\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,}
                       \PYG{n}{size\PYGZus{}type} \PYG{n}{indbrick}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Once the brick is added to the model, the master and slave contact boundaries have to be added with the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}contact\PYGZus{}boundary\PYGZus{}to\PYGZus{}large\PYGZus{}sliding\PYGZus{}contact\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,}
    \PYG{n}{size\PYGZus{}type} \PYG{n}{indbrick}\PYG{p}{,} \PYG{k}{const} \PYG{n}{mesh\PYGZus{}im} \PYG{o}{\PYGZam{}}\PYG{n}{mim}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{region}\PYG{p}{,}
    \PYG{k+kt}{bool} \PYG{n}{is\PYGZus{}master}\PYG{p}{,} \PYG{k+kt}{bool} \PYG{n}{is\PYGZus{}slave}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{u}\PYG{p}{,}
    \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{lambda} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{o}{\PYGZam{}}\PYG{n}{w} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
    \PYG{k+kt}{bool} \PYG{n}{frame\PYGZus{}indifferent} \PYG{o}{=} \PYG{n+nb}{false}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{region}} should be a valid mesh region number representing a boundary, \sphinxcode{\sphinxupquote{is\_master}} should be set to \sphinxcode{\sphinxupquote{true}} if the contact detection is to be done on that contact boundary, \sphinxcode{\sphinxupquote{is\_slave}} should be set to \sphinxcode{\sphinxupquote{true}} if the integration of contact terms is to be done on that boundary. Note that a contact boundary is allowed to be both master and slave, in particular to allow self\sphinxhyphen{}contact detection. \sphinxcode{\sphinxupquote{u}} is the displacement variable. If \sphinxcode{\sphinxupquote{is\_slave}} is set to true, \sphinxcode{\sphinxupquote{lambda}} should describe a multiplier variable with degrees of freedom on the contact boundary (typically added to the model with the \sphinxcode{\sphinxupquote{md.add\_filtered\_fem\_variable(...) method). Pure master contact boundary do not need the definition of a multiplier. Additionally, \textasciigrave{}\textasciigrave{}w}} is for the evolutionnary case and represents the displacement at the previous time step.

A rigid obstacle can be added to the brick with:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{add\PYGZus{}rigid\PYGZus{}obstacle\PYGZus{}to\PYGZus{}large\PYGZus{}sliding\PYGZus{}contact\PYGZus{}brick}\PYG{p}{(}\PYG{n}{model} \PYG{o}{\PYGZam{}}\PYG{n}{md}\PYG{p}{,}
    \PYG{n}{size\PYGZus{}type} \PYG{n}{indbrick}\PYG{p}{,} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string} \PYG{n}{expr}\PYG{p}{,} \PYG{n}{size\PYGZus{}type} \PYG{n}{N}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxtitleref{expr} is an expression using GWFL (with \sphinxtitleref{X} is the current position) which should be a signed distance to the obstacle. \sphinxtitleref{N} is the mesh dimension.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\chapter{Numerical continuation and bifurcation}
\label{\detokenize{userdoc/model_continuation:numerical-continuation-and-bifurcation}}\label{\detokenize{userdoc/model_continuation:ud-model-continuation}}\label{\detokenize{userdoc/model_continuation:index-0}}\label{\detokenize{userdoc/model_continuation::doc}}
Let an algebraic problem coming from discretisation of an FEM\sphinxhyphen{}model can be
written in the form
\begin{equation*}
\begin{split}F(U) = 0.\end{split}
\end{equation*}
In what follows, we shall suppose that the model depends on an additional scalar
parameter \(\lambda\) so that \(F(U) = F(U, \lambda)\).


\section{Numerical continuation}
\label{\detokenize{userdoc/model_continuation:numerical-continuation}}
Methods of numerical continuation serve for tracing solutions of the system
\begin{equation*}
\begin{split}F(U, \lambda) = 0, \quad F\colon \mathbb{R}^{N} \times \mathbb{R} \to \mathbb{R}^{N}.\end{split}
\end{equation*}
In \sphinxstyleemphasis{GetFEM}, a continuation technique for piecewise \(C^{1}\) (\(PC^{1}\))
solution curves is implemented (see \sphinxcite{biblio:li-re2014} for more details). Since it
does not make an explicit difference between the state variable \(U\) and
the parameter \(\lambda\), we shall denote \(Y := (U, \lambda)\) for
brevity. Nevertheless, to avoid bad scaling when calculating tangents, for
example, we shall use the following weighted scalar product and norm:
\begin{equation*}
\begin{split}\langle Y, \tilde{Y} \rangle_{w} := \kappa \langle U, \tilde{U} \rangle + \lambda \tilde{\lambda},\quad \lVert Y \rVert_{w} := \sqrt{\kappa \lVert U \rVert^{2} + \lambda^{2}},\qquad Y = (U, \lambda),\, \tilde{Y} = (\tilde{U}, \tilde{\lambda}).\end{split}
\end{equation*}
Here, \(\kappa\) should be chosen so that
\(\kappa \langle U, \tilde{U} \rangle\) is proportional to the scalar
product of the corresponding space variables, usually in \(L^{2}\). One can
take, for example, \(\kappa = h^{d}\), where \(h\) is the mesh size and
\(d\) stands for the dimension of the underlying problem. Alternatively,
\(\kappa\) can be chosen as \(1/N\) for simplicity.

The idea of the continuation strategy is to continue smooth pieces of solution
curves by a classical predictor\sphinxhyphen{}corrector method and to join the smooth pieces
continuously.

The particular predictor\sphinxhyphen{}corrector method employed is a slight modification of
the \sphinxstyleemphasis{inexact Moore\sphinxhyphen{}Penrose} continuation implemented in MATCONT \sphinxcite{biblio:dh-go-ku2003}.
It computes a sequence of consecutive points \(Y_{j}\) lying approximately
on a solution curve and a sequence of the corresponding unit tangent vectors
\(T_{j}\):
\begin{equation*}
\begin{split}\lVert F(Y_{j}) \rVert \leq \varepsilon,\quad F'(Y_{j}; T_{j}) = 0,\quad \lVert T_{j} \rVert_{w} = 1,\quad j = 0, 1,\dotsc.\end{split}
\end{equation*}
To describe it, let us suppose that we have a couple \((Y_{j}, T_{j})\)
satisfying the relations above at our disposal. In the \sphinxstyleemphasis{prediction}, an initial
approximation of \((Y_{j+1}, T_{j+1})\) is taken as
\begin{equation*}
\begin{split}Y_{j+1}^{0} := Y_{j} + h_{j} T_{j},\quad T_{j+1}^{0} := T_{j},\end{split}
\end{equation*}
where \(h_{j}\) is a step size. Its choice will be discussed later on.

In the \sphinxstyleemphasis{correction}, one computes a sequence
\(\{(Y_{j+1}^{l}, T_{j+1}^{l})\}\), where
\(T_{j+1}^{l} := \tilde{T}_{j+1}^{l} / \lVert \tilde{T}_{j+1}^{l} \rVert_{w}\)
and the couple \((Y_{j+1}^{l}, \tilde{T}_{j+1}^{l})\) is given by one
iteration of the Newton method applied to the equation \(F^{l}(Y, T) = 0\)
with
\begin{equation*}
\begin{split}F^{l}(Y, T) := \begin{pmatrix}F(Y)\\ (T_{j+1}^{l-1})^{\top}(Y - Y_{j+1}^{l-1})\\ \nabla F(Y_{j+1}^{l-1})T\\ \langle T_{j+1}^{l-1}, T \rangle_{w} - \langle T_{j+1}^{l-1}, T_{j+1}^{l-1} \rangle_{w}\end{pmatrix}\end{split}
\end{equation*}
and the initial approximation \((Y_{j+1}^{l-1}, T_{j+1}^{l-1})\). Due to the
potential non\sphinxhyphen{}differentiability of \(F\), a piecewise\sphinxhyphen{}smooth variant of the
Newton method is used (Algorithm 7.2.14 in \sphinxcite{biblio:fa-pa2003}).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{getfemusercorrection}.png}
\caption{Correction.}\label{\detokenize{userdoc/model_continuation:id10}}\label{\detokenize{userdoc/model_continuation:ud-fig-correction}}\end{figure}

A couple \((Y_{j+1}^{l}, T_{j+1}^{l})\) is accepted for
\((Y_{j+1}, T_{j+1})\) if
\(\lVert F(Y_{j+1}^{l})\rVert \leq \varepsilon\),
\(\lVert Y_{j+1}^{l} - Y_{j+1}^{l-1}\rVert_{w} \leq \varepsilon'\), and the
cosine of the angle between \(T_{j+1}^{l}\) and \(T_{j}\) is greater or
equal to \(c_{\mathrm{min}}\). Let us note that the partial gradient of
\(F\) (or of one of its selection functions in the case of the
non\sphinxhyphen{}differentiability) with respect to \(U\) is assembled analytically
whereas the partial gradient with respect to \(\lambda\) is evaluated by
forward finite differences with an increment equal to 1e\sphinxhyphen{}8.

The step size \(h_{j+1}\) in the next prediction depends on how the Newton
correction has been successful. Denoting the number of iterations needed by
\(l_{\mathrm{it}}\), it is selected as
\begin{equation*}
\begin{split}h_{j+1} := \begin{cases}\max\{h_{\mathrm{dec}} h_{j}, h_{\mathrm{min}}\}& \text{if no new couple has been accepted},\\ \min\{h_{\mathrm{inc}} h_{j}, h_{\mathrm{max}}\}& \text{if a new couple has been accepted and } l_{\mathrm{it}} < l_{\mathrm{thr}},\\ h_{j}& \text{otherwise},\end{cases}\end{split}
\end{equation*}
where \(0 < h_{\mathrm{dec}} < 1 < h_{\mathrm{inc}}\),
\(0 < l_{\mathrm{thr}}\) and
\(0 < h_{\mathrm{min}} < h_{\mathrm{max}}\) are given constants. At the
beginning, one sets \(h_{1} := h_{\mathrm{init}}\) for some
\(h_{\mathrm{min}} \leq h_{\mathrm{init}} \leq h_{\mathrm{max}}\).

Now, let us suppose that we have approximated a piece of a solution curve
corresponding to one sub\sphinxhyphen{}domain of smooth behaviour of \(F\) and we want to
recover a piece corresponding to another sub\sphinxhyphen{}domain of smooth behaviour. Let
\((Y_{j},T_{j})\) be the last computed couple.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{getfemusertransition}.png}
\caption{Transition between smooth pieces of a solution curve.}\label{\detokenize{userdoc/model_continuation:id11}}\label{\detokenize{userdoc/model_continuation:ud-fig-transition}}\end{figure}

To approximate the tangent to the other smooth piece, we first take a point
\(Y_{j} + h T_{j}\) with \(h\) a bit greater than
\(h_{\mathrm{min}}\) so that this point belongs to the interior of the other
sub\sphinxhyphen{}domain of smooth behaviour. Then we find \(\tilde{T}\) such that
\begin{equation*}
\begin{split}\nabla F(Y_{j} + h T_{j}) \tilde{T} = 0,\quad \lVert \tilde{T} \rVert_{w} = 1,\end{split}
\end{equation*}
and it remains to determine an appropriate direction of this vector. This can be
done on the basis of the following observations:  First, there exists
\(r \in \{\pm 1\}\) such that \(Y_{j} - r \tilde{h} \tilde{T}\) remains
in the same sub\sphinxhyphen{}domain as \(Y_{j}\) for any \(\tilde{h}\) positive.
This is characterised by the fact that
\(\frac{\lvert T_{-}^{\top} \tilde{T}\rvert}{\lVert T_{-} \rVert \lVert \tilde{T} \rVert}\)
is significantly smaller than 1 for \(T_{-}\) with
\(\nabla F(Y_{j} - r \tilde{h} \tilde{T}) T_{-} = 0\). Second,
\(Y_{j} + r \tilde{h} \tilde{T}\) appears in the other sub\sphinxhyphen{}domain for
\(\tilde{h}\) larger than some positive threshold, and, for such values,
\(\frac{\lvert T_{+}^{\top} \tilde{T}\rvert}{\lVert T_{+} \rVert \lVert \tilde{T} \rVert}\)
is close to 1 for \(T_{+}\) with
\(\nabla F(Y_{j} + r \tilde{h} \tilde{T}) T_{+} = 0\).

This suggests the following procedure for selecting the desired direction of
\(\tilde{T}\): Increase the values of \(\tilde{h}\) successively from
\(h_{\mathrm{min}}\), and when you arrive at \(\tilde{h}\) and
\(r \in \{\pm 1\}\) such that
\begin{equation*}
\begin{split}\frac{\lvert T^{\top} \tilde{T}\rvert}{\lVert T \rVert \lVert \tilde{T} \rVert} \approx 1\quad \text{if}\ \nabla F(Y_{j} + r \tilde{h} \tilde{T}) T = 0,\end{split}
\end{equation*}
take \(r \tilde{T}\) as the approximation of the tangent to the other smooth
piece.

Having this approximation at our disposal, we restart the predictor\sphinxhyphen{}corrector
with \((Y_{j}, r \tilde{T})\).

In \sphinxstyleemphasis{GetFEM}, the continuation is implemented for two ways of parameterization of the
model:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
The parameter \(\lambda\) is directly a scalar datum, which the model
depends on.

\item {} 
The model is parametrised by the scalar parameter \(\lambda\) \sphinxstyleemphasis{via} a
vector datum \(P\), which the model depends on. In this case, one takes
the linear path
\begin{equation*}
\begin{split}\lambda \mapsto P(\lambda) := (1 - \lambda)P^{0} + \lambda P^{1},\end{split}
\end{equation*}
where \(P^{0}\) and \(P^{1}\) are given values of \(P\), and one
traces the solution set of the problem
\begin{equation*}
\begin{split}F(U, P(\lambda)) = 0.\end{split}
\end{equation*}
\end{enumerate}


\section{Detection of limit points}
\label{\detokenize{userdoc/model_continuation:detection-of-limit-points}}
When tracing solutions of the system \(F(U,\lambda) = 0\), one may be
interested in \sphinxstyleemphasis{limit points} (also called fold or turning points), where the
number of solutions with the same value of \(\lambda\) changes. These points
can be detected by a sign change of a test function \(\tau_{\mathrm{LP}}\):
\begin{quote}
\begin{equation*}
\begin{split}\tau_{\mathrm{LP}}(T_{j}) \tau_{\mathrm{LP}}(T_{j+1}) < 0,\end{split}
\end{equation*}\end{quote}

where \(\tau_{\mathrm{LP}}\) is defined by
\begin{quote}
\begin{equation*}
\begin{split}\tau_{\mathrm{LP}}(T) := T_{\lambda},\quad T = (T_{U},T_{\lambda}) \in \mathbb{R}^{N} \times \mathbb{R}.\end{split}
\end{equation*}\end{quote}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{getfemuserlimitpoint}.png}
\caption{Limit point.}\label{\detokenize{userdoc/model_continuation:id12}}\label{\detokenize{userdoc/model_continuation:ud-fig-limitpoint}}\end{figure}


\section{Numerical bifurcation}
\label{\detokenize{userdoc/model_continuation:numerical-bifurcation}}
A point \(\bar{Y}\) is called a \sphinxstyleemphasis{bifurcation point} of the system
\(F(Y) = 0\) if \(F(\bar{Y}) = 0\) and two or more distinct solution
curves pass through it. The following result gives a test for \sphinxstyleemphasis{smooth}
bifurcation points (see, e.g., \sphinxcite{biblio:georg2001}):

Let \(s \mapsto Y(s)\) be a parameterization of a solution curve and
\(\bar{Y} := Y(\bar{s})\) be a bifurcation point. Moreover, let
\(T^{\top} \dot{Y}(\bar{s}) > 0\),
\(B \notin \mathrm{Im}(J(\bar{Y}))\),
\(C \notin \mathrm{Im}(J(\bar{Y})^{\top})\), \(d \in \mathbb{R}\) and
\begin{quote}
\begin{equation*}
\begin{split}J(Y) := \begin{pmatrix}\nabla F(Y)\\ T^{\top}\end{pmatrix}.\end{split}
\end{equation*}\end{quote}

Define \(\tau_{\mathrm{BP}}(Y)\) via
\begin{quote}
\begin{equation*}
\begin{split}\begin{pmatrix}J(Y)& B\\ C^{\top}& d\end{pmatrix} \begin{pmatrix}V(Y)\\ \tau_{\mathrm{BP}}(Y)\end{pmatrix} = \begin{pmatrix}0\\ 1\end{pmatrix}.\end{split}
\end{equation*}\end{quote}

Then \(\tau_{\mathrm{BP}}(Y(s))\) changes its sign at \(s = \bar{s}\).

Obviously, if one takes \(B\), \(C\) and \(d\) randomly, it is
highly possible that they satisfy the requirements above. Consequently, the
numerical continuation method is able to detect bifurcation points by
taking the vectors \(Y\) and \(T\) supplied by the correction at each
continuation step and monitoring the signs of \(\tau_{\mathrm{BP}}\).

Once a bifurcation point \(\bar{Y}\) is detected by a sign change
\(\tau_{\mathrm{BP}}(Y_{j}) \tau_{\mathrm{BP}}(Y_{j+1}) < 0\), it can be
approximated more precisely by the predictor\sphinxhyphen{}corrector steps described above
with a special step\sphinxhyphen{}length adaptation (see Section 8.1 in \sphinxcite{biblio:al-ge1997}). Namely,
one can take the subsequent step lengths as
\begin{quote}
\begin{equation*}
\begin{split}h_{j+1} := -\frac{\tau_{\mathrm{BP}}(Y_{j+1})}{\tau_{\mathrm{BP}}(Y_{j+1}) - \tau_{\mathrm{BP}}(Y_{j})}h_{j}\end{split}
\end{equation*}\end{quote}

until \(\lvert h_{j+1} \rvert < h_{\mathrm{min}}\), which corresponds to the
secant method for finding a zero of the function
\(s \mapsto \tau_{\mathrm{BP}}(Y(s))\).

Finally, it would be desirable to switch solution branches. To this end, we
shall consider the case of the so\sphinxhyphen{}called \sphinxstyleemphasis{simple bifurcation point}, where only
two distinct solution curves intersect.

Let \(\tilde{Y}\) be an approximation of \(\bar{Y}\) that we are given
and \(V(\tilde{Y})\) be the first part of the solution of the augmented
system for computing the test function \(\tau_{\mathrm{BP}}(\tilde{Y})\). As
proposed in \sphinxcite{biblio:georg2001}, one can take \(V(\tilde{Y})\) as a predictor
direction and do one continuation step starting with
\((\tilde{Y}, V(\tilde{Y}))\) to obtain a point on a new branch. After this
continuation step has been performed successfully and a point on the new branch
has been recovered, one can proceed with usual predictor\sphinxhyphen{}corrector steps to
trace this branch.

Recently, tools for numerical \(PC^{1}\)\sphinxhyphen{}bifurcation have been developed in
\sphinxstyleemphasis{GetFEM}. Let \(J\) be a matrix function of a real parameter now defined by
\begin{quote}
\begin{equation*}
\begin{split}J(\alpha) := (1-\alpha)\begin{pmatrix}\nabla F(Y_{j})\\ T_{j}^{\top}\end{pmatrix} + \alpha\begin{pmatrix}\nabla F(Y_{j+1})\\ T_{j+1}^{\top}\end{pmatrix}.\end{split}
\end{equation*}\end{quote}

As proposed in \sphinxcite{biblio:li-re2014hal}, the following test can be used for detection of
a \(PC^{1}\) bifurcation point between \(Y_{j}\) and \(Y_{j+1}\):
\begin{quote}
\begin{equation*}
\begin{split}\det J(0) \det J(1) < 0.\end{split}
\end{equation*}\end{quote}

To perform this test numerically, introduce
\begin{quote}
\begin{equation*}
\begin{split}M(\alpha) := \begin{pmatrix}J(\alpha)& B\\ C^{\top}& d\end{pmatrix}\end{split}
\end{equation*}\end{quote}

and \(\tau_{\mathrm{BP}}(\alpha)\) analogously as above via
\begin{quote}
\begin{equation*}
\begin{split}M(\alpha) \begin{pmatrix}V(\alpha)\\ \tau_{\mathrm{BP}}(\alpha)\end{pmatrix} = \begin{pmatrix}0\\ 1\end{pmatrix}.\end{split}
\end{equation*}\end{quote}

It follows from Cramer’s rule that
\begin{quote}
\begin{equation*}
\begin{split}\tau_{\mathrm{BP}}(\alpha) = \frac{\det J(\alpha)}{\det M(\alpha)}\end{split}
\end{equation*}\end{quote}

provided that \(\det M(\alpha)\) is non\sphinxhyphen{}zero. Hence if \(B\), \(C\)
and \(d\) are chosen so that \(\det M(\alpha)\) is non\sphinxhyphen{}zero whenever
\(\det J(\alpha)\) is zero, then the sign changes of \(\det J(\alpha)\)
are characterised by passings of \(\tau_{\mathrm{BP}}(\alpha)\) through 0
whereas the sign changes of \(\det M(\alpha)\) by sign changes of
\(\tau_{\mathrm{BP}}(\alpha)\) caused by singularities. To conclude, the
sign of \(\det J(0)\det J(1)\) is determined by following the
behaviour of \(\tau_{\mathrm{BP}}(\alpha)\) and monitoring the sign changes
of \(\det J(\alpha)\) when \(\alpha\) passes through \([0,1]\).

As justified in \sphinxcite{biblio:li-re2014hal}, \(B\), \(C\) and \(d\) can be
chosen randomly again. The increments \(\delta\) of the current values of
\(\alpha\) are changed adaptively so that singularities of
\(\tau_{\mathrm{BP}}\) are treated effectively. After each calculation of
\(\tau_{\mathrm{BP}}(\alpha)\), \(\delta\) is set as follows:
\begin{quote}
\begin{equation*}
\begin{split}\delta := \begin{cases}\min\{2\delta, \delta_{\mathrm{max}}\}& \text{if $\lvert \tau_{\mathrm{BP}}(\alpha) - \tau_{\mathrm{BP}}(\alpha - \delta) \rvert < 0.5 \tau_{\mathrm{fac}} \tau_{\mathrm{ref}}$,}\\ \max\{0.1\delta, \delta_{\mathrm{min}}\}& \text{if $\lvert \tau_{\mathrm{BP}}(\alpha) - \tau_{\mathrm{BP}}(\alpha - \delta) \rvert > \tau_{\mathrm{fac}} \tau_{\mathrm{ref}}$,}\\ \delta& \text{otherwise},\end{cases}\end{split}
\end{equation*}\end{quote}

where \(\delta_{\mathrm{max}} > \delta_{\mathrm{min}} > 0\) and
\(\tau_{\mathrm{fac}} > 0\) are given constants and
\(\tau_{\mathrm{ref}} := \max\{\lvert \tau_{\mathrm{BP}}(1) - \tau_{\mathrm{BP}}(0) \rvert, 10^{-8}\}\).

When a \(PC^{1}\) bifurcation point is detected between \(Y_{j}\) and
\(Y_{j+1}\), it is approximated more precisely by a bisection\sphinxhyphen{}like
procedure. The obtained approximation lies on the same smooth branch as
\(Y_{j},\) and the corresponding unit tangent that points out from the
corresponding region of smoothness is calculated too.

Contrary to the smooth case, it is not clear how many branches can emanate from
the \(PC^{1}\) bifurcation point and in which directions they could be
sought. For this reason, continuation steps for a whole sequence of predictor
directions are tried out for finding points on new branches.

Denoting \(\tilde{Y}\), \(\tilde{T}\) the approximation of the
bifurcation point and the corresponding tangent, respectively, the predictor
directions are taken as follows: For a couple of reference vectors
\(\tilde{V}_{1}\) and \(\tilde{V}_{2}\), one takes \(\pm V\) with
\(V\) satisfying
\begin{quote}
\begin{equation*}
\begin{split}\nabla F(\tilde{Y}+h_{\mathrm{min}}\tilde{V}) V = 0, \quad \lVert V \rVert_{w} = 1,\end{split}
\end{equation*}\end{quote}

where \(\tilde{V}\) passes through a set of linear combinations of
\(\tilde{V}_{1}\) and \(\tilde{V}_{2}\). The total number of the linear
combinations is given by \(n_{\mathrm{dir}},\) and the reference vectors are
chosen successively according to the following strategy:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
One takes \(\tilde{V}_{1} := -\tilde{T}\) and \(\tilde{V}_{2}\) such
that
\begin{equation*}
\begin{split}\nabla F(\tilde{Y}+h_{\mathrm{min}}\tilde{T}) \tilde{V}_{2} = 0, \quad \lVert \tilde{V}_{2} \rVert_{w} = 1.\end{split}
\end{equation*}
\item {} 
Let \(\{\tilde{T}_{1},\dotsc\tilde{T}_{n_{\mathrm{br}}}\}\) denote the
set of unit tangents that correspond to the points from the branches found so
far and that are oriented in the directions of branching from the bifurcation
point. Then \(\tilde{V}_{1}\) and \(\tilde{V}_{2}\) are taken
successively as different combinations from
\(\{\tilde{T}_{1},\dotsc\tilde{T}_{n_{\mathrm{br}}}\}\).

\item {} 
If all combinations that are available so far have already been used, let
\(\tilde{V}_{1}\) be unchanged and take
\(\tilde{V}_{2} := \tilde{V}_{2}^{+}\) with \(\tilde{V}_{2}^{+}\)
satisfying
\begin{equation*}
\begin{split}\nabla F\Bigl(\tilde{Y}+h_{\mathrm{min}}\Bigl(\tilde{V}_{2}^{-} + 0.1\frac{\tilde{V}_{3}}{\lVert \tilde{V}_{3} \rVert_{w}}\Bigr)\Bigr) \tilde{V}_{2}^{+} = 0, \quad \lVert \tilde{V}_{2}^{+} \rVert_{w} = 1.\end{split}
\end{equation*}
Here, \(\tilde{V}_{2}^{-}\) equals the vector \(\tilde{V}_{2}\)
employed previously and \(\tilde{V}_{3}\) is chosen randomly.

\end{enumerate}

The total number of selections of \(\tilde{V}_{1}\) and
\(\tilde{V}_{2}\) is given by \(n_{\mathrm{span}}\).

More details on \(PC^1\) numerical branching can be found in
\sphinxcite{biblio:li-re2015hal}.


\section{Approximation of solution curves of a model}
\label{\detokenize{userdoc/model_continuation:approximation-of-solution-curves-of-a-model}}
The numerical continuation is defined in \sphinxcode{\sphinxupquote{getfem/getfem\_continuation.h}}. In
order to use it, one has to set it up via the corresponding object first:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{cont\PYGZus{}struct\PYGZus{}getfem\PYGZus{}model} \PYG{n}{S}\PYG{p}{(}\PYG{n}{model}\PYG{p}{,} \PYG{n}{parameter\PYGZus{}name}\PYG{p}{,} \PYG{n}{sfac}\PYG{p}{,} \PYG{n}{ls}\PYG{p}{,} \PYG{n}{h\PYGZus{}init}\PYG{p}{,} \PYG{n}{h\PYGZus{}max}\PYG{p}{,} \PYG{n}{h\PYGZus{}min}\PYG{p}{,} \PYG{n}{h\PYGZus{}inc}\PYG{p}{,} \PYG{n}{h\PYGZus{}dec}\PYG{p}{,}
                                   \PYG{n}{maxit}\PYG{p}{,} \PYG{n}{thrit}\PYG{p}{,} \PYG{n}{maxres}\PYG{p}{,} \PYG{n}{maxdiff}\PYG{p}{,} \PYG{n}{mincos}\PYG{p}{,} \PYG{n}{maxres\PYGZus{}solve}\PYG{p}{,} \PYG{n}{noisy}\PYG{p}{,} \PYG{n}{singularities}\PYG{p}{,}
                                   \PYG{n}{non}\PYG{o}{\PYGZhy{}}\PYG{n}{smooth}\PYG{p}{,} \PYG{n}{delta\PYGZus{}max}\PYG{p}{,} \PYG{n}{delta\PYGZus{}min}\PYG{p}{,} \PYG{n}{thrvar}\PYG{p}{,} \PYG{n}{ndir}\PYG{p}{,} \PYG{n}{nspan}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{parameter\_name}} is the name of the model datum representing
\(\lambda\), \sphinxcode{\sphinxupquote{sfac}} represents the scale factor \(\kappa\), and \sphinxcode{\sphinxupquote{ls}}
is the name of the solver to be used for the linear systems incorporated in the
process (e.g., \sphinxcode{\sphinxupquote{getfem::default\_linear\_solver\textless{}getfem::model\_real\_sparse\_matrix, getfem::model\_real\_plain\_vector\textgreater{}(model)}}). The real numbers \sphinxcode{\sphinxupquote{h\_init}},
\sphinxcode{\sphinxupquote{h\_max}}, \sphinxcode{\sphinxupquote{h\_min}}, \sphinxcode{\sphinxupquote{h\_inc}}, \sphinxcode{\sphinxupquote{h\_dec}} denote \(h_{\mathrm{init}}\),
\(h_{\mathrm{max}}\), \(h_{\mathrm{min}}\), \(h_{\mathrm{inc}}\),
and \(h_{\mathrm{dec}}\), the integer \sphinxcode{\sphinxupquote{maxit}} is the maximum number of
iterations allowed in the correction and \sphinxcode{\sphinxupquote{thrit}}, \sphinxcode{\sphinxupquote{maxres}}, \sphinxcode{\sphinxupquote{maxdiff}},
\sphinxcode{\sphinxupquote{mincos}}, and \sphinxcode{\sphinxupquote{maxres\_solve}} denote \(l_{\mathrm{thr}}\),
\(\varepsilon\), \(\varepsilon'\), \(c_{\mathrm{min}}\), and the
target residual value for the linear systems to be solved, respectively. The
non\sphinxhyphen{}negative integer \sphinxcode{\sphinxupquote{noisy}} determines how detailed information has to be
displayed in the course of the continuation process (the larger value the more
details), the integer \sphinxcode{\sphinxupquote{singularities}} determines whether the tools for
detection and treatment of singular points have to be used (0 for ignoring them
completely, 1 for detecting limit points, and 2 for detecting and treating
bifurcation points, as well), and the boolean value of \sphinxcode{\sphinxupquote{non\sphinxhyphen{}smooth}} determines
whether only tools for smooth continuation and bifurcation have to be used
or even tools for non\sphinxhyphen{}smooth ones do. The real numbers \sphinxcode{\sphinxupquote{delta\_max}},
\sphinxcode{\sphinxupquote{delta\_min}} and \sphinxcode{\sphinxupquote{thrvar}} represent \(\delta_{\mathrm{max}}\),
\(\delta_{\mathrm{min}}\) and \(\tau_{\mathrm{fac}}\), and the integers
\sphinxcode{\sphinxupquote{ndir}} and \sphinxcode{\sphinxupquote{nspan}} stand for \(n_{\mathrm{dir}}\) and
\(n_{\mathrm{span}}\), respectively.

Optionally, parameterization by a vector datum is then declared by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{S}\PYG{p}{.}\PYG{n}{set\PYGZus{}parametrised\PYGZus{}data\PYGZus{}names}\PYG{p}{(}\PYG{n}{initdata\PYGZus{}name}\PYG{p}{,} \PYG{n}{finaldata\PYGZus{}name}\PYG{p}{,} \PYG{n}{currentdata\PYGZus{}name}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

Here, the data names \sphinxcode{\sphinxupquote{initdata\_name}} and \sphinxcode{\sphinxupquote{finaldata\_name}} should represent
\(P^{0}\) and \(P^{1}\), respectively. Under \sphinxcode{\sphinxupquote{currentdata\_name}}, the
values of \(P(\lambda)\) have to be stored, that is, actual values of the
datum the model depends on.

Next, the continuation is initialised by:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{S}\PYG{p}{.}\PYG{n}{init\PYGZus{}Moore\PYGZus{}Penrose\PYGZus{}continuation}\PYG{p}{(}\PYG{n}{U}\PYG{p}{,} \PYG{n}{lambda}\PYG{p}{,} \PYG{n}{T\PYGZus{}U}\PYG{p}{,} \PYG{n}{T\PYGZus{}lambda}\PYG{p}{,} \PYG{n}{h}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{U}} should be a solution for the value of the parameter \(\lambda\)
equal to \sphinxcode{\sphinxupquote{lambda}} so that \(Y_{0}=\) (\sphinxcode{\sphinxupquote{U}},\sphinxcode{\sphinxupquote{lambda}}). During
this initialisation, an initial unit tangent \(T_{0}\) corresponding to
\(Y_{0}\) is computed in accordance with the sign of the initial value
\sphinxcode{\sphinxupquote{T\_lambda}}, and it is returned in \sphinxcode{\sphinxupquote{T\_U}}, \sphinxcode{\sphinxupquote{T\_lambda}}. Moreover, \sphinxcode{\sphinxupquote{h}} is
set to the initial step size \sphinxcode{\sphinxupquote{h\_init}}.

Subsequently, one step of the continuation is called by

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{S}\PYG{p}{.}\PYG{n}{Moore\PYGZus{}Penrose\PYGZus{}continuation}\PYG{p}{(}\PYG{n}{U}\PYG{p}{,} \PYG{n}{lambda}\PYG{p}{,} \PYG{n}{T\PYGZus{}U}\PYG{p}{,} \PYG{n}{T\PYGZus{}lambda}\PYG{p}{,} \PYG{n}{h}\PYG{p}{,} \PYG{n}{h0}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

After each call, a new point on a solution curve and the corresponding tangent
are returned in the variables \sphinxcode{\sphinxupquote{U}}, \sphinxcode{\sphinxupquote{lambda}} and \sphinxcode{\sphinxupquote{T\_U}}, \sphinxcode{\sphinxupquote{T\_lambda}}. The
step size for the next prediction is returned in \sphinxcode{\sphinxupquote{h}}. The size of the
current step is returned in the optional argument \sphinxcode{\sphinxupquote{h0}}. According to the
chosen value of \sphinxcode{\sphinxupquote{singularities}}, the test functions for limit and bifurcation
points are evaluated at the end of each continuation step. Furthermore, if a
smooth bifurcation point is detected, the procedure for numerical bifurcation
is performed and an approximation of the branching point as well as tangents to
both bifurcating curves are saved in the continuation object \sphinxcode{\sphinxupquote{S}}. From
there, they can easily be recovered with member functions of \sphinxcode{\sphinxupquote{S}} so that one
can initialise the continuation to trace either of the curves next time.

Complete examples of use on a smooth problem are shown in the test programs
\sphinxcode{\sphinxupquote{tests/test\_continuation.cc}}, \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_continuation.m}}
and \sphinxcode{\sphinxupquote{interface/src/scilab/demos/demo\_continuation.sce}}, whereas
\sphinxcode{\sphinxupquote{interface/src/scilab/demos/demo\_continuation\_vee.sce}} and
\sphinxcode{\sphinxupquote{interface/src/scilab/demos/demo\_continuation\_block.sce}} employ also
non\sphinxhyphen{}smooth tools.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\chapter{Finite strain Elasticity bricks}
\label{\detokenize{userdoc/model_nonlinear_elasticity:finite-strain-elasticity-bricks}}\label{\detokenize{userdoc/model_nonlinear_elasticity:ud-model-nonlinear-elasticity}}\label{\detokenize{userdoc/model_nonlinear_elasticity:index-0}}\label{\detokenize{userdoc/model_nonlinear_elasticity::doc}}
This brick implements some classical hyperelastic constitutive law for large deformation elasticity.


\section{Some recalls on finite strain elasticity}
\label{\detokenize{userdoc/model_nonlinear_elasticity:some-recalls-on-finite-strain-elasticity}}
Let \(\Omega\) be the reference configuration and \(\Omega_t\) the deformed configuration of an elastic media. Then for \(X \in \Omega\) we will denote by \(\Phi(x) = u(X) + X\) the deformation. the vector field \(u\) is the displacement with respect to the initial position.

The Cauchy\sphinxhyphen{}Green tensor is defined by
\begin{equation*}
\begin{split}C = \nabla\Phi^T\nabla\Phi\end{split}
\end{equation*}
The deformation tensor (Green\sphinxhyphen{}Lagrange)
\begin{equation*}
\begin{split}E = \frac{1}{2}\left(\nabla\Phi^T\nabla\Phi - I)\right)
  = \frac{1}{2}\left({\nabla u^T}{\nabla u} + {\nabla u^T} + {\nabla u}\right)\end{split}
\end{equation*}
(In the case of linear elasticity, \({\nabla u^T}{\nabla u}\) is neglected).

One has
\begin{equation*}
\begin{split}C = \nabla\Phi^T\nabla\Phi = 2 E + I.\end{split}
\end{equation*}
Both tensors \(E\) and \(C\) are used to describe finite strain elasticity constitutive laws.


\subsection{Main invariants and derivatives}
\label{\detokenize{userdoc/model_nonlinear_elasticity:main-invariants-and-derivatives}}
The description of finite strain elasticity constitutive laws often requires the principal invariants of the deformation tensors:

\(i_1,i_2,i_3\) are the invariants of orders \(1,2\) and \(3\):
\begin{equation*}
\begin{split}i_1( E) = \mbox{tr } E \hspace{5cm} &i_1( C) = 2\mbox{tr } E + 3\\
i_2( E) = \frac{(\mbox{tr } E)^2 - \mbox{tr } E^2}{2}\quad\hspace{3cm}& i_2( C)=4i_2( E)+4i_1( E)+3\\
i_3( E) = \det E \hspace{5cm} &i_3( C) = 8i_3( E) + 4i_2( E) + 2i_1( E) + 1\end{split}
\end{equation*}
The derivatives of the invariants with respect to the tensor \(E\) in the direction \(H\) are:
\begin{equation*}
\begin{split}&\frac{\partial i_1}{\partial E}(E;H) = I:H = \mbox{tr } H\\
&\frac{\partial i_2}{\partial E}(E;H) = (i_1( E)I -  E^T):H = (\mbox{tr }  E)(\mbox{tr } H) -  E^T:H\\
&\frac{\partial i_3}{\partial E}(E;H) = i_3( E)(E^{-T}):H  = (i_2( E)I - i_1( E) E +  E^2):H \mbox{ in 3D}.\end{split}
\end{equation*}
We will write
\begin{equation*}
\begin{split}&\frac{\partial i_1}{\partial E}(E) = I\\
&\frac{\partial i_2}{\partial E}(E) = i_1( E)I -  E^T\\
&\frac{\partial i_3}{\partial E}(E) = i_3( E)E^{-T}.\end{split}
\end{equation*}
Let us also recall that
\begin{equation*}
\begin{split}\frac{\partial (M^{-1})}{\partial M}(M;H) = -M^{-1}HM^{-1}\end{split}
\end{equation*}
The second derivatives of the invariants are fourth order tensors defined by
\begin{equation*}
\begin{split}&\frac{\partial^2 i_1}{\partial E^2}(E) = 0\\
&\frac{\partial^2 i_2}{\partial E^2}(E)_{ijkl} = \delta_{ij}\delta_{kl} - \delta_{il}\delta_{jk} \\
&\frac{\partial^2 i_3}{\partial E^2}(E)_{ijkl} = i_3(E) (E^{-1}_{ji}E^{-1}_{lk} - E^{-1}_{jk}E^{-1}_{li}).\end{split}
\end{equation*}
The notation \(A:B\) denotes the Frobenius product \(A:B = \displaystyle\sum_{ij}A_{ij}B_{ij}\). This product has the following properties:
\begin{equation*}
\begin{split}A:B &= \mbox{tr }(A^TB) = \mbox{tr }(AB^T) = \mbox{tr }(BA^T) = \mbox{tr }(B^TA),\\
A:BC &= B^TA:C,\\
A:BC &= AC^T:B,\\
\mbox{tr }(ABC) &= \mbox{tr }(B^TA^TC^T)\end{split}
\end{equation*}
Note also that
\begin{equation*}
\begin{split}\frac{\partial i_j}{\partial E}(C;H) = 2 \frac{\partial i_j}{\partial C}(C;H).\end{split}
\end{equation*}
This property enables us to write the constitutive laws as a function of the Cauchy\sphinxhyphen{}Green tensor invariants, especially for the case of the generalized Blatz\sphinxhyphen{}Ko strain energy.


\subsection{Potential elastic energy and its derivative}
\label{\detokenize{userdoc/model_nonlinear_elasticity:potential-elastic-energy-and-its-derivative}}
The stress in the reference configuration can be describe by the second Piola\sphinxhyphen{}Kirchhoff stress tensor \({\hat{\hat{\sigma}}} = \nabla\Phi^{-1}\sigma\nabla\Phi^{-t}~\det \nabla\Phi\) where \(\sigma\) is the Cauchy stress tensor in the deformed configuration \(\Omega_t\). An hyper\sphinxhyphen{}elastic constitutive law is given by
\begin{equation*}
\begin{split}{\hat{\hat{\sigma}}} = \frac{\partial}{\partial E} {W}(E) = 2\frac{\partial}{\partial C} {W}(C)\end{split}
\end{equation*}
where \({W}\) is the density of strain energy of the material. The total strain energy is given by
\begin{equation*}
\begin{split}\mathcal{I}(u) = \int_{\Omega} W( E(u)) dX\end{split}
\end{equation*}
and the derivative of the energy in a direction \(v\) can be writen
\begin{equation*}
\begin{split}D\mathcal{I}(u;v) = \int_{\Omega} \frac{\partial W}{\partial E}( E(u)):(I+{\nabla u^T}){\nabla v}  dX\end{split}
\end{equation*}
because in particular
\begin{equation*}
\begin{split}D E(u;v) &= \frac{1}{2}({\nabla u^T}{\nabla v} + {\nabla v^T}{\nabla u} + {\nabla v^T} + {\nabla v})\\
&= \frac{1}{2}({\nabla v^T}(I+{\nabla u}) + (I+{\nabla u^T}){\nabla v})\end{split}
\end{equation*}
and \(A:B = A:(B+B^T)/2\) when A is symmetric which is the case for \({\hat{\hat{\sigma}}}\).

Another way is to consider the static equilibrium which can be written as follows in the reference configuration:
\begin{equation*}
\begin{split}-\mbox{div } \left((I+{\nabla u}){\hat{\hat{\sigma}}}\right) = f.\end{split}
\end{equation*}
Integrating by parts, one obtains:
\begin{equation*}
\begin{split}\int_{\Omega}(I + {\nabla u}){\hat{\hat{\sigma}}} : {\nabla v}  dX = l(v).\end{split}
\end{equation*}

\subsection{Tangent matrix}
\label{\detokenize{userdoc/model_nonlinear_elasticity:tangent-matrix}}
The displacement \(u\) is fixed. In order to obtain the tangent matrix, one subsitutes \(u\) with \(u+h\)
\begin{equation*}
\begin{split}\int_\Omega(I + {\nabla u} + {\nabla h}){\hat{\hat{\sigma}}}( E(u)+ E(h) + \frac{1}{2}({\nabla h^T}{\nabla u}+{\nabla u^T}{\nabla h})) : {\nabla v}  dX = l(v)\end{split}
\end{equation*}
and considers the linear part w.r.t. \(h\), which is
\begin{equation*}
\begin{split}\int_\Omega{\nabla h}~{\hat{\hat{\sigma}}}( E(u)) : {\nabla v}  dX +\\
\int_\Omega \frac{\partial^2 W}{\partial E^2}\left(\frac{{\nabla h}+{\nabla h^T}+{\nabla h^T}{\nabla u}+{\nabla u^T}{\nabla h}}{2}\right) : (I+{\nabla u}^T){\nabla v}  dX\end{split}
\end{equation*}
which is symmetric w.r.t. \(v\) and \(h\). It can be rewritten as
\begin{equation*}
\begin{split}\int_\Omega {\nabla h}~{\hat{\hat{\sigma}}}( E(u)) : {\nabla v}  + \mathcal{A}((I+{\nabla u^T}){\nabla h}):(I+{\nabla u}^T){\nabla v}~ dX\end{split}
\end{equation*}
where \(\mathcal{A}\) is the symmetric \(3\times3\times3\times3\) tensor given by \(\mathcal{A}_{ijkl} = ((\frac{\partial^2 W}{\partial E^2})_{ijkl} + (\frac{\partial^2 W}{\partial E^2})_{ijlk})/2\).


\subsection{Some classical constitutive laws}
\label{\detokenize{userdoc/model_nonlinear_elasticity:some-classical-constitutive-laws}}

\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{Linearized: Saint\sphinxhyphen{}Venant Kirchhoff  law (small deformations)}}}
\label{\detokenize{userdoc/model_nonlinear_elasticity:linearized-saint-venant-kirchhoff-law-small-deformations}}\begin{equation*}
\begin{split}{W} &= \frac{\lambda}{2}i_1( E)^2 + \mu i_1( E^2)\\
{\hat{\hat{\sigma}}}   &= \lambda i_1( E)I + 2\mu E\\
\mathcal{A} &= \lambda i_1(H)I + \mu (H + H^T)\end{split}
\end{equation*}

\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{Three parameters Mooney\sphinxhyphen{}Rivlin law}}}
\label{\detokenize{userdoc/model_nonlinear_elasticity:three-parameters-mooney-rivlin-law}}
Compressible material.
\begin{equation*}
\begin{split}{W} = c_1(j_1( C) - 3) + c_2(j_2( C)-3) + d_1(i_3( C)^{1/2}-1)^2\end{split}
\end{equation*}
where \(c_1\), \(c_2\) and \(d_1\) are given coefficients and
\begin{equation*}
\begin{split}j_1(C) &= i_1(C) i_3(C)^{-1/3}\\
j_2(C) &= i_2(C) i_3(C)^{-2/3}\\
\frac{\partial j_1}{\partial C}(C) &= i_3(C)^{-1/3}\left(\frac{\partial i_1}{\partial C}(C) - \frac{i_1(C)}{3i_3(C)} \frac{\partial i_3}{\partial C}(C)\right)\\
\frac{\partial j_2}{\partial C}(C) &= i_3(C)^{-2/3}\left(\frac{\partial i_2}{\partial C}(C) - \frac{2i_2(C)}{3i_3(C)} \frac{\partial i_3}{\partial C}(C)\right)\\
\frac{\partial^2 j_1}{\partial C^2}(C) &= i_3(C)^{-1/3}\left(\frac{4i_1(C)}{9i_3(C)^2} \frac{\partial i_3}{\partial C}(C) \otimes \frac{\partial i_3}{\partial C}(C) - \frac{1}{3i_3(C)}\left(\frac{\partial i_3}{\partial C}(C) \otimes \frac{\partial i_1}{\partial C}(C)\right.\right. \\
& ~~~~~~~~~~~~~~~~\left.\left. + \frac{\partial i_1}{\partial C}(C) \otimes \frac{\partial i_3}{\partial C}(C)\right) - \frac{i_1(C)}{3i_3(C)} \frac{\partial^2 i_3}{\partial C^2}(C)\right)\\
\frac{\partial^2 j_2}{\partial C^2}(C) &= i_3(C)^{-2/3}\left(\frac{\partial^2 i_2}{\partial C^2}(C) + \frac{10i_2(C)}{9i_3(C)^2} \frac{\partial i_3}{\partial C}(C) \otimes \frac{\partial i_3}{\partial C}(C) \right. \\
& ~~~~~~~~~~~~~~~~\left. - \frac{2}{3i_3(C)}(\frac{\partial i_3}{\partial C}(C) \otimes \frac{\partial i_2}{\partial C}(C) + \frac{\partial i_2}{\partial C}(C) \otimes \frac{\partial i_3}{\partial C}(C)) - \frac{2i_2(C)}{3i_3(C)} \frac{\partial^2 i_3}{\partial C^2}(C)\right)\end{split}
\end{equation*}
and then
\begin{equation*}
\begin{split}{\hat{\hat{\sigma}}}   &= 2c_1 \frac{\partial j_1}{\partial C}(C) + 2c_2 \frac{\partial j_2}{\partial C}(C)  + 2d_1\left(1-i_3(C)^{-1/2}\right)\frac{\partial i_3}{\partial C}(C) \\
\mathcal{B} &= 4 c_1 \frac{\partial^2 j_1}{\partial C^2}(C) + 4c_2 \frac{\partial^2 j_2}{\partial C^2}(C) + 4d_1\left(\left(1-i_3(C)^{-1/2}\right)\frac{\partial^2 i_3}{\partial C^2}(C) + \frac{1}{2}i_3(C)^{-3/2} \frac{\partial i_3}{\partial C}(C) \otimes \frac{\partial i_3}{\partial C}(C)\right) \\
\mathcal{A}_{ijkl} &= (\mathcal{B}_{ijkl} + \mathcal{B}_{jikl})/2\end{split}
\end{equation*}
Incompressible material.
\begin{equation*}
\begin{split}{d_1} = 0
\mbox{ with the additional constraint: }
i_3( C) = 1\end{split}
\end{equation*}
The incompressibility constraint \(i_3( C) = 1\) is handled with a Lagrange multiplier \(p\) (the pressure)

constraint: \(\sigma = -pI \Rightarrow {\hat{\hat{\sigma}}} = -p\nabla\Phi\nabla\Phi^{-T}\det\nabla\Phi\)
\begin{equation*}
\begin{split}1 - i_3(\nabla\Phi) &= 0 \\
-\int_{\Omega_0} (\det\nabla\Phi  -1) q  dX &= 0 ~~~ \forall q\end{split}
\end{equation*}\begin{equation*}
\begin{split}B &= -\int_{\Omega_0} p(\nabla\Phi)^{-T} \det \nabla\Phi : \nabla v  dX \\
K &= \int_{\Omega_0} \left( p(\nabla\Phi)^{-T}(\nabla h)^{T}(\nabla\Phi)^{-T}\det\nabla\Phi : \nabla v  dX -
p(\nabla\Phi)^{-T}(\det \nabla\Phi(\nabla\Phi)^{-T}:\nabla h) : \nabla v \right)  dX\\
&= \int_{\Omega_0} p(\nabla h^T\nabla\Phi^{-T}):(\nabla\Phi^{-1}\nabla v)\det\nabla\Phi dX - \int_{\Omega_0} p(\nabla\Phi^{-T}:\nabla h)(\nabla\Phi^{-T}:\nabla v)\det\nabla\Phi dX\end{split}
\end{equation*}

\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{Ciarlet\sphinxhyphen{}Geymonat law}}}
\label{\detokenize{userdoc/model_nonlinear_elasticity:ciarlet-geymonat-law}}\begin{equation*}
\begin{split}{W} = a\; i_1(C) + (\frac{\mu}{2} - a)i_2(C) + (\frac{\lambda}{4} - \frac{\mu}{2} + a)i_3(C) - (\frac{\mu}{2}+\frac{\lambda}{4})\log \det(C)\end{split}
\end{equation*}
with  \(\lambda, \mu\) the Lame coefficients and \(\max(0,\frac{\mu}{2}-\frac{\lambda}{4})<a<\frac{\mu}{2}\) (see \sphinxcite{biblio:ciarlet1988}).


\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{Generalized Blatz\sphinxhyphen{}Ko law}}}
\label{\detokenize{userdoc/model_nonlinear_elasticity:generalized-blatz-ko-law}}\begin{equation*}
\begin{split}{W} = (a i_1(C) + b i_3(C)^{1/2} + c\frac{i_2(C)}{i_3(C)} + d)^n\end{split}
\end{equation*}
Since \(\frac{\partial}{\partial C} {W}(C) = \displaystyle\sum_{j}\frac{\partial W}{\partial i_j(C)} \frac{\partial i_j(C)}{\partial C}\), and \(\frac{\partial^2}{\partial C^2} {W}(C) = \displaystyle\sum_{j} \displaystyle\sum_{k} \frac{\partial^2 W}{\partial i_j(C) \partial i_k(C)} \frac{\partial i_k(C)}{\partial C} \otimes \frac{\partial i_j(C)}{\partial C} + \displaystyle\sum_{j} \frac{\partial W}{\partial i_j(C)} \frac{\partial^2 i_j(C)}{\partial C^2}\) we must compute the derivatives of the strain energy function with respect to the Cauchy\sphinxhyphen{}Green tensor invariants (we don’t need to compute the invariants derivatives with respect to \(E\) since \(\frac{\partial i_j}{\partial E}(C;H) = 2 \frac{\partial i_j}{\partial C}(C;H)\)) :
\begin{equation*}
\begin{split}\begin{array}{l}
\frac{\partial W}{\partial i_1(C)} = naZ^{n-1}
~~~~\mbox{with } Z = (a i_1(C) + b i_3(C)^{1/2} + c\frac{i_2(C)}{i_3(C)} + d)\\
\frac{\partial W}{\partial i_2(C)} = n\frac{c}{i_3(C)}Z^{n-1}\\
\frac{\partial W}{\partial i_3(C)} = n(\frac{b}{2i_3(C)^{1/2}}-\frac{ci_2(C)}{i_3(C)^2})Z^{n-1}\\
\frac{\partial W^2}{\partial^2 i_1(C)} = n(n-1)A^2Z^{n-2}\\
\frac{\partial W^2}{\partial i_1(C) \partial i_2(C)} = n(n-1)A\frac{c}{i_3(C)}Z^{n-2}\\
\frac{\partial W^2}{\partial i_1(C) \partial i_3(C)} = n(n-1)A(\frac{b}{2i_3(C)^{1/2}}-\frac{ci_2(C)}{i_3(C)^2})Z^{n-2}\\
\frac{\partial W^2}{\partial^2 i_2(C)} = n(n-1)\frac{c^2}{i_3(C)^2}Z^{n-2}\\
\frac{\partial W^2}{\partial i_2(C) \partial i_3(C)} = n(n-1)(\frac{b}{2i_3(C)^{1/2}}-\frac{ci_2(C)}{i_3(C)^2})Z^{n-2} - n\frac{c^2}{i_3(C)^2}Z^{n-1}\\
\frac{\partial W^2}{\partial i_3(C)^2} = n(n-1)(\frac{b}{2i_3(C)^{1/2}}-\frac{ci_2(C)}{i_3(C)^2})^2Z^{n-2} + n(-\frac{b}{4i_3(C)^{3/2}}+2\frac{ci_2(C)}{i_3(C)^4})Z^{n-1}
\end{array}\end{split}
\end{equation*}

\subsubsection{\sphinxstyleliteralintitle{\sphinxupquote{Plane strain hyper\sphinxhyphen{}elasticity}}}
\label{\detokenize{userdoc/model_nonlinear_elasticity:plane-strain-hyper-elasticity}}
All previous models are valid in volumic domains. Corresponding plane strain 2D models can be obtained by restricting the stress tensor and the fourth order tensor \(\mathcal{A}\) to their plane components.


\section{Add an nonlinear elasticity brick to a model}
\label{\detokenize{userdoc/model_nonlinear_elasticity:add-an-nonlinear-elasticity-brick-to-a-model}}
This brick represents a large strain elasticity problem. It is defined in the files \sphinxcode{\sphinxupquote{getfem/getfem\_nonlinear\_elasticity.h}} and \sphinxcode{\sphinxupquote{getfem/getfem\_nonlinear\_elasticity.cc}}. The function adding this brick to a model is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ind = getfem::add\PYGZus{}nonlinear\PYGZus{}elasticity\PYGZus{}brick
  (md, mim, varname, AHL, dataname, region = \PYGZhy{}1);
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{AHL}} is an object of type \sphinxcode{\sphinxupquote{getfem::abstract\_hyperelastic\_law}} which represents the considered hyperelastic law. It has to be chosen between:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
getfem::SaintVenant\PYGZus{}Kirchhoff\PYGZus{}hyperelastic\PYGZus{}law AHL;
getfem::Ciarlet\PYGZus{}Geymonat\PYGZus{}hyperelastic\PYGZus{}law AHL;
getfem::Mooney\PYGZus{}Rivlin\PYGZus{}hyperelastic\PYGZus{}law AHL(compressible, neohookean);
getfem::plane\PYGZus{}strain\PYGZus{}hyperelastic\PYGZus{}law AHL(pAHL);
getfem::generalized\PYGZus{}Blatz\PYGZus{}Ko\PYGZus{}hyperelastic\PYGZus{}law AHL;
\end{sphinxVerbatim}

The Saint\sphinxhyphen{}Venant Kirchhoff law is a linearized law defined with the two Lame coefficients, Ciarlet Geymonat law is defined with the two Lame coefficients and an additional coefficient (\(\lambda, \mu, a\)).

The Mooney\sphinxhyphen{}Rivlin law accepts two optional flags, the first one determines if the material will be compressible (\(d_1 \neq 0\)) and the second one determines if the material is neo Hookean (\(c_2 = 0\)). Depending on these flags one to three coefficients may be necessary. By default it is defined as incompressible and non neo Hookean, thus it needs two material coefficients (\(c_1\), \(c_2\)). In this case, it is to be used with the large strain incompressibility condition.

The plane strain hyperelastic law takes a pointer on a hyperelastic law as a parameter and performs a 2D plane strain approximation.

\sphinxcode{\sphinxupquote{md}} is the model variable, \sphinxcode{\sphinxupquote{mim}} the integration method, \sphinxcode{\sphinxupquote{varname}} the string being the name of the variable on which the term is added, \sphinxcode{\sphinxupquote{dataname}} the string being the name of the data in the model representing the coefficients of the law (can be constant or describe on a finite element method) and \sphinxcode{\sphinxupquote{region}} is the region on which the term is considered (by default, all the mesh).

The program \sphinxcode{\sphinxupquote{nonlinear\_elastostatic.cc}} in \sphinxcode{\sphinxupquote{tests}} directory and \sphinxcode{\sphinxupquote{demo\_nonlinear\_elasticity.m}} in \sphinxcode{\sphinxupquote{interface/tests/matlab}} directory are some examples of use of this brick with or without an incompressibility condition.

Note that the addition of a new hyperelastic constitutive law consists in furnishing the expression of the strain energy, the stress tensor and the derivative of the stress tensor. See the file  \sphinxcode{\sphinxupquote{getfem/getfem\_nonlinear\_elasticity.cc}} for more details. In particular, expression of the invariants and their derivatives are available.

A function which computes the Von Mises or Tresca stresses is also available:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
VM = compute\PYGZus{}Von\PYGZus{}Mises\PYGZus{}or\PYGZus{}Tresca
  (md, varname, AHL, dataname, mf\PYGZus{}vm, VM, tresca)
\end{sphinxVerbatim}

It returns a vector of the degrees of freedom of the Von Mises or Tresca stress on the finite element method mf\_vm. \sphinxcode{\sphinxupquote{tresca}} is a boolean whose value should be \sphinxcode{\sphinxupquote{true}} for Tresca stress and \sphinxcode{\sphinxupquote{false}} for Von Mises stress.


\section{Add a large strain incompressibility brick to a model}
\label{\detokenize{userdoc/model_nonlinear_elasticity:add-a-large-strain-incompressibility-brick-to-a-model}}
This brick adds an incompressibility condition in a large strain problem of type
\begin{equation*}
\begin{split}\mbox{det}(I+\nabla u) = 1,\end{split}
\end{equation*}
A Lagrange multiplier representing the pressure is introduced in a mixed formulation. The function adding this brick to a model is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ind = add\PYGZus{}nonlinear\PYGZus{}incompressibility\PYGZus{}brick
  (md, mim, varname, multname, region = \PYGZhy{}1)
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is the model, \sphinxcode{\sphinxupquote{mim}} the integration method, \sphinxcode{\sphinxupquote{varname}} the variable of the model on which the incompressibility condition is added, \sphinxcode{\sphinxupquote{multanme}} the multiplier variable corresponding to the pressure (be aware that at least a linear Ladyzhenskaja\sphinxhyphen{}Babuska\sphinxhyphen{}Brezzi inf\sphinxhyphen{}sup condition is satisfied between the f.e.m. of the variable and the one of the multiplier). \sphinxcode{\sphinxupquote{region}} is an optional parameter correponding to the mesh region on which the term is considered (by default, all the mesh).


\section{High\sphinxhyphen{}level generic assembly versions}
\label{\detokenize{userdoc/model_nonlinear_elasticity:high-level-generic-assembly-versions}}
The generic weak form language (GWFL) gives access to the hyperelastic potential and constitutive laws implemented in \sphinxstyleemphasis{GetFEM}. This allows to directly use them in the language, for instance using a generic assembly brick in a model or for interpolation of certain quantities (the stress for instance).

Here is the list of nonlinear operators in the language which can be useful for nonlinear elasticity:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Det(M)                                \PYGZpc{} determinant of the matrix M
Trace(M)                              \PYGZpc{} trace of the matrix M
Matrix\PYGZus{}i2(M)                          \PYGZpc{} second invariant of M (in 3D): (sqr(Trace(m)) \PYGZhy{} Trace(m*m))/2
Matrix\PYGZus{}j1(M)                          \PYGZpc{} modified first invariant of M: Trace(m)pow(Det(m),\PYGZhy{}1/3).
Matrix\PYGZus{}j2(M)                          \PYGZpc{} modified second invariant of M: Matrix\PYGZus{}I2(m)*pow(Det(m),\PYGZhy{}2/3).
Right\PYGZus{}Cauchy\PYGZus{}Green(F)                 \PYGZpc{} F\PYGZsq{} * F
Left\PYGZus{}Cauchy\PYGZus{}Green(F)                  \PYGZpc{} F * F\PYGZsq{}
Green\PYGZus{}Lagrangian(F)                   \PYGZpc{} (F\PYGZsq{}F \PYGZhy{} Id(meshdim))/2
Cauchy\PYGZus{}stress\PYGZus{}from\PYGZus{}PK2(sigma, Grad\PYGZus{}u) \PYGZpc{} (Id+Grad\PYGZus{}u)*sigma*(I+Grad\PYGZus{}u\PYGZsq{})/det(I+Grad\PYGZus{}u)
\end{sphinxVerbatim}

The potentials:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Saint\PYGZus{}Venant\PYGZus{}Kirchhoff\PYGZus{}potential(Grad\PYGZus{}u, [lambda; mu])
Plane\PYGZus{}Strain\PYGZus{}Saint\PYGZus{}Venant\PYGZus{}Kirchhoff\PYGZus{}potential(Grad\PYGZus{}u, [lambda; mu])
Generalized\PYGZus{}Blatz\PYGZus{}Ko\PYGZus{}potential(Grad\PYGZus{}u, [a;b;c;d;n])
Plane\PYGZus{}Strain\PYGZus{}Generalized\PYGZus{}Blatz\PYGZus{}Ko\PYGZus{}potential(Grad\PYGZus{}u, [a;b;c;d;n])
Ciarlet\PYGZus{}Geymonat\PYGZus{}potential(Grad\PYGZus{}u, [lambda;mu;a])
Plane\PYGZus{}Strain\PYGZus{}Ciarlet\PYGZus{}Geymonat\PYGZus{}potential(Grad\PYGZus{}u, [lambda;mu;a])
Incompressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}potential(Grad\PYGZus{}u, [c1;c2])
Plane\PYGZus{}Strain\PYGZus{}Incompressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}potential(Grad\PYGZus{}u, [c1;c2])
Compressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}potential(Grad\PYGZus{}u, [c1;c2;d1])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}potential(Grad\PYGZus{}u, [c1;c2;d1])
Incompressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}potential(Grad\PYGZus{}u, [c1])
Plane\PYGZus{}Strain\PYGZus{}Incompressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}potential(Grad\PYGZus{}u, [c1])
Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}potential(Grad\PYGZus{}u, [c1;d1])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}potential(Grad\PYGZus{}u, [c1;d1])
Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Bonet\PYGZus{}potential(Grad\PYGZus{}u, [lambda;mu])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Bonet\PYGZus{}potential(Grad\PYGZus{}u, [lambda;mu])
Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Ciarlet\PYGZus{}potential(Grad\PYGZus{}u, [lambda;mu])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Ciarlet\PYGZus{}potential(Grad\PYGZus{}u, [lambda;mu])
\end{sphinxVerbatim}

The second Piola\sphinxhyphen{}Kirchhoff stress tensors:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
Saint\PYGZus{}Venant\PYGZus{}Kirchhoff\PYGZus{}PK2(Grad\PYGZus{}u, [lambda; mu])
Plane\PYGZus{}Strain\PYGZus{}Saint\PYGZus{}Venant\PYGZus{}Kirchhoff\PYGZus{}PK2(Grad\PYGZus{}u, [lambda; mu])
Generalized\PYGZus{}Blatz\PYGZus{}Ko\PYGZus{}PK2(Grad\PYGZus{}u, [a;b;c;d;n])
Plane\PYGZus{}Strain\PYGZus{}Generalized\PYGZus{}Blatz\PYGZus{}Ko\PYGZus{}PK2(Grad\PYGZus{}u, [a;b;c;d;n])
Ciarlet\PYGZus{}Geymonat\PYGZus{}PK2(Grad\PYGZus{}u, [lambda;mu;a])
Plane\PYGZus{}Strain\PYGZus{}Ciarlet\PYGZus{}Geymonat\PYGZus{}PK2(Grad\PYGZus{}u, [lambda;mu;a])
Incompressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}PK2(Grad\PYGZus{}u, [c1;c2])
Plane\PYGZus{}Strain\PYGZus{}Incompressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}PK2(Grad\PYGZus{}u, [c1;c2])
Compressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}PK2(Grad\PYGZus{}u, [c1;c2;d1])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Mooney\PYGZus{}Rivlin\PYGZus{}PK2(Grad\PYGZus{}u, [c1;c2;d1])
Incompressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}PK2(Grad\PYGZus{}u, [c1])
Plane\PYGZus{}Strain\PYGZus{}Incompressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}PK2(Grad\PYGZus{}u, [c1])
Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}PK2(Grad\PYGZus{}u, [c1;d1])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}PK2(Grad\PYGZus{}u, [c1;d1])
Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Bonet\PYGZus{}PK2(Grad\PYGZus{}u, [lambda;mu])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Bonet\PYGZus{}PK2(Grad\PYGZus{}u, [lambda;mu])
Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Ciarlet\PYGZus{}PK2(Grad\PYGZus{}u, [lambda;mu])
Plane\PYGZus{}Strain\PYGZus{}Compressible\PYGZus{}Neo\PYGZus{}Hookean\PYGZus{}Ciarlet\PYGZus{}PK2(Grad\PYGZus{}u, [lambda;mu])
\end{sphinxVerbatim}

Note that the derivatives with respect to the material parameters have not been implemented apart for the Saint Venant Kirchhoff hyperelastic law. Therefore, it is not possible to make the parameter depend on other variables of a model (derivatives are not necessary complicated to implement but for the moment, only a wrapper with old implementations has been written).

Note that the coupling of models is to be done at the weak formulation level. In a general way, it is recommended not to use the potential to define a problem. Main couplings cannot be obtained at the potential level. Thus the use of potential should be restricted to the actual computation of the potential.

An example of use to add a Saint Venant\sphinxhyphen{}Kirchhoff hyperelastic term to a variable \sphinxcode{\sphinxupquote{u}} in a model or a ga\_workspace is given by the addition of the following assembly string:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYGZdq{}((Id(meshdim)+Grad\PYGZus{}u)*(Saint\PYGZus{}Venant\PYGZus{}Kirchhoff\PYGZus{}PK2(Grad\PYGZus{}u,[lambda;mu]))):Grad\PYGZus{}Test\PYGZus{}u\PYGZdq{}
\end{sphinxVerbatim}

Note that in that case, \sphinxcode{\sphinxupquote{lambda}} and \sphinxcode{\sphinxupquote{mu}} have to be declared data of the model/ga\_workspace. It is of course possible to replace them by explicit constants or expressions depending on several data.

Concerning the incompressible Mooney\sphinxhyphen{}Rivlin law, it has to be completed by an incompressibility term. For instance by adding the following incompressibility brick:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ind = add\PYGZus{}finite\PYGZus{}strain\PYGZus{}incompressibility\PYGZus{}brick(md, mim, varname, multname, region = \PYGZhy{}1);
\end{sphinxVerbatim}

This brick just adds the term \sphinxcode{\sphinxupquote{p*(1\sphinxhyphen{}Det(Id(meshdim)+Grad\_u))}} if \sphinxcode{\sphinxupquote{p}} is the multiplier and \sphinxcode{\sphinxupquote{u}} the variable which represents the displacement.

The addition of an hyperelastic term to a model can also be done thanks to the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
ind = add\PYGZus{}finite\PYGZus{}strain\PYGZus{}elasticity\PYGZus{}brick(md, mim, lawname, varname, params,
                                         region = size\PYGZus{}type(\PYGZhy{}1));
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is the model, \sphinxcode{\sphinxupquote{mim}} the integration method, \sphinxcode{\sphinxupquote{varname}} the variable of the model representing the large strain displacement, \sphinxcode{\sphinxupquote{lawname}} is the constitutive law name which could be \sphinxcode{\sphinxupquote{Saint\_Venant\_Kirchhoff}}, \sphinxcode{\sphinxupquote{Generalized\_Blatz\_Ko}}, \sphinxcode{\sphinxupquote{Ciarlet\_Geymonat}}, \sphinxcode{\sphinxupquote{Incompressible\_Mooney\_Rivlin}}, \sphinxcode{\sphinxupquote{Compressible\_Mooney\_Rivlin}}, \sphinxcode{\sphinxupquote{Incompressible\_Neo\_Hookean}}, \sphinxcode{\sphinxupquote{Compressible\_Neo\_Hookean}}, \sphinxcode{\sphinxupquote{Compressible\_Neo\_Hookean\_Bonet}} or \sphinxcode{\sphinxupquote{Compressible\_Neo\_Hookean\_Ciarlet}}. \sphinxcode{\sphinxupquote{params}} is a string representing the parameters of the law defined as a small vector or a vector field.

The Von Mises stress can be interpolated with the following function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
void compute\PYGZus{}finite\PYGZus{}strain\PYGZus{}elasticity\PYGZus{}Von\PYGZus{}Mises(md, varname, lawname, params, mf\PYGZus{}vm, VM,
                                                rg=mesh\PYGZus{}region::all\PYGZus{}convexes());
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{md}} is the model, \sphinxcode{\sphinxupquote{varname}} the variable of the model representing the large strain displacement, \sphinxcode{\sphinxupquote{lawname}} is the constitutive law name (see previou brick), \sphinxcode{\sphinxupquote{params}} is a string representing the parameters of the law, \sphinxcode{\sphinxupquote{mf\_vm}} a (preferably discontinuous) Lagrange  finite element method on which the interpolation will be done and \sphinxcode{\sphinxupquote{VM}} a vector of type \sphinxcode{\sphinxupquote{model\_real\_plain\_vector}} in which the interpolation will be stored.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\chapter{Small strain plasticity}
\label{\detokenize{userdoc/model_plasticity_small_strain:small-strain-plasticity}}\label{\detokenize{userdoc/model_plasticity_small_strain:ud-model-plasticity-small-strain}}\label{\detokenize{userdoc/model_plasticity_small_strain:index-0}}\label{\detokenize{userdoc/model_plasticity_small_strain::doc}}
A framework for the approximation of plasticity models in \sphinxstyleemphasis{GetFEM}. See in \sphinxcode{\sphinxupquote{src/getfem\_plasticity.cc}} and \sphinxcode{\sphinxupquote{interface/src/gf\_model\_set.cc}} for the brick implementation and to extend the implementation to new plasticity models.


\section{Theoretical background}
\label{\detokenize{userdoc/model_plasticity_small_strain:theoretical-background}}
We present a short introduction to small strain plasticity. We refer mainly to \sphinxcite{biblio:si-hu1998} and \sphinxcite{biblio:so-pe-ow2008} for a more detailed presentation.


\subsection{Additive decomposition of the small strain tensor}
\label{\detokenize{userdoc/model_plasticity_small_strain:additive-decomposition-of-the-small-strain-tensor}}
Let \(\Omega \subset \rm I\hspace{-0.15em}R^3\) be the reference configuration of a deformable body and \(u : \Omega \rightarrow \rm I\hspace{-0.15em}R^3\) be the displacement field. Small strain plasticity is based on the additive decomposition of the small strain tensor \(\varepsilon(u) = \dfrac{\nabla u + \nabla u^T}{2}\) in
\begin{equation*}
\begin{split}\varepsilon(u) = \varepsilon^e + \varepsilon^p\end{split}
\end{equation*}
where \(\varepsilon^e\) is the elastic part of the strain tensor and \(\varepsilon^p\) the plastic one.


\subsection{Internal variables, free energy potential and elastic law}
\label{\detokenize{userdoc/model_plasticity_small_strain:internal-variables-free-energy-potential-and-elastic-law}}
We consider
\begin{equation*}
\begin{split}\alpha : \Omega \rightarrow \rm I\hspace{-0.15em}R^{d_{\alpha}},\end{split}
\end{equation*}
a vector field of \(d_{\alpha}\) strain type internal variables (\(d_{\alpha} = 0\) if no internal variables are considered). We consider also a free energy potential
\begin{equation*}
\begin{split}\psi(\varepsilon^e, \alpha),\end{split}
\end{equation*}
such that corresponding stress type variables are determined by
\begin{equation*}
\begin{split}\sigma = \dfrac{\partial \psi}{\partial \varepsilon^e}(\varepsilon^e, \alpha), ~~~~ A =  \dfrac{\partial \psi}{\partial \alpha}(\varepsilon^e, \alpha),\end{split}
\end{equation*}
where \(\sigma\) is the Cauchy stress tensor and \(A\) the stress type internal variables. The plastic dissipation is given by
\begin{equation*}
\begin{split}\sigma:\dot{\varepsilon}^p - A.\dot{\alpha} \ge 0.\end{split}
\end{equation*}
In the standard cases, \(\psi(\varepsilon^e, \alpha)\) is decomposed into
\begin{equation*}
\begin{split}\psi(\varepsilon^e, \alpha) = \psi^e(\varepsilon^e) + \psi^p(\alpha).\end{split}
\end{equation*}
In the case of linearized elasticity, one has \(\psi^e(\varepsilon^e) = \frac{1}{2} ({\cal A}\varepsilon^e) :\varepsilon^e\) where \({\cal A}\) is the fourth order elasticity tensor. For isotropic linearized elasticity this expression reduces to \(\psi^e(\varepsilon^e) = \mu \mbox{dev}(\varepsilon^e) : \mbox{dev}(\varepsilon^e) + \frac{1}{2} K (\mbox{tr}(\varepsilon^e))^2\) where \(\mu\) is the shear modulus and \(K = \lambda + 2\mu/3\) is the bulk modulus.


\subsection{Plastic potential, yield function and plastic flow rule}
\label{\detokenize{userdoc/model_plasticity_small_strain:plastic-potential-yield-function-and-plastic-flow-rule}}
Plastic yielding is supposed to occur when the stress attains a critical value. This limit is determined by a yield function \(f(\sigma, A)\) and the condition
\begin{equation*}
\begin{split}f(\sigma, A) \le 0.\end{split}
\end{equation*}
The surface \(f(\sigma, A) = 0\) is the yield surface where the plastic deformation may occur.

Let us also consider the plastic potential \(\Psi(\sigma, A)\), (convex with respect to its both variables) which determines the plastic flow direction in the sense that the flow rule is defined as
\begin{equation*}
\begin{split}\dot{\varepsilon}^p = \gamma \dfrac{\partial \Psi}{\partial \sigma}(\sigma, A), ~~~~~~ \dot{\alpha} = -\gamma \dfrac{\partial \Psi}{\partial A}(\sigma, A),\end{split}
\end{equation*}
with the additional complementarity condition
\begin{equation*}
\begin{split}f(\sigma, A) \le 0, ~~~ \gamma \ge 0, ~~~ f(\sigma, A) \gamma = 0.\end{split}
\end{equation*}
The variable \(\gamma\) is called the plastic multiplier. Note that when \(\psi(\varepsilon^e, \alpha), f(\sigma, A) \mbox{ or } \Psi(\sigma, A)\) are not differentiable, subdifferentials have to be used. Associated plasticity corresponds to the choice \(\Psi(\sigma, A) = f(\sigma, A)\).


\subsection{Initial boundary value problem}
\label{\detokenize{userdoc/model_plasticity_small_strain:initial-boundary-value-problem}}
The weak formulation of a dynamic elastoplastic problem can be written, for an arbitrary kinematically admissible test function \(v\), as follows:
\begin{equation*}
\begin{split}\left| \begin{array}{l}
 \int_{\Omega} \rho \ddot{u}\cdot v + \sigma : \nabla v dx =  \int_{\Omega} f\dot v dx + \int_{\Gamma_N} g\dot v dx, \\
u(0,x) = u_0(x), ~~~\dot{u}(0) = \mathrm{v}_0(x), \\
\varepsilon^p(0,x) = \varepsilon^p_0, ~~~ \alpha(0,x) = \alpha_0,
\end{array} \right.\end{split}
\end{equation*}
for \(u_0, \mathrm{v}_0, \varepsilon^p_0, \alpha_0\) being initial values and \(f\) and \(g\) being prescribed forces in the interior of domain \(\Omega\) and on the part of the boundary \(\Gamma_N\).

Note that plasticity models are often applied on quasi\sphinxhyphen{}static problems which correspond to the term \(\rho \ddot{u}\) being neglected.

Given a time step \(\Delta t = t_{n+1} -t_n\), from time \(t_n\) to \(t_{n+1}\), we will denote in the sequel \(u_n, \varepsilon^p_n  \mbox{ and } \alpha_n\) the approximations at time \(t_n\) of \(u(t_n), \varepsilon^p_n(t_n) \mbox{ and } \alpha(t_n)\) respectively. These approximations correspond to the chosen time integration scheme (for instance one of the proposed schemes in {\hyperref[\detokenize{userdoc/model_time_integration:ud-model-time-integration}]{\sphinxcrossref{\DUrole{std,std-ref}{The model tools for the integration of transient problems}}}}) which can be different than the time integration scheme used for the integration of the flow rule (see below).


\section{Flow rule integration}
\label{\detokenize{userdoc/model_plasticity_small_strain:flow-rule-integration}}
The plastic flow rule has to be integrated with its own time integration scheme. Among standards schemes, the backward Euler scheme, the \(\theta\)\sphinxhyphen{}scheme (or generalized trapezoidal rule) and the generalized mid\sphinxhyphen{}point scheme are the most commonly used in that context. We make here the choice of the \(\theta\)\sphinxhyphen{}scheme (\(\theta = 1\) corresponds to the backward Euler scheme as a special case).

Let \(u_{n+1}\) be the displacement at the considered time step and  \(u_{n}\) at the previous one.

The \(\theta\)\sphinxhyphen{}scheme for the integration of the plastic flow rules reads as
\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:thetascheme1}
\begin{split}\varepsilon^p_{n+1} - \varepsilon^p_{n} = (1-\theta)\Delta t \gamma_n \dfrac{\partial \Psi}{\partial \sigma}(\sigma_{n}, A_{n}) + \theta \Delta t \gamma_{n+1} \dfrac{\partial \Psi}{\partial \sigma}(\sigma_{n+1}, A_{n+1}),\end{split}
\end{equation}\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:thetascheme2}
\begin{split}\alpha_{n+1} - \alpha_n = -(1-\theta)\Delta t \gamma_n \dfrac{\partial \Psi}{\partial A}(\sigma_{n}, A_{n}) - \theta\Delta t \gamma_{n+1} \dfrac{\partial \Psi}{\partial A}(\sigma_{n+1}, A_{n+1}),\end{split}
\end{equation}
with the complementary condition
\begin{equation*}
\begin{split}f(\sigma_{n+1}, A_{n+1}) \le 0, ~~~ \gamma_{n+1} \ge 0, ~~~ f(\sigma_{n+1}, A_{n+1}) \gamma_{n+1} = 0.\end{split}
\end{equation*}
where \(0 < \theta \le 1\) is the parameter of the \(\theta\)\sphinxhyphen{}scheme. We exclude \(\theta = 0\) because we will not consider explicit integration of plasticity. Let us recall that \(\theta = 1\) corresponds to the backward Euler scheme and \(\theta = 1/2\) to the Crank\sphinxhyphen{}Nicolson scheme (or trapezoidal rule) which is a second order consistent scheme. Note that the complementarity condition for the quantities at time step \(n\) is prescribed at the previous time step (\(\sigma_{n}, \alpha_n, \mbox{and } \gamma_n\) are supposed to be already determined).

A solution would be to solve the whole problem with all the unknows, that is \(u_{n+1},  \gamma_{n+1}, \varepsilon^p_{n+1} \mbox{ and } A_{n+1}\). This is of course possible but would be a rather expensive strategy because of the resulting high number of degrees of freedom. A classical strategy (the return mapping one for instance, see \sphinxcite{biblio:so-pe-ow2008} or the closest point projection one) consist in integrating locally the plastic flow on each Gauss point of the considered integration method separately, or more precisely to consider on each Gauss point the maps
\begin{align*}\!\begin{aligned}
{\mathscr E}^p : (u_{n+1}, \zeta_n, \eta_n) \mapsto \varepsilon^p_{n+1}\\
{\mathscr A} : (u_{n+1}, \zeta_{n}, \eta_n) \mapsto \alpha_{n+1}\\
\end{aligned}\end{align*}
with \(\eta_n, \zeta_{n}\) the right hand side of equations \eqref{equation:userdoc/model_plasticity_small_strain:thetascheme1}, \eqref{equation:userdoc/model_plasticity_small_strain:thetascheme2}, i.e.
\begin{align*}\!\begin{aligned}
\zeta_n = \varepsilon^p_{n} + (1-\theta)\Delta t \gamma_n \dfrac{\partial \Psi}{\partial \sigma}(\sigma_{n}, A_{n}) ,\\
\eta_n = \alpha_n - (1-\theta)\Delta t \gamma_n \dfrac{\partial \Psi}{\partial A}(\sigma_{n}, A_{n})\\
\end{aligned}\end{align*}
This means in particular that \((\varepsilon^p_{n+1}, \alpha_{n+1}) = ({\mathscr E}^p(u_{n+1},  \zeta_n, \eta_n), {\mathscr A}(u_{n+1}, \zeta_{n}, \eta_n))\) is the solution to equations \eqref{equation:userdoc/model_plasticity_small_strain:thetascheme1} and \eqref{equation:userdoc/model_plasticity_small_strain:thetascheme2}. Both these maps and their tangent moduli (usually called consistent tangent moduli) are then used in the global solve of the problem with a Newton method and for \(u_{n+1}\) the unique remaining variable. The advantage of the return mapping strategy is that the unique variable of the global solve is the displacement \(u_{n+1}\). A nonlinear solve on each Gauss point is often necessary which is usualy performed with a local Newton method.

In \sphinxstyleemphasis{GetFEM} we propose both the return mapping strategy and also an alternative strategy developed below which is mainly inspired from  \sphinxcite{biblio:po-ni2016},  \sphinxcite{biblio:se-po-wo2015} and \sphinxcite{biblio:ha-wo2009} and allow more simple tangent moduli. It consists in keeping (a multiple of) \(\gamma_{n+1}\) as an additional unknown with respect to \(u_{n+1}\). As we will see, this will allow a more generic treatment of the yield functions, the price for the simplicity being this additional unknown scalar field.

First, we consider an additional (and optional) given function \(\alpha(\sigma_{n+1}, A_{n+1}) > 0\) whose interest will appear later on (it will allow simple local inverses) and the new unknown scalar field
\begin{equation*}
\begin{split}\xi_{n+1} = \dfrac{\gamma_{n+1}}{\alpha(\sigma_{n+1}, A_{n+1})} ,\end{split}
\end{equation*}
so that our two main unknows are now \(u_{n+1} \mbox{ and } \xi_{n+1}\). The discretized plastic flow rule integration now reads:
\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:flowrule1}
\begin{split}\varepsilon^p_{n+1} - \varepsilon^p_{n} = (1-\theta)\alpha(\sigma_n,A_n)\Delta t \xi_n \dfrac{\partial \Psi}{\partial \sigma}(\sigma_{n}, A_{n}) + \theta \alpha(\sigma_{n+1},A_{n+1}) \Delta t \xi_{n+1} \dfrac{\partial \Psi}{\partial \sigma}(\sigma_{n+1}, A_{n+1}),\end{split}
\end{equation}\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:flowrule2}
\begin{split}\alpha_{n+1} - \alpha_n = (1-\theta) \alpha(\sigma_n,A_n)\Delta t \xi_n \dfrac{\partial \Psi}{\partial A}(\sigma_{n}, A_{n}) + \theta \alpha(\sigma_{n+1},A_{n+1}) \Delta t \xi_{n+1} \dfrac{\partial \Psi}{\partial A}(\sigma_{n+1}, A_{n+1}),\end{split}
\end{equation}\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:flowrule3}
\begin{split}f(\sigma_{n+1}, A_{n+1}) \le 0, ~~~ \xi_{n+1} \ge 0, ~~~ f(\sigma_{n+1}, A_{n+1}) \xi_{n+1} = 0.\end{split}
\end{equation}
For \(u_{n+1} \mbox{ and } \xi_{n+1}\) be given, we define the two maps
\begin{align*}\!\begin{aligned}
\tilde{\mathscr E}^p : (u_{n+1}, \theta \Delta t \xi_{n+1}, \zeta_{n}, \eta_n) \mapsto \varepsilon^p_{n+1}\\
\tilde{\mathscr A} : (u_{n+1}, \theta \Delta t \xi_{n+1}, \zeta_{n}, \eta_n) \mapsto \alpha_{n+1}\\
\end{aligned}\end{align*}
where the pair \((\varepsilon^p_{n+1}, \alpha_{n+1}) = (\tilde{\mathscr E}^p(u_{n+1}, \theta \xi_{n+1}, \zeta_{n}, \eta_n), \tilde{\mathscr A}(u_{n+1}, \theta \xi_{n+1}, \zeta_{n}, \eta_n))\) is the solution to equations \eqref{equation:userdoc/model_plasticity_small_strain:flowrule1}, \eqref{equation:userdoc/model_plasticity_small_strain:flowrule2} (without the consideration of  \eqref{equation:userdoc/model_plasticity_small_strain:flowrule3}). We will see later, that, at least for simple isotropic plastic flow rules, these maps have a simple expression, even sometimes a linear one with respect to \(u_{n+1}\).

Still \(u_{n+1} \mbox{ and } \xi_{n+1}\) be given the stress \(\sigma_{n+1}\) reads
\begin{equation*}
\begin{split}\sigma_{n+1} = \dfrac{\partial \psi^e}{\partial \varepsilon^e}(\varepsilon(u_{n+1}) -\varepsilon^p_{n+1}).\end{split}
\end{equation*}\begin{equation*}
\begin{split}A_{n+1} = \dfrac{\partial \psi^p}{\partial \alpha}(\alpha_{n+1}).\end{split}
\end{equation*}
The complementarity equation \eqref{equation:userdoc/model_plasticity_small_strain:flowrule3} is then prescribed with the use of a well chosen complementarity function, as in \sphinxcite{biblio:ha-wo2009} for \(r > 0\) such as:
\begin{equation*}
\begin{split}\int_{\Omega} (\xi_{n+1} - (\xi_{n+1} + r f(\sigma_{n+1}, A_{n+1}))_+) \lambda dx = 0,   \forall \lambda\end{split}
\end{equation*}
or
\begin{equation*}
\begin{split}\int_{\Omega} (f(\sigma_{n+1} + (-f(\sigma_{n+1}, A_{n+1}) - \xi_{n+1}/r)_+ , A_{n+1}) ) \lambda dx = 0,   \forall \lambda\end{split}
\end{equation*}
NOTE : The notation \(\Delta \xi_{n+1} = \Delta t \xi_{n+1}\) is often used in the litterature. The choice here is to preserve the distinction between the two quantities, mainly because ot the possible use of adaptative time step : when the time step is changing, the value \(\xi_n\) has to be multiplied by the new time step, so that it is preferable to store \(\xi_n\) instead of \(\Delta \xi_{n}\) when using the \(\theta\)\sphinxhyphen{}scheme.


\subsection{Plane strain approximation}
\label{\detokenize{userdoc/model_plasticity_small_strain:plane-strain-approximation}}
A plane strain approximation is a 2D problem which corresponds to the deformation of a long cylindrical object where the strain in the length direction (assumed to be along the \(z\) axis) is considered small compared to the ones in the other directions and is neglected. It result in a plane strain tensor of the form
\begin{equation*}
\begin{split}\varepsilon(u) = \left(\hspace{-0.5em}\begin{array}{ccc} \varepsilon_{1,1} & \varepsilon_{1,2} & 0 \\ \varepsilon_{1,2} & \varepsilon_{2,2} & 0 \\ 0 & 0 & 0 \end{array}\hspace{-0.5em}\right).\end{split}
\end{equation*}
We denote
\begin{equation*}
\begin{split}\bar{\varepsilon}(u) =  \left(\hspace{-0.5em}\begin{array}{cc} \varepsilon_{1,1} & \varepsilon_{1,2} \\ \varepsilon_{1,2} & \varepsilon_{2,2} \end{array}\hspace{-0.5em}\right)\end{split}
\end{equation*}
the non neglected components of the strain tensor.
In the decomposition of plastic and elastic part of the strain tensor, we assume
\begin{equation*}
\begin{split}\varepsilon^p_{1,3} = \varepsilon^p_{2,3} = \varepsilon^e_{1,3} = \varepsilon^e_{2,3} = 0\end{split}
\end{equation*}
and
\begin{equation*}
\begin{split}\varepsilon^e_{3,3} + \varepsilon^p_{3,3} = \varepsilon_{3,3} = 0.\end{split}
\end{equation*}
The adaptation to the plane strain approximation to plastic model is most of the time an  easy task. An isotropic linearized elastic response reads
\begin{equation*}
\begin{split}\sigma = \lambda \mbox{tr}(\varepsilon(u)) I + 2\mu(\varepsilon(u) - \varepsilon^p),\end{split}
\end{equation*}
and thus
\begin{equation*}
\begin{split}\bar{\sigma} = \lambda \mbox{tr}(\bar{\varepsilon}(u)) \bar{I} + 2\mu(\bar{\varepsilon}(u) -\bar{\varepsilon}^p),\end{split}
\end{equation*}
The nonzero \(\sigma_{3,3}\) component of the stress tensor is given by
\begin{equation*}
\begin{split}\sigma_{3,3} = \lambda \mbox{tr}(\bar{\varepsilon}(u)) - 2\mu \varepsilon^p_{3,3}\end{split}
\end{equation*}
Note that in the common case where isochoric plastic strain is assumed, one has
\begin{equation*}
\begin{split}\mbox{ tr}(\varepsilon^p) = 0 ~~~~ \rm I\hspace{-0.15em}Rightarrow  ~~~ \varepsilon^p_{3,3} = - (\varepsilon^p_{1,1} + \varepsilon^p_{2,2}).\end{split}
\end{equation*}

\subsection{Plane stress approximation}
\label{\detokenize{userdoc/model_plasticity_small_strain:plane-stress-approximation}}
The plane stress approximation describe generally the 2D membrane deformation of a thin plate. It consist in prescribing the stress tensor to have only in\sphinxhyphen{}plane nonzero components, i.e.
\begin{equation*}
\begin{split}\sigma = \left(\hspace{-0.5em}\begin{array}{ccc} \sigma_{1,1} & \sigma_{1,2} & 0 \\ \sigma_{1,2} & \sigma_{2,2} & 0 \\ 0 & 0 & 0 \end{array}\hspace{-0.5em}\right).\end{split}
\end{equation*}
We will still denote
\begin{equation*}
\begin{split}\bar{\sigma} =  \left(\hspace{-0.5em}\begin{array}{cc} \sigma_{1,1} & \sigma_{1,2} \\ \sigma_{1,2} & \sigma_{2,2} \end{array}\hspace{-0.5em}\right)\end{split}
\end{equation*}
the in\sphinxhyphen{}plane components of the stress tensor. For elastoplasticity, it consists generally to apply the 2D plastic flow rule, prescribing the out\sphinxhyphen{}plane components of the stress tensor to be zero with the additionnal variables \(\varepsilon^e_{1,3}\), \(\varepsilon^e_{2,3}\), \(\varepsilon^e_{3,3}\) being unknown (see for instance \sphinxcite{biblio:so-pe-ow2008}).

For an isotropic linearized elastic response, one has \(\sigma = \lambda \mbox{tr}(\varepsilon^e) + 2\mu\varepsilon^e\) such that
\begin{equation*}
\begin{split}\varepsilon^e = \left(\hspace{-0.5em}\begin{array}{ccc} \varepsilon^e_{1,1} & \varepsilon^e_{1,2} & 0 \\ \varepsilon^e_{1,2} & \varepsilon^e_{2,2} & 0 \\ 0 & 0 & \varepsilon^e_{3,3} \end{array}\hspace{-0.5em}\right).\end{split}
\end{equation*}
with
\begin{equation*}
\begin{split}\varepsilon^e_{3,3} = -\dfrac{\lambda}{\lambda+2\mu}(\varepsilon^e_{1,1} + \varepsilon^e_{2,2})\end{split}
\end{equation*}
so that
\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:plane_stress_iso}
\begin{split}\bar{\sigma} = \lambda^* \mbox{tr}(\bar{\varepsilon}^e) + 2\mu\bar{\varepsilon}^e ~~~\mbox{ with } \lambda^* = \dfrac{2\mu\lambda}{\lambda+2\mu}\end{split}
\end{equation}
Moreover
\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:plane_stress_dev}
\begin{split}\|\mbox{Dev}(\sigma)\| = \left(\|\bar{\sigma}\|^2 - \dfrac{1}{3}(\mbox{tr}(\bar{\sigma}))^2\right)^{1/2}.\end{split}
\end{equation}
Note that in the case where isochoric plastic strain is assumed, one still has
\begin{equation*}
\begin{split}\mbox{ tr}(\varepsilon^p) = 0 ~~~~ \rm I\hspace{-0.15em}Rightarrow  ~~~ \varepsilon^p_{3,3} = - (\varepsilon^p_{1,1} + \varepsilon^p_{2,2}).\end{split}
\end{equation*}

\section{Some classical laws}
\label{\detokenize{userdoc/model_plasticity_small_strain:some-classical-laws}}
Tresca : \(\rho(\sigma) \le \sigma_y\) where \(\rho(\sigma)\) spectral radius of the Cauchy stress tensor and \(\sigma_y\) the uniaxial yield stress (which may depend on some hardening internal variables).

Von Mises :  \(\|\mbox{Dev}(\sigma)\| \le \sqrt{\frac{2}{3}}\sigma_y\) where
\(\mbox{Dev}(\sigma) = \sigma - \frac{1}{3}\mbox{tr}(\sigma)I\) the deviatoric part of \(\sigma\) and \(\|\sigma\| = \sqrt{\sigma:\sigma}\).


\subsection{Perfect isotropic associated elastoplasticity with Von\sphinxhyphen{}Mises criterion (Prandl\sphinxhyphen{}Reuss model)}
\label{\detokenize{userdoc/model_plasticity_small_strain:perfect-isotropic-associated-elastoplasticity-with-von-mises-criterion-prandl-reuss-model}}
There is no internal variables and we consider an isotropic elastic response. The flow rule reads
\begin{equation*}
\begin{split}\dot{\varepsilon}^p = \gamma \dfrac{\mbox{Dev}(\sigma)}{\|\mbox{Dev}(\sigma)\|}\end{split}
\end{equation*}
This corresponds to \(\Psi(\sigma) = f(\sigma) = \|\mbox{Dev}(\sigma)\| - \sqrt{\frac{2}{3}}\sigma_y\).

The \(\theta\)\sphinxhyphen{}scheme for the integration of the plastic flow rule reads:
\begin{equation*}
\begin{split}\varepsilon^p_{n+1} - \varepsilon^p_{n} = (1-\theta)\alpha(\sigma_{n}) \Delta t \xi_n \dfrac{\mbox{Dev}(\sigma_{n})}{\|\mbox{Dev}(\sigma_{n})\|} + \theta\alpha(\sigma_{n+1}) \Delta t \xi_{n+1} \dfrac{\mbox{Dev}(\sigma_{n+1})}{\|\mbox{Dev}(\sigma_{n+1})\|}.\end{split}
\end{equation*}
Choosing the factor \(\alpha(\sigma_{n}) = \|\mbox{Dev}(\sigma_{n})\|\) and still with \(\xi_n = \dfrac{\gamma_n}{\alpha(\sigma_{n})}\) this gives the equation
\begin{equation*}
\begin{split}\varepsilon^p_{n+1} - \varepsilon^p_{n} = (1-\theta)\Delta t \xi_n \mbox{Dev}(\sigma_{n}) + \theta \Delta t \xi_{n+1} \mbox{Dev}(\sigma_{n+1}).\end{split}
\end{equation*}
Since \(\mbox{Dev}(\sigma_{n+1}) = 2\mu\mbox{Dev}(\varepsilon(u_{n+1})) - 2\mu\varepsilon^p_{n+1}\) this directly gives:
\begin{equation*}
\begin{split}\tilde{\mathscr E}^p(u_{n+1}, \theta \Delta t \xi_{n+1}, \zeta_{n}) = \zeta_n + \left(1-\dfrac{1}{1+2\mu\theta\Delta t\xi_{n+1}}\right)(\mbox{Dev}(\varepsilon(u_{n+1})) - \zeta_n),\end{split}
\end{equation*}
which is a linear expression with respect to \(u_{n+1}\) (but not with respect to \(\xi_{n+1}\)).

Moreover, \(\zeta_n\) is defined by
\begin{equation*}
\begin{split}\zeta_n = \varepsilon^p_n+(1-\theta)\Delta t \xi_n (\mbox{Dev}(\sigma_n)) = \varepsilon^p_n+(1-\theta)\Delta t \xi_n 2\mu \left(\mbox{Dev}(\varepsilon(u_{n}))-\varepsilon^p_n\right).\end{split}
\end{equation*}
\sphinxstylestrong{Elimination of the multiplier (for the return mapping approach)}

One has
\begin{equation*}
\begin{split}\|\mbox{Dev}(\sigma_{n+1})\| = 2\mu\|\mbox{Dev}(\varepsilon(u_{n+1})) -\varepsilon^p_{n+1}\| = \dfrac{2\mu}{1+2\mu\theta\Delta t \xi_{n+1}}\|\mbox{Dev}(\varepsilon(u_{n+1})) - \zeta_n\|,\end{split}
\end{equation*}
Thus, denoting \(B = \mbox{Dev}(\varepsilon(u_{n+1})) - \zeta_n\), either
\begin{equation*}
\begin{split}2\mu\|B\| \le \sqrt{\frac{2}{3}}\sigma_y,\end{split}
\end{equation*}
and \(\xi_{n+1} = 0\), i.e. we are in the elastic case, or  \(\|\mbox{Dev}(\sigma_{n+1})\| =  \sqrt{\frac{2}{3}}\) and one obtains
\begin{equation*}
\begin{split}1+2\mu\theta\Delta t \xi_{n+1} = \dfrac{2\mu\|B\|}{\sqrt{\frac{2}{3}}\sigma_y},\end{split}
\end{equation*}
and thus
\begin{equation*}
\begin{split}\varepsilon^p_{n+1} = \zeta_n + \left( 1 - \sqrt{\frac{2}{3}}\dfrac{\sigma_y}{2\mu\|B\|}\right) B.\end{split}
\end{equation*}
The two options can be summarized by
\begin{equation*}
\begin{split}\varepsilon^p_{n+1} = {\mathscr E}^p(u_{n+1}, \zeta_{n}) = \zeta_n + \left( 1 - \sqrt{\frac{2}{3}}\dfrac{\sigma_y}{2\mu\|B\|}\right)_+ B.\end{split}
\end{equation*}
The multiplier \(\xi_{n+1}\) (needed for the \(\theta\)\sphinxhyphen{}scheme for \(\theta \ne 1\)) is given by
\begin{equation*}
\begin{split}\xi_{n+1} = \dfrac{1}{\theta\Delta t}\left(\sqrt{\frac{3}{2}}\dfrac{\|B\|}{\sigma_y} - \dfrac{1}{2\mu}\right)_+.\end{split}
\end{equation*}
\sphinxstylestrong{Plane strain approximation}

The plane strain approximation has the same expression replacing the 3D strain tensors by the in\sphinxhyphen{}plane ones \(\bar{\varepsilon}^p\) and  \(\bar{\varepsilon}(u_{n+1})\).
\begin{equation*}
\begin{split}\bar{\tilde{\mathscr E}}^p(u_{n+1}, \theta \Delta t \xi_{n+1}, \bar{\zeta}_{n}) = \bar{\zeta}_n + \left(1-\dfrac{1}{1+2\mu\theta\Delta t\xi_{n+1}}\right)(\overline{\mbox{Dev}}(\bar{\varepsilon}(u_{n+1})) - \bar{\zeta}_n),\end{split}
\end{equation*}
where \(\overline{\mbox{Dev}}(\bar{\varepsilon}) = \bar{\varepsilon} - \dfrac{\mbox{tr}(\bar{\varepsilon})}{3} \bar{I}\) is the 2D restriction of the 3D deviator.

Moreover, for the yield condition,
\begin{equation*}
\begin{split}\|\mbox{Dev}(\sigma)\|^2 = 4\mu^2\left(\|\overline{\mbox{Dev}}\bar{\varepsilon}(u) - \bar{\varepsilon}^p\|^2 + \left(\dfrac{\mbox{tr}(\bar{\varepsilon}(u))}{3} -\mbox{tr}(\bar{\varepsilon}^p) \right)^2\right).\end{split}
\end{equation*}
And for the elimination of the multiplier,
\begin{equation*}
\begin{split}\bar{\mathscr E}^p(\bar{u}_{n+1}, \bar{\varepsilon}^p_{n}) = \bar{\zeta}^p_{n} + \left( 1 - \sqrt{\frac{2}{3}}\dfrac{\sigma_y}{2\mu\|B\|}\right)_+ \bar{B}\end{split}
\end{equation*}
with \(\bar{B} = \overline{\mbox{Dev}}(\bar{\varepsilon}(u_{n+1}))-\bar{\zeta}_{n}\) and \(\|B\|^2 = \|\overline{\mbox{Dev}}(\bar{\varepsilon}(u_{n+1})) - \bar{\zeta}_n\|^2 + \left(\dfrac{\mbox{tr}(\bar{\varepsilon}(u_{n+1}))}{3} -\mbox{tr}(\bar{\zeta}_n) \right)^2\).

\sphinxstylestrong{Plane stress approximation}

For plane stress approximation, using \eqref{equation:userdoc/model_plasticity_small_strain:plane_stress_iso} we deduce from the expression of the 3D case
\begin{equation*}
\begin{split}\bar{\varepsilon}^p_{n+1} = \dfrac{1}{1+2\mu\theta\Delta \xi}\left(\bar{\zeta}_{n} +2\mu\theta\Delta \xi\left(\bar{\varepsilon}(u_{n+1}) - \dfrac{2\mu}{3(\lambda+2\mu)}(\mbox{tr}(\bar{\varepsilon}(u_{n+1})) - \mbox{tr}(\bar{\varepsilon}_{n+1}^p))\bar{I}\right) \right),\end{split}
\end{equation*}
since \(\mbox{Dev}(\varepsilon(u)) = \varepsilon(u) - \dfrac{2\mu}{3(\lambda+2\mu)}(\mbox{tr}(\bar{\varepsilon}(u)) - \mbox{tr}(\bar{\varepsilon}^p))\). Of course, this relation still has to be inverted. Denoting \(\alpha = 1+2\mu\theta\Delta \xi\), \(\beta = \dfrac{4\mu^2\theta\Delta \xi}{3\lambda+6\mu}\) and \(C = \bar{\zeta}_{n} +2\mu\theta\Delta \xi\left(\bar{\varepsilon}(u_{n+1}) - \dfrac{2\mu}{3(\lambda+2\mu)}(\mbox{tr}(\bar{\varepsilon}(u_{n+1}))))\bar{I}\right)\) one obtains
\begin{equation*}
\begin{split}\bar{\varepsilon}^p_{n+1} = \dfrac{\beta \mbox{tr}(C)}{\alpha(\alpha-2\beta)}\bar{I} + \dfrac{1}{\alpha}C.\end{split}
\end{equation*}
Moreover, for the yield condition, expression \eqref{equation:userdoc/model_plasticity_small_strain:plane_stress_dev} can be used.


\subsection{Isotropic elastoplasticity with linear isotropic and kinematic hardening and Von\sphinxhyphen{}Mises criterion}
\label{\detokenize{userdoc/model_plasticity_small_strain:isotropic-elastoplasticity-with-linear-isotropic-and-kinematic-hardening-and-von-mises-criterion}}
We consider an isotropic elastic reponse and the internal variable \(\alpha : \Omega \rightarrow \rm I\hspace{-0.15em}R\) being the accumulated plastic strain which satisfies
\begin{equation*}
\begin{split}\dot{\alpha} = \sqrt{\dfrac{2}{3}}\gamma\end{split}
\end{equation*}
For \(H_i\) the isotropic hardening modulus, the linear hardening consists in
\begin{equation*}
\begin{split}\psi^p(\alpha) = \frac{1}{2}H_i\alpha^2\end{split}
\end{equation*}
i.e. \(A = H_i\alpha\) and a uniaxial yield stress defined by
\begin{equation*}
\begin{split}\sigma_y(a) = \sigma_{y0} + A = \sigma_{y0} + H_i\alpha,\end{split}
\end{equation*}
for \(\sigma_{y0}\) the initial uniaxial yield stress. The yield function (and plastic potential since this is an associated plastic model) can be defined by
\begin{equation*}
\begin{split}\Psi(\sigma, A) = f(\sigma, A) = \|\mbox{Dev}(\sigma - \frac{2}{3}H_k\varepsilon^p)\| - \sqrt{\frac{2}{3}}(\sigma_{y0} + A),\end{split}
\end{equation*}
where \(H_k\) is the kinematic hardening modulus. The same computation as in the previous section leads to
\begin{equation*}
\begin{split}\tilde{\mathscr E}^p(u_{n+1}, \theta\Delta t \xi_{n+1}, \zeta_n) = \zeta_n + \dfrac{1}{2(\mu+H_k/3)}\left(1 - \dfrac{1}{1+2(\mu+H_k/3)\theta\Delta t\xi_{n+1}}\right)(2\mu\mbox{Dev}(\varepsilon(u_{n+1}))-2(\mu+H_k/3)\zeta_n)\end{split}
\end{equation*}\begin{equation*}
\begin{split}\begin{array}{rcl} \tilde{\mathscr A}(u_{n+1}, \theta \Delta t \xi_{n+1}, \zeta_{n}, \eta_n) &=& \eta_n + \sqrt{\dfrac{2}{3}} \theta \Delta t \xi_{n+1}\|\mbox{Dev}(\sigma_{n+1} - \frac{2}{3}H_k\varepsilon^p_{n+1})\| \\ &=& \eta_n + \sqrt{\dfrac{2}{3}} \theta \Delta t \xi_{n+1}\|2\mu\mbox{Dev}(\varepsilon(u_{n+1})) - 2(\mu+H_k/3)\varepsilon^p_{n+1}\| \\ &=&  \eta_n + \sqrt{\dfrac{2}{3}} \dfrac{\theta \Delta t \xi_{n+1}}{1+2(\mu+H_k/3)\theta\Delta t\xi_{n+1}}\|2\mu\mbox{Dev}(\varepsilon(u_{n+1})) - 2(\mu+H_k/3)\zeta_{n}\| \\ &=& \eta_n + \sqrt{\dfrac{2}{3}}\dfrac{1}{2(\mu+H_k/3)}\left(1 - \dfrac{1}{1+2(\mu+H_k/3)\theta\Delta t\xi_{n+1}}\right) \|2\mu\mbox{Dev}(\varepsilon(u_{n+1})) - 2(\mu+H_k/3)\zeta_{n}\|\end{array}\end{split}
\end{equation*}
where \(\zeta_n\) and \(\eta_n\) are defined by
\begin{equation*}
\begin{split}\zeta_n = \varepsilon^p_n+(1-\theta)\Delta t \xi_n (\mbox{Dev}(\sigma_n)-\frac{2}{3}H_k\varepsilon^n_p) = \varepsilon^p_n+(1-\theta)\Delta t \xi_n \left(2\mu\mbox{Dev}(\varepsilon(u_{n}))-2(\mu+H_k/3)\varepsilon^n_p\right),\end{split}
\end{equation*}\begin{equation*}
\begin{split}\eta_n  = \alpha_n+(1-\theta)\sqrt{\dfrac{2}{3}}\Delta t \xi_n \|\mbox{Dev}(\sigma_n)-\frac{2}{3}H_k\varepsilon^n_p\| =  \alpha_n+(1-\theta)\sqrt{\dfrac{2}{3}}\Delta t \xi_n \|2\mu\mbox{Dev}(\varepsilon(u_{n}))-2(\mu+H_k/3)\varepsilon^n_p\|.\end{split}
\end{equation*}
Note that the isotropic hardening modulus do not intervene in \(\tilde{\mathscr E}^p(u_{n+1}, \theta \Delta \xi, \varepsilon^p_{n})\) but only in \(f(\sigma, A)\).

\sphinxstylestrong{Elimination of the multiplier (for the return mapping approach)}

Denoting \(\delta = \dfrac{1}{1+2(\mu+H_k/3)\theta\Delta t\xi_{n+1}}\), \(\beta = \dfrac{1-\delta}{2(\mu+H_k/3)}\) and \(B = 2\mu\mbox{Dev}(\varepsilon(u_{n+1}))-2(\mu+H_k/3)\zeta_n\) the expression for \(\varepsilon^p_{n+1}\) and \(\alpha_{n+1}\) becomes
\begin{equation}\label{equation:userdoc/model_plasticity_small_strain:hardeningepsalp}
\begin{split}\varepsilon^p_{n+1} = \zeta_n+\beta B, ~~~ \alpha_{n+1} = \eta_n + \sqrt{\dfrac{2}{3}}\beta \|B\|,\end{split}
\end{equation}
and the plastic constraint
\begin{equation*}
\begin{split}\delta \|B\| \le \sqrt{\dfrac{2}{3}}(\sigma_{y0}+H_i \alpha_{n+1}).\end{split}
\end{equation*}
Thus, either we are in the elastic case, i.e. \(\xi_{n+1} = 0, \delta = 1\) and
\begin{equation*}
\begin{split}\|B\| \le \sqrt{\dfrac{2}{3}}(\sigma_{y0}+H_i \eta_n),\end{split}
\end{equation*}
or we are in the plastic case and \(\xi_{n+1} > 0, \delta < 1\), \(\delta \|B\| = \sqrt{\dfrac{2}{3}}(\sigma_{y0}+H_i \alpha_{n+1})\) and \((1-\delta)\) solves the equation
\begin{equation*}
\begin{split}\|B\| - (1-\delta)\|B\| = \sqrt{\dfrac{2}{3}}\left(\sigma_{y0}+H_i \eta_n + \sqrt{\dfrac{2}{3}} \dfrac{H_i}{2(\mu+H_k/3)}(1-\delta)\|B\|\right),\end{split}
\end{equation*}
which leads to
\begin{equation*}
\begin{split}1-\delta = \dfrac{2(\mu+H_k/3)}{\|B\|(2\mu+\frac{2}{3}(H_k+H_i))}\left(\|B\|-\sqrt{\dfrac{2}{3}}(\sigma_{y0}+H_i \eta_n) \right)\end{split}
\end{equation*}
The two cases can be summarized by
\begin{equation*}
\begin{split}\beta = \dfrac{1}{\|B\|(2\mu+\frac{2}{3}(H_k+H_i))}\left(\|B\|-\sqrt{\dfrac{2}{3}}(\sigma_{y0}+H_i \eta_n) \right)_+\end{split}
\end{equation*}
which directly gives \({\mathscr E}^p(u_{n+1}, \zeta_n, \eta_n)\) and \({\mathscr A}(u_{n+1}, \zeta_n, \eta_n)\) thanks to \eqref{equation:userdoc/model_plasticity_small_strain:hardeningepsalp}. The multiplier \(\xi_{n+1}\) being given by
\begin{equation*}
\begin{split}\xi_{n+1} = \dfrac{1}{(2(\mu+H_k/3))\theta\Delta t}(\dfrac{1}{\delta}-1) = \dfrac{1}{\theta\Delta t}~\dfrac{\beta}{1-2(\mu+H_k/3)\beta}.\end{split}
\end{equation*}
\sphinxstylestrong{Plane strain approximation}

Still denoting  \(\delta = \dfrac{1}{1+2(\mu+H_k/3)\theta\Delta t\xi_{n+1}}\), \(\beta = \dfrac{1-\delta}{2(\mu+H_k/3)}\), \(B = 2\mu\mbox{Dev}(\varepsilon(u_{n+1}))-2(\mu+H_k/3)\zeta_n\) and \(\overline{B} = 2\mu\overline{Dev}(\bar{\varepsilon}(u_{n+1}))-2(\mu+H_k/3)\bar{\zeta}_n\) its in\sphinxhyphen{}plane part, one has
\begin{equation*}
\begin{split}\bar{\tilde{\mathscr E}}^p(u_{n+1}, \theta\Delta t \xi_{n+1}, \bar{\zeta}_n) = \bar{\zeta}_n + \beta \overline{B},\end{split}
\end{equation*}\begin{equation*}
\begin{split}\tilde{\mathscr A}(u_{n+1}, \theta \Delta t \xi_{n+1}, \zeta_{n}, \eta_n) = \eta_n + \sqrt{\dfrac{2}{3}}\beta\|B\|,\end{split}
\end{equation*}
with
\begin{equation*}
\begin{split}\|B\|^2 = \|2\mu\overline{\mbox{Dev}}(\bar{\varepsilon}(u_{n+1})) - 2(\mu+H_k/3)\bar{\zeta}_n\|^2 + \left(2\mu\dfrac{\mbox{tr}(\bar{\varepsilon}(u_{n+1}))}{3} -2(\mu+H_k/3)\mbox{tr}(\bar{\zeta}_n) \right)^2.\end{split}
\end{equation*}
The yield condition still reads
\begin{equation*}
\begin{split}\delta \|B\| \le \sqrt{\dfrac{2}{3}}(\sigma_{y0}+H_i \alpha_{n+1}).\end{split}
\end{equation*}
and for the elimination of the multiplier, \(\beta\) has the same expression as in the previous section adapting the value of \(\|B\|\). The expressions of \(\bar{\zeta}_n\) and \(\eta_n\) have to be adapted accoringly.


\subsection{Souza\sphinxhyphen{}Auricchio elastoplasticity law (for shape memory alloys)}
\label{\detokenize{userdoc/model_plasticity_small_strain:souza-auricchio-elastoplasticity-law-for-shape-memory-alloys}}
See for instance \sphinxcite{biblio:gr-st2015} for the justification of the construction of this flow rule. A Von\sphinxhyphen{}Mises stress criterion together with an isotropic elastic response, no internal variables and a special type of kinematic hardening is considered with a constraint \(\|\varepsilon^p\| \le c_3\). The plastic potential and yield function have the form
\begin{equation*}
\begin{split}\Psi(\sigma) = f(\sigma)  = \left\|\mbox{Dev}\left(\sigma - c_1\dfrac{\varepsilon^p}{\|\varepsilon^p\|} - c_2\varepsilon^p - \delta \dfrac{\varepsilon^p}{\|\varepsilon^p\|}\right)\right\| - \sqrt{\frac{2}{3}}\sigma_{y},\end{split}
\end{equation*}
with the complementarity condition
\begin{equation*}
\begin{split}\delta \ge 0, \|\varepsilon^p\| \le c_3,  \delta (\|\varepsilon^p\|-c_3) = 0,\end{split}
\end{equation*}
where \(c_1, c_2 \mbox{ and } c_3\) are some physical parameters. Note that \(\dfrac{\varepsilon^p}{\|\varepsilon^p\|}\) has to be understood to be the whole unit ball for \(\varepsilon^p = 0\).

to be done …


\section{Elasto\sphinxhyphen{}plasticity bricks}
\label{\detokenize{userdoc/model_plasticity_small_strain:elasto-plasticity-bricks}}
See the test programs \sphinxcode{\sphinxupquote{tests/plasticity.cc}}, \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_plasticity.m}}, \sphinxcode{\sphinxupquote{interface/tests/matlab/demo\_plasticity.py}} and in \sphinxcode{\sphinxupquote{contrib/test\_plasticity}}.


\subsection{Generic brick}
\label{\detokenize{userdoc/model_plasticity_small_strain:generic-brick}}
There are two versions of the generic brick. A first one when the plastic multiplier is kept as a variable of the problem where the added term is of the form:
\begin{equation*}
\begin{split}\int_{\Omega} \sigma_{n+1} : \nabla \delta u dx +   \int_{\Omega} (\xi_{n+1} - (\xi_{n+1} + r f(\sigma_{n+1}, A_{n+1}))_+) \delta\xi dx = 0,\end{split}
\end{equation*}
with \(r > 0\) having a specific value chosen by the brick (in terms of the elasticity coefficients), and when the return mapping strategy is selected (plastic multiplier is just a data), just the added term:
\begin{equation*}
\begin{split}\int_{\Omega} \sigma_{n+1} : \nabla v dx.\end{split}
\end{equation*}
The function which adds the brick to a model \sphinxtitleref{md} is

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}small\PYGZus{}strain\PYGZus{}elastoplasticity\PYGZus{}brick}
  \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{lawname}\PYG{p}{,} \PYG{n}{unknowns\PYGZus{}type}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZam{}}\PYG{n}{varnames}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZam{}}\PYG{n}{params}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxtitleref{lawname} is the name of an implemented plastic law, \sphinxtitleref{unknowns\_type}
indicates the choice between a discretization where the plastic multiplier
is an unknown of the problem or (return mapping approach) just a data of
the model stored for the next iteration. Remember that in both cases, a
multiplier is stored anyway. \sphinxtitleref{varnames} is a set of variable and data
names with length which may depend on the plastic law (at least the
displacement, the plastic multiplier and the plastic strain).
\sphinxtitleref{params} is a list of expressions for the parameters (at least elastic
coefficients and the yield stress). These expressions can be some data
names (or even variable names) of the model but can also be any scalar
valid expression of GWFL, the generic weak form language (such as “1/2”,
“2+sin(X{[}0{]})”, “1+Norm(v)” …). The last two parameters optionally
provided in \sphinxtitleref{params} are the \sphinxtitleref{theta} parameter of the \sphinxtitleref{theta}\sphinxhyphen{}scheme
(generalized trapezoidal rule) used for the plastic strain integration
and the time\sphinxhyphen{}step\textasciigrave{}dt\textasciigrave{}. The default value for \sphinxtitleref{theta} if omitted is 1,
which corresponds to the classical Backward Euler scheme which is first
order consistent. \sphinxtitleref{theta=1/2} corresponds to the Crank\sphinxhyphen{}Nicolson scheme
(trapezoidal rule) which is second order consistent. Any value
between 1/2 and 1 should be a valid value. The default value of \sphinxtitleref{dt} is
‘timestep’ which simply indicates the time step defined in the model
(by md.set\_time\_step(dt)). Alternatively it can be any expression
(data name, constant value …). The time step can be altered from one
iteration to the next one. \sphinxtitleref{region} is a mesh region.

The available plasticity laws are:
\begin{itemize}
\item {} 
“Prandtl Reuss” (or “isotropic perfect plasticity”).
Isotropic elasto\sphinxhyphen{}plasticity with no hardening. The variables are the
displacement, the plastic multiplier and the plastic strain.
The displacement should be a variable and have a corresponding data
having the same name preceded by “Previous\_” corresponding to the
displacement at the previous time step (typically “u” and “Previous\_u”).
The plastic multiplier should also have two versions (typically “xi”
and “Previous\_xi”) the first one being defined as data if
\sphinxtitleref{unknowns\_type = DISPLACEMENT\_ONLY} or as a variable if
\sphinxtitleref{unknowns\_type = DISPLACEMENT\_AND\_PLASTIC\_MULTIPLIER}.
The plastic strain should represent a n x n data tensor field stored
on mesh\_fem or (preferably) on an im\_data (corresponding to \sphinxtitleref{mim}).
The data are the first Lame coefficient, the second one (shear modulus)
and the uniaxial yield stress. IMPORTANT: Note that this law implements
the 3D expressions. If it is used in 2D, the expressions are just
transposed to the 2D. For the plane strain approximation, see below.

\item {} 
“plane strain Prandtl Reuss”
(or “plane strain isotropic perfect plasticity”)
The same law as the previous one but adapted to the plane strain
approximation. Can only be used in 2D.

\item {} 
“Prandtl Reuss linear hardening”
(or “isotropic plasticity linear hardening”).
Isotropic elasto\sphinxhyphen{}plasticity with linear isotropic and kinematic
hardening. An additional variable compared to “Prandtl Reuss” law:
the accumulated plastic strain. Similarly to the plastic strain, it
is only stored at the end of the time step, so a simple data is
required (preferably on an im\_data).
Two additional parameters: the kinematic hardening modulus and the
isotropic one. 3D expressions only.

\item {} 
“plane strain Prandtl Reuss linear hardening”
(or “plane strain isotropic plasticity linear hardening”).
The same law as the previous one but adapted to the plane strain
approximation. Can only be used in 2D.

\end{itemize}

IMPORTANT : remember that \sphinxtitleref{small\_strain\_elastoplasticity\_next\_iter} has
to be called at the end of each time step, before the next one
(and before any post\sphinxhyphen{}treatment : this sets the value of the plastic
strain and plastic multiplier).

Additionaly, the following function allow to pass from a time step to another for the small strain plastic brick:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{small\PYGZus{}strain\PYGZus{}elastoplasticity\PYGZus{}next\PYGZus{}iter}
  \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{lawname}\PYG{p}{,} \PYG{n}{unknowns\PYGZus{}type}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZam{}}\PYG{n}{varnames}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZam{}}\PYG{n}{params}\PYG{p}{,} \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

The parameters have to be exactly the same as the ones of the
\sphinxtitleref{add\_small\_strain\_elastoplasticity\_brick},  so see the documentation of
this function for any explanations.
Basically, this brick computes the plastic strain and the plastic
multiplier and stores them for the next step. Additionaly, it copies
the computed displacement to the data that stores the displacement
of the previous time step (typically “u” to “Previous\_u”).
It has to be called before any use of
\sphinxtitleref{compute\_small\_strain\_elastoplasticity\_Von\_Mises}.

The function

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}small\PYGZus{}strain\PYGZus{}elastoplasticity\PYGZus{}Von\PYGZus{}Mises}
  \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{lawname}\PYG{p}{,} \PYG{n}{unknowns\PYGZus{}type}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZam{}}\PYG{n}{varnames}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{vector}\PYG{o}{\PYGZlt{}}\PYG{n}{std}\PYG{o}{:}\PYG{o}{:}\PYG{n}{string}\PYG{o}{\PYGZgt{}} \PYG{o}{\PYGZam{}}\PYG{n}{params}\PYG{p}{,}
   \PYG{k}{const} \PYG{n}{mesh\PYGZus{}fem} \PYG{o}{\PYGZam{}}\PYG{n}{mf\PYGZus{}vm}\PYG{p}{,} \PYG{n}{model\PYGZus{}real\PYGZus{}plain\PYGZus{}vector} \PYG{o}{\PYGZam{}}\PYG{n}{VM}\PYG{p}{,}
   \PYG{n}{region} \PYG{o}{=} \PYG{n}{size\PYGZus{}type}\PYG{p}{(}\PYG{l+m+mi}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

computes the Von Mises stress field with respect to
a small strain elastoplasticity term, approximated on \sphinxtitleref{mf\_vm},
and stores the result into \sphinxtitleref{VM}.  All other parameters have to be
exactly the same as for \sphinxtitleref{add\_small\_strain\_elastoplasticity\_brick}.
Remember that \sphinxtitleref{small\_strain\_elastoplasticity\_next\_iter} has to be called
before any call of this function.


\subsection{A specific brick based on the low\sphinxhyphen{}level generic assembly for perfect plasticity}
\label{\detokenize{userdoc/model_plasticity_small_strain:a-specific-brick-based-on-the-low-level-generic-assembly-for-perfect-plasticity}}
This is an previous version of a elastoplasticity brick which is restricted to  isotropic perfect plasticity and is based on the low\sphinxhyphen{}level generic assembly. Its specificity which could be interesting for testing is that the flow rule is integrated on  finite element nodes (not on Gauss points).

The function adding this brick to a model is:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{add\PYGZus{}elastoplasticity\PYGZus{}brick}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{ACP}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{previous\PYGZus{}varname}\PYG{p}{,} \PYG{n}{datalambda}\PYG{p}{,} \PYG{n}{datamu}\PYG{p}{,} \PYG{n}{datathreshold}\PYG{p}{,} \PYG{n}{datasigma}\PYG{p}{,} \PYG{n}{region}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}
\begin{description}
\item[{where:}] \leavevmode\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{varname}} represents the main displacement unknown on which the brick is added (u).

\item {} 
\sphinxcode{\sphinxupquote{previous\_varname}} is the displacement at the previous time step.

\item {} 
\sphinxcode{\sphinxupquote{datalambda}} and \sphinxcode{\sphinxupquote{datamu}} are the data corresponding to the Lame coefficients.

\item {} 
\sphinxcode{\sphinxupquote{datathreshold}} represents the plastic threshold of the studied material.

\item {} 
\sphinxcode{\sphinxupquote{datasigma}} represents the stress constraint values supported by the material. It should be composed of 2 iterates for the time scheme needed for the Newton algorithm used. Note that the finite element method on which \sphinxcode{\sphinxupquote{datasigma}} is defined should be able to represent the derivative of \sphinxcode{\sphinxupquote{varname}}.

\item {} 
\sphinxcode{\sphinxupquote{ACP}} corresponds to the type of projection to be used. It has an \sphinxtitleref{abstract\_constraints\_projection} type and for the moment, only exists the \sphinxtitleref{VM\_projection} corresponding to the Von Mises one.

\end{itemize}

\end{description}

Be careful: \sphinxcode{\sphinxupquote{datalambda}}, \sphinxcode{\sphinxupquote{datamu}} and \sphinxcode{\sphinxupquote{datathreshold}} could be constants or described on the same finite element method.

This function assembles the tangent matrix and the right hand side vector which will be solved using a Newton algorithm.

Additionaly, The function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{elastoplasticity\PYGZus{}next\PYGZus{}iter}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{previous\PYGZus{}varname}\PYG{p}{,} \PYG{n}{ACP}\PYG{p}{,} \PYG{n}{datalambda}\PYG{p}{,} \PYG{n}{datamu}\PYG{p}{,} \PYG{n}{datathreshold}\PYG{p}{,} \PYG{n}{datasigma}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

computes the new stress constraint values supported by the material after a load or an unload (once a solve has been done earlier) and upload the variables \sphinxcode{\sphinxupquote{varname}} and \sphinxcode{\sphinxupquote{datasigma}} as follows:
\begin{equation*}
\begin{split}u^{n+1} \rm I\hspace{-0.15em}Rightarrow u^n \ \ \ \ \ \textrm{ and } \ \ \ \ \ \sigma^{n+1} \rm I\hspace{-0.15em}Rightarrow \sigma^n\end{split}
\end{equation*}
Then, \(u^n\) and \(\sigma^n\) contains the new values computed and one can restart the process.

The function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}elastoplasticity\PYGZus{}Von\PYGZus{}Mises\PYGZus{}or\PYGZus{}Tresca}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{datasigma}\PYG{p}{,} \PYG{n}{mf\PYGZus{}vm}\PYG{p}{,} \PYG{n}{VM}\PYG{p}{,} \PYG{n}{tresca}\PYG{o}{=}\PYG{n+nb}{false}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

computes the Von Mises (or Tresca if \sphinxcode{\sphinxupquote{tresca}} = true) criterion on the stress tensor stored in \sphinxcode{\sphinxupquote{datasigma}} . The stress is evaluated on the \sphinxtitleref{mesh\_fem} \sphinxcode{\sphinxupquote{mf\_vm}} and stored into the vector \sphinxcode{\sphinxupquote{VM}}.
Of course, this function can be used if and only if the previous function \sphinxcode{\sphinxupquote{elastoplasticity\_next\_iter}} has been called earlier.

The function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{compute\PYGZus{}plastic\PYGZus{}part}
    \PYG{p}{(}\PYG{n}{md}\PYG{p}{,} \PYG{n}{mim}\PYG{p}{,} \PYG{n}{mf\PYGZus{}pl}\PYG{p}{,} \PYG{n}{varname}\PYG{p}{,} \PYG{n}{previous\PYGZus{}varname}\PYG{p}{,} \PYG{n}{ACP}\PYG{p}{,} \PYG{n}{datalambda}\PYG{p}{,} \PYG{n}{datamu}\PYG{p}{,} \PYG{n}{datathreshold}\PYG{p}{,} \PYG{n}{datasigma}\PYG{p}{,} \PYG{n}{Plast}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

computes on \sphinxcode{\sphinxupquote{mf\_pl}} the plastic part of the material, that could appear after a load and an unload, into the vector \sphinxcode{\sphinxupquote{Plast}}.

Note that \sphinxcode{\sphinxupquote{datasigma}} should be the vector containing the new stress constraint values, i.e. after a load or an unload of the material.

\index{models@\spxentry{models}}\index{model bricks@\spxentry{model bricks}}\ignorespaces 

\chapter{ALE Support for object having a large rigid body motion}
\label{\detokenize{userdoc/model_ALE_rotating:ale-support-for-object-having-a-large-rigid-body-motion}}\label{\detokenize{userdoc/model_ALE_rotating:ud-model-ale-rotating}}\label{\detokenize{userdoc/model_ALE_rotating:index-0}}\label{\detokenize{userdoc/model_ALE_rotating::doc}}

\section{ALE terms for rotating objects}
\label{\detokenize{userdoc/model_ALE_rotating:ale-terms-for-rotating-objects}}
This section present a set of bricks facilitating the use of an ALE formulation for rotating bodies having a rotational symmetry (typically a train wheel).


\subsection{Theoretical background}
\label{\detokenize{userdoc/model_ALE_rotating:theoretical-background}}
This strategy consists in adopting an intermediary description between an Eulerian and a Lagrangian ones for a rotating body having a rotational symmetry. This intermediary description consist in a rotating axes with respect to the reference configuration. See for instance \sphinxcite{biblio:dr-la-ek2014} and \sphinxcite{biblio:nackenhorst2004}.

It is supposed that the considered body is submitted approximately to a rigid body motion
\begin{equation*}
\begin{split}\tau(X) = R(t)X + Z(t)\end{split}
\end{equation*}
and may have additonal deformation (exptected smaller) with respect to this rigid motion, where \(R(t)\) is a rotation matrix
\begin{equation*}
\begin{split}R(t) = \left(\begin{array}{ccc}
\cos(\theta(t)) & \sin(\theta(t)) & 0 \\
-\sin(\theta(t)) & \cos(\theta(t)) & 0 \\
0 & 0 & 1
\end{array} \right),\end{split}
\end{equation*}
and \(Z(t)\) is a translation. Note that, in order to be consistent with a positive translation for a positive angle for a rolling contact, the rotation is \sphinxstylestrong{clockwise}. This illustrated in the following figure:

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=0.400\linewidth]{{ALE_rotating_body}.png}
\end{figure}

Note that the description is given for a three\sphinxhyphen{}dimensional body. For two\sphinxhyphen{}dimensional bodies, the third axes is neglected so that \(R(t)\) is a \(2\times 2\) rotation matrix. Let us denote \(r(t)\) the rotation:
\begin{equation*}
\begin{split}r(t,X) = R(t)X, ~~~~~~~~~ \mbox{ and }
A = \left(\begin{array}{ccc}
0 & 1 & 0 \\
-1 & 0 & 0 \\
0 & 0 & 0
\end{array} \right).\end{split}
\end{equation*}
We have then
\begin{equation*}
\begin{split}\dot{r}(t,X) = \dot{\theta}AR(t)X\end{split}
\end{equation*}
If \(\varphi(t, X)\) is the deformation of the body which maps the reference configuration \(\Omega^0\) to the deformed configuration \(\Omega_t\) at time \(t\), the ALE description consists in the decomposition of the deformation of the cylinder in
\begin{equation*}
\begin{split}\varphi(t, X) = (\tau(t) \circ \bar{\varphi}(t) \circ r(t))(X) = \bar{\varphi}(t, r(t, X)) + Z(t)\end{split}
\end{equation*}
With \(\bar{X} = R(t)X\) the new considered deformation is
\begin{equation*}
\begin{split}\bar{\varphi}(t,\bar{X}) = \varphi(X) - Z(t)\end{split}
\end{equation*}
Thanks to the rotation symmetry of the reference configuration \(\Omega^0:\), we note that \(\bar{\Omega}^0 = r(t, \Omega^0)\) is independant of \(t\) and will serve as the new reference configuration. This is illustrated in the following figure:

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=0.800\linewidth]{{ALE_rotating_conf}.png}
\end{figure}

The denomination ALE of the method is justified by the fact that \(\bar{\Omega}^0\) is an intermediate configuration which is of Euler type for the rigid motion and a Lagrangian one for the additional deformation of the solid. If we denote
\begin{equation*}
\begin{split}\bar{u}(t,\bar{X}) = \bar{\varphi}(t, \bar{X}) - \bar{X}\end{split}
\end{equation*}
the displacement with respect to this intermediate configuration, the advantage is that if this additional displacement with respect to the rigid body motion is small, it is possible to use a small deformation model (for instance linearized elasticity).

Due to the objectivity properties of standard constitutive laws, the expression of these laws in the intermediate configuration is most of the time identical to the expression in a standard reference configuration except for the expression of the time derivative which are modified because the change of coordinate is  nonconstant in time :
\begin{align*}\!\begin{aligned}
\dfrac{\partial \varphi}{\partial t} = \dfrac{\partial \bar{\varphi}}{\partial t} + \dot{\theta} \nabla \bar{\varphi} A \bar{X} + \dot{Z}(t),\\
\dfrac{\partial^2 \varphi}{\partial t^2} = \dfrac{\partial^2 \bar{\varphi}}{\partial t^2} + 2\dot{\theta} \nabla\dfrac{\partial \bar{\varphi}}{\partial t}A \bar{X} + \dot{\theta}^2\mbox{div}((\nabla\bar{\varphi}A \bar{X}) \otimes (A \bar{X}) )  + \ddot{\theta}\nabla\bar{\varphi}A \bar{X} + \ddot{Z}(t).\\
\end{aligned}\end{align*}
Note that the term \(\dot{\theta} A \bar{X} = \left(\hspace*{-0.5em}\begin{array}{c} \dot{\theta}\bar{X}_2 \\ -\dot{\theta}\bar{X}_1 \\ 0 \end{array}\hspace*{-0.5em}\right)\) is the rigid motion velocity vector. Now, If \(\Theta(t,X)\) is a quantity attached to the material points (for instance the temperature), then, with \(\bar{\Theta}(t,\bar{X}) = \Theta(t,X)\) , one simply has
\begin{equation*}
\begin{split}\dfrac{\partial \Theta}{\partial t} = \dfrac{\partial \bar{\Theta}}{\partial t} + \dot{\theta} \nabla \bar{\Theta} A \bar{X}\end{split}
\end{equation*}
This should not be forgotten that a correction has to be provided for each evolving variable for which the time derivative intervene in the considered model (think for instance to platic flow for plasticity). So that certain model bricks canot be used directly (plastic bricks for instance).

\sphinxstyleemphasis{GetFEM} bricks for structural mechanics are mainly considering the displacement as the amin unknown. The expression for the displacement is the following:
\begin{align*}\!\begin{aligned}
\dfrac{\partial u}{\partial t} = \dfrac{\partial \bar{u}}{\partial t} + \dot{\theta} (I_d + \nabla \bar{u}) A \bar{X} + \dot{Z}(t),\\
\dfrac{\partial^2 u}{\partial t^2} = \dfrac{\partial^2 \bar{u}}{\partial t^2} + 2\dot{\theta} \nabla\dfrac{\partial \bar{u}}{\partial t}A \bar{X} +  \dot{\theta}^2\mbox{div}(((I_d + \nabla\bar{u})A \bar{X}) \otimes (A \bar{X}) )  + \ddot{\theta} (I_d + \nabla\bar{u}) A \bar{X}  + \ddot{Z}(t).\\
\end{aligned}\end{align*}

\subsubsection{Weak formulation of the transient terms}
\label{\detokenize{userdoc/model_ALE_rotating:weak-formulation-of-the-transient-terms}}
Assuming \(\rho^0\) the density in the reference configuration having a rotation symmetry, the term corresponding to acceleration in the weak formulation reads (with \(v(X) = \bar{v}(\bar{X})\) a test function):
\begin{align*}\!\begin{aligned}
\int_{\Omega^0} \rho^0 \dfrac{\partial^2 u}{\partial t^2}\cdot vdX =\\
\int_{\bar{\Omega}^0} \rho^0 \left[\dfrac{\partial^2 \bar{u}}{\partial t^2} + 2\dot{\theta} \nabla\dfrac{\partial \bar{u}}{\partial t}A \bar{X} +  \dot{\theta}^2\mbox{div}(((I_d + \nabla\bar{u})A \bar{X}) \otimes (A \bar{X}) )  + \ddot{\theta} (I_d + \nabla\bar{u}) A \bar{X}  + \ddot{Z}(t) \right] \cdot \bar{v} d\bar{X}.\\
\end{aligned}\end{align*}
The third term in the right hand side can be integrated by part as follows:
\begin{equation*}
\begin{split}\begin{array}{rcl}
  \int_{\bar{\Omega}^0} \rho^0 \dot{\theta}^2\mbox{div}(((I_d + \nabla\bar{u})A \bar{X}) \otimes (A \bar{X}) ) \cdot \bar{v} d\bar{X} &=& -  \int_{\bar{\Omega}^0} (\dot{\theta}^2 (I_d + \nabla\bar{u})A \bar{X})) \cdot (\nabla (\rho^0 \bar{v}) A \bar{X}) d\bar{X} \\
 && + \int_{\partial \bar{\Omega}^0} \rho^0 \dot{\theta}^2 (((I_d + \nabla\bar{u})A \bar{X}) \otimes (A \bar{X}) ) \bar{N} \cdot \bar{v} d\bar{\Gamma}.
\end{array}\end{split}
\end{equation*}
Since \(\bar{N}\) the outward unit normal vector on \(\partial \bar{\Omega}^0\) is orthogonal to \(A \bar{X}\) the boundary term is zero and \(\nabla (\rho^0 \bar{v}) = \bar{v} \otimes \nabla \rho^0   + \rho^0 \nabla \bar{v}\) and since \(\nabla \rho^0.(A\bar{X}) = 0\) because of the assumption on \(\rho^0\) to have a rotation symmetry, we have
\begin{equation*}
\begin{split}\int_{\bar{\Omega}^0} \rho^0 \dot{\theta}^2\mbox{div}(((I_d + \nabla\bar{u})A \bar{X}) \otimes (A \bar{X}) ) \cdot \bar{v} d\bar{X} = - \int_{\bar{\Omega}^0} \rho^0 \dot{\theta}^2(\nabla\bar{u}A \bar{X}) \cdot (\nabla \bar{v} A \bar{X}) d\bar{X} - \int_{\bar{\Omega}^0} \rho^0 \dot{\theta}^2 (A^2 \bar{X})\cdot \bar{v} d\bar{X}.\end{split}
\end{equation*}
Thus globally
\begin{equation*}
\begin{split}\begin{array}{rcl}
 \int_{\Omega^0} \rho^0 \dfrac{\partial^2 u}{\partial t^2}\cdot vdX &=&
 \int_{\bar{\Omega}^0} \rho^0 \left[\dfrac{\partial^2 \bar{u}}{\partial t^2} + 2\dot{\theta} \nabla\dfrac{\partial \bar{u}}{\partial t}A \bar{X} + \ddot{\theta} \nabla\bar{u} A \bar{X}   \right] \cdot \bar{v} d\bar{X}\\
&& - \int_{\bar{\Omega}^0} \rho^0 \dot{\theta}^2(\nabla\bar{u}A \bar{X}) \cdot (\nabla \bar{v} A \bar{X}) d\bar{X} - \int_{\bar{\Omega}^0} \rho^0 (\dot{\theta}^2 A^2 \bar{X} + \ddot{\theta} A\bar{X} + \ddot{Z}(t))\cdot \bar{v} d\bar{X}.
\end{array}\end{split}
\end{equation*}
Note that two terms can deteriorate the coercivity of the problem and thus its well posedness and the stability of time integration schemes: the second one (convection term) and the fifth one. This may oblige to use additional stabilization techniques for large values of the angular velocity \(\dot{\theta}\).


\subsection{The available bricks …}
\label{\detokenize{userdoc/model_ALE_rotating:the-available-bricks}}
To be adapted

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ind} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{brick\PYGZus{}name}\PYG{p}{(}\PYG{n}{parmeters}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{parameters}} are the parameters …


\section{ALE terms for a uniformly translated part of an object}
\label{\detokenize{userdoc/model_ALE_rotating:ale-terms-for-a-uniformly-translated-part-of-an-object}}
This section present a set of bricks facilitating the use of an ALE formulation for an object being potentially infinite in one direction and which whose part of interests (on which the computation is considered) is translated uniformly in that direction (typically a bar).


\subsection{Theoretical background}
\label{\detokenize{userdoc/model_ALE_rotating:id3}}
Let us consider an object whose reference configuration \(\Omega^0 \in \rm I\hspace{-0.15em}R^{d}\) is infinite in the direction \(E_1\), i.e. \(\Omega^0 = \rm I\hspace{-0.15em}R \times \omega^0\) where \(\omega^0 \in \rm I\hspace{-0.15em}R^{d-1}\). At a time \(t\), only a “windows” of this object is considered
\begin{equation*}
\begin{split}\Omega^{0t} = (\alpha + z(t), \beta + z(t)) \times \omega^0\end{split}
\end{equation*}
where \(z(t)\) represents the translation.

If \(\varphi(t, X)\) is the deformation of the body which maps the reference configuration \(\Omega^0\) to the deformed configuration \(\Omega_t\) at time \(t\), the ALE description consists in considering the intermediary reference configuration
\begin{equation*}
\begin{split}\bar{\Omega}^{0} = (\alpha, \beta) \times \omega^0\end{split}
\end{equation*}
and \(\bar{\varphi}(t, X) : \rm I\hspace{-0.15em}R_+ \times \bar{\Omega}^{0} \rightarrow \rm I\hspace{-0.15em}R^d\) defined by
\begin{equation*}
\begin{split}\bar{\varphi}(t,\bar{X}) = \varphi(t,X), ~~~\mbox{ with } \bar{X} = X - Z(t),\end{split}
\end{equation*}
where \(Z(t) = z(t)E_1\). The interest of \(\bar{\Omega}^{0}\) is of course to be time independant. Of course, some special boundary conditions have to be defined on \(\{\alpha\} \times \omega^0\) and \(\{\beta\} \times \omega^0\) (absorbing or periodic boundary conditions) in order to approximate the fact that the body is infinite.

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[width=0.400\linewidth]{{ALE_translation_body}.png}
\end{figure}

If we denote
\begin{equation*}
\begin{split}\bar{u}(t,\bar{X}) = \bar{\varphi}(t, \bar{X}) - X = u(t, X),\end{split}
\end{equation*}
the displacement on the intermediary configuration, then it is easy to check that
\begin{align*}\!\begin{aligned}
\dfrac{\partial \varphi}{\partial t} = \dfrac{\partial \bar{u}}{\partial t} - \nabla \bar{u} \dot{Z}\\
\dfrac{\partial^2 \varphi}{\partial t^2} = \dfrac{\partial^2 \bar{u}}{\partial t^2} - \nabla\dfrac{\partial \bar{u}}{\partial t}\dot{Z} + \dfrac{\partial^2 \bar{u}}{\partial \dot{Z}^2} - \nabla\bar{u}\ddot{Z}.\\
\end{aligned}\end{align*}

\subsubsection{Weak formulation of the transient terms}
\label{\detokenize{userdoc/model_ALE_rotating:id4}}
Assuming \(\rho^0\) the density in the reference being invariant with the considered translation, the term corresponding to acceleration in the weak formulation reads (with \(v(X) = \bar{v}(\bar{X})\) a test function and after integration by part):
\begin{align*}\!\begin{aligned}
\int_{\Omega^0} \rho^0 \dfrac{\partial^2 u}{\partial t^2}\cdot vdX =\\
\int_{\bar{\Omega}^{0}} \rho^0 \left[\dfrac{\partial^2 \bar{u}}{\partial t^2} - 2\nabla\dfrac{\partial \bar{u}}{\partial t}\dot{Z} - \nabla\bar{u}\ddot{Z}\right]\cdot \bar{v}  - \rho^0 (\nabla\bar{u}\dot{Z}).(\nabla\bar{v}\dot{Z}) d\bar{X} + \int_{\partial \bar{\Omega}^0} \rho^0 (\nabla\bar{u}\dot{Z}).\bar{v}(\dot{Z}.\bar{N}) d\bar{\Gamma},\\
\end{aligned}\end{align*}
where \(\bar{N}\) is the outward unit normal vector on \(\partial \bar{\Omega}^0\). Note that the last term vanishes on \((\alpha, \beta) \times \partial \omega^0\) but not necessarily on \(\{\alpha\} \times \omega^0\) and \(\{\beta\} \times \omega^0\).


\chapter{Appendix A. Finite element method list}
\label{\detokenize{userdoc/appendixA:appendix-a-finite-element-method-list}}\label{\detokenize{userdoc/appendixA:ud-appendixa}}\label{\detokenize{userdoc/appendixA::doc}}\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Symbols representing degree of freedom types}\label{\detokenize{userdoc/appendixA:id8}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{90}|\X{30}{90}|\X{30}{90}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols00}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols01}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols02}.png}\hspace*{\fill}}
\\
\hline
Value of the function at the node.
&
Value of the gradient along of the first coordinate.
&
Value of the gradient along of the second coordinate.
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols03}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols04}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols05}.png}\hspace*{\fill}}
\\
\hline
Value of the gradient along of the third coordinate for 3D elements.
&
Value of the whole gradient at the node.
&
Value of the normal derivative to a face.
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols06}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols07}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols08}.png}\hspace*{\fill}}
\\
\hline
Value of the second derivative along the first coordinate (twice).
&
Value of the second derivative along the second coordinate (twice).
&
Value of the second cross derivative in 2D or second derivative
along the third coordinate (twice) in 3D.
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols09}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols10}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols11}.png}\hspace*{\fill}}
\\
\hline
Value of the whole second derivative (hessian) at the node.
&
Scalar product with a certain vector (for instance an edge) for a
vector elements.
&
Scalar product with the normal to a face for a vector elements.
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols12}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistsymbols13}.png}\hspace*{\fill}}
&\\
\hline
Bubble function on an element or a face, to be specified.
&
Lagrange hierarchical d.o.f. value at the node in a space of details.
&\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

Let us recall that all finite element methods defined in \sphinxstyleemphasis{GetFEM} are declared in the
file \sphinxcode{\sphinxupquote{getfem\_fem.h}} and that a descriptor on a finite element method is obtained
thanks to the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{pfem} \PYG{n}{pf} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{fem\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{name of method}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{"name of method"}} is a string to be choosen among the existing methods.


\section{Classical \protect\(P_K\protect\) Lagrange elements on simplices}
\label{\detokenize{userdoc/appendixA:classical-p-k-lagrange-elements-on-simplices}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistsegmentPk}.png}
\caption{Examples of classical \(P_K\) Lagrange elements on a segment}\label{\detokenize{userdoc/appendixA:id9}}\label{\detokenize{userdoc/appendixA:ud-fig-segmentpk}}\end{figure}

It is possible to define a classical \(P_K\) Lagrange element of arbitrary
dimension and arbitrary degree. Each degree of freedom of such an element
corresponds to the value of the function on a corresponding node. The grid of
node is the so\sphinxhyphen{}called Lagrange grid. Figures {\hyperref[\detokenize{userdoc/appendixA:ud-fig-segmentpk}]{\sphinxcrossref{\DUrole{std,std-ref}{Examples of classical P\_K Lagrange elements on a segment}}}}.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Examples of classical \protect\(P_K\protect\) Lagrange elements on a triangle.}\label{\detokenize{userdoc/appendixA:id10}}\label{\detokenize{userdoc/appendixA:ud-fig-trianglepk}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{60}|\X{30}{60}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttriangleP1}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttriangleP2}.png}\hspace*{\fill}}
\\
\hline
\(P_1\), 3 d.o.f., \(C^0\)
&
\(P_2\) element, 6 d.o.f., \(C^0\)
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttriangleP3}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttriangleP6}.png}\hspace*{\fill}}
\\
\hline
\(P_3\), 10 d.o.f., \(C^0\)
&
\(P_6\) element, 28 d.o.f., \(C^0\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

The number of degrees of freedom for a classical \(P_K\) Lagrange element of
dimension \(P\) and degree \(K\) is \(\dfrac{(P+K)!}{P!K!}\). For
instance, in dimension 2 \((P = 2)\), this value is \(\dfrac{(K+1)
(K+2)}{2}\) and in dimension 3 \((P = 3)\), it is \(\dfrac{(K+1) (K+2)
(K+3)}{6}\).
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Examples of classical \protect\(P_K\protect\) Lagrange elements on a tetrahedron.}\label{\detokenize{userdoc/appendixA:id11}}\label{\detokenize{userdoc/appendixA:ud-fig-tetrahedronpk}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{60}|\X{30}{60}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttetrahedronP1}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttetrahedronP2}.png}\hspace*{\fill}}
\\
\hline
\(P_1\) element, 4 d.o.f., \(C^0\)
&
\(P_2\) element, 10 d.o.f., \(C^0\)
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttetrahedronP4}.png}\hspace*{\fill}}
&\\
\hline
\(P_4\) element, 35 d.o.f., \(C^0\)
&\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

The particular way used in \sphinxstyleemphasis{GetFEM} to numerate the nodes are also shown in figures
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-segmentpk}]{\sphinxcrossref{\DUrole{std,std-ref}{segment}}}}, {\hyperref[\detokenize{userdoc/appendixA:ud-fig-trianglepk}]{\sphinxcrossref{\DUrole{std,std-ref}{triangle}}}} and
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-tetrahedronpk}]{\sphinxcrossref{\DUrole{std,std-ref}{tetrahedron}}}}. Using another numeration, let
\begin{equation*}
\begin{split}i_0, i_1, ... i_P,\end{split}
\end{equation*}
be some indices such that
\begin{equation*}
\begin{split}0 \leq i_0, i_1, ... i_P \leq K, \ \mbox{ and } \ \sum_{n = 0}^{P} i_n = K.\end{split}
\end{equation*}
Then, the coordinate of a node can be computed as
\begin{equation*}
\begin{split}a_{i_0, i_1, ... i_P} = \sum_{n = 0}^{P} \dfrac{i_n}{K}S_n, \ \ \mbox{ for } K \neq 0,\end{split}
\end{equation*}
where \(S_0, S_1, ... S_N\) are the vertices of the simplex (for \(K = 0\)
the particular choice \(a_{0, 0, ... 0} =  \sum_{n = 0}^{P}
\dfrac{1}{P+1}S_n\) has been chosen). Then each base function, corresponding of each
node \(a_{i_0, i_1, ... i_P}\) is defined by
\begin{equation*}
\begin{split}\phi_{i_0, i_1, ... i_P} = \prod_{n = 0}^{P} \prod_{j=0}^{i_n-1} \left(\dfrac{K \lambda_n - j}{j+1}\right).\end{split}
\end{equation*}
where \(\lambda_n\) are the barycentric coordinates, i.e. the polynomials of
degree 1 whose value is \(1\) on the vertex \(S_n\) and whose value is
\(0\) on other vertices. On the reference element, one has
\begin{equation*}
\begin{split}\lambda_n = x_n, \ \ 0 \leq n < P,\end{split}
\end{equation*}\begin{equation*}
\begin{split}\lambda_P = 1 - x_0 - x_1 - ... - x_{P-1}.\end{split}
\end{equation*}
When between two elements of the same degrees (even with different dimensions),
the d.o.f. of a common face are linked, the element is of class \(C^0\). This
means that the global polynomial is continuous. If you try to link elements of
different degrees, you will get some trouble with the unlinked d.o.f. This is not
automatically supported by \sphinxstyleemphasis{GetFEM}, so you will have to support it (add constraints
on these d.o.f.).

For some applications (computation of a gradient for instance) one may not want
the d.o.f. of a common face to be linked. This is why there are two versions of
the classical \(P_K\) Lagrange element.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Classical \protect\(P_K\protect\) Lagrange element \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK(P, K)"}}}\label{\detokenize{userdoc/appendixA:id12}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\), \(0 \leq K \leq 255\)
&
\(P\), \(~ 1 \leq P \leq 255\)
&
\(\dfrac{(K+P)!}{K! P!}\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Discontinuous \protect\(P_K\protect\) Lagrange element \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_DISCONTINUOUS(P, K)"}}}\label{\detokenize{userdoc/appendixA:id13}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\), \(0 \leq K \leq 255\)
&
\(P\), \(~ 1 \leq P \leq 255\)
&
\(\dfrac{(K+P)!}{K! P!}\)
&
discontinuous
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Discontinuous \protect\(P_K\protect\) Lagrange element with internal dofs \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_DISCONTINUOUS(P, K, alpha)"}}. The method \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_DISCONTINUOUS(P, K, 0)"}} is identical to \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_DISCONTINUOUS(P, K)"}}. For alpha \textgreater{} 0, \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_DISCONTINUOUS(P, K, alpha)"}} corresponds to a Lagrange method with all finite element nodes in the interior of the domain located at the position \protect\((\mbox{alpha})g + (1-\mbox{alpha})a_i\protect\) for \protect\(g\protect\) the centroid of the element and \protect\(a_i\protect\) the node of the standard \protect\(P_K\protect\) method.}\label{\detokenize{userdoc/appendixA:id14}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\), \(0 \leq K \leq 255\)
&
\(P\), \(~ 1 \leq P \leq 255\)
&
\(\dfrac{(K+P)!}{K! P!}\)
&
discontinuous
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

Even though Lagrange elements are defined for arbitrary degrees, choosing a
high degree can be problematic for a large number of applications due to
the “noisy” characteristic of the lagrange basis. These elements are
recommended for the basic interpolation but for p.d.e. applications elements
with hierarchical basis are preferable (see the corresponding section).


\section{Classical Lagrange elements on other geometries}
\label{\detokenize{userdoc/appendixA:classical-lagrange-elements-on-other-geometries}}
Classical Lagrange elements on parallelepipeds or prisms are obtained as tensor
product of Lagrange elements on simplices. When two elements are defined, one on a
dimension \(P^1\) and the other in dimension \(P^2\), one obtains the base
functions of the tensorial product (on the reference element) as
\begin{equation*}
\begin{split}\widehat{\varphi}_{ij}(x,y) = \widehat{\varphi}^1_i(x) \widehat{\varphi}^2_j(y), ~~ x \in \rm I\hspace{-0.15em}R^{P^1}, y \in  \rm I\hspace{-0.15em}R^{P^2},\end{split}
\end{equation*}
where \(\widehat{\varphi}^1_i\) and \(\widehat{\varphi}^2_i\) are respectively the base functions
of the first and second element.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Examples of classical \protect\(Q_K\protect\) Lagrange elements in dimension 2.}\label{\detokenize{userdoc/appendixA:id15}}\label{\detokenize{userdoc/appendixA:ud-fig-prodpkdeux}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{60}|\X{30}{60}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistquadQ1}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistquadQ3}.png}\hspace*{\fill}}
\\
\hline
\(Q_1\) element, 4 d.o.f., \(C^0\)
&
\(Q_3\) element, 16 d.o.f., \(C^0\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

The \(Q_K\) element on a parallelepiped of dimension \(P\) is obtained as
the tensorial product of \(P\) classical \(P_K\) elements on the segment.
Examples in dimension 2 are shown in figure {\hyperref[\detokenize{userdoc/appendixA:ud-fig-prodpkdeux}]{\sphinxcrossref{\DUrole{std,std-ref}{dimension 2}}}}
and in dimension 3 in figure {\hyperref[\detokenize{userdoc/appendixA:ud-fig-prodpktrois}]{\sphinxcrossref{\DUrole{std,std-ref}{dimension 3}}}}.

A prism in dimension \(P > 1\) is the direct product of a simplex of dimension
\(P-1\) with a segment. The \(P_K \otimes P_K\) element on this prism is
the tensorial product of the classical \(P_K\) element on a simplex of
dimension \(P-1\) with the classical \(P_K\) element on a segment. For
\(P=2\) this coincide with a parallelepiped. Examples in dimension \(3\)
are shown in figure {\hyperref[\detokenize{userdoc/appendixA:ud-fig-prodpktrois}]{\sphinxcrossref{\DUrole{std,std-ref}{dimension 3}}}}. This is also possible
not to have the same degree on each dimension. An example is shown on figure
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-prism-p2-p1}]{\sphinxcrossref{\DUrole{std,std-ref}{dimension 3, prism}}}}.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Examples of classical Lagrange elements in dimension 3.}\label{\detokenize{userdoc/appendixA:id16}}\label{\detokenize{userdoc/appendixA:ud-fig-prodpktrois}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{60}|\X{30}{60}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistcubeQ1}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistcubeQ3}.png}\hspace*{\fill}}
\\
\hline
\(Q_1\) element, 8 d.o.f., \(C^0\)
&
\(Q_3\) element, 64 d.o.f., \(C^0\)
\\
\hline
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistprismP1}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistprismP3}.png}\hspace*{\fill}}
\\
\hline
\(P_1 \otimes P_1\) element, 6 d.o.f., \(C^0\)
&
\(P_3 \otimes P_3\) element, 40 d.o.f., \(C^0\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistprismP2P1}.png}
\caption{\(P_2 \otimes P_1\) Lagrange element on a prism, 12 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id17}}\label{\detokenize{userdoc/appendixA:ud-fig-prism-p2-p1}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(Q_K\protect\) Lagrange element on parallelepipeds \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_QK(P, K)"}}}\label{\detokenize{userdoc/appendixA:id18}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(KP\), \(0 \leq K \leq 255\)
&
\(P\), \(~ 1 \leq P \leq 255\)
&
\((K+1)^P\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(P_K \otimes P_K\protect\) Lagrange element on prisms \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_PRISM(P, K)"}}}\label{\detokenize{userdoc/appendixA:id19}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(2K\), \(0 \leq K \leq 255\)
&
\(P\), \(~ 2 \leq P \leq 255\)
&
\((K+1)\) \(\times~\dfrac{(K+P-1)!}{K! (P-1)!}\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(P_{K_1} \otimes P_{K_2}\protect\) Lagrange element on prisms \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PRODUCT(FEM\_PK(P\sphinxhyphen{}1, K1), FEM\_PK(1, K2))"}}}\label{\detokenize{userdoc/appendixA:id20}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K_1+K_2\), \(0 \leq K_1,K_2 \leq 255\)
&
\(P\), \(~ 2 \leq P \leq 255\)
&
\((K_2+1)\) \(\times~\dfrac{(K_1+P-1)!}{K_1! (P-1)!}\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistincomplete}.png}
\caption{Incomplete \(Q_2\) elements in dimension two and three, 8 or 20 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id21}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Incomplete \protect\(Q_2\protect\) Lagrange element on parallelepipeds (Quad 8 and Hexa 20 serendipity elements) \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_Q2\_INCOMPLETE(P)"}}}\label{\detokenize{userdoc/appendixA:id22}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
3
&
\(P\), \(~ 2 \leq P \leq 3\)
&
\(8\ \text{for}\ P = 2~~~~~\) \(20\ \text{for}\ P = 3\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\section{Elements with hierarchical basis}
\label{\detokenize{userdoc/appendixA:elements-with-hierarchical-basis}}
The idea behind hierarchical basis is the description of the solution at different
level: a rough level, a more refined level … In the same discretization some
degrees of freedom represent the rough description, some other the more rafined
and so on. This corresponds to imbricated spaces of discretization. The
hierarchical basis contains a basis of each of these spaces (this is not the case
in classical Lagrange elements when the mesh is refined).

Among the advantages, the condition number of rigidity matrices can be greatly
improved, it allows local raffinement and a resolution with a multigrid approach.


\subsection{Hierarchical elements with respect to the degree}
\label{\detokenize{userdoc/appendixA:hierarchical-elements-with-respect-to-the-degree}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistsegmenthier}.png}
\caption{\(P_K\) Hierarchical element on a segment, \(C^0\)}\label{\detokenize{userdoc/appendixA:id23}}\label{\detokenize{userdoc/appendixA:ud-fig-seg-hier}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(P_{K}\protect\) Classical Lagrange element on simplices but with a hierarchical basis with respect to the degree \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_HIERARCHICAL(P,K)"}}}\label{\detokenize{userdoc/appendixA:id24}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\), \(0 \leq K\leq 255\)
&
\(P\), \(~ 1 \leq P \leq 255\)
&
\(\dfrac{(K+P)!}{K! P!}\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(Q_{K}\protect\) Classical Lagrange element on parallelepipeds but with a hierarchical basis with respect to the degree \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_QK\_HIERARCHICAL(P,K)"}}}\label{\detokenize{userdoc/appendixA:id25}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\), \(0 \leq K\leq 255\)
&
\(P\), \(~ 1 \leq P \leq 255\)
&
\((K+1)^P\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(P_{K}\protect\) Classical Lagrange element on prisms but with a hierarchical basis with respect to the degree \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_PRISM\_HIERARCHICAL(P,K)"}}}\label{\detokenize{userdoc/appendixA:id26}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\), \(0 \leq K\leq 255\)
&
\(P\), \(~ 2 \leq P \leq 255\)
&
\((K+1)\) \(\times~\dfrac{(K+P-1)!}{K! (P-1)!}\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

some particular choices: \(P_4\) will be built with the basis of the
\(P_1\), the additional basis of the \(P_2\) then the additional basis of the \(P_4\).

\(P_6\) will be built with the basis of the \(P_1\), the additional basis
:of the \(P_2\) then the additional basis of the \(P_6\) (not with the
:basis of the \(P_1\), the additional basis of the \(P_3\) then the
:additional basis of the \(P_6\), it is possible to build the latter with
:\sphinxcode{\sphinxupquote{"FEM\_GEN\_HIERARCHICAL(a,b)"}})


\subsection{Composite elements}
\label{\detokenize{userdoc/appendixA:composite-elements}}
The principal interest of the composite elements is to build hierarchical
elements. But this tool can also be used to build piecewise polynomial elements.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttriangleP1comp}.png}
\caption{composite element \sphinxcode{\sphinxupquote{"FEM\_STRUCTURED\_COMPOSITE(FEM\_PK(2,1), 3)"}}}\label{\detokenize{userdoc/appendixA:id27}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-comp}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Composition of a finite element method on an element with \sphinxstyleliteralintitle{\sphinxupquote{S}} subdivisions \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_STRUCTURED\_COMPOSITE(FEM1, S)"}}}\label{\detokenize{userdoc/appendixA:id28}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
degree of FEM1
&
dimension of FEM1
&
variable
&
variable
&
No \((Q = 1)\)
&
If \sphinxcode{\sphinxupquote{FEM1}} is
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

It is important to use a corresponding composite integration method.


\subsection{Hierarchical composite elements}
\label{\detokenize{userdoc/appendixA:hierarchical-composite-elements}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttriangleP1comphier}.png}
\caption{hierarchical composite element \sphinxcode{\sphinxupquote{"FEM\_PK\_HIERARCHICAL\_COMPOSITE(2,1,3)"}}}\label{\detokenize{userdoc/appendixA:id29}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-compdeux}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Hierarchical composition of a \protect\(P_K\protect\) finite element method on a simplex with \sphinxstyleliteralintitle{\sphinxupquote{S}} subdivisions \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_HIERARCHICAL\_COMPOSITE(P,K,S)"}}}\label{\detokenize{userdoc/appendixA:id30}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\)
&
\(P\)
&
\(\dfrac{(SK+P)!}{(SK)! P!}\)
&
variable
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Hierarchical composition of a hierarchical \protect\(P_K\protect\) finite element method on a simplex with \sphinxstyleliteralintitle{\sphinxupquote{S}} subdivisions \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_FULL\_HIERARCHICAL\_COMPOSITE(P,K,S)"}}}\label{\detokenize{userdoc/appendixA:id31}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\)
&
\(P\)
&
\(\dfrac{(SK+P)!}{(SK)! P!}\)
&
variable
&
No \((Q = 1)\)
&
Yes \((M = Id)\)
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

Other constructions are possible thanks to \sphinxcode{\sphinxupquote{"FEM\_GEN\_HIERARCHICAL(FEM1, FEM2)"}}
and \sphinxcode{\sphinxupquote{"FEM\_STRUCTURED\_COMPOSITE(FEM1, S)"}}.

It is important to use a corresponding composite integration method.


\section{Classical vector elements}
\label{\detokenize{userdoc/appendixA:classical-vector-elements}}

\subsection{Raviart\sphinxhyphen{}Thomas of lowest order elements}
\label{\detokenize{userdoc/appendixA:raviart-thomas-of-lowest-order-elements}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistRT0}.png}
\caption{RT0 elements in dimension two and three. (P+1 dof, H(div))}\label{\detokenize{userdoc/appendixA:id32}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-comptrois}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Raviart\sphinxhyphen{}Thomas of lowest order element on simplices \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_RT0(P)"}}}\label{\detokenize{userdoc/appendixA:id33}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(1\)
&
\(P\)
&
\(P+1\)
&
H(div)
&
Yes \((Q = P)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Raviart\sphinxhyphen{}Thomas of lowest order element on parallelepipeds (quadrilaterals, hexahedrals) \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_RT0Q(P)"}}}\label{\detokenize{userdoc/appendixA:id34}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(1\)
&
\(P\)
&
\(2P\)
&
H(div)
&
Yes \((Q = P)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Nedelec (or Whitney) edge elements}
\label{\detokenize{userdoc/appendixA:nedelec-or-whitney-edge-elements}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistnedelec}.png}
\caption{Nedelec edge elements in dimension two and three. (P(P+1)/2 dof, H(rot))}\label{\detokenize{userdoc/appendixA:id35}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-compquatre}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Nedelec (or Whitney) edge element \sphinxtitleref{“FEM\_NEDELEC(P)”\textasciigrave{}}}\label{\detokenize{userdoc/appendixA:id36}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(1\)
&
\(P\)
&
\(P(P+1)/2\)
&
H(rot)
&
Yes \((Q = P)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\section{Specific elements in dimension 1}
\label{\detokenize{userdoc/appendixA:specific-elements-in-dimension-1}}

\subsection{GaussLobatto element}
\label{\detokenize{userdoc/appendixA:gausslobatto-element}}
The 1D GaussLobatto \(P_K\) element is similar to the classical \(P_K\)
fem on the segment, but the nodes are given by the Gauss\sphinxhyphen{}Lobatto\sphinxhyphen{}Legendre
quadrature rule of order \(2K-1\). This FEM is known to lead to better
conditioned linear systems, and can be used with the corresponding quadrature to
perform mass\sphinxhyphen{}lumping (on segments or parallelepipeds).

The polynomials coefficients have been pre\sphinxhyphen{}computed with Maple (they require the
inversion of an ill\sphinxhyphen{}conditioned system), hence they are only available for the
following values of \(K\): \(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,
14, 16, 24, 32\). Note that for \(K=1\) and \(K=2\), this is the classical
\(P1\) and \(P2\) fem.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{GaussLobatto \protect\(P_K\protect\) element on the segment \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_GAUSSLOBATTO1D(K)"}}}\label{\detokenize{userdoc/appendixA:id37}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(K\)
&
\(1\)
&
\(K+1\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Hermite element}
\label{\detokenize{userdoc/appendixA:hermite-element}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistsegmenthermite}.png}
\caption{\(P_3\) Hermite element on a segment, 4 d.o.f., \(C^1\)}\label{\detokenize{userdoc/appendixA:id38}}\label{\detokenize{userdoc/appendixA:ud-fig-segment-hermite}}\end{figure}

Base functions on the reference element
\begin{equation*}
\begin{split}\begin{array}{ll}
  \widehat{\varphi}_0 = (2x+1)(x-1)^2,&\ \ \ \widehat{\varphi}_1 = x(x-1)^2, \\
  \widehat{\varphi}_2 = x^2(3-2x),& \ \ \ \widehat{\varphi}_3 = x^2(x - 1).
\end{array}\end{split}
\end{equation*}
This element is close to be \(\tau\)\sphinxhyphen{}equivalent but it is not. On the real
element the value of the gradient on vertices will be multiplied by the gradient
of the geometric transformation. The matrix \(M\) is not equal to identity but
is still diagonal.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Hermite element on the segment \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_HERMITE(1)"}}}\label{\detokenize{userdoc/appendixA:id39}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(1\)
&
\(4\)
&
\(C^1\)
&
No \((Q = 1)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Lagrange element with an additional bubble function}
\label{\detokenize{userdoc/appendixA:lagrange-element-with-an-additional-bubble-function}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistsegmentbubble}.png}
\caption{\(P_1\) Lagrange element on a segment with additional internal bubble function, 3 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id40}}\label{\detokenize{userdoc/appendixA:ud-fig-segment-bubble}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange \protect\(P_1\protect\) element with an additional internal bubble function \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_WITH\_CUBIC\_BUBBLE(1, 1)"}}}\label{\detokenize{userdoc/appendixA:id41}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(2\)
&
\(1\)
&
\(3\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\section{Specific elements in dimension 2}
\label{\detokenize{userdoc/appendixA:specific-elements-in-dimension-2}}

\subsection{Elements with additional bubble functions}
\label{\detokenize{userdoc/appendixA:elements-with-additional-bubble-functions}}\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange element on a triangle with additional internal bubble function}\label{\detokenize{userdoc/appendixA:id42}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-p1-bubble}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{60}|\X{30}{60}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttriangleP1bubble}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttriangleP2bubble}.png}\hspace*{\fill}}
\\
\hline
\(P_1\) with additional bubble function, 4 d.o.f., \(C^0\)
&
\(P_2\) with additional bubble function, 7 d.o.f., \(C^0\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange \protect\(P_1\protect\) or \protect\(P_2\protect\) element with an additional internal bubble function \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_WITH\_CUBIC\_BUBBLE(2, K)"}}}\label{\detokenize{userdoc/appendixA:id43}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(2\)
&
\(4\) or \(7\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttriangleP1linbubble}.png}
\caption{\(P_1\) Lagrange element on a triangle with additional internal piecewise linear bubble function}\label{\detokenize{userdoc/appendixA:id44}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-p1-bubblepie}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange \protect\(P_1\protect\) with an additional internal piecewise linear bubble function \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_P1\_PIECEWISE\_LINEAR\_BUBBLE"}}}\label{\detokenize{userdoc/appendixA:id45}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(1\)
&
\(2\)
&
\(4\) or \(7\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttriangleP1bubbleface}.png}
\caption{\(P_1\) Lagrange element on a triangle with additional bubble function on face 0, 4 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id46}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-p1-bubble-face}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange \protect\(P_1\protect\) element with an additional bubble function on face 0 \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_P1\_BUBBLE\_FACE(2)"}}}\label{\detokenize{userdoc/appendixA:id47}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(2\)
&
\(2\)
&
\(4\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttriangleP1withP2face}.png}
\caption{\(P_1\) Lagrange element on a triangle with additional d.o.f on face 0, 4 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id48}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-p1-p2-face}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(P_1\protect\) Lagrange element on a triangle with additional d.o.f on face 0 \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_P1\_BUBBLE\_FACE\_LAG"}}}\label{\detokenize{userdoc/appendixA:id49}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(2\)
&
\(2\)
&
\(4\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Non\sphinxhyphen{}conforming \protect\(P_1\protect\) element}
\label{\detokenize{userdoc/appendixA:non-conforming-p-1-element}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttriangleP1nonconforming}.png}
\caption{\(P_1\) non\sphinxhyphen{}conforming element on a triangle, 3 d.o.f., discontinuous}\label{\detokenize{userdoc/appendixA:id50}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-non-conforming}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(P_1\protect\) non\sphinxhyphen{}conforming element on a triangle \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_P1\_NONCONFORMING"}}}\label{\detokenize{userdoc/appendixA:id51}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(1\)
&
\(2\)
&
\(3\)
&
\(discontinuous\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Hermite element}
\label{\detokenize{userdoc/appendixA:id1}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttrianglehermite}.png}
\caption{Hermite element on a triangle, \(P_3\), 10 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id52}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-hermite}}\end{figure}

Base functions on the reference element:
\begin{equation*}
\begin{split}\begin{array}{ll}
\widehat{\varphi}_0 = (1-x-y)(1+x+y-2x^2-2y^2-11xy),~~ & (\widehat{\varphi}_0(0,0) = 1), \\
\widehat{\varphi}_1 = x(1-x-y)(1-x-2y), & (\partial_x\widehat{\varphi}_1(0,0) = 1), \\
\widehat{\varphi}_2 = y(1-x-y)(1-2x-y), & (\partial_y\widehat{\varphi}_2(0,0) = 1), \\
\widehat{\varphi}_3 = -2x^3 + 7 x^2y + 7xy^2 + 3x^2 - 7xy, & (\widehat{\varphi}_3(1,0) = 1), \\
\widehat{\varphi}_4 = x^3-2x^2y-2xy^2-x^2+2xy, & (\partial_x\widehat{\varphi}_4(1,0) = 1), \\
\widehat{\varphi}_5 = xy(y+2x-1), & (\partial_y\widehat{\varphi}_5(1,0) = 1), \\
\widehat{\varphi}_6 = 7x^2y + 7xy^2 - 2y^3+3y^2-7xy, & (\widehat{\varphi}_6(0,1) = 1), \\
\widehat{\varphi}_7 = xy(x+2y-1), & (\partial_x\widehat{\varphi}_7(0,1) = 1), \\
\widehat{\varphi}_8 = y^3-2x^2y-2xy^2-y^2+2xy, & (\partial_y\widehat{\varphi}_8(0,1) = 1), \\
\widehat{\varphi}_9 = 27xy(1-x-y), & (\widehat{\varphi}_9(1/3,1/3) = 1), \\
\end{array}\end{split}
\end{equation*}
This element is not \(\tau\)\sphinxhyphen{}equivalent (The matrix \(M\) is not equal to
identity). On the real element linear combinations of \(\widehat{\varphi}_4\) and
\(\widehat{\varphi}_7\) are used to match the gradient on the corresponding vertex.
Idem for the two couples \((\widehat{\varphi}_5\), \(\widehat{\varphi}_8)\) and
\((\widehat{\varphi}_6\), \(\widehat{\varphi}_9)\) for the two other vertices.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Hermite element on a triangle \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_HERMITE(2)"}}}\label{\detokenize{userdoc/appendixA:id53}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(2\)
&
\(10\)
&
\(C^0\)
&
No \((Q = 1)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Morley element}
\label{\detokenize{userdoc/appendixA:morley-element}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistmorley}.png}
\caption{triangle Morley element, \(P_2\), 6 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id54}}\label{\detokenize{userdoc/appendixA:ud-fig-triangle-morley}}\end{figure}

This element is not \(\tau\)\sphinxhyphen{}equivalent (The matrix \(M\) is not equal to
identity). In particular, it can be used for non\sphinxhyphen{}conforming discretization of
fourth order problems, despite the fact that it is not \({\cal C}^1\).
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Morley element on a triangle \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_MORLEY"}}}\label{\detokenize{userdoc/appendixA:id55}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(2\)
&
\(2\)
&
\(6\)
&
discontinuous
&
No \((Q = 1)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Argyris element}
\label{\detokenize{userdoc/appendixA:argyris-element}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistargyris}.png}
\caption{Argyris element, \(P_5\), 21 d.o.f., \(C^1\)}\label{\detokenize{userdoc/appendixA:id56}}\label{\detokenize{userdoc/appendixA:ud-fig-argyris}}\end{figure}

The base functions on the reference element are:
\begin{equation*}
\begin{split}\begin{array}{ll}
\widehat{\varphi}_{0}(x,y) = 1 - 10x^3 - 10y^3 + 15x^4 - 30x^2y^2 + 15y^4 - 6x^5 + 30x^3y^2 + 30x^2y^3 - 6y^5, & (\widehat{\varphi}_0(0,0) = 1), \\
\widehat{\varphi}_{1}(x,y) = x - 6x^3 - 11xy^2 + 8x^4 + 10x^2y^2 + 18xy^3 - 3x^5 + x^3y^2 - 10x^2y^3 - 8xy^4, & (\partial_x\widehat{\varphi}_1(0,0) = 1),\\
\widehat{\varphi}_{2}(x,y) = y - 11x^2y - 6y^3 + 18x^3y + 10x^2y^2 + 8y^4 - 8x^4y - 10x^3y^2 + x^2y^3 - 3y^5, & (\partial_y\widehat{\varphi}_2(0,0) = 1),\\
\widehat{\varphi}_{3}(x,y) = 0.5x^2 - 1.5x^3 + 1.5x^4 - 1.5x^2y^2 - 0.5x^5 + 1.5x^3y^2 + x^2y^3, & (\partial^2_{xx}\widehat{\varphi}_3(0,0) = 1),\\
\widehat{\varphi}_{4}(x,y) = xy - 4x^2y - 4xy^2 + 5x^3y + 10x^2y^2 + 5xy^3 - 2x^4y - 6x^3y^2 - 6x^2y^3 - 2xy^4, & (\partial^2_{xy}\widehat{\varphi}_{4}(0,0) = 1),\\
\widehat{\varphi}_{5}(x,y) = 0.5y^2 - 1.5y^3 - 1.5x^2y^2 + 1.5y^4 + x^3y^2 + 1.5x^2y^3 - 0.5y^5, & (\partial^2_{yy}\widehat{\varphi}_{5}(0,0) = 1),\\
\widehat{\varphi}_{6}(x,y) = 10x^3 - 15x^4 + 15x^2y^2 + 6x^5 - 15x^3y^2 - 15x^2y^3, & (\widehat{\varphi}_6(1,0) = 1),\\
\widehat{\varphi}_{7}(x,y) = -4x^3 + 7x^4 - 3.5x^2y^2 - 3x^5 + 3.5x^3y^2 + 3.5x^2y^3, & (\partial_x\widehat{\varphi}_7(1,0) = 1),\\
\widehat{\varphi}_{8}(x,y) = -5x^2y + 14x^3y + 18.5x^2y^2 - 8x^4y - 18.5x^3y^2 - 13.5x^2y^3, & (\partial_y\widehat{\varphi}_8(1,0) = 1),\\
\widehat{\varphi}_{9}(x,y) = 0.5x^3 - x^4 + 0.25x^2y^2 + 0.5x^5 - 0.25x^3y^2 - 0.25x^2y^3, & (\partial^2_{xx}\widehat{\varphi}_{9}(1,0) = 1),\\
\widehat{\varphi}_{10}(x,y) = x^2y - 3x^3y - 3.5x^2y^2 + 2x^4y + 3.5x^3y^2 + 2.5x^2y^3, & (\partial^2_{xy}\widehat{\varphi}_{10}(1,0) = 1),\\
\widehat{\varphi}_{11}(x,y) = 1.25x^2y^2 - 0.75x^3y^2 - 1.25x^2y^3, & (\partial^2_{yy}\widehat{\varphi}_{11}(1,0) = 1),\\
\widehat{\varphi}_{12}(x,y) = 10y^3 + 15x^2y^2 - 15y^4 - 15x^3y^2 - 15x^2y^3 + 6y^5, & (\widehat{\varphi}_{12}(0,1) = 1),\\
\widehat{\varphi}_{13}(x,y) = -5xy^2 + 18.5x^2y^2 + 14xy^3 - 13.5x^3y^2 - 18.5x^2y^3 - 8xy^4, & (\partial_x\widehat{\varphi}_{13}(0,1) = 1),\\
\widehat{\varphi}_{14}(x,y) = -4y^3 - 3.5x^2y^2 + 7y^4 + 3.5x^3y^2 + 3.5x^2y^3 - 3y^5, & (\partial_y\widehat{\varphi}_{14}(0,0) = 1),\\
\widehat{\varphi}_{15}(x,y) = 1.25x^2y^2 - 1.25x^3y^2 - 0.75x^2y^3, & (\partial^2_{xx}\widehat{\varphi}_{15}(0,1) = 1),\\
\widehat{\varphi}_{16}(x,y) = xy^2 - 3.5x^2y^2 - 3xy^3 + 2.5x^3y^2 + 3.5x^2y^3 + 2xy^4, & (\partial^2_{xy}\widehat{\varphi}_{16}(0,1) = 1),\\
\widehat{\varphi}_{17}(x,y) = 0.5y^3 + 0.25x^2y^2 - y^4 - 0.25x^3y^2 - 0.25x^2y^3 + 0.5y^5, & (\partial^2_{yy}\widehat{\varphi}_{17}(0,1) = 1),\\
\widehat{\varphi}_{18}(x,y) = \sqrt{2}(-8x^2y^2 + 8x^3y^2 + 8x^2y^3), & ~\hspace{-10.5em}(\sqrt{0.5}(\partial_{x}\widehat{\varphi}_{18}(0.5,0.5) + \partial_{y}\widehat{\varphi}_{18}(0.5,0.5)) = 1),\\
\widehat{\varphi}_{19}(x,y) = -16xy^2 + 32x^2y^2 + 32xy^3 - 16x^3y^2 - 32x^2y^3 - 16xy^4, & (-\partial_{x}\widehat{\varphi}_{19}(0,0.5) = 1),\\
\widehat{\varphi}_{20}(x,y) = -16x^2y + 32x^3y + 32x^2y^2 - 16x^4y - 32x^3y^2 - 16x^2y^3, & (-\partial_{y}\widehat{\varphi}_{20}(0.5,0) = 1),\\
\end{array}\end{split}
\end{equation*}
This element is not \(\tau\)\sphinxhyphen{}equivalent (The matrix \(M\) is not equal to
identity). On the real element linear combinations of the transformed base
functions \(\widehat{\varphi}_i\) are used to match the gradient, the second
derivatives and the normal derivatives on the faces. Note that the use of the
matrix \(M\) allows to define Argyris element even with nonlinear geometric
transformations (for instance to treat curved boundaries).
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Argyris element on a triangle \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_ARGYRIS"}}}\label{\detokenize{userdoc/appendixA:id57}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(5\)
&
\(2\)
&
\(21\)
&
\(C^1\)
&
No \((Q = 1)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Hsieh\sphinxhyphen{}Clough\sphinxhyphen{}Tocher element}
\label{\detokenize{userdoc/appendixA:hsieh-clough-tocher-element}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistHCT}.png}
\caption{Hsieh\sphinxhyphen{}Clough\sphinxhyphen{}Tocher (HCT) element, \(P_3\), 12 d.o.f., \(C^1\)}\label{\detokenize{userdoc/appendixA:id58}}\label{\detokenize{userdoc/appendixA:ud-fig-hct-tr}}\end{figure}

This element is not \(\tau\)\sphinxhyphen{}equivalent. This is a composite element.
Polynomial of degree 3 on each of the three sub\sphinxhyphen{}triangles (see figure
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-hct-tr}]{\sphinxcrossref{\DUrole{std,std-ref}{Hsieh\sphinxhyphen{}Clough\sphinxhyphen{}Tocher (HCT) element, P\_3, 12 d.o.f., C\textasciicircum{}1}}}} and \sphinxcite{biblio:ciarlet1978}). It is strongly advised to use a
\sphinxcode{\sphinxupquote{"IM\_HCT\_COMPOSITE"}} integration method with this finite element. The numeration
of the dof is the following: 0, 3 and 6 for the lagrange dof on the first second
and third vertex respectively; 1, 4, 7 for the derivative with respects to the
first variable; 2, 5, 8 for the derivative with respects to the second variable
and 9, 10, 11 for the normal derivatives on face 0, 1, 2 respectively.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{HCT element on a triangle \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_HCT\_TRIANGLE"}}}\label{\detokenize{userdoc/appendixA:id59}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(2\)
&
\(12\)
&
\(C^1\)
&
No \((Q = 1)\)
&
No
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistreducedHCT}.png}
\caption{Reduced Hsieh\sphinxhyphen{}Clough\sphinxhyphen{}Tocher (reduced HCT) element, \(P_3\), 9 d.o.f., \(C^1\)}\label{\detokenize{userdoc/appendixA:id60}}\label{\detokenize{userdoc/appendixA:ud-fig-reduced-hct-tr}}\end{figure}

This element exists also in its reduced form, where the normal derivatives are
assumed to be polynomial of degree one on each edge (see figure
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-reduced-hct-tr}]{\sphinxcrossref{\DUrole{std,std-ref}{Reduced Hsieh\sphinxhyphen{}Clough\sphinxhyphen{}Tocher (reduced HCT) element, P\_3, 9 d.o.f., C\textasciicircum{}1}}}})
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Reduced HCT element on a triangle \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_REDUCED\_HCT\_TRIANGLE"}}}\label{\detokenize{userdoc/appendixA:id61}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(2\)
&
\(9\)
&
\(C^1\)
&
No \((Q = 1)\)
&
No
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{A composite \protect\(C^1\protect\) element on quadrilaterals}
\label{\detokenize{userdoc/appendixA:a-composite-c-1-element-on-quadrilaterals}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistquadc1composite}.png}
\caption{Composite element on quadrilaterals, piecewise \(P_3\), 16 d.o.f., \(C^1\)}\label{\detokenize{userdoc/appendixA:id62}}\label{\detokenize{userdoc/appendixA:ud-fig-qc1-tr}}\end{figure}

This element is not \(\tau\)\sphinxhyphen{}equivalent. This is a composite element.
Polynomial of degree 3 on each of the four sub\sphinxhyphen{}triangles (see figure
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-qc1-tr}]{\sphinxcrossref{\DUrole{std,std-ref}{Composite element on quadrilaterals, piecewise P\_3, 16 d.o.f., C\textasciicircum{}1}}}}). At least on the reference element it corresponds to the
Fraeijs de Veubeke\sphinxhyphen{}Sander element (see  \sphinxcite{biblio:ciarlet1978}). It is strongly advised
to use a \sphinxcode{\sphinxupquote{"IM\_QUADC1\_COMPOSITE"}} integration method with this finite element.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{. \protect\(C^1\protect\) composite element on a quadrilateral (FVS) \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_QUADC1\_COMPOSITE"}}}\label{\detokenize{userdoc/appendixA:id63}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(2\)
&
\(16\)
&
\(C^1\)
&
No \((Q = 1)\)
&
No
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlistreducedquadc1composite}.png}
\caption{Reduced composite element on quadrilaterals, piecewise \(P_3\), 12 d.o.f., \(C^1\)}\label{\detokenize{userdoc/appendixA:id64}}\label{\detokenize{userdoc/appendixA:ud-fig-reduced-qc1-tr}}\end{figure}

This element exists also in its reduced form, where the normal derivatives are
assumed to be polynomial of degree one on each edge (see figure
{\hyperref[\detokenize{userdoc/appendixA:ud-fig-reduced-qc1-tr}]{\sphinxcrossref{\DUrole{std,std-ref}{Reduced composite element on quadrilaterals, piecewise P\_3, 12 d.o.f., C\textasciicircum{}1}}}})
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Reduced \protect\(C^1\protect\) composite element on a quadrilateral (reduced FVS) \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_REDUCED\_QUADC1\_COMPOSITE"}}}\label{\detokenize{userdoc/appendixA:id65}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(2\)
&
\(12\)
&
\(C^1\)
&
No \((Q = 1)\)
&
No
&
piecewise
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\section{Specific elements in dimension 3}
\label{\detokenize{userdoc/appendixA:specific-elements-in-dimension-3}}

\subsection{Lagrange elements on 3D pyramid}
\label{\detokenize{userdoc/appendixA:lagrange-elements-on-3d-pyramid}}
\sphinxstyleemphasis{GetFEM} proposes some Lagrange pyramidal elements of degree 0, 1 and two based on \sphinxcite{biblio:gr-gh1999} and \sphinxcite{biblio:be-co-du2010}. See these references for more details. The proposed element can be raccorded to standard \(P_1\) or \(P_2\) Lagrange fem on the triangular faces and to a standard \(Q_1\) or \(Q_2\) Lagrange fem on the quatrilateral face.


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange element on a pyramidal element of order 0, 1 and 2}\label{\detokenize{userdoc/appendixA:id66}}\label{\detokenize{userdoc/appendixA:ud-fig-pyramid-lagrange}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{20}{60}|\X{20}{60}|\X{20}{60}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistpyramidP0}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistpyramidP1}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlistpyramidP2}.png}\hspace*{\fill}}
\\
\hline
Degree 0 pyramidal element with 1 dof
&
Degree 1 pyramidal element with 5 dof
&
Degree 2 pyramidal element with 14 dof
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}

The associated geometric transformations are \sphinxcode{\sphinxupquote{"GT\_PYRAMID(K)"}} for K = 1 or 2. The associated integration methods \sphinxcode{\sphinxupquote{"IM\_PYRAMID(im)"}} where \sphinxcode{\sphinxupquote{im}} is an integration method on a hexahedron (or alternatively \sphinxcode{\sphinxupquote{"IM\_PYRAMID\_COMPOSITE(im)"}} where \sphinxcode{\sphinxupquote{im}} is an integration method on a tetrahedron, but it is theoretically less accurate)
The shape functions are not polynomial ones but rational fractions. For the first degree the shape functions read:
\begin{equation*}
\begin{split}\begin{array}{l}
\widehat{\varphi}_{0}(x,y,z) =  \frac{1}{4}\left(1-x-y-z+\dfrac{xy}{1-z}\right), \\
\widehat{\varphi}_{1}(x,y,z) =  \frac{1}{4}\left(1+x-y-z-\dfrac{xy}{1-z}\right), \\
\widehat{\varphi}_{2}(x,y,z) =  \frac{1}{4}\left(1-x+y-z-\dfrac{xy}{1-z}\right), \\
\widehat{\varphi}_{3}(x,y,z) =  \frac{1}{4}\left(1+x+y-z+\dfrac{xy}{1-z}\right), \\
\widehat{\varphi}_{4}(x,y,z) =  z.\\
\end{array}\end{split}
\end{equation*}
For the second degree, setting
\begin{equation*}
\begin{split}\xi_0 = \dfrac{1-z-x}{2}, ~~~\xi_1 = \dfrac{1-z-y}{2}, ~~~\xi_2 = \dfrac{1-z+x}{2}, ~~~\xi_3 = \dfrac{1-z+y}{2}, ~~~\xi_4 = z,\end{split}
\end{equation*}
the shape functions read:
\begin{equation*}
\begin{split}\begin{array}{l}
\widehat{\varphi}_{0}(x,y,z) = \dfrac{\xi_0 \xi_1}{(1-\xi_4)^2}((1-\xi_4-2\xi_0)(1-\xi_4-2\xi_1) -\xi_4(1-\xi_4)), \\
\widehat{\varphi}_{1}(x,y,z) = 4\dfrac{\xi_0\xi_1\xi_2}{(1-\xi_4)^2}(2\xi_1-(1-\xi_4)), \\
\widehat{\varphi}_{2}(x,y,\xi_4) = \dfrac{\xi_1 \xi_2}{(1-\xi_4)^2}((1-\xi_4-2\xi_1)(1-\xi_4-2\xi_2) -\xi_4(1-\xi_4)), \\
\widehat{\varphi}_{3}(x,y,z) = 4\dfrac{\xi_3\xi_0\xi_1}{(1-\xi_4)^2}(2\xi_0-(1-\xi_4)), \\
\widehat{\varphi}_{4}(x,y,z) = 16\dfrac{\xi_0\xi_1\xi_2\xi_3}{(1-\xi_4)^2}, \\
\widehat{\varphi}_{5}(x,y,z) = 4\dfrac{\xi_1\xi_2\xi_3}{(1-\xi_4)^2}(2\xi_2-(1-\xi_4)), \\
\widehat{\varphi}_{6}(x,y,z) = \dfrac{\xi_3 \xi_0}{(1-\xi_4)^2}((1-\xi_4-2\xi_3)(1-\xi_4-2\xi_0) -\xi_4(1-\xi_4)), \\
\widehat{\varphi}_{7}(x,y,z) = 4\dfrac{\xi_2\xi_3\xi_0}{(1-\xi_4)^2}(2\xi_3-(1-\xi_4)), \\
\widehat{\varphi}_{8}(x,y,z) = \dfrac{\xi_2 \xi_3}{(1-\xi_4)^2}((1-\xi_4-2\xi_2)(1-\xi_4-2\xi_3) -\xi_4(1-\xi_4)), \\
\widehat{\varphi}_{9}(x,y,z) = 4\dfrac{\xi_4}{1-\xi_4}\xi_0\xi_1, \\
\widehat{\varphi}_{10}(x,y,z) = 4\dfrac{\xi_4}{1-\xi_4}\xi_1\xi_2,  \\
\widehat{\varphi}_{11}(x,y,z) = 4\dfrac{\xi_4}{1-\xi_4}\xi_3\xi_0,  \\
\widehat{\varphi}_{12}(x,y,z) = 4\dfrac{\xi_4}{1-\xi_4}\xi_2\xi_3,  \\
\widehat{\varphi}_{13}(x,y,z) = \xi_4(2\xi_4-1). \\
\end{array}\end{split}
\end{equation*}

\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Continuous Lagrange element of order 0, 1 or 2 \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PYRAMID\_LAGRANGE(K)"}}}\label{\detokenize{userdoc/appendixA:id67}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(0\)
&
\(3\)
&
\(1\)
&
discontinuous
&
No \((Q = 1)\)
&
Yes
&
No
\\
\hline
\(1\)
&
\(3\)
&
\(5\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
No
\\
\hline
\(2\)
&
\(3\)
&
\(14\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
No
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Discontinuous Lagrange element of order 0, 1 or 2 \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PYRAMID\_DISCONTINUOUS\_LAGRANGE(K)"}}}\label{\detokenize{userdoc/appendixA:id68}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(0\)
&
\(3\)
&
\(1\)
&
discontinuous
&
No \((Q = 1)\)
&
Yes
&
No
\\
\hline
\(1\)
&
\(3\)
&
\(5\)
&
discontinuous
&
No \((Q = 1)\)
&
Yes
&
No
\\
\hline
\(2\)
&
\(3\)
&
\(14\)
&
discontinuous
&
No \((Q = 1)\)
&
Yes
&
No
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\subsection{Elements with additional bubble functions}
\label{\detokenize{userdoc/appendixA:id6}}\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange element on a tetrahedron with additional internal bubble function}\label{\detokenize{userdoc/appendixA:id69}}\label{\detokenize{userdoc/appendixA:ud-fig-tetrahedron-p1-bubble}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{30}{90}|\X{30}{90}|\X{30}{90}|}
\hline

\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttetrahedronP1bubble}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttetrahedronP2bubble}.png}\hspace*{\fill}}
&
\noindent{\hspace*{\fill}\sphinxincludegraphics[scale=0.5]{{getfemlisttetrahedronP3bubble}.png}\hspace*{\fill}}
\\
\hline
\(P_1\) with additional bubble function, 5 d.o.f., \(C^0\)
&
\(P_2\) with additional bubble function, 11 d.o.f., \(C^0\)
&
\(P_3\) with additional bubble function, 21 d.o.f., \(C^0\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{\protect\(P_K\protect\) Lagrange element with an additional internal bubble function \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_PK\_WITH\_CUBIC\_BUBBLE(3, K)"}}}\label{\detokenize{userdoc/appendixA:id70}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(4\)
&
\(3\)
&
\(5\), \(11\) or \(21\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

\(.\\\)

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttetrahedronP1bubbleface}.png}
\caption{\(P_1\) Lagrange element on a tetrahedron with additional bubble function on face 0, 5 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id71}}\label{\detokenize{userdoc/appendixA:ud-fig-tetrahedron-p1-bubble-face}}\end{figure}

\(.\\\)
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Lagrange \protect\(P_1\protect\) element with an additional bubble function on face 0 \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_P1\_BUBBLE\_FACE(3)"}}}\label{\detokenize{userdoc/appendixA:id72}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(3\)
&
\(5\)
&
\(C^0\)
&
No \((Q = 1)\)
&
Yes
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\subsection{Hermite element}
\label{\detokenize{userdoc/appendixA:id7}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{getfemlisttetrahedronhermite}.png}
\caption{Hermite element on a tetrahedron, \(P_3\), 20 d.o.f., \(C^0\)}\label{\detokenize{userdoc/appendixA:id73}}\label{\detokenize{userdoc/appendixA:ud-fig-tetrahedron-hermite}}\end{figure}

Base functions on the reference element:
\begin{equation*}
\begin{split}\begin{array}{ll}
\widehat{\varphi}_{0}(x,y) = 1 - 3x^2 - 13xy - 13xz - 3y^2 - 13yz - 3z^2 + 2x^3 + 13x^2y + 13x^2z & \\
~~~~~~~~~~~~~~~ + 13xy^2 + 33xyz + 13xz^2 + 2y^3 + 13y^2z + 13yz^2 + 2z^3, & (\widehat{\varphi}_0(0,0,0) = 1),\\
\widehat{\varphi}_{1}(x,y) = x - 2x^2 - 3xy - 3xz + x^3 + 3x^2y + 3x^2z + 2xy^2 + 4xyz + 2xz^2, & (\partial_x\widehat{\varphi}_1(0,0,0) = 1),\\
\widehat{\varphi}_{2}(x,y) = y - 3xy - 2y^2 - 3yz + 2x^2y + 3xy^2 + 4xyz + y^3 + 3y^2z + 2yz^2, & (\partial_y\widehat{\varphi}_2(0,0,0) = 1),\\
\widehat{\varphi}_{3}(x,y) = z - 3xz - 3yz - 2z^2 + 2x^2z + 4xyz + 3xz^2 + 2y^2z + 3yz^2 + z^3, & (\partial_z\widehat{\varphi}_3(0,0,0) = 1),\\
\widehat{\varphi}_{4}(x,y) = 3x^2 - 7xy - 7xz - 2x^3 + 7x^2y + 7x^2z + 7xy^2 + 7xyz + 7xz^2, & (\widehat{\varphi}_4(1,0,0) = 1),\\
\widehat{\varphi}_{5}(x,y) = -x^2 + 2xy + 2xz + x^3 - 2x^2y - 2x^2z - 2xy^2 - 2xyz - 2xz^2, & (\partial_x\widehat{\varphi}_5(1,0,0) = 1),\\
\widehat{\varphi}_{6}(x,y) = -xy + 2x^2y + xy^2, & (\partial_y\widehat{\varphi}_6(1,0,0) = 1),\\
\widehat{\varphi}_{7}(x,y) = -xz + 2x^2z + xz^2, & (\partial_z\widehat{\varphi}_7(1,0,0) = 1),\\
\widehat{\varphi}_{8}(x,y) = -7xy + 3y^2 - 7yz + 7x^2y + 7xy^2 + 7xyz - 2y^3 + 7y^2z + 7yz^2, & (\widehat{\varphi}_8(0,1,0) = 1),\\
\widehat{\varphi}_{9}(x,y) = -xy + x^2y + 2xy^2, & (\partial_x\widehat{\varphi}_9(0,1,0) = 1),\\
\widehat{\varphi}_{10}(x,y) = 2xy - y^2 + 2yz - 2x^2y - 2xy^2 - 2xyz + y^3 - 2y^2z - 2yz^2, & (\partial_y\widehat{\varphi}_{10}(0,1,0) = 1),\\
\widehat{\varphi}_{11}(x,y) = -yz + 2y^2z + yz^2, & (\partial_z\widehat{\varphi}_{11}(0,1,0) = 1),\\
\widehat{\varphi}_{12}(x,y) = -7xz - 7yz + 3z^2 + 7x^2z + 7xyz + 7xz^2 + 7y^2z + 7yz^2 - 2z^3, & (\widehat{\varphi}_{12}(0,0,1) = 1),\\
\widehat{\varphi}_{13}(x,y) = -xz + x^2z + 2xz^2, & (\partial_x\widehat{\varphi}_{13}(0,0,1) = 1),\\
\widehat{\varphi}_{14}(x,y) = -yz + y^2z + 2yz^2, & (\partial_y\widehat{\varphi}_{14}(0,0,1) = 1),\\
\widehat{\varphi}_{15}(x,y) = 2xz + 2yz - z^2 - 2x^2z - 2xyz - 2xz^2 - 2y^2z - 2yz^2 + z^3, & (\partial_z\widehat{\varphi}_{15}(0,0,1) = 1),\\
\widehat{\varphi}_{16}(x,y) = 27xyz, & (\widehat{\varphi}_{16}(1/3,1/3,1/3) = 1),\\
\widehat{\varphi}_{17}(x,y) = 27yz - 27xyz - 27y^2z - 27yz^2, & (\widehat{\varphi}_{17}(0,1/3,1/3) = 1),\\
\widehat{\varphi}_{18}(x,y) = 27xz - 27x^2z - 27xyz - 27xz^2, & (\widehat{\varphi}_{18}(1/3,0,1/3) = 1),\\
\widehat{\varphi}_{19}(x,y) = 27xy - 27x^2y - 27xy^2 - 27xyz, & (\widehat{\varphi}_{19}(1/3,1/3,0) = 1),\\
\end{array}\end{split}
\end{equation*}
This element is not \(\tau\)\sphinxhyphen{}equivalent (The matrix \(M\) is not equal to
identity). On the real element linear combinations of \(\widehat{\varphi}_8\),
\(\widehat{\varphi}_{12}\) and \(\widehat{\varphi}_{16}\) are used to match the gradient on
the corresponding vertex. Idem on the other vertices.
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Hermite element on a tetrahedron \sphinxstyleliteralintitle{\sphinxupquote{"FEM\_HERMITE(3)"}}}\label{\detokenize{userdoc/appendixA:id74}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|\X{10}{70}|}
\hline
\sphinxstyletheadfamily 
degree
&\sphinxstyletheadfamily 
dimension
&\sphinxstyletheadfamily 
d.o.f. number
&\sphinxstyletheadfamily 
class
&\sphinxstyletheadfamily 
vector
&\sphinxstyletheadfamily 
\(\tau\)\sphinxhyphen{}equivalent
&\sphinxstyletheadfamily 
Polynomial
\\
\hline
\(3\)
&
\(3\)
&
\(20\)
&
\(C^0\)
&
No \((Q = 1)\)
&
No
&
Yes
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\chapter{Appendix B. Cubature method list}
\label{\detokenize{userdoc/appendixB:appendix-b-cubature-method-list}}\label{\detokenize{userdoc/appendixB:ud-appendixb}}\label{\detokenize{userdoc/appendixB::doc}}
For more information on cubature formulas, the reader is referred to \sphinxcite{biblio:encyclopcubature} for instance. The integration methods are of two kinds. Exact integrations of polynomials and
approximated integrations (cubature formulas) of any function. The exact
integration can only be used if all the elements are polynomial and if the
geometric transformation is linear.

A descriptor on an integration method is given by the function:

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{ppi} \PYG{o}{=} \PYG{n}{getfem}\PYG{o}{:}\PYG{o}{:}\PYG{n}{int\PYGZus{}method\PYGZus{}descriptor}\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{name of method}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{"name of method"}} is a string to be chosen among the existing methods.

The program \sphinxcode{\sphinxupquote{integration}} located in the \sphinxcode{\sphinxupquote{tests}} directory lists and checks
the degree of each integration method.


\section{Exact Integration methods}
\label{\detokenize{userdoc/appendixB:exact-integration-methods}}
\sphinxstyleemphasis{GetFEM} furnishes a set of exact integration methods. This means that polynomials are integrated exactly. However, their use is (very) limited and not recommended. The use of exact integration methods is limited to the low\sphinxhyphen{}level generic assembly for polynomial \(\tau\)\sphinxhyphen{}equivalent elements with linear transformations and for linear terms. It is not possible to use them in the high\sphinxhyphen{}level generic assembly.

The list of available exact integration methods is the following
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Exact Integration Methods}\label{\detokenize{userdoc/appendixB:id6}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{100}|\X{60}{100}|}
\hline

\sphinxcode{\sphinxupquote{"IM\_NONE()"}}
&
Dummy integration method.
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_EXACT\_SIMPLEX(n)"}}
&
Description of the exact integration of polynomials on the simplex of
reference of dimension \sphinxcode{\sphinxupquote{n}}.
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_PRODUCT(a, b)"}}
&
Description of the exact integration on the convex which is the direct
product of the convex in \sphinxcode{\sphinxupquote{a}} and in \sphinxcode{\sphinxupquote{b}}.
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_EXACT\_PARALLELEPIPED(n)"}}
&
Description of the exact integration of polynomials on the parallelepiped
of reference of dimension \sphinxcode{\sphinxupquote{n}}.
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_EXACT\_PRISM(n)"}}
&
Description of the exact integration of polynomials on the prism of
reference of dimension \sphinxcode{\sphinxupquote{n}}
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

Even though a description of exact integration method exists on
parallelepipeds or prisms, most of the time the geometric transformations
on such elements are
nonlinear and the exact integration cannot be used.


\section{Newton cotes Integration methods}
\label{\detokenize{userdoc/appendixB:newton-cotes-integration-methods}}
Newton cotes integration of order \sphinxcode{\sphinxupquote{K}} on simplices, parallelepipeds
and prisms
are denoted by \sphinxcode{\sphinxupquote{"IM\_NC(N,K)"}}, \sphinxcode{\sphinxupquote{"IM\_NC\_PARALLELEPIPED(N,K)"}} and
\sphinxcode{\sphinxupquote{"IM\_NC\_PRISM(N,K)"}} respectively.


\section{Gauss Integration methods on dimension 1}
\label{\detokenize{userdoc/appendixB:gauss-integration-methods-on-dimension-1}}
Gauss\sphinxhyphen{}Legendre integration on the segment of order
\sphinxcode{\sphinxupquote{K}} (with \sphinxcode{\sphinxupquote{K/2+1}} points)
are denoted by \sphinxcode{\sphinxupquote{"IM\_GAUSS1D(K)"}}. Gauss\sphinxhyphen{}Lobatto\sphinxhyphen{}Legendre integration on the
segment of order \sphinxcode{\sphinxupquote{K}} (with \sphinxcode{\sphinxupquote{K/2+1}} points) are denoted by
\sphinxcode{\sphinxupquote{"IM\_GAUSSLOBATTO1D(K)"}}. It is only available for odd values of \sphinxcode{\sphinxupquote{K}}. The
Gauss\sphinxhyphen{}Lobatto integration method can be used in conjunction with
\sphinxcode{\sphinxupquote{"FEM\_PK\_GAUSSLOBATTO1D(K/2)"}} to perform mass\sphinxhyphen{}lumping.


\section{Gauss Integration methods on dimension 2}
\label{\detokenize{userdoc/appendixB:gauss-integration-methods-on-dimension-2}}\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Integration methods on dimension 2}\label{\detokenize{userdoc/appendixB:id7}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{90}|\X{20}{90}|\X{10}{90}|\X{20}{90}|}
\hline
\sphinxstyletheadfamily 
graphic
&\sphinxstyletheadfamily 
coordinates (x,  y)
&\sphinxstyletheadfamily 
weights
&\sphinxstyletheadfamily 
function to call / order
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle1}.png}
&
(1/3, 1/3)
&
1/2
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(1)"}}

1 point, order 1.
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle2}.png}
&
(1/6,  1/6)

(2/3,  1/6)

(1/6,  2/3)
&
1/6

1/6

1/6
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(2)"}}

3 points, order 2.
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Integration methods on dimension 2}\label{\detokenize{userdoc/appendixB:id8}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{90}|\X{20}{90}|\X{10}{90}|\X{20}{90}|}
\hline
\sphinxstyletheadfamily 
graphic
&\sphinxstyletheadfamily 
coordinates (x,  y)
&\sphinxstyletheadfamily 
weights
&\sphinxstyletheadfamily 
function to call / order
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle3}.png}
&
(1/3, 1/3)

(1/5, 1/5)

(3/5, 1/5)

(1/5, 3/5)
&
\sphinxhyphen{}27/96

25/96

25/96

25/96
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(3)"}}

4 points, order 3.
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle4}.png}
&
(a, a)

(1\sphinxhyphen{}2a, a)

(a, 1\sphinxhyphen{}2a)

(b, b)

(1\sphinxhyphen{}2b, b)

(b, 1\sphinxhyphen{}2b)
&
c

c

c

d

d

d
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(4)"}}

6 points, order 4

\(a = 0.445948490915965\)
\(b=0.091576213509771\)
\(c=0.111690794839005\)
\(d=0.054975871827661\)
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle5}.png}
&
(1/3, 1/3)

(a, a)

(1\sphinxhyphen{}2a, a)

(a, 1\sphinxhyphen{}2a)

(b, b)

(1\sphinxhyphen{}2b, b)

(b, 1\sphinxhyphen{}2b)
&
9/80

c

c

c

d

d

d
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(5)"}}

7 points, order 5

\(a = \dfrac{6+\sqrt{15}}{21}\)
\(b = 4/7 - a\)
\(c = \dfrac{155+\sqrt{15}}{2400}\)
\(d = 31/240 - c\)
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle6}.png}
&
(a, a)

(1\sphinxhyphen{}2a, a)

(a, 1\sphinxhyphen{}2a)

(b, b)

(1\sphinxhyphen{}2b, b)

(b, 1\sphinxhyphen{}2b)

(c, d)

(d, c)

(1\sphinxhyphen{}c\sphinxhyphen{}d, c)

(1\sphinxhyphen{}c\sphinxhyphen{}d, d)

(c, 1\sphinxhyphen{}c\sphinxhyphen{}d)

(d, 1\sphinxhyphen{}c\sphinxhyphen{}d)
&
e

e

e

f

f

f

g

g

g

g

g

g
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(6)"}}

12 points, order 6

\(a = 0.063089104491502\)
\(b = 0.249286745170910\)
\(c = 0.310352451033785\)
\(d = 0.053145049844816\)
\(e = 0.025422453185103\)
\(f = 0.058393137863189\)
\(g = 0.041425537809187\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Integration methods on dimension 2}\label{\detokenize{userdoc/appendixB:id9}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{90}|\X{20}{90}|\X{10}{90}|\X{20}{90}|}
\hline
\sphinxstyletheadfamily 
graphic
&\sphinxstyletheadfamily 
coordinates (x,  y)
&\sphinxstyletheadfamily 
weights
&\sphinxstyletheadfamily 
function to call / order
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtriangle7}.png}
&
(a, a)

(b, a)

(a, b)

(c, e)

(d, c)

(e, d)

(d, e)

(c, d)

(e, c)

(f, f)

(g, f)

(f, g)

(1/3, 1/3)
&
h

h

h

i

i

i

i

i

i

j

j

j

k
&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(7)"}}

13 points, order 7

\(a = 0.0651301029022\)
\(b = 0.8697397941956\)
\(c = 0.3128654960049\)
\(d = 0.6384441885698\)
\(e = 0.0486903154253\)
\(f = 0.2603459660790\)
\(g = 0.4793080678419\)
\(h = 0.0266736178044\)
\(i = 0.0385568804451\)
\(j = 0.0878076287166\)
\(k = -0.0747850222338\)
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(8)"}}

(see \sphinxcite{biblio:encyclopcubature})
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(9)"}}

(see \sphinxcite{biblio:encyclopcubature})
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(10)"}}

(see \sphinxcite{biblio:encyclopcubature})
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_TRIANGLE(13)"}}

(see \sphinxcite{biblio:encyclopcubature})
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodquad2}.png}
&
(\(1/2+\sqrt{1/6}, 1/2\))

(\((1/2-\sqrt{1/24}, 1/2\pm\sqrt{1/8}\))
&
1/3

1/3
&
\sphinxcode{\sphinxupquote{"IM\_QUAD(2)"}}

3 points, order 2
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Integration methods on dimension 2}\label{\detokenize{userdoc/appendixB:id10}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{90}|\X{20}{90}|\X{10}{90}|\X{20}{90}|}
\hline
\sphinxstyletheadfamily 
graphic
&\sphinxstyletheadfamily 
coordinates (x,  y)
&\sphinxstyletheadfamily 
weights
&\sphinxstyletheadfamily 
function to call / order
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodquad3}.png}
&
(\(1/2\pm\sqrt{1/6}, 1/2\))

(\(1/2, 1/2\pm\sqrt{1/6}\))
&
1/4

1/4
&
\sphinxcode{\sphinxupquote{"IM\_QUAD(3)"}}

4 points, order 3
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodquad5}.png}
&
(\(1/2, 1/2\))

(\(1/2 \pm \sqrt{7/30}, 1/2\))

(\(1/2\pm\sqrt{1/12}, 1/2\pm\sqrt{3/20}\))
&
2/7

5/63

5/36
&
\sphinxcode{\sphinxupquote{"IM\_QUAD(5)"}}

7 points, order 5
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_QUAD(7)"}}

12 points, order 7
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_QUAD(9)"}}

20 points, order 9
\\
\hline&&&
\sphinxcode{\sphinxupquote{"IM\_QUAD(17)"}}

70 points, order 17
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

There is also the \sphinxcode{\sphinxupquote{"IM\_GAUSS\_PARALLELEPIPED(n,k)"}} which is a direct product of
1D gauss integrations.

\sphinxstylestrong{Important note:} do not forget that \sphinxcode{\sphinxupquote{IM\_QUAD(k)}} is exact for
polynomials up to degree \(k\), and that a \(Q_k\) polynomial has a degree
of \(2*k\). For example, \sphinxcode{\sphinxupquote{IM\_QUAD(7)}} cannot integrate exactly the product
of two \(Q_{2}\) polynomials. On the other hand,
\sphinxcode{\sphinxupquote{IM\_GAUSS\_PARALLELEPIPED(2,4)}} can integrate exactly that product …


\section{Gauss Integration methods on dimension 3}
\label{\detokenize{userdoc/appendixB:gauss-integration-methods-on-dimension-3}}\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Integration methods on dimension 3}\label{\detokenize{userdoc/appendixB:id11}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{90}|\X{20}{90}|\X{10}{90}|\X{20}{90}|}
\hline
\sphinxstyletheadfamily 
graphic
&\sphinxstyletheadfamily 
coordinates (x,  y)
&\sphinxstyletheadfamily 
weights
&\sphinxstyletheadfamily 
function to call / order
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtetrahedron1}.png}
&
(1/4, 1/4, 1/4)
&
1/6
&
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(1)"}}

1 point, order 1
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtetrahedron2}.png}
&
\((a, a, a)\)

\((a, b, a)\)

\((a, a, b)\)

\((b, a, a)\)
&
1/24

1/24

1/24

1/24
&
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(2)"}}

4 points, order 2

\(a = \dfrac{5 - \sqrt{5}}{20}\)

\(b = \dfrac{5 + 3\sqrt{5}}{20}\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}


\begin{savenotes}\sphinxattablestart
\centering
\sphinxcapstartof{table}
\sphinxthecaptionisattop
\sphinxcaption{Integration methods on dimension 3}\label{\detokenize{userdoc/appendixB:id12}}
\sphinxaftertopcaption
\begin{tabular}[t]{|\X{40}{90}|\X{20}{90}|\X{10}{90}|\X{20}{90}|}
\hline
\sphinxstyletheadfamily 
graphic
&\sphinxstyletheadfamily 
coordinates (x,  y)
&\sphinxstyletheadfamily 
weights
&\sphinxstyletheadfamily 
function to call / order
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtetrahedron3}.png}
&
(1/4, 1/4, 1/4)

(1/6, 1/6, 1/6)

(1/6, 1/2, 1/6)

(1/6, 1/6, 1/2)

(1/2, 1/6, 1/6)
&
\sphinxhyphen{}2/15

3/40

3/40

3/40

3/40
&
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(3)"}}

5 points, order 3
\\
\hline
\noindent\sphinxincludegraphics[scale=0.5]{{getfemlistintmethodtetrahedron5}.png}
&
\((1/4, 1/4, 1/4)\)

\((a, a, a)\)

\((a, a, c)\)

\((a, c, a)\)

\((c, a, a)\)

\((b, b, b)\)

\((b, b, d)\)

\((b, d, b)\)

\((d, b, b)\)

\((e, e, f)\)

\((e, f, e)\)

\((f, e, e)\)

\((e, f, f)\)

\((f, e, f)\)

\((f, f, e)\)
&
8/405

\(h\)

\(h\)

\(h\)

\(h\)

\(i\)

\(i\)

\(i\)

\(i\)

5/567

5/567

5/567

5/567

5/567

5/567
&
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(5)"}}

15 points, order 5

\(a = \dfrac{7 + \sqrt{15}}{34}\)

\(b = \dfrac{7 - \sqrt{15}}{34}\)

\(c = \dfrac{13 + 3\sqrt{15}}{34}\)

\(d = \dfrac{13 - 3\sqrt{15}}{34}\)

\(e = \dfrac{5 - \sqrt{15}}{20}\)

\(f = \dfrac{5 + \sqrt{15}}{20}\)

\(h = \dfrac{2665 - 14\sqrt{15}}{226800}\)

\(i = \dfrac{2665 + 14\sqrt{15}}{226800}\)
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}

Others methods are:
\begin{quote}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabular}[t]{|\X{30}{90}|\X{30}{90}|\X{30}{90}|}
\hline
\sphinxstyletheadfamily 
name
&\sphinxstyletheadfamily 
element type
&\sphinxstyletheadfamily 
number of points
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(6)"}}
&
tetrahedron
&
24
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_TETRAHEDRON(8)"}}
&
tetrahedron
&
43
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_SIMPLEX4D(3)"}}
&
4D simplex
&
6
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_HEXAHEDRON(5)"}}
&
3D hexahedron
&
14
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_HEXAHEDRON(9)"}}
&
3D hexahedron
&
58
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_HEXAHEDRON(11)"}}
&
3D hexahedron
&
90
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_CUBE4D(5)"}}
&
4D parallelepiped
&
24
\\
\hline
\sphinxcode{\sphinxupquote{"IM\_CUBE4D(9)"}}
&
4D parallelepiped
&
145
\\
\hline
\end{tabular}
\par
\sphinxattableend\end{savenotes}
\end{quote}


\section{Direct product of integration methods}
\label{\detokenize{userdoc/appendixB:direct-product-of-integration-methods}}
You can use \sphinxcode{\sphinxupquote{"IM\_PRODUCT(IM1, IM2)"}} to produce integration methods on
quadrilateral or prisms. It gives the direct product of two integration methods.
For instance \sphinxcode{\sphinxupquote{"IM\_GAUSS\_PARALLELEPIPED(2,k)"}} is an alias for
\sphinxcode{\sphinxupquote{"IM\_PRODUCT(IM\_GAUSS1D(2,k),IM\_GAUSS1D(2,k))"}} and can be use instead of the
\sphinxcode{\sphinxupquote{"IM\_QUAD"}} integrations.


\section{Specific integration methods}
\label{\detokenize{userdoc/appendixB:specific-integration-methods}}
For pyramidal elements, \sphinxcode{\sphinxupquote{"IM\_PYRAMID(im)"}} provides an integration method corresponding to the transformation of an integration \sphinxcode{\sphinxupquote{im}} from a hexahedron (for instance \sphinxcode{\sphinxupquote{"IM\_GAUSS\_PARALLELEPIPED(3,5)"}}) onto a pyramid. It is a singular integration method specically adapted to rational fraction shape functions of the pyramidal elements.


\section{Composite integration methods}
\label{\detokenize{userdoc/appendixB:composite-integration-methods}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{getfemlistintmethodtriangle2comp}.png}
\caption{Composite method \sphinxcode{\sphinxupquote{"IM\_STRUCTURED\_COMPOSITE(IM\_TRIANGLE(2), 3)"}}}\label{\detokenize{userdoc/appendixB:id13}}\label{\detokenize{userdoc/appendixB:ud-fig-triangle-compcinq}}\end{figure}

Use \sphinxcode{\sphinxupquote{"IM\_STRUCTURED\_COMPOSITE(IM1, S)"}} to copy \sphinxcode{\sphinxupquote{IM1}} on an element with \sphinxcode{\sphinxupquote{S}}
subdivisions. The resulting integration method has the same order but with more
points. It could be more stable to use a composite method rather than to improve
the order of the method. Those methods have to be used also with composite
elements. Most of the time for composite element, it is preferable to choose the
basic method \sphinxcode{\sphinxupquote{IM1}} with no points on the boundary (because the gradient could be
not defined on the boundary of sub\sphinxhyphen{}elements).

For the HCT element, it is advised to use the \sphinxcode{\sphinxupquote{"IM\_HCT\_COMPOSITE(im)"}} composite
integration (which split the original triangle into 3 sub\sphinxhyphen{}triangles).

For pyramidal elements, \sphinxcode{\sphinxupquote{"IM\_PYRAMID\_COMPOSITE(im)"}} provides an integration method ase on the decomposition of the pyramid into two tetrahedrons (\sphinxcode{\sphinxupquote{im}} should be an integration method on a tetrahedron). Note that the integraton method \sphinxcode{\sphinxupquote{"IM\_PYRAMID(im)"}} where \sphinxcode{\sphinxupquote{im}} is an integration method on an hexahedron, should be prefered.


\chapter{References}
\label{\detokenize{biblio:references}}\label{\detokenize{biblio:id1}}\label{\detokenize{biblio::doc}}
\begin{sphinxthebibliography}{Encyclop}
\bibitem[AB\sphinxhyphen{}ER\sphinxhyphen{}PI2018]{biblio:ab-er-pi2018}
M. Abbas, A. Ern, N. Pignet.
\sphinxstyleemphasis{Hybrid High\sphinxhyphen{}Order methods for finite deformations of hyperelastic materials}.
Computational Mechanics, 62(4), 909\sphinxhyphen{}928, 2018.
\bibitem[AB\sphinxhyphen{}ER\sphinxhyphen{}PI2019]{biblio:ab-er-pi2019}
M. Abbas, A. Ern, N. Pignet.
\sphinxstyleemphasis{A Hybrid High\sphinxhyphen{}Order method for incremental associative plasticity with small deformations}.
Computer Methods in Applied Mechanics and Engineering, 346, 891\sphinxhyphen{}912, 2019.
\bibitem[AL\sphinxhyphen{}CU1991]{biblio:al-cu1991}
P. Alart, A. Curnier.
\sphinxstyleemphasis{A mixed formulation for frictional contact problems prone to newton like solution methods}. Comput. Methods Appl. Mech. Engrg. 92, 353\textendash{}375, 1991.
\bibitem[Al\sphinxhyphen{}Ge1997]{biblio:al-ge1997}
E.L. Allgower and K. Georg.
\sphinxstyleemphasis{Numerical Path Following}, Handbook of Numerical Analysis, Vol. V (P.G. Ciarlet and J.L. Lions, eds.). Elsevier, pp. 3\sphinxhyphen{}207, 1997.
\bibitem[AM\sphinxhyphen{}MO\sphinxhyphen{}RE2014]{biblio:am-mo-re2014}
S. Amdouni, M. Moakher, Y. Renard,
\sphinxstyleemphasis{A local projection stabilization of fictitious domain method for elliptic boundary value problems}. Appl. Numer. Math., 76:60\sphinxhyphen{}75, 2014.
\bibitem[AM\sphinxhyphen{}MO\sphinxhyphen{}RE2014b]{biblio:am-mo-re2014b}
S. Amdouni, M. Moakher, Y. Renard.
\sphinxstyleemphasis{A stabilized Lagrange multiplier method for the enriched finite element approximation of Tresca contact problems of cracked elastic bodies}. Comput. Methods Appl. Mech. Engrg., 270:178\sphinxhyphen{}200, 2014.
\bibitem[bank1983]{biblio:bank1983}
R.E. Bank, A.H. Sherman, A. Weiser.
\sphinxstyleemphasis{Refinement algorithms and data structures for regular local mesh refinement}. In Scientific Computing IMACS, Amsterdam, North\sphinxhyphen{}Holland, pp 3\sphinxhyphen{}17, 1983.
\bibitem[ba\sphinxhyphen{}dv1985]{biblio:ba-dv1985}
K.J. Bathe, E.N. Dvorkin,
\sphinxstyleemphasis{A four\sphinxhyphen{}node plate bending element based on Mindlin\sphinxhyphen{}Reissner plate theory and a mixed interpolation}. Internat. J. Numer. Methods Engrg., 21, 367\sphinxhyphen{}383, 1985.
\bibitem[Be\sphinxhyphen{}Mi\sphinxhyphen{}Mo\sphinxhyphen{}Bu2005]{biblio:be-mi-mo-bu2005}
Bechet E, Minnebo H, Moës N, Burgardt B.
\sphinxstyleemphasis{Improved implementation and robustness study of the X\sphinxhyphen{}FEM for stress analysis around cracks}.
Internat. J. Numer. Methods Engrg., 64, 1033\sphinxhyphen{}1056, 2005.
\bibitem[BE\sphinxhyphen{}CO\sphinxhyphen{}DU2010]{biblio:be-co-du2010}
M. Bergot, G. Cohen, M. Duruflé.
\sphinxstyleemphasis{Higher\sphinxhyphen{}order finite elements for hybrid meshes using new nodal pyramidal elements}
J. Sci. Comput., 42, 345\sphinxhyphen{}381, 2010.
\bibitem[br\sphinxhyphen{}ba\sphinxhyphen{}fo1989]{biblio:br-ba-fo1989}
F. Brezzi, K.J. Bathe, M. Fortin.
\sphinxstyleemphasis{Mixed\sphinxhyphen{}interpolated element for Reissner\sphinxhyphen{}Mindlin plates}. Internat. J. Numer. Methods Engrg., 28, 1787\sphinxhyphen{}1801, 1989.
\bibitem[bu\sphinxhyphen{}ha2010]{biblio:bu-ha2010}
E. Burman, P. Hansbo.
\sphinxstyleemphasis{Fictitious domain finite element methods using cut elements: I. A stabilized Lagrange multiplier method}. Computer Methods in Applied Mechanics, 199:41\sphinxhyphen{}44, 2680\sphinxhyphen{}2686, 2010.
\bibitem[ca\sphinxhyphen{}re\sphinxhyphen{}so1994]{biblio:ca-re-so1994}
D. Calvetti, L. Reichel and D.C. Sorensen.
\sphinxstyleemphasis{An implicitly restarted Lanczos method for large symmetric eigenvalue problems}. Electronic Transaction on Numerical Analysis\}. 2:1\sphinxhyphen{}21, 1994.
\bibitem[ca\sphinxhyphen{}ch\sphinxhyphen{}er2019]{biblio:ca-ch-er2019}
K. Cascavita, F. Chouly and A. Ern
\sphinxstyleemphasis{Hybrid High\sphinxhyphen{}Order discretizations combined with Nitsche’s method for Dirichlet and Signorini boundary conditions}.
hal\sphinxhyphen{}02016378v2, 2019
\bibitem[CH\sphinxhyphen{}LA\sphinxhyphen{}RE2008]{biblio:ch-la-re2008}
E. Chahine, P. Laborde, Y. Renard.
\sphinxstyleemphasis{Crack\sphinxhyphen{}tip enrichment in the Xfem method using a cut\sphinxhyphen{}off function}. Int. J. Numer. Meth. Engng., 75(6):629\sphinxhyphen{}646, 2008.
\bibitem[CH\sphinxhyphen{}LA\sphinxhyphen{}RE2011]{biblio:ch-la-re2011}
E. Chahine, P. Laborde, Y. Renard.
\sphinxstyleemphasis{A non\sphinxhyphen{}conformal eXtended Finite Element approach: Integral matching Xfem}. Applied Numerical Mathematics, 61:322\sphinxhyphen{}343, 2011.
\bibitem[ciarlet1978]{biblio:ciarlet1978}
P.G. Ciarlet.
\sphinxstyleemphasis{The finite element method for elliptic problems}. Studies in Mathematics and its Applications vol. 4, North\sphinxhyphen{}Holland, 1978.
\bibitem[ciarlet1988]{biblio:ciarlet1988}
P.G. Ciarlet.
\sphinxstyleemphasis{Mathematical Elasticity}. Volume 1: Three\sphinxhyphen{}Dimensional Elasticity. North\sphinxhyphen{}Holland, 1988.
\bibitem[EncyclopCubature]{biblio:encyclopcubature}
R. Cools, \sphinxhref{http://www.cs.kuleuven.ac.be/~ines/research/ecf/ecf.html}{An Encyclopedia of Cubature Formulas}, J. Complexity.
\bibitem[Dh\sphinxhyphen{}Go\sphinxhyphen{}Ku2003]{biblio:dh-go-ku2003}
A. Dhooge, W. Govaerts and Y. A. Kuznetsov.
\sphinxstyleemphasis{MATCONT: A MATLAB Package for Numerical Bifurcation Analysis of ODEs}.
ACM Trans. Math. Software 31, 141\sphinxhyphen{}164, 2003.
\bibitem[Di\sphinxhyphen{}Er2015]{biblio:di-er2015}
D.A. Di Pietro, A. Ern.
\sphinxstyleemphasis{A hybrid high\sphinxhyphen{}order locking free method for linear elasticity on general meshes}.
Comput. Methods Appl. Mech. Engrg., 283:1\sphinxhyphen{}21, 2015
\bibitem[Di\sphinxhyphen{}Er2017]{biblio:di-er2017}
D.A. Di Pietro, A. Ern.
\sphinxstyleemphasis{Arbitrary\sphinxhyphen{}order mixed methods for heterogeneous anisotropic diffusion on general meshes}.
IMA Journal of Numerical Analysis, 37(1), 40\sphinxhyphen{}63. 2017
\bibitem[Duan2014]{biblio:duan2014}
H. Duan.
\sphinxstyleemphasis{A finite element method for Reissner\sphinxhyphen{}Mindlin plates}.
Math. Comp., 83:286, 701\sphinxhyphen{}733, 2014.
\bibitem[Dr\sphinxhyphen{}La\sphinxhyphen{}Ek2014]{biblio:dr-la-ek2014}
A. Draganis, F. Larsson, A. Ekberg.
\sphinxstyleemphasis{Finite element analysis of transient thermomechanical rolling contact using
an efficient arbitrary Lagrangian\sphinxhyphen{}Eulerian description}.
Comput. Mech., 54, 389\sphinxhyphen{}405, 2014.
\bibitem[Fa\sphinxhyphen{}Po\sphinxhyphen{}Re2015]{biblio:fa-po-re2015}
M. Fabre, J. Pousin, Y. Renard.
\sphinxstyleemphasis{A fictitious domain method for frictionless contact problems in elasticity using Nitsche’s method}. preprint, \sphinxurl{https://hal.archives-ouvertes.fr/hal-00960996v1}
\bibitem[Fa\sphinxhyphen{}Pa2003]{biblio:fa-pa2003}
F. Facchinei and J.\sphinxhyphen{}S. Pang.
\sphinxstyleemphasis{Finite\sphinxhyphen{}Dimensional Variational Inequalities and Complementarity Problems, Vol. II}.
Springer Series in Operations Research, Springer, New York, 2003.
\bibitem[Georg2001]{biblio:georg2001}
K. Georg.
\sphinxstyleemphasis{Matrix\sphinxhyphen{}free numerical continuation and bifurcation}. Numer. Funct. Anal. Optimization 22, 303\sphinxhyphen{}320, 2001.
\bibitem[GR\sphinxhyphen{}GH1999]{biblio:gr-gh1999}
R.D. Graglia, I.\sphinxhyphen{}L. Gheorma.
\sphinxstyleemphasis{Higher order interpolatory vector bases on pyramidal elements}
IEEE transactions on antennas and propagation, 47:5, 775\sphinxhyphen{}782, 1999.
\bibitem[GR\sphinxhyphen{}ST2015]{biblio:gr-st2015}
D. Grandi, U. Stefanelli.
\sphinxstyleemphasis{The Souza\sphinxhyphen{}Auricchio model for shape\sphinxhyphen{}memory alloys}
Discrete and Continuous Dynamical Systems, Series S, 8(4):723\sphinxhyphen{}747, 2015.
\bibitem[HA\sphinxhyphen{}WO2009]{biblio:ha-wo2009}
C. Hager, B.I. Wohlmuth.
\sphinxstyleemphasis{Nonlinear complementarity functions for plasticity problems with frictional contact}. Comput. Methods Appl. Mech. Engrg., 198:3411\sphinxhyphen{}3427, 2009
\bibitem[HA\sphinxhyphen{}HA2004]{biblio:ha-ha2004}
A Hansbo, P Hansbo.
\sphinxstyleemphasis{A finite element method for the simulation of strong and weak discontinuities in solid mechanics}. Comput. Methods Appl. Mech. Engrg. 193 (33\sphinxhyphen{}35), 3523\sphinxhyphen{}3540, 2004.
\bibitem[HA\sphinxhyphen{}RE2009]{biblio:ha-re2009}
J. Haslinger, Y. Renard.
\sphinxstyleemphasis{A new fictitious domain approach inspired by the extended finite element method}. Siam J. on Numer. Anal., 47(2):1474\sphinxhyphen{}1499, 2009.
\bibitem[HI\sphinxhyphen{}RE2010]{biblio:hi-re2010}
Hild P., Renard Y.
\sphinxstyleemphasis{Stabilized lagrange multiplier method for the finite element approximation of contact problems in elastostatics}. Numer. Math. 15:1, 101\textendash{}129, 2010.
\bibitem[KH\sphinxhyphen{}PO\sphinxhyphen{}RE2006]{biblio:kh-po-re2006}
Khenous H., Pommier J., Renard Y.
\sphinxstyleemphasis{Hybrid discretization of the Signorini problem with Coulomb friction, theoretical aspects and comparison of some numerical solvers}. Applied Numerical Mathematics, 56/2:163\sphinxhyphen{}192, 2006.
\bibitem[KI\sphinxhyphen{}OD1988]{biblio:ki-od1988}
N. Kikuchi, J.T. Oden.
\sphinxstyleemphasis{Contact problems in elasticity}. SIAM, 1988.
\bibitem[LA\sphinxhyphen{}PO\sphinxhyphen{}RE\sphinxhyphen{}SA2005]{biblio:la-po-re-sa2005}
Laborde P., Pommier J., Renard Y., Salaun M.
\sphinxstyleemphasis{High order extended finite element method for cracked domains}. Int. J. Numer. Meth. Engng., 64:354\sphinxhyphen{}381, 2005.
\bibitem[LA\sphinxhyphen{}RE\sphinxhyphen{}SA2010]{biblio:la-re-sa2010}
J. Lasry, Y. Renard, M. Salaun.
\sphinxstyleemphasis{eXtended Finite Element Method for thin cracked plates with Kirchhoff\sphinxhyphen{}Love theory}. Int. J. Numer. Meth. Engng., 84(9):1115\sphinxhyphen{}1138, 2010.
\bibitem[KO\sphinxhyphen{}RE2014]{biblio:ko-re2014}
K. Poulios, Y. Renard,
\sphinxstyleemphasis{An unconstrained integral approximation of large sliding frictional contact between deformable solids}. Computers and Structures, 153:75\sphinxhyphen{}90, 2015.
\bibitem[LA\sphinxhyphen{}RE2006]{biblio:la-re2006}
P. Laborde, Y. Renard.
\sphinxstyleemphasis{Fixed point strategies for elastostatic frictional contact problems}. Math. Meth. Appl. Sci., 31:415\sphinxhyphen{}441, 2008.
\bibitem[Li\sphinxhyphen{}Re2014]{biblio:li-re2014}
T. Ligurský and Y. Renard.
\sphinxstyleemphasis{A Continuation Problem for Computing Solutions of Discretised Evolution Problems with Application to Plane Quasi\sphinxhyphen{}Static Contact Problems with Friction}. Comput. Methods Appl. Mech. Engrg. 280, 222\sphinxhyphen{}262, 2014.
\bibitem[Li\sphinxhyphen{}Re2014hal]{biblio:li-re2014hal}
T. Ligurský and Y. Renard.
\sphinxstyleemphasis{Bifurcations in Piecewise\sphinxhyphen{}Smooth Steady\sphinxhyphen{}State Problems: Abstract Study and Application to Plane Contact Problems with Friction}. Computational Mechanics, 56:1:39\sphinxhyphen{}62, 2015.
\bibitem[Li\sphinxhyphen{}Re2015hal]{biblio:li-re2015hal}
T. Ligurský and Y. Renard.
\sphinxstyleemphasis{A Method of Piecewise\sphinxhyphen{}Smooth Numerical Branching}. Z. Angew. Math. Mech., 97:7:815\textendash{}827, 2017.
\bibitem[Mi\sphinxhyphen{}Zh2002]{biblio:mi-zh2002}
P. Ming and Z. Shi,
\sphinxstyleemphasis{Optimal L2 error bounds for MITC3 type element}. Numer. Math. 91, 77\sphinxhyphen{}91, 2002.
\bibitem[Xfem]{biblio:xfem}
N. Moës, J. Dolbow and T. Belytschko,
\sphinxstyleemphasis{A finite element method for crack growth without remeshing}.
Internat. J. Numer. Methods Engrg., 46, 131\sphinxhyphen{}150, 1999.
\bibitem[Nackenhorst2004]{biblio:nackenhorst2004}
U. Nackenhorst,
\sphinxstyleemphasis{The ALE formulation of bodies in rolling contact. Theoretical foundation
and finite element approach}.
Comput. Methods Appl. Mech. Engrg., 193:4299\sphinxhyphen{}4322, 2004.
\bibitem[NI\sphinxhyphen{}RE\sphinxhyphen{}CH2011]{biblio:ni-re-ch2011}
S. Nicaise, Y. Renard, E. Chahine,
\sphinxstyleemphasis{Optimal convergence analysis for the eXtended Finite Element Method}. Int. J. Numer. Meth. Engng., 86:528\sphinxhyphen{}548, 2011.
\bibitem[Pantz2008]{biblio:pantz2008}
O. Pantz
\sphinxstyleemphasis{The Modeling of Deformable Bodies with Frictionless (Self\sphinxhyphen{})Contacts}. Archive for Rational Mechanics and Analysis, Volume 188, Issue 2, pp 183\sphinxhyphen{}212, 2008.
\bibitem[SCHADD]{biblio:schadd}
L.F. Pavarino.
\sphinxstyleemphasis{Domain decomposition algorithms for the p\sphinxhyphen{}version finite element method for elliptic problems}. Luca F. Pavarino. PhD thesis, Courant Institute of Mathematical Sciences\}. 1992.
\bibitem[PO\sphinxhyphen{}NI2016]{biblio:po-ni2016}
K. Poulios, C.F. Niordson,
\sphinxstyleemphasis{Homogenization of long fiber reinforced composites including fiber bending effects}. Journal of the Mechanics and Physics of Solids, 94, pp 433\sphinxhyphen{}452, 2016.
\bibitem[GetFEM2020]{biblio:getfem2020}
Y. Renard, K. Poulios
\sphinxstyleemphasis{GetFEM: Automated FE modeling of multiphysics problems based on a generic weak form language}. Preprint, \sphinxurl{https://hal.archives-ouvertes.fr/hal-02532422/document}
\bibitem[remacle2003]{biblio:remacle2003}
J.\sphinxhyphen{}F. Remacle, M.S. Shephard;
\sphinxstyleemphasis{An algorithm oriented mesh database}. International Journal for Numerical Methods in Engineering, 58:2, pp 349\sphinxhyphen{}374, 2003.
\bibitem[SE\sphinxhyphen{}PO\sphinxhyphen{}WO2015]{biblio:se-po-wo2015}
A. Seitz, A. Popp, W.A. Wall,
\sphinxstyleemphasis{A semi\sphinxhyphen{}smooth Newton method for orthotropic plasticity and frictional contact at finite strains}. Comput. Methods Appl. Mech. Engrg. 285:228\sphinxhyphen{}254, 2015.
\bibitem[SI\sphinxhyphen{}HU1998]{biblio:si-hu1998}
J.C. Simo, T.J.R. Hughes.
\sphinxstyleemphasis{Computational Inelasticity}. Interdisciplinary Applied Mathematics, vol 7, Springer, New York 1998.
\bibitem[SO\sphinxhyphen{}PE\sphinxhyphen{}OW2008]{biblio:so-pe-ow2008}
E.A. de Souza Neto, D Perić, D.R.J. Owen.
\sphinxstyleemphasis{Computational methods for plasticity}. J. Wiley \& Sons, New York, 2008.
\bibitem[renard2013]{biblio:renard2013}
Y. Renard,
\sphinxstyleemphasis{Generalized Newton’s methods for the approximation and resolution of frictional contact problems in elasticity}.  Comput. Methods Appl. Mech. Engrg., 256:38\sphinxhyphen{}55, 2013.
\bibitem[SU\sphinxhyphen{}CH\sphinxhyphen{}MO\sphinxhyphen{}BE2001]{biblio:su-ch-mo-be2001}
Sukumar N., Chopp D.L., Moës N., Belytschko T.
\sphinxstyleemphasis{Modeling holes and inclusions by level sets in the extended finite\sphinxhyphen{}element method}. Comput. Methods Appl. Mech. Engrg., 190:46\sphinxhyphen{}47, 2001.
\bibitem[ZT1989]{biblio:zt1989}
Zienkiewicz and Taylor. \sphinxstyleemphasis{The finite element method}. 5th edition,
volume 3 : Fluids Dynamics.
\end{sphinxthebibliography}



\renewcommand{\indexname}{Index}
\printindex
\end{document}